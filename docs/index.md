---
layout: default
---

## Updated on 2025.12.22
> Usage instructions: [here](./docs/README.md#usage)

## 多模态

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-12-19**|[Adversarial Robustness of Vision in Open Foundation Models](http://arxiv.org/abs/2512.17902)|null|随着深度学习的普及，理解AI系统识别物体的方式变得越来越困难。因此，攻击者可能会通过在图像中添加未曾见过的元素来修改图像，从而混淆AI对实体的识别。本文因此研究了LLaVA-1.5-13B和Meta的Llama 3.2 Vision-8B-2的对抗鲁棒性。这些模型针对视觉输入模态在非目标PGD（投影梯度下降）攻击下进行了测试，并在Visual Question Answering (VQA) v2数据集子集上进行了实证评估。这些对抗攻击的结果随后使用标准VQA准确率指标进行量化。此次评估随后与LLaVA和Llama 3.2 Vision的准确率下降（准确率跌幅）进行了比较。一个主要发现是，Llama 3.2 Vision尽管在此设置下基线准确率较低，但在攻击下表现出比LLaVA更小的性能下降，尤其是在较高扰动水平下。总的来说，这些发现证实视觉模态是降低当代开源VLM（包括Meta的Llama 3.2 Vision）性能的一个可行攻击向量。此外，它们强调对抗鲁棒性不一定与标准基准性能直接相关，并且可能受到底层架构和训练因素的影响。|
|**2025-12-19**|[RadarGen: Automotive Radar Point Cloud Generation from Cameras](http://arxiv.org/abs/2512.17897)|null|我们提出了RadarGen，这是一种扩散模型，用于从多视角相机图像中合成逼真的车载雷达点云。RadarGen通过以鸟瞰图形式表示雷达测量数据，将高效的图像潜在扩散适应到雷达领域，该鸟瞰图形式编码了空间结构以及雷达散射截面（RCS）和多普勒属性。一个轻量级的恢复步骤从生成的地图中重建点云。为了使生成与视觉场景更好地对齐，RadarGen整合了从预训练基础模型中提取的鸟瞰图对齐深度、语义和运动线索，这些线索指导随机生成过程产生物理上合理的雷达模式。以图像为条件使得该方法原则上与现有视觉数据集和仿真框架广泛兼容，为多模态生成仿真提供了可扩展的方向。对大规模驾驶数据的评估表明，RadarGen捕获了特征雷达测量分布，并缩小了与在真实数据上训练的感知模型之间的差距，标志着向跨感知模态的统一生成仿真迈进了一步。|
|**2025-12-19**|[Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow](http://arxiv.org/abs/2512.17878)|null|基于分数的扩散模型目前代表了连续生成建模的最新技术水平。这些方法通常通过过阻尼或欠阻尼的Ornstein--Uhlenbeck型随机微分方程来构建，其中采样由确定性漂移和布朗扩散的组合驱动，从而在环境空间中产生连续的粒子轨迹。尽管这种动力学对强对数凹目标分布具有指数收敛保证，但众所周知，在存在非凸或多模态景观（例如双势阱）的情况下，它们的混合速率会呈指数级恶化。由于许多实际的生成建模任务涉及高度非对数凹的目标分布，最近大量工作致力于开发超越经典扩散动力学、能够改进探索的采样方案。一个有前景的研究方向是利用信息几何工具，通过受控的质量重加权机制来增强基于扩散的采样器。这种视角自然引出了Wasserstein--Fisher--Rao (WFR) 几何，它将样本空间中的传输与概率测度空间上的垂直（反应）动力学相结合。在这项工作中，我们通过引入显式修正项来提出这种重加权机制，并展示了如何利用Feynman--Kac表示通过加权随机微分方程实现它们。我们的研究对基于WFR的采样动力学进行了初步但严谨的探究，旨在阐明其几何和算子理论结构，为未来的理论和算法发展奠定基础。|
|**2025-12-19**|[Visually Prompted Benchmarks Are Surprisingly Fragile](http://arxiv.org/abs/2512.17875)|null|评估视觉语言模型（VLM）的一个关键挑战是测试模型独立于其文本先验知识分析视觉内容的能力。最近的基准测试，例如BLINK，通过视觉提示来探究视觉感知，其中关于视觉内容的问题与问题所指的坐标配对，并且这些坐标在图像本身中明确标记。尽管这些基准测试是VLM评估的重要组成部分，但我们发现现有模型对视觉提示中看似不相关的细节出人意料地脆弱：仅仅将视觉标记从红色更改为蓝色就可以完全改变模型在排行榜上的排名。通过在两个视觉提示任务上评估九个常用的开源和闭源VLM，我们展示了基准设置中的细节，包括视觉标记设计和数据集大小，如何对模型性能和排行榜排名产生显著影响。这些影响甚至可以被利用来使弱模型超越强模型；例如，稍微增加视觉标记的大小，就能使开源的InternVL3-8B与Gemini 2.5 Pro等大得多的专有模型排名持平或更优。我们进一步表明，在基准测试中经常被忽略的低级推理选择，例如API调用中的JPEG压缩级别，也可能导致模型阵容的变化。这些细节对视觉提示基准的影响远大于对传统语义VLM评估的影响。为了减轻这种不稳定性，我们整理现有数据集，创建了VPBench，这是一个更大的视觉提示基准，包含16种视觉标记变体。VPBench和附加分析工具已在https://lisadunlap.github.io/vpbench/发布。|
|**2025-12-19**|[AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning](http://arxiv.org/abs/2512.17853)|null|通用机器人学习仍受数据限制：大规模、多样化、高质量的交互数据在现实世界中收集成本高昂。虽然仿真已成为扩展数据收集的一种有前景的方式，但其相关任务，包括仿真任务设计、任务感知场景生成、专家演示合成和虚实迁移，仍然需要大量人工投入。我们提出了AnyTask，一个自动化框架，它将大规模并行GPU仿真与基础模型相结合，以设计多样化的操作任务并合成机器人数据。我们介绍了三个AnyTask智能体，用于生成旨在解决尽可能多任务的专家演示：1) ViPR，一种新颖的任务与运动规划智能体，采用VLM循环并行优化；2) ViPR-Eureka，一种强化学习智能体，具有生成的密集奖励和LLM引导的接触采样；3) ViPR-RL，一种混合规划与学习方法，仅利用稀疏奖励共同生成高质量演示。我们在生成数据上训练行为克隆策略，在仿真中验证它们，并将其直接部署到真实机器人硬件上。这些策略泛化到新颖的物体姿态，在一系列现实世界的抓取与放置、抽屉开启、接触丰富的推移和长周期操作任务中实现了44%的平均成功率。我们的项目网站是https://anytask.rai-inst.com。|
|**2025-12-19**|[AdaptPrompt: Parameter-Efficient Adaptation of VLMs for Generalizable Deepfake Detection](http://arxiv.org/abs/2512.17730)|null|图像生成领域的最新进展导致高度逼真合成媒体的广泛普及，增加了可靠深度伪造检测的难度。一个关键挑战是泛化能力，因为在狭窄类别生成器上训练的检测器在面对未见模型时往往会失效。在这项工作中，我们通过利用大型视觉-语言模型，特别是CLIP，来识别跨越不同生成技术的合成内容，从而解决对可泛化检测的迫切需求。首先，我们引入了Diff-Gen，一个大规模基准数据集，包含10万个扩散生成的伪造图像，这些图像捕获了与传统GAN数据集不同的广泛频谱伪影。在Diff-Gen上训练的模型表现出更强的跨领域泛化能力，尤其是在以前未见的图像生成器上。其次，我们提出了AdaptPrompt，一个参数高效的迁移学习框架，它联合学习任务特定的文本提示和视觉适配器，同时保持CLIP骨干网络冻结。我们通过层消融实验进一步表明，剪枝视觉编码器的最后一个Transformer块增强了高频生成伪影的保留，显著提高了检测准确性。我们的评估涵盖了25个具有挑战性的测试集，涵盖了由GAN、扩散模型和商业工具生成的合成内容，在标准和跨领域场景中均建立了新的最先进水平。我们进一步通过少样本泛化（使用低至320张图像）和来源归因展示了该框架的多功能性，从而实现在封闭集设置中精确识别生成器架构。|
|**2025-12-19**|[Generative Human-Object Interaction Detection via Differentiable Cognitive Steering of Multi-modal LLMs](http://arxiv.org/abs/2512.17640)|null|人物-物体交互 (HOI) 检测旨在定位人物-物体对及其间的交互。现有方法在封闭世界假设下运行，将该任务视为对小型预定义动词集的分类问题，这使其难以泛化到真实世界中未见或模糊交互的长尾问题。尽管最近的多模态大语言模型 (MLLMs) 具备开放词汇理解所需的丰富世界知识，但由于对其进行微调的计算成本过高，它们仍然与现有HOI检测器解耦。为解决这些限制，我们提出了\GRASP-HO}，一个新颖的生成式推理与可控感知框架，它将HOI检测从封闭集分类任务重新定义为开放词汇生成问题。为了连接视觉与认知，我们首先提取混合交互表示，然后设计了一个轻量级可学习认知引导通路 (CSC) 模块，将细粒度视觉证据注入到冻结的MLLM中以进行有效推理。为解决基于分类的HOI数据集与开放词汇生成模型之间的监督不匹配问题，我们引入了一种混合指导策略，该策略结合了语言建模损失和辅助分类损失，从而在不牺牲生成灵活性的前提下实现判别性接地。实验证明了最先进的封闭集性能和强大的零样本泛化能力，实现了一个统一的范式，该范式无缝连接了判别性感知和生成式推理，以进行开放世界HOI检测。|
|**2025-12-19**|[PathFLIP: Fine-grained Language-Image Pretraining for Versatile Computational Pathology](http://arxiv.org/abs/2512.17621)|null|尽管视觉-语言模型（VLM）在计算病理学（CPath）中取得了显著进展，但全切片图像（WSI）的千兆像素级别和空间异质性持续对多模态理解构成挑战。现有对齐方法难以捕捉一张切片中数千个图像块的文本描述与视觉线索之间的细粒度对应关系，从而损害了它们在下游任务上的性能。在本文中，我们提出了PathFLIP（病理学细粒度语言-图像预训练），一个用于全局WSI解读的新颖框架。PathFLIP将切片级标题分解为区域级子标题，并生成文本条件区域嵌入，以促进精确的视觉-语言基础。通过利用大语言模型（LLM），PathFLIP可以无缝遵循多样化的临床指令并适应多变的诊断环境。此外，它在多种范式下展现出多功能能力，有效处理切片级分类和检索、细粒度病灶定位以及指令遵循。大量实验表明，PathFLIP在四个代表性基准上优于现有的大规模病理学VLM，同时所需训练数据显著减少，为临床实践中细粒度、指令感知的WSI解读铺平了道路。|
|**2025-12-19**|[HeadHunt-VAD: Hunting Robust Anomaly-Sensitive Heads in MLLM for Tuning-Free Video Anomaly Detection](http://arxiv.org/abs/2512.17601)|**[link](https://github.com/CebCai/HeadHunt-VAD)**|视频异常检测（VAD）旨在定位视频中偏离正常模式的事件。传统方法通常依赖大量标注数据并产生高计算成本。最近基于多模态大型语言模型（MLLM）的免调优方法，通过利用其丰富的世界知识，提供了一种有前景的替代方案。然而，这些方法通常依赖文本输出，这会引入信息丢失、表现出正常性偏差并遭受提示敏感性问题，使其不足以捕获细微的异常线索。为了解决这些限制，我们提出了HeadHunt-VAD，这是一种新颖的免调优VAD范式，它通过直接寻找冻结MLLM中鲁棒的异常敏感内部注意力头来绕过文本生成。我们方法的核心是一个鲁棒注意力头识别模块，它通过对显著性和稳定性进行多准则分析，系统地评估所有注意力头，从而识别出一个在不同提示下始终具有判别性的稀疏注意力头子集。来自这些专家注意力头的特征随后被送入一个轻量级异常评分器和一个时间定位器，从而实现高效准确且具有可解释输出的异常检测。广泛的实验表明，HeadHunt-VAD在两个主要的VAD基准上，在免调优方法中取得了最先进的性能，同时保持了高效率，验证了MLLM中的注意力头层面探测是真实世界异常检测的一个强大而实用的解决方案。|
|**2025-12-19**|[Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing](http://arxiv.org/abs/2512.17574)|null|多模态大语言模型（MLLM）通过三阶段流水线——多模态预处理、视觉编码和LLM推理——扩展了LLM的视觉理解能力。尽管这些阶段增强了功能，但也引入了显著的系统瓶颈。首先，多模态预处理（尤其是视频解码）常常在“首个词元生成时间”（Time-to-First-Token, TTFT）中占据主导地位。大多数系统依赖基于CPU的解码，这严重限制了吞吐量，而现有的基于GPU的方法则优先考虑吞吐量优先的并行性，未能满足MLLM推理对延迟敏感的要求。其次，视觉编码器是一个独立的、计算密集型阶段，它生成视觉嵌入，并且无法与LLM预填充（prefill）或解码进行批处理。这种异构性导致阶段间阻塞并增加了词元生成延迟。即使部署在独立的GPU上，这些阶段也未能充分利用可用的计算和内存资源，降低了整体利用率并限制了系统吞吐量。为了解决这些挑战，我们提出了FlashCodec和UnifiedServe，这是两个互补的设计，共同优化了端到端的MLLM流水线。FlashCodec通过协作式多GPU视频解码加速多模态预处理阶段，在保持高吞吐量的同时减少了解码延迟。UnifiedServe通过逻辑上解耦视觉到文本和推理阶段的执行来消除阶段间阻塞，同时物理上共享GPU资源以最大化GPU系统利用率，从而优化了这些阶段。通过精心编排跨阶段执行并最小化干扰，我们提出的框架共同形成了一个端到端优化的堆栈，与现有最先进的系统相比，能够服务多达3.0倍的请求，或强制执行1.5倍更严格的服务水平目标（SLO），同时实现高达4.4倍的吞吐量提升。|
|**2025-12-18**|[The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text](http://arxiv.org/abs/2512.16924)|null|我们提出WorldCanvas，这是一个用于可提示世界事件的框架，它通过结合文本、轨迹和参考图像来实现丰富的、用户导向的模拟。与纯文本方法以及现有的轨迹控制图像到视频方法不同，我们的多模态方法结合了轨迹（编码运动、时间安排和可见性）、自然语言（用于语义意图）和参考图像（用于对象身份的视觉基础），从而能够生成连贯的、可控的事件，这些事件包括多智能体交互、对象进入/退出、参考指导的外观以及反直觉事件。生成的视频不仅展现出时间连贯性，而且展现出涌现一致性，即使在暂时消失的情况下也能保持对象身份和场景。通过支持富有表现力的世界事件生成，WorldCanvas将世界模型从被动预测器提升为交互式、用户塑造的模拟器。我们的项目页面可在以下网址访问：https://worldcanvas.github.io/。|
|**2025-12-18**|[Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification](http://arxiv.org/abs/2512.16921)|null|传统多模态大型语言模型（MLLM）的评估方法缺乏可解释性，且往往不足以充分揭示不同模型之间显著的能力差距。为解决此问题，我们引入了AuditDM，一个自动化框架，通过审计MLLM的分歧来主动发现并纠正其失效模式。AuditDM通过强化学习微调一个MLLM作为审计器，以生成具有挑战性的问题和反事实图像，从而最大化目标模型之间的分歧。训练完成后，该审计器会发现多样化、可解释的示例，这些示例揭示了模型弱点，并作为免标注数据用于纠正。当应用于Gemma-3和PaliGemma-2等最先进（SoTA）模型时，AuditDM发现了20多种不同的故障类型。基于这些发现进行微调持续改进了所有模型在16个基准测试中的表现，并使一个3B模型超越了其28B的同类模型。我们的结果表明，随着数据扩展达到边际效益递减，针对性的模型审计为模型诊断和改进提供了一条有效的途径。|
|**2025-12-18**|[AdaTooler-V: Adaptive Tool-Use for Images and Videos](http://arxiv.org/abs/2512.16918)|null|最近的进展表明，多模态大语言模型 (MLLM) 受益于结合视觉工具交互的多模态交错思维链 (CoT)。然而，现有的开源模型经常表现出盲目使用工具的推理模式，即使在不必要时也调用视觉工具，这显著增加了推理开销并降低了模型性能。为此，我们提出了AdaTooler-V，一个通过判断视觉问题是否真正需要工具来执行自适应工具使用的多模态大语言模型 (MLLM)。首先，我们引入了AT-GRPO，一种强化学习算法，它根据每个样本的工具效益得分 (Tool Benefit Score) 自适应地调整奖励尺度，鼓励模型仅在工具提供真正改进时才调用。此外，我们构建了两个数据集来支持训练：AdaTooler-V-CoT-100k 用于 SFT 冷启动，以及 AdaTooler-V-300k 用于强化学习 (RL)，其中包含单图像、多图像和视频数据上的可验证奖励。跨十二个基准的实验证明了AdaTooler-V强大的推理能力，在各种视觉推理任务中优于现有方法。值得注意的是，AdaTooler-V-7B 在高分辨率基准 V* 上达到了 89.8% 的准确率，超越了商业专有模型 GPT-4o 和 Gemini 1.5 Pro。所有代码、模型和数据均已发布。|
|**2025-12-18**|[SFTok: Bridging the Performance Gap in Discrete Tokenizers](http://arxiv.org/abs/2512.16910)|null|多模态模型的最新进展凸显了图像标记化在高分辨率图像生成中的关键作用。通过将图像压缩成紧凑的潜在表示，标记器使生成模型能够在低维空间中运行，从而提高计算效率并降低复杂性。离散标记器天然契合自回归范式，但仍落后于连续标记器，限制了它们在多模态系统中的应用。为了解决这个问题，我们提出了SFTok，这是一种离散标记器，它结合了多步迭代机制以实现精确重建。通过整合自强制引导视觉重建和去偏和拟合训练策略，SFTok解决了多步过程中的训练-推理不一致性，显著提高了图像重建质量。在每张图像仅64个标记的高压缩率下，SFTok在ImageNet上实现了最先进的重建质量（rFID = 1.21），并在类别到图像生成任务中展现出卓越的性能（gFID = 2.29）。|
|**2025-12-18**|[MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning](http://arxiv.org/abs/2512.16909)|null|家居环境中的移动操作器必须同时具备导航和操作能力。这需要一个紧凑、语义丰富的场景表示，能够捕捉物体的位置、它们的功能以及哪些部件是可操作的。场景图是一个自然的选择，然而，先前的工作常常将空间关系和功能关系分离，将场景视为没有物体状态或时间更新的静态快照，并且忽略了对完成当前任务最相关的信息。为了解决这些局限性，我们引入了MomaGraph，这是一种面向具身智能体的统一场景表示，它集成了空间功能关系和部件级别的交互元素。然而，推进这种表示需要适用的数据和严格的评估，而这些在很大程度上是缺失的。因此，我们贡献了MomaGraph-Scenes，这是首个在家居环境中大规模丰富标注的任务驱动场景图数据集，以及MomaGraph-Bench，一个涵盖从高层规划到细粒度场景理解六种推理能力的系统性评估套件。在此基础上，我们进一步开发了MomaGraph-R1，这是一个基于MomaGraph-Scenes并采用强化学习训练的7B视觉语言模型。MomaGraph-R1能够预测面向任务的场景图，并作为“图然后规划”框架下的零样本任务规划器。大量实验表明，我们的模型在开源模型中取得了最先进的结果，在基准测试中达到了71.6%的准确率（比最佳基线高出11.4%），同时在公共基准测试中表现出泛化能力，并有效地迁移到真实机器人实验中。|
|**2025-12-18**|[VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization](http://arxiv.org/abs/2512.16906)|null|基于指令的视频编辑旨在根据自然语言指令修改输入视频，同时保持内容保真度和时间连贯性。然而，现有的基于扩散的方法通常使用简单编辑操作的成对数据进行训练，这从根本上限制了它们泛化到多样化、复杂和真实世界指令的能力。为解决这一泛化差距，我们提出了VIVA，一个可扩展的基于指令的视频编辑框架，它利用VLM引导的编码和奖励优化。首先，我们引入了一个基于VLM的指令器，它将文本指令、源视频的第一帧以及一个可选的参考图像编码成视觉接地的指令表示，为扩散Transformer骨干网络提供了细粒度的空间和语义上下文。其次，我们提出了一个后训练阶段Edit-GRPO，它将群体相对策略优化（Group Relative Policy Optimization）适应到视频编辑领域，通过使用相对奖励直接优化模型以实现指令忠实、内容保持和美观的编辑。此外，我们提出了一个数据构建流程，旨在合成生成多样化、高保真的基本编辑操作的成对视频-指令数据。大量实验表明，VIVA在指令遵循、泛化能力和编辑质量方面均优于现有最先进的方法。Website: https://viva-paper.github.io|
|**2025-12-18**|[Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image](http://arxiv.org/abs/2512.16899)|null|奖励模型 (RM) 对于训练大型语言模型 (LLM) 至关重要，但对于处理交错图像和文本序列的全能模型而言，其探索仍不充分。我们引入了多模态奖励基准 2 (MMRB2)，这是首个针对多模态理解和（交错）生成奖励模型的综合性基准。MMRB2 涵盖文本到图像、图像编辑、交错生成和多模态推理（“图像思维”）四项任务，为每项任务提供了 1,000 对专家标注的偏好对，这些数据来源于 21 个源任务中的 23 个模型和智能体。MMRB2 的设计特点包括：(1) 实用但具有挑战性的提示；(2) 来自最先进模型和智能体的响应；以及 (3) 通过集成过滤策略筛选出的、具有强大人类专家共识的偏好对。利用 MMRB2，我们研究了每个子任务的现有评判器，包括多模态大语言模型作为评判器以及通过人类偏好训练的模型。最新的 Gemini 3 Pro 达到了 75-80% 的准确率。GPT-5 和 Gemini 2.5 Pro 达到了 66-75% 的准确率，相比之下人类的准确率超过 90%，但它们仍超越了广泛使用的 GPT-4o (59%)。表现最佳的开源模型 Qwen3-VL-32B 取得了与 Gemini 2.5 Flash (64%) 相似的准确率。我们还表明，使用 Best-of-N 采样时，MMRB2 的性能与下游任务的成功强烈相关，并进行了深入分析，揭示了未来改进奖励模型的关键领域。|
|**2025-12-18**|[OPENTOUCH: Bringing Full-Hand Touch to Real-World Interaction](http://arxiv.org/abs/2512.16842)|null|人手是我们与物理世界交互的主要界面，然而第一人称感知却很少知道手何时、何地以及以何种力度进行接触。鲁棒的可穿戴触觉传感器稀缺，并且尚无野外数据集能将第一人称视频与全手触觉对齐。为了弥合视觉感知与物理交互之间的鸿沟，我们提出了 OpenTouch，这是首个野外以自我为中心的全手触觉数据集，包含 5.1 小时同步的视频-触觉-姿态数据和 2,900 个带有详细文本标注的精选片段。利用 OpenTouch，我们引入了检索和分类基准，以探究触觉如何为感知和行动奠定基础。我们展示了触觉信号为抓取理解提供了一种紧凑而强大的线索，加强了跨模态对齐，并且可以从野外视频查询中可靠地检索。通过发布这个带标注的视觉-触觉-姿态数据集和基准，我们旨在推动多模态第一人称感知、具身学习和接触丰富的机器人操作。|
|**2025-12-18**|[Radiology Report Generation with Layer-Wise Anatomical Attention](http://arxiv.org/abs/2512.16841)|null|自动放射学报告生成是多模态深度学习一个有前景的应用，旨在减少报告工作量并提高一致性。然而，当前最先进的（SOTA）系统——例如放射学应用多模态人工智能（MAIRA-2）和医疗通路语言模型-多模态（MedPaLM-M）——依赖于大规模多模态训练、临床元数据和多种影像视图，这使得它们资源密集且在大多数环境下难以实现。我们引入了一种紧凑的图像到文本架构，可以从单一正面图像生成胸部X射线报告的“发现”部分。该模型结合了一个冻结的无标签自蒸馏v3（DINOv3）视觉Transformer（ViT）编码器和一个通过层级解剖注意力增强的生成式预训练Transformer 2（GPT-2）解码器。这种机制通过分层高斯平滑整合了肺部和心脏分割掩模，将注意力偏向临床相关区域，而不增加可训练参数。在官方重症监护医疗信息市场-胸部X射线（MIMIC-CXR）数据集上，使用胸部X射线专家（CheXpert）和放射学图谱（RadGraph）指标进行评估，我们的方法取得了显著提升：CheXpert针对五种关键病理的宏F1值增加了168%（从0.083到0.238），微F1值增加了146%（从0.137到0.337），同时在14项观察结果上的更广泛性能提高了86%（从0.170到0.316）。结构一致性也得到改善，RadGraph F1值增加了9.7%。尽管其规模小且设计纯粹基于图像条件，但该模型表明解码器级别的解剖学指导改善了空间定位并增强了临床相关区域的一致性。源代码可在以下网址公开获取：https://github.com/devMuniz02/UDEM-CXR-Reporting-Thesis-2025。|
|**2025-12-18**|[R3ST: A Synthetic 3D Dataset With Realistic Trajectories](http://arxiv.org/abs/2512.16784)|null|数据集对于训练和评估用于交通分析和提高道路安全的计算机视觉模型至关重要。现有真实数据集符合真实世界场景，能够捕捉真实的道路物体行为，然而它们通常缺乏精确的真值标注。相比之下，合成数据集发挥着关键作用，无需额外成本或时间即可标注大量帧。然而，合成数据集的一个普遍缺点是缺乏真实的车辆运动，因为轨迹是使用AI模型或基于规则的系统生成的。在这项工作中，我们引入了R3ST（真实3D合成轨迹），这是一个合成数据集，它通过生成一个合成3D环境并整合源自SinD（一个从无人机拍摄画面记录的鸟瞰视图数据集）的真实世界轨迹来克服这一局限性。所提出的数据集弥补了合成数据与真实轨迹之间的差距，推动了道路车辆轨迹预测方面的研究，同时提供了精确的多模态真值标注和真实的由人类驾驶的车辆轨迹。|
|**2025-12-12**|[Multiscale Causal Geometric Deep Learning for Modeling Brain Structure](http://arxiv.org/abs/2512.11738)|**[link](https://github.com/xxxcz222/Multiscale-Causal-Geometric-Deep-Learning-for-Modeling-Brain-Structure)**|多模态MRI提供互补的多尺度信息来表征大脑结构。然而，在实现神经科学可解释性的同时有效整合多模态MRI仍然具有挑战性。本文提出使用拉普拉斯谐波和谱图理论进行多模态对齐和多尺度整合。基于提供多尺度表示的皮层网格和连接组矩阵，我们设计了拉普拉斯算子和谱图注意力来构建共享潜在空间以实现模型对齐。接下来，我们采用解耦学习结合图变分自编码器架构来分离尺度特异性特征和共享特征。最后，我们设计了一个互信息引导的双层正则化器，基于解耦特征分离因果和非因果因素，从而实现鲁棒的模型性能和增强的可解释性。我们的模型优于基线模型和其他最先进的模型。消融研究证实了所提出模块的有效性。我们的模型有望为多尺度大脑结构分析提供一个鲁棒且可解释的框架。|
|**2025-12-12**|[Depth-Copy-Paste: Multimodal and Depth-Aware Compositing for Robust Face Detection](http://arxiv.org/abs/2512.11683)|null|数据增强对于提高人脸检测系统的鲁棒性至关重要，尤其是在遮挡、光照变化和复杂环境等挑战性条件下。传统的复制粘贴增强由于不准确的前景提取、不一致的场景几何和不匹配的背景语义，常常生成不真实的合成图像。为了解决这些局限性，我们提出了深度复制粘贴，这是一个多模态且深度感知的增强框架，通过复制全身人物实例并将其粘贴到语义兼容的场景中，生成多样化且物理上一致的人脸检测训练样本。我们的方法首先利用BLIP和CLIP共同评估语义和视觉连贯性，从而能够自动检索最合适的背景图像用于给定的前景人物。为了确保能够保留面部细节的高质量前景掩码，我们集成了SAM3进行精确分割，并利用Depth-Anything仅提取非遮挡的可见人物区域，防止损坏的面部纹理被用于增强。为了实现几何真实感，我们引入了一种深度引导的滑动窗口放置机制，该机制在背景深度图上搜索，以识别具有最佳深度连续性和尺度对齐的粘贴位置。得到的合成图像展现出自然的深度关系并提高了视觉合理性。大量实验表明，与传统复制粘贴和无深度增强方法相比，深度复制粘贴提供了更多样化和真实的训练数据，从而显著提高了下游人脸检测任务的性能。|
|**2025-12-12**|[Cross-modal Context-aware Learning for Visual Prompt Guided Multimodal Image Understanding in Remote Sensing](http://arxiv.org/abs/2512.11680)|null|图像理解的近期进展促成了利用大语言模型进行遥感多模态推理的方法。然而，当仅提供简单、通用文本提示时，现有方法仍然难以将模型引导至用户相关区域。此外，在大规模航空影像中，许多目标呈现出高度相似的视觉外观并具有丰富的对象间关系，这进一步使准确识别复杂化。为应对这些挑战，我们提出了跨模态上下文感知学习用于视觉提示引导的多模态图像理解（CLV-Net）。CLV-Net允许用户提供一个简单的视觉线索——一个边界框来指示感兴趣区域，并利用该线索引导模型生成忠实反映用户意图的相关的分割掩码和文本描述。我们设计的核心是一个上下文感知掩码解码器，该解码器建模并整合对象间关系，以增强目标表示并提高掩码质量。此外，我们引入了一个语义和关系对齐模块：跨模态语义一致性损失增强了针对视觉相似目标的细粒度判别能力，而关系一致性损失强制对齐了文本关系与视觉交互。在两个基准数据集上的全面实验表明，CLV-Net优于现有方法并取得了新的最先进结果。该模型有效捕捉用户意图，并生成精确、意图对齐的多模态输出。|
|**2025-12-12**|[A Modeling and Optimization Framework for Fostering Modal Shift through the Integration of Tradable Credits and Demand-Responsive Autonomous Shuttles](http://arxiv.org/abs/2512.11607)|null|可交易信用计划（TCS）通过限制私家车使用并允许信用交易来促进公共交通和共享交通的使用，同时维持公平的福利结果。然而，大多数现有研究假设公共交通运力无限或共享模式的固定载客量，经常忽略等待时间，并通过仅依赖车内出行时间来过度简化基于时间的成本。这些假设可能会夸大系统在TCS监管下的性能，特别是在公共交通或共享交通供应不足时。为解决此问题，我们开发了一个动态多模式均衡模型，以捕捉TCS监管下的运营约束和产生的等待时间。该模型整合了出行者的模式选择、信用交易、交通动态和等待时间，这些都取决于服务车辆的关键运营特征，例如车队规模和容量。此外，大多数TCS研究假设交通供应是固定的，忽略了由需求变化触发的供应侧响应。因此，我们进一步提出通过部署按需响应式自动穿梭巴士（DRAS）来整合自适应供应管理，并开发一个结合了均衡模型的双层优化框架，以联合优化TCS设计和DRAS的运营策略。我们将该框架应用于法国巴黎附近A10高速公路的一个路段，以检验需求-供应互动并评估联合实施TCS和DRAS的潜在益处。数值结果表明，在多模式均衡中建模运营特征以及在TCS政策中纳入灵活供应对于降低总体广义成本的重要性。|
|**2025-12-12**|[Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet](http://arxiv.org/abs/2512.11567)|null|社交媒体在现代政治中扮演着关键角色，因为它既反映了政治家的意识形态，也促进了与年轻一代的交流。我们提出了MultiParTweet，一个来自X平台的多语言推文语料库，它将政治家的社交媒体论述与德国政治语料库GerParCor关联起来，从而实现了在线交流和议会辩论之间的比较分析。MultiParTweet包含39,546条推文，其中包括19,056个媒体项。此外，我们通过九个基于文本的模型和一个视觉语言模型（VLM）丰富了标注，用情感、情绪和主题标注MultiParTweet。此外，自动化标注还对照手动标注的子集进行了评估。MultiParTweet可以使用我们的工具TTLABTweetCrawler进行重建，该工具提供了一个从X平台收集数据的框架。为了进行方法学演示，我们检验了模型是否可以使用剩余模型的输出相互预测。总而言之，我们提供了MultiParTweet，一个整合了自动文本和基于媒体标注并经人工标注验证的资源，以及TTLABTweetCrawler，一个通用的X平台数据收集工具。我们的分析表明模型是相互可预测的。此外，基于VLM的标注受到人类标注者的青睐，这表明多模态表示与人类解释更为一致。|
|**2025-12-12**|[DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry](http://arxiv.org/abs/2512.11558)|null|牙科多模态数据的可靠解读对自动化口腔医疗至关重要，然而当前的多模态大语言模型（MLLMs）在捕捉细粒度牙科视觉细节方面存在困难，并缺乏足够的推理能力来进行精确诊断。为解决这些局限性，我们提出了DentalGPT，一个专门的牙科MLLM，通过高质量的领域知识注入和强化学习开发。具体而言，我们构建了迄今为止最大的牙科标注多模态数据集，该数据集聚合了超过12万张牙科图像，并搭配详细描述，突出了诊断相关的视觉特征，使其成为迄今为止收集牙科图像最广泛的多模态数据集。在此数据集上进行训练显著增强了MLLM对牙科疾病的视觉理解能力，而随后的强化学习阶段进一步强化了其多模态复杂推理能力。在口内和全景基准测试，以及医学VQA基准测试中的牙科子集上进行的全面评估表明，尽管DentalGPT只有70亿参数，但它在疾病分类和牙科VQA任务中均取得了卓越的性能，优于许多最先进的MLLMs。这些结果表明，高质量的牙科数据结合分阶段适应为构建有能力且领域专业的牙科MLLMs提供了一条有效的途径。|
|**2025-12-12**|[HFS: Holistic Query-Aware Frame Selection for Efficient Video Reasoning](http://arxiv.org/abs/2512.11534)|null|视频理解中的关键帧选择面临重大挑战。传统的top-K选择方法独立地对帧进行评分，通常未能从整体上优化选择。这种独立的评分经常导致选择时间上聚类且视觉冗余的帧。此外，使用多模态大型语言模型（MLLM）离线生成的伪标签训练轻量级选择器，会阻止监督信号动态适应任务目标。为了解决这些局限性，我们提出了一种端到端可训练的任务自适应帧选择框架。思维链方法引导小型语言模型（SLM）生成任务特定的隐式查询向量，这些向量与多模态特征相结合，以实现动态帧评分。我们进一步定义了一个连续的集合级目标函数，该函数结合了相关性、覆盖率和冗余性，通过Gumbel-Softmax实现可微分优化，以在集合层面选择最优帧组合。最后，采用师生互学习，其中学生选择器（SLM）和教师推理器（MLLM）通过KL散度训练以对齐其帧重要性分布。结合交叉熵损失，这实现了端到端优化，消除了对静态伪标签的依赖。在包括Video-MME、LongVideoBench、MLVU和NExT-QA在内的各种基准上的实验表明，我们的方法显著优于现有方法。|
|**2025-12-12**|[Reconstruction as a Bridge for Event-Based Visual Question Answering](http://arxiv.org/abs/2512.11510)|**[link](https://github.com/HYLZ-2019/EvQA)**|将事件相机与多模态大语言模型（MLLMs）结合有望在挑战性视觉条件下实现通用场景理解，但这需要在保留事件数据独特优势与确保其与基于帧的模型兼容性之间进行权衡。为应对这一挑战，我们以重建为桥梁，提出了一种直接的基于帧的重建与标记（FRT）方法，并设计了一种利用事件稀疏性的高效自适应重建与标记（ART）方法。为进行鲁棒评估，我们引入了EvQA，这是首个针对基于事件的MLLM的客观、真实世界基准，该基准包含来自22个公共数据集的1,000个事件问答对。我们的实验表明，所提出的方法在EvQA上取得了最先进的性能，突显了MLLM在基于事件的视觉领域中的巨大潜力。|
|**2025-12-12**|[VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing](http://arxiv.org/abs/2512.11490)|null|卫星图像与自然图像存在根本性差异：其空中视角、极高分辨率、多样的尺度变化以及大量小目标，要求同时进行区域级空间推理和整体场景理解。当前遥感方法在双编码器检索模型（擅长大规模跨模态搜索但无法交错处理模态）和生成式助手（支持区域级解释但缺乏可扩展检索能力）之间仍然是碎片化的。我们提出了VLM2GeoVec，一个遵循指令的单编码器视觉-语言模型，采用对比学习训练，将交错输入（图像、文本、边界框和地理坐标）嵌入到统一向量空间中。我们的单编码器将所有输入交错为一个联合嵌入，并使用对比损失进行训练，从而消除了多阶段流水线和特定任务模块。为了评估其通用性，我们引入了RSMEB，一个新颖的基准，涵盖了关键的遥感嵌入应用：场景分类；跨模态搜索；组合检索；视觉问答；视觉定位和区域级推理；以及语义地理空间检索。在RSMEB上，它在区域-标题检索中实现了26.6%的P@1（比双编码器基线提高了25个百分点），在指代表达检索中实现了32.5%的P@1（提高了19个百分点），在语义地理定位检索中实现了17.8%的P@1（是先前最佳水平的3倍以上），同时在场景分类和跨模态检索等传统任务上达到或超越了专用基线。VLM2GeoVec将可扩展检索与区域级空间推理相结合，从而在遥感领域实现了连贯的多模态分析。我们将在论文被接收后公开发布代码、检查点和数据。|
|**2025-12-12**|[Exploring MLLM-Diffusion Information Transfer with MetaCanvas](http://arxiv.org/abs/2512.11464)|**[link](https://github.com/MetaCanvas/metacanvas.github.io)**|多模态学习通过使用强大大语言模型作为认知核心的多模态大语言模型（MLLM），迅速推动了视觉理解。然而，在视觉生成领域，这些强大的核心模型通常被简化为扩散模型的全局文本编码器，使得它们大部分的推理和规划能力未被利用。这就造成了一个鸿沟：当前的多模态大语言模型能够解析复杂的布局、属性和知识密集型场景，然而却难以生成具有同样精确和结构化控制的图像或视频。我们提出了 MetaCanvas，一个轻量级框架，它允许 MLLM 直接在空间和时空潜在空间中进行推理和规划，并与扩散生成器紧密衔接。我们在三个不同的扩散骨干网络上经验性地实现了 MetaCanvas，并在六项任务中对其进行了评估，包括文本到图像生成、文本/图像到视频生成、图像/视频编辑以及上下文视频生成，每项任务都要求精确的布局、鲁棒的属性绑定和推理密集型控制。MetaCanvas 始终优于全局条件基线，这表明将 MLLM 视为潜在空间规划器是缩小多模态理解和生成之间鸿沟的一个有前景的方向。|
|**2025-12-11**|[Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](http://arxiv.org/abs/2512.10949)|**[link](https://github.com/Ivan-Tang-3D/3DGen-R1)**|强化学习（RL）此前已被证明在大语言模型和多模态模型中行之有效，最近已成功拓展到增强二维图像生成。然而，由于三维物体更高的空间复杂度，需要全局一致的几何结构和细粒度的局部纹理，将RL应用于三维生成仍未得到充分探索。这使得三维生成对奖励设计和RL算法高度敏感。为解决这些挑战，我们首次从多个维度对文本到三维自回归生成中的RL进行了系统研究。(1) 奖励设计：我们评估了奖励维度和模型选择，表明与人类偏好对齐至关重要，并且通用多模态模型为三维属性提供了稳健的信号。(2) RL算法：我们研究了GRPO变体，强调了令牌级优化的有效性，并进一步研究了训练数据和迭代的规模扩展。(3) 文本到三维基准：由于现有基准未能衡量三维生成模型中的隐式推理能力，我们引入了MME-3DR。(4) 先进的RL范式：受三维生成自然层次结构的启发，我们提出了Hi-GRPO，通过专用奖励集成优化了从全局到局部的分层三维生成。基于这些见解，我们开发了AR3D-R1，这是首个RL增强的文本到三维模型，精通从粗略形状到纹理细化的过程。我们希望这项研究能为RL驱动的三维生成推理提供见解。代码已发布在https://github.com/Ivan-Tang-3D/3DGen-R1。|
|**2025-12-11**|[VL-JEPA: Joint Embedding Predictive Architecture for Vision-language](http://arxiv.org/abs/2512.10942)|null|我们引入了 VL-JEPA，一个基于联合嵌入预测架构（JEPA）构建的视觉-语言模型。与经典的视觉-语言模型（VLM）自回归生成 token 不同，VL-JEPA 预测目标文本的连续嵌入。通过在抽象表示空间中学习，该模型专注于任务相关的语义，同时抽象掉表面层次的语言变异性。在与使用相同视觉编码器和训练数据的标准 token 空间 VLM 训练进行严格控制的对比中，VL-JEPA 实现了更强的性能，同时可训练参数减少了 50%。在推理时，仅在需要将 VL-JEPA 预测的嵌入转换为文本时，才会调用轻量级文本解码器。我们表明 VL-JEPA 原生支持选择性解码，与非自适应均匀解码相比，它将解码操作的数量减少了 2.85 倍，同时保持了相似的性能。除了生成之外，VL-JEPA 的嵌入空间无需任何架构修改即可自然支持开放词汇分类、文本到视频检索和判别式视觉问答（VQA）。在八个视频分类和八个视频检索数据集上，VL-JEPA 的平均性能超越了 CLIP、SigLIP2 和 Perception Encoder。同时，尽管该模型只有 16 亿参数，但在四个 VQA 数据集（GQA、TallyQA、POPE 和 POPEv2）上，其性能与经典的视觉-语言模型（InstructBLIP、QwenVL）相当。|
|**2025-12-11**|[Mull-Tokens: Modality-Agnostic Latent Thinking](http://arxiv.org/abs/2512.10941)|null|推理超越语言；现实世界需要对空间、时间、功能以及更多仅凭语言无法传达的内容进行推理。现有探索图像推理潜力的多模态模型脆弱且难以扩展。它们依赖于调用专业工具、昂贵的图像生成或手工制作的推理数据来在文本和图像思维之间切换。相反，我们提供一个更简单的替代方案——Mull-Tokens——一种模态无关的潜在Token，经过预训练，可以在图像或文本模态中保存中间信息，从而让模型自由地思考以得出正确答案。我们研究了受潜在推理框架启发来训练Mull-Tokens的最佳实践。我们首先利用交错文本-图像轨迹的监督来训练Mull-Tokens，然后在没有任何监督的情况下仅使用最终答案进行微调。在四个具有挑战性的空间推理基准测试中，涉及解决谜题和采取不同视角等任务，我们证明Mull-Tokens优于几个采用纯文本推理或交错图像-文本推理的基线，相比我们最强的基线，平均提升了+3%，并在一个推理密集型谜题解决子集上最高提升了+16%。对于围绕文本和视觉推理接地挑战的讨论，Mull-Tokens提供了一个简单的解决方案，用于在多种模态中进行抽象思考。|
|**2025-12-11**|[BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models](http://arxiv.org/abs/2512.10932)|**[link](https://github.com/ShawnKing98/BabyVLM-v2)**|幼儿发展轨迹为视觉基础模型的样本高效预训练设定了一个自然目标。我们引入了BabyVLM-V2，这是一个基于发展学原理、受婴儿启发式的视觉语言建模框架，它通过一个纵向的、多方面的预训练数据集、一个多功能模型，以及最重要的是，用于认知评估的DevCV工具箱，在BabyVLM-V1的基础上进行了广泛改进。该预训练数据集最大化了对一个纵向的、以婴儿为中心的视听语料库的覆盖范围，同时最小化了人工筛选，生成了模仿婴儿体验的视频-话语、图像-话语和多轮对话数据。DevCV工具箱将最近发布的NIH Baby Toolbox中所有视觉相关的测量方法改编成为一个包含十个多模态任务的基准套件，涵盖了与幼儿能力相符的空间推理、记忆和词汇理解。实验结果表明，一个从零开始预训练的紧凑模型可以在DevCV工具箱上实现有竞争力的性能，并在某些任务上超越GPT-4o。我们希望这一有原则的、统一的BabyVLM-V2框架将加速视觉基础模型在发展学合理预训练方面的研究。|
|**2025-12-11**|[CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences](http://arxiv.org/abs/2512.10918)|null|社交临场感是共同观看内容时获得乐趣的核心，然而现代媒体消费却日益趋于独立。我们研究多智能体对话式AI系统是否能重现跨越不同内容类型的共享观看体验的动态。我们提出了CompanionCast，这是一个通用框架，用于协调多个角色专业化的AI智能体，这些智能体利用多模态输入、语音合成和空间音频对视频内容做出响应。独特的是，CompanionCast集成了一个“大语言模型作为评判者”的模块，该模块迭代地评估和优化对话在五个维度（相关性、真实性、参与度、多样性、个性一致性）上的表现。我们通过体育观赛来验证这个框架，体育观赛是一个具有丰富动态和强大社交传统的领域；一项针对足球迷的初步研究表明，与单独观看相比，多智能体交互提高了感知的社交临场感。我们的贡献包括：(1) 一个用于围绕多模态视频内容协调多智能体对话的可泛化框架；(2) 一个用于对话质量控制的新颖的评估者-智能体管道；以及 (3) AI介导的共同观看中社交临场感提升的探索性证据。我们讨论了将这种方法应用于不同观看情境（包括娱乐、教育和协作观看体验）所面临的挑战和未来方向。|
|**2025-12-11**|[DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance](http://arxiv.org/abs/2512.10894)|null|最近基于视觉-语言模型（VLM）的方法在SVG生成方面取得了令人印象深刻的成果。然而，由于它们只生成文本并在解码过程中缺乏视觉信号，它们常常难以处理复杂的语义，并且无法生成视觉上吸引人或几何上连贯的SVG。我们引入DuetSVG，这是一种统一的多模态模型，能够以端到端的方式联合生成图像tokens和对应的SVG tokens。DuetSVG在图像和SVG数据集上进行训练。在推理时，我们应用了一种新颖的测试时缩放策略，该策略利用模型固有的视觉预测作为指导，以提高SVG解码质量。大量实验表明，我们的方法优于现有方法，能够在广泛的应用中生成视觉上忠实、语义上对齐且语法上干净的SVG。|
|**2025-12-11**|[PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction](http://arxiv.org/abs/2512.10888)|null|表格提取（TE）是视觉文档理解中的一个关键挑战。传统方法首先检测表格，然后识别其结构。近期，人们对开发能够直接从完整的页面或文档上下文中提取表格的方法（例如视觉语言模型 (VLM)）的兴趣激增。然而，由于缺乏标注数据，进展一直难以证明。为了解决这个问题，我们创建了一个新的大规模数据集PubTables-v2。PubTables-v2支持多个当前具有挑战性的表格提取任务。值得注意的是，它是第一个用于多页表格结构识别的大规模基准。我们通过评估在这些任务上的领域专用VLM并突出当前进展来展示其实用性。最后，我们使用PubTables-v2创建了页面对象表格Transformer (POTATR)，它是将Table Transformer扩展到综合页面级TE的图像到图模型。数据、代码和训练模型将发布。|
|**2025-12-11**|[Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](http://arxiv.org/abs/2512.10882)|null|情感在政治中处于核心地位，分析其在政治传播中的作用具有悠久传统。随着研究日益利用音视频材料来分析情感表达，多模态生成式人工智能的兴起预示着巨大进步。然而，关于多模态人工智能在情感分析中有效性的证据仍然缺乏。本文通过在两个互补的人工标注视频记录数据集中，评估当前多模态大语言模型（mLLMs）在基于视频的情绪唤醒分析中的表现，旨在弥补这一空白。我发现，在理想情况下，mLLMs的情绪唤醒评分高度可靠，并且几乎不显示人口统计学偏见的迹象。然而，在真实世界议会辩论中发言者的记录中，mLLMs的唤醒评分未能兑现这一承诺，可能对后续的统计推断产生负面影响。因此，本研究强调了在政治分析中对新兴生成式人工智能方法进行持续、彻底评估的必要性，并贡献了一个合适的、可复制的框架。|
|**2025-12-11**|[From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models](http://arxiv.org/abs/2512.10867)|null|本文介绍了微观空间智能 (MiSI) 的概念，即感知和推理不可见微观实体空间关系的能力，这对科学发现至关重要。为了评估视觉语言模型 (VLM) 在该领域的潜力，我们提出了一个系统的基准框架 MiSI-Bench。该框架包含超过163,000个问答对和587,000张图像，这些图像源自大约4,000个分子结构，涵盖九项互补任务，评估的能力范围从基本空间变换到复杂关联识别。实验结果表明，当前最先进的VLM在此基准上的表现远低于人类水平。然而，一个经过微调的7B模型展示了巨大的潜力，甚至在空间变换任务中超越了人类，而它在氢键识别等科学基础任务中表现不佳，这强调了整合明确领域知识对于推动科学通用人工智能 (AGI) 发展的必要性。数据集可在 https://huggingface.co/datasets/zongzhao/MiSI-bench 获取。|
|**2025-12-11**|[MMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence](http://arxiv.org/abs/2512.10863)|null|连续视觉输入上的空间理解对于MLLM发展成为物理环境中的通用助手至关重要。然而，目前仍没有一个能够全面评估实现这一目标的进展的综合基准。在这项工作中，我们引入了MMSI-Video-Bench，这是一个用于评估MLLM中基于视频的空间智能的完全人工标注基准。它通过基于25个数据集和自制视频中1,278个片段的1,106个问题，运作了一个四级框架：感知、规划、预测和跨视频推理。每个项目都由3DV专家精心设计和审查，并附有解释性原理，以确保精确、无歧义的定位。MMSI-Video-Bench利用其多样化的数据来源和全面的任务覆盖，还支持三个面向领域的子基准（室内场景感知基准、机器人基准和定位基准），用于有针对性的能力评估。我们评估了25个强大的开源和专有MLLM，揭示了一个惊人的人机差距：许多模型表现接近随机，而最佳推理模型落后人类近60%。我们进一步发现，经过空间微调的模型在我们的基准上仍然未能有效泛化。细粒度错误分析揭示了在几何推理、运动定位、长时预测和跨视频对应方面的系统性故障。我们还表明，典型的帧采样策略在我们的推理密集型基准上泛化效果差，并且3D空间线索和思维链提示均未产生有意义的提升。我们期望我们的基准能够为推进基于视频的空间智能建立一个坚实的试验台。|
|**2025-12-04**|[DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation](http://arxiv.org/abs/2512.05112)|**[link](https://github.com/CaraJ7/DraCo)**|近期的统一多模态大语言模型（MLLMs）展现出令人印象深刻的能力，结合了思维链（CoT）推理以增强文本到图像生成。然而，现有方法仍存在局限性，要么将模型仅视为一个独立的生成器，要么依赖于抽象的文本规划。为此，我们提出了Draft-as-CoT (DraCo)，这是一种新颖的交错推理范式，充分利用CoT中的文本和视觉内容以实现更好的规划和验证。我们的方法首先生成一个低分辨率的草图图像作为预览，提供更具体和结构化的视觉规划和指导。接着，我们利用模型固有的理解能力来验证草图与输入提示之间潜在的语义错位，并通过超分辨率的选择性修正进行细化。通过这种方式，我们的方法解决了两个基本挑战：文本规划的粗粒度性质和生成稀有属性组合的难度。为了支持训练，我们整理了DraCo-240K数据集，旨在增强三种原子能力，涵盖通用修正、实例操作和布局重组。在DraCo-CFG（一种针对交错推理的专用无分类器引导（CFG）策略）的支持下，DraCo在GenEval上实现了显著提升（+8%），在Imagine-Bench上提升了0.91，在GenEval++上提升了3%，显著优于直接生成和其他由CoT赋能的生成方法。|
|**2025-12-04**|[ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning](http://arxiv.org/abs/2512.05111)|**[link](https://github.com/InternLM/ARM-Thinker)**|奖励模型对于使视觉-语言系统与人类偏好对齐至关重要，然而现有方法存在幻觉、视觉基础薄弱以及无法使用工具进行验证的问题，这限制了它们在复杂多模态推理任务上的可靠性。我们提出了ARM-Thinker，一个具备智能体能力的多模态奖励模型，它能够自主调用外部工具（例如，图像裁剪、文档页面检索），将判断建立在可验证的证据之上，取代了静态、非交互式的奖励评分。这使得模型能够验证细粒度视觉细节、交叉引用多页证据并验证推理主张，这些能力是现有奖励模型所不具备的。我们使用多阶段强化学习训练ARM-Thinker，联合优化工具调用决策和判断准确性。为了评估智能体奖励建模，我们引入了ARMBench-VL，它包含三个基准，用于评估细粒度视觉基础（图像级工具）、多页文档理解（检索工具）以及指令遵循（文本级验证）。ARM-Thinker在奖励建模基准上平均提升了16.2%，在工具使用任务上提升了9.6%，并且在多模态数学和逻辑推理基准上超越了基线。我们的结果表明，智能体能力显著增强了奖励模型的准确性和可解释性。|
|**2025-12-04**|[STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models](http://arxiv.org/abs/2512.05107)|null|大语言模型和基于强化学习的微调推动了视觉-语言-动作 (VLA) 模型的最新进展，这些模型在机器人操作方面取得了显著进步。现有方法通常将长时序动作视为语言序列，并应用轨迹级优化方法，例如轨迹级偏好优化 (TPO) 或近端策略优化 (PPO)，这导致了粗粒度的信用分配和不稳定的训练。然而，与语言不同（语言尽管句序灵活但仍能保持统一的语义），动作轨迹通过具有不同学习难度的因果链式阶段进展。这促使我们进行渐进式阶段优化。因此，我们提出了阶段感知强化 (STARE)，这是一个将长时序动作轨迹分解为语义有意义的阶段，并提供密集的、可解释的、与阶段对齐的强化信号的模块。将STARE集成到TPO和PPO中，我们分别形成了用于离线阶段式偏好的阶段感知TPO (STA-TPO) 和用于在线阶段内交互的阶段感知PPO (STA-PPO)。进一步以监督微调作为初始化，我们提出了模仿 -> 偏好 -> 交互 (IPI)，这是一个用于提高VLA模型中动作准确性的串行微调流程。在SimplerEnv和ManiSkill3上的实验证明了显著的提升，在SimplerEnv上实现了98.0%的最先进成功率，在ManiSkill3任务上实现了96.4%的最先进成功率。|
|**2025-12-04**|[TV2TV: A Unified Framework for Interleaved Language and Video Generation](http://arxiv.org/abs/2512.05103)|null|视频生成模型正在迅速发展，但在处理需要大量语义分支或对接下来发生什么进行重复高级推理的复杂视频输出时仍可能遇到困难。在本文中，我们介绍了一类新型的全能视频-文本模型，这些模型整合了近期语言模型（LM）推理进展中的思想以应对这一挑战。更具体地说，我们提出了TV2TV，这是一个统一的生成建模框架，它将视频生成分解为交错的文本和视频生成过程。TV2TV使用混合Transformer（MoT）架构联合学习语言建模（下一词元预测）和视频流匹配（下一帧预测）。在推理时，TV2TV决定何时在生成文本和视频帧之间交替，从而允许模型在“用像素行动”生成帧之前，“用文字思考”后续内容。这种设计将决定接下来发生什么的大部分责任卸载给语言建模模块，从而提高了生成视频的视觉质量和提示对齐度。它还实现了细粒度可控性，允许用户通过在过程中的任何一点进行文本干预来修改视频生成轨迹。在视频游戏数据上的受控实验中，TV2TV在视觉质量和可控性两方面都展示了显著的改进。TV2TV也适用于自然视频，正如我们通过使用视觉-语言模型（VLM）为体育视频增强交错的自然语言动作描述所展示的。在此语料库上训练TV2TV产生了强大的视觉质量和提示对齐度，展示了模型对复杂真实世界动作序列进行推理和生成的能力。综上所述，这些结果突出了TV2TV是迈向具有开放式文本推理和控制能力的视频生成的有希望的一步。|
|**2025-12-04**|[SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards](http://arxiv.org/abs/2512.05098)|null|近年来，针对AI生成图像（AIGI）的图像质量评估（IQA）发展迅速；然而，现有方法主要针对肖像和艺术图像，缺乏对室内场景的系统评估。我们引入了空间美学，这是一种从布局、和谐、光照和失真四个维度评估室内图像美学质量的范式。我们构建了SA-BENCH，首个空间美学基准，包含18,000张图像和50,000条精确标注。利用SA-BENCH，我们系统地评估了当前的IQA方法，并通过多模态大语言模型（MLLM）微调和多维度融合方法开发了SA-IQA，作为一个评估空间美学的综合奖励框架。我们将SA-IQA应用于两个下游任务：(1) 作为奖励信号，与GRPO强化学习相结合以优化AIGC生成流程；(2) 进行N选一（Best-of-N）筛选，以过滤高质量图像并提高生成质量。实验表明，SA-IQA在SA-BENCH上显著优于现有方法，为空间美学评估树立了新标准。代码和数据集将开源以推动该领域的研究和应用。|
|**2025-12-04**|[Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark](http://arxiv.org/abs/2512.05091)|null|多模态大语言模型（MLLMs）的最新进展显著提升了视觉定位和视觉问答等任务的性能。然而，这些模型的推理过程仍然大多不透明；它们通常只输出最终预测，而不揭示导致结果的中间步骤或细粒度证据（例如，像素、位置）。这与通过视觉推理链自然运行的人类智能形成对比。为解决这一局限性，我们引入了视觉推理追踪器（VRT）任务，该任务要求模型不仅要定位目标对象，还要明确预测构成推理路径的中间对象。为推进该领域的研究，我们贡献了：(1) VRT-Bench，一个用于评估视觉推理的人工标注基准；(2) 一个用于评估推理轨迹质量的新度量；以及 (3) VRT-80k，一个用于推理模型训练的大规模数据集。我们的实验表明，现有模型虽然通常能产生正确的最终输出，但它们难以对其中间推理进行定位。相比之下，在 VRT-80k 上训练的模型在追踪推理路径方面取得了显著改进。|
|**2025-12-04**|[Multimode RF Reflectometry for Spin Qubit Readout and Device Characterization](http://arxiv.org/abs/2512.05087)|null|我们引入了一种多模超导电感器架构，它能够实现最高2 GHz的多个离散频率的射频反射测量，解决了传统单模设计的局限性。螺旋电感器的分布式匝间电容产生了具有不同阻抗匹配条件的独特谐振模式。通过在多个模式下探测量子点，我们在宽频率范围内提取了隧穿速率，并识别出附近电荷缺陷的特征。利用其中一个高阶模式，我们通过射频单电子晶体管（RF-SET）演示了单次自旋读出，实现了积分时间为8微秒、读出保真度为98%的单重态-三重态读出。这些结果确立了多模电感器作为一种可扩展且灵活的组件，用于快速自旋量子比特读出和器件质量表征。|
|**2025-12-04**|[OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design](http://arxiv.org/abs/2512.05080)|null|基于结构的药物设计（SBDD）专注于设计与特定蛋白质口袋结合的小分子配体。计算方法在现代SBDD工作流程中不可或缺，并常通过分子对接或药效团搜索等虚拟筛选方法加以利用。现代生成建模方法致力于通过从头设计来改进新型配体发现。在这项工作中，我们认识到这些任务共享一个共同结构，因此可以被表示为一致生成建模框架的不同实例化。我们提出了OMTRA中的统一方法，OMTRA是一个多模态流匹配模型，它灵活地执行许多与SBDD相关的任务，包括一些在传统工作流程中没有对应物的任务。此外，我们整理了一个包含5亿个3D分子构象的数据集，补充了蛋白质-配体数据并扩大了可用于训练的化学多样性。OMTRA在口袋条件下的从头设计和分子对接方面获得了最先进的性能；然而，大规模预训练和多任务训练的效果有限。用于重现这项工作的所有代码、训练模型和数据集可在https://github.com/gnina/OMTRA获取。|
|**2025-12-04**|[Semantic-Guided Two-Stage GAN for Face Inpainting with Hybrid Perceptual Encoding](http://arxiv.org/abs/2512.05039)|null|人脸图像修复旨在恢复人脸图像中缺失或损坏的区域，同时保留身份信息、结构一致性和照片真实感图像质量，这是一项专为照片修复而创建的任务。尽管深度生成模型最近取得了许多进展，但现有方法在处理大尺寸不规则掩码时面临问题，经常由于直接的像素级合成方法以及对人脸先验知识的有限利用，在掩码区域边缘产生模糊的纹理、语义不一致性或不自然的人脸结构。在本文中，我们提出了一种新颖的架构，通过语义引导的分层合成来解决上述挑战。我们的方法首先通过一种基于语义组织和合成信息的方法，随后进行纹理细化。这一过程为人脸结构提供了清晰的洞察，然后我们再创建详细的图像。在第一阶段，我们融合了两种技术：一种是利用CNNs关注局部特征，另一种是利用Vision Transformers关注全局特征。这有助于我们创建清晰详细的语义布局。在第二阶段，我们使用多模态纹理生成器通过整合来自不同尺度的信息来细化这些布局，确保整体的连贯性和一致性。该架构通过动态注意力机制自然地处理任意掩码配置，无需针对特定掩码进行训练。在CelebA-HQ和FFHQ这两个数据集上的实验表明，我们的模型优于其他最先进的方法，在LPIPS、PSNR和SSIM等指标上显示出改进。它在具有挑战性的大面积修复场景中产生了视觉效果显著的结果，并具有更好的语义保留性。|
|**2025-12-04**|[RAMEN: Resolution-Adjustable Multimodal Encoder for Earth Observation](http://arxiv.org/abs/2512.05025)|null|地球观测(EO)数据涵盖了广泛的空间、光谱和时间分辨率，从高分辨率光学图像到低分辨率多光谱产品或雷达时间序列。尽管最近的基础模型改进了多模态集成以学习有意义的表示，但它们通常期望固定的输入分辨率，或基于传感器特定的编码器，从而限制了在异构EO模态间的泛化能力。为克服这些限制，我们引入了RAMEN，这是一种分辨率可调的多模态编码器，它以完全与传感器无关的方式学习跨EO数据的共享视觉表示。RAMEN将模态以及空间和时间分辨率视为关键的输入数据特征，从而在统一的潜在空间中实现跨模态的连贯分析。其主要方法论贡献是将空间分辨率定义为一个可控的输出参数，赋予用户在推理时直接控制所需细节级别的能力，并允许在空间精度和计算成本之间进行明确的权衡。我们训练了一个单一的统一Transformer编码器，重构来源于不同来源的掩码多模态EO数据，从而确保了跨传感器和分辨率的泛化能力。预训练完成后，RAMEN能有效迁移到已知和未见的传感器配置，并在社区标准PANGAEA基准测试中超越了更大的最先进模型，该基准测试包含各种多传感器和多分辨率的下游任务。我们的代码和预训练模型可在https://github.com/nicolashoudre/RAMEN获取。|
|**2025-12-02**|[OneThinker: All-in-one Reasoning Model for Image and Video](http://arxiv.org/abs/2512.03043)|**[link](https://github.com/isLinXu/OneThinker)**|强化学习（RL）最近在激发多模态大语言模型（MLLMs）的视觉推理能力方面取得了显著成功。然而，现有方法通常为不同任务训练独立的模型，并将图像和视频推理视为不相干的领域。这导致了在构建多模态推理通才方面的可扩展性有限，从而限制了实际的多功能性，并阻碍了任务和模态之间潜在的知识共享。为此，我们提出了 OneThinker，这是一种一体化推理模型，它统一了图像和视频理解，涵盖了多种基本视觉任务，包括问答、图像描述生成、空间和时间定位、跟踪以及分割。为实现这一目标，我们构建了涵盖所有这些任务的 OneThinker-600k 训练语料库，并利用商业模型进行 CoT 注释，从而生成 OneThinker-SFT-340k 用于 SFT 冷启动。此外，我们提出了 EMA-GRPO，通过跟踪任务奖励标准差的移动平均值来处理多任务强化学习中的奖励异质性，以实现平衡优化。在多样化的视觉基准上进行的广泛实验表明，OneThinker 在 31 个基准上，涵盖 10 种基本视觉理解任务中展现出强大的性能。此外，它在特定任务之间展现出有效的知识迁移能力以及初步的零样本泛化能力，这标志着向统一的多模态推理通才迈进了一步。所有代码、模型和数据均已发布。|
|**2025-12-02**|[MAViD: A Multimodal Framework for Audio-Visual Dialogue Understanding and Generation](http://arxiv.org/abs/2512.03034)|null|我们提出了MAViD，一个用于视听对话理解和生成的新颖多模态框架。现有方法主要侧重于非交互式系统，并且局限于生成受限且不自然的人类语音。这项任务的主要挑战在于有效整合理解和生成能力，以及实现无缝的多模态音视频融合。为解决这些问题，我们提出了一种Conductor-Creator架构，将对话系统划分为两个主要组件。Conductor负责理解、推理并生成指令，将其分解为动作和语音组件，从而实现对交互的细粒度控制。Creator随后根据这些指令提供交互式响应。此外，为解决使用双DiT结构生成具有一致身份、音色和语调的长视频的难题，Creator采用了一种结合自回归（AR）和扩散模型的结构。AR模型负责音频生成，而扩散模型确保高质量视频生成。此外，我们提出了一种新颖的融合模块，以增强上下文连续片段和模态之间的连接，从而实现同步的长时长视听内容生成。大量实验表明，我们的框架能够生成生动且上下文连贯的长时长对话交互，并准确解释用户的多模态查询。|
|**2025-12-02**|[LORE: A Large Generative Model for Search Relevance](http://arxiv.org/abs/2512.03025)|null|我们引入了LORE，一个用于电商搜索中基于大型生成模型相关性的系统性框架。LORE历经三年部署和迭代，在在线GoodRate指标上实现了累计27%的提升。本报告分享了其开发生命周期中在数据、特征、训练、评估和部署方面获得的宝贵经验。现有工作在应用思维链（CoT）以提升相关性时，常常遇到性能瓶颈。我们认为这源于将相关性视为一个单一任务，缺乏原则性的解构。我们的关键见解是，相关性包含不同的能力：知识与推理、多模态匹配和规则遵循。我们主张，质量驱动的分解对于突破当前性能瓶颈至关重要。LORE为大型语言模型（LLM）相关性生命周期提供了一个完整蓝图。主要贡献包括：(1) 一个结合通过SFT进行的渐进式CoT合成与通过RL进行的人类偏好对齐的两阶段训练范式。(2) 一个旨在评估这些核心能力的综合基准测试RAIR。(3) 一个能够有效地将离线LLM能力转移到在线系统的查询频率分层部署策略。LORE既是一个实用解决方案，也为其他垂直领域提供了方法论参考。|
|**2025-12-02**|[DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling](http://arxiv.org/abs/2512.03000)|**[link](https://github.com/Dynamics-X/DynamicVerse)**|理解动态物理世界，其特点是不断演化的3D结构、真实世界运动以及带有文本描述的语义内容，对于人机交互至关重要，并使具身智能体能够以类似人类的能力在真实环境中感知和行动。然而，现有数据集通常源自有限的模拟器，或利用传统运动恢复结构（SfM）进行按比例标注，并提供有限的描述性字幕，这限制了基础模型从通常来源于互联网的单目视频中准确解释真实世界动态的能力。为了弥合这些差距，我们引入了DynamicVerse，一个用于动态真实世界视频的物理尺度、多模态4D世界建模框架。我们利用大型视觉模型、几何模型和多模态模型来解释米制尺度的静态几何、真实世界动态运动、实例级掩码和整体描述性字幕。通过将基于窗口的捆集调整与全局优化相结合，我们的方法将长视频序列转换为综合的4D多模态格式。DynamicVerse提供了一个大规模数据集，包含10万多段视频、80万多个标注掩码和1000万多帧来自互联网视频。在视频深度估计、相机姿态估计和相机内参估计这三项基准任务上的实验评估表明，我们的4D建模在捕获物理尺度测量方面实现了卓越的性能，并比现有方法具有更高的全局精度。|
|**2025-12-02**|[GraphFusion3D: Dynamic Graph Attention Convolution with Adaptive Cross-Modal Transformer for 3D Object Detection](http://arxiv.org/abs/2512.02991)|null|尽管三维目标检测取得了显著进展，点云仍因数据稀疏、结构不完整和语义信息有限而面临挑战。捕获远距离物体之间的上下文关系带来了额外的困难。为了解决这些挑战，我们提出了GraphFusion3D，一个结合了多模态融合和先进特征学习的统一框架。我们的方法引入了自适应跨模态Transformer (ACMT)，它自适应地将图像特征整合到点表示中，以丰富几何和语义信息。对于候选区域细化，我们引入了图推理模块 (GRM)，这是一种新颖的机制，它通过建模邻域关系同时捕获局部几何结构和全局语义上下文。该模块采用多尺度图注意力机制，动态地权衡候选区域之间的空间接近度和特征相似度。我们进一步采用级联解码器，通过多阶段预测逐步细化检测结果。在SUN RGB-D (70.6% AP $_{25}$和51.2% AP$_{50}$) 和ScanNetV2 (75.1% AP$_{25}$和60.8% AP$_{50}$ ) 上的大量实验表明，与现有方法相比，性能有显著提升。|
|**2025-12-02**|[InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration](http://arxiv.org/abs/2512.02981)|null|幻觉仍然是大型语言模型（LLM）中的一个关键挑战，阻碍了可靠的多模态大型语言模型（MLLM）的发展。现有解决方案通常依赖人工干预，或未充分利用智能体自主缓解幻觉的能力。为了解决这些局限性，我们从人类在现实世界中如何做出可靠决策中汲取灵感。他们首先通过内省推理来减少不确定性并形成初步判断，然后依赖来自多样化视角的外部验证来做出最终决策。受此认知范式启发，我们提出了InEx，一个无需训练的多智能体框架，旨在自主缓解幻觉。InEx引入了内部内省推理，以基于熵的不确定性估计为指导，从而提高了决策智能体推理过程的可靠性。智能体首先生成一个响应，随后通过与编辑智能体和自我反思智能体进行外部跨模态多智能体协作，对该响应进行迭代验证和完善，进一步增强了可靠性并缓解了幻觉。大量实验表明，InEx持续优于现有方法，在通用和幻觉基准上取得了4%-27%的提升，并表现出强大的鲁棒性。|
|**2025-12-02**|[Contextual Image Attack: How Visual Context Exposes Multimodal Safety Vulnerabilities](http://arxiv.org/abs/2512.02973)|null|尽管多模态大语言模型 (MLLMs) 展现出卓越的能力，但它们的安全对齐容易受到越狱攻击。现有攻击方法通常侧重于文本-图像交互，将视觉模态视为次要提示。这种方法未充分利用图像承载复杂上下文信息的独特潜力。为弥补这一不足，我们提出了一种新的以图像为中心的攻击方法——上下文图像攻击 (CIA)，该方法采用多智能体系统，利用四种不同的可视化策略，巧妙地将有害查询嵌入到看似良性的视觉上下文。为进一步增强攻击效果，该系统整合了上下文元素增强和自动毒性混淆技术。在MMSafetyBench-tiny数据集上的实验结果表明，CIA分别针对GPT-4o和Qwen2.5-VL-72B模型实现了4.73和4.83的高毒性分数，攻击成功率 (ASR) 分别达到86.31\%和91.07\%。我们的方法显著优于现有工作，证明视觉模态本身是越狱高级MLLMs的强大载体。|
|**2025-12-02**|[Lumos: Let there be Language Model System Certification](http://arxiv.org/abs/2512.02966)|null|我们引入了首个基于原理的框架Lumos，用于规范和形式化认证语言模型系统（LMS）的行为。Lumos是一种基于图的命令式概率编程DSL，具有用于为LMS生成独立同分布提示的构造。它通过图提供了提示分布的结构化视图，从采样的子图生成随机提示。Lumos通过与统计认证器集成，支持对任意提示分布下的LMS进行认证。我们为Lumos提供了混合（操作和指称）语义，从而提供了一种严格解释这些规范的方法。Lumos仅使用一小组可组合的构造，即可编码现有的LMS规范，包括复杂的关系和时间规范。它也促进了新属性的规范——我们提出了使用Lumos开发的、用于自动驾驶场景中视觉语言模型（VLM）的首个安全规范。利用这些规范，我们表明最先进的VLM Qwen-VL在雨天驾驶条件下的右转场景中，以至少90%的概率产生不正确和不安全的响应，表现出严重的安全故障，揭示了巨大的安全风险。Lumos的模块化结构允许轻松修改规范，使LMS认证能够跟上快速演变的威胁环境。我们进一步证明，用Lumos编写的规范程序能够发现最先进LMS所表现出的特定故障案例。Lumos是首个系统性、可扩展的基于语言的框架，用于规范和认证LMS行为，为LMS认证的更广泛采用铺平了道路。|
|**2025-12-02**|[Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench](http://arxiv.org/abs/2512.02942)|null|视频生成领域的下一个前沿在于开发具备零样本推理能力的模型，在此过程中，理解真实世界的科学定律对于在不同条件下准确模拟物理结果至关重要。然而，现有的视频基准测试多基于物理常识，对视频模型的科学推理能力提供的洞察有限。我们引入了VideoScience-Bench，一个旨在评估视频模型在本科级别科学理解能力的基准测试。每个提示都编码了一个复合科学场景，需要理解和推理多个科学概念才能生成正确的现象。该基准测试包含200个精心策划的提示，涵盖物理和化学领域的14个主题和103个概念。我们对七个最先进的视频模型在文本到视频(T2V)和图像到视频(I2V)设置下进行了专家标注评估，评估维度包括五个方面：提示一致性、现象一致性、正确动态性、不变性和时空连续性。利用VLM（视觉语言模型）作为评估者来评估视频生成结果，我们观察到其与人类评估结果之间存在很强的相关性。据我们所知，VideoScience-Bench是第一个基准测试，它不仅将视频模型评估为生成器，还评估为推理器，要求其生成结果展现出与预期的物理和化学现象保持一致的科学理解能力。我们的数据和评估代码可在以下网址获取：github.com/hao-ai-lab/VideoScience。|
|**2025-12-02**|[AutoNeural: Co-Designing Vision-Language Models for NPU Inference](http://arxiv.org/abs/2512.02924)|null|尽管神经网络处理器 (NPU) 为边缘AI提供了高理论效率，但针对GPU优化的最先进视觉-语言模型 (VLM) 在这些基板上往往表现不佳。我们将这种硬件-模型不匹配归因于两个主要因素：视觉Transformer (ViT) 的量化脆弱性，以及自回归注意力机制的I/O密集型特性，后者未能充分利用NPU的高算术吞吐量。为了弥合这一差距，我们提出了AutoNeural，这是一种NPU原生的VLM架构，协同设计用于纯整数推理。我们用一个利用深度可分离卷积的MobileNetV5风格主干网络取代了标准ViT编码器，这确保了有界激活分布，从而实现稳定的INT4/8/16量化。作为补充，我们的语言主干网络将状态空间模型 (SSM) 原理与Transformer层相结合，采用高效门控卷积以实现线性时间复杂度。这种混合设计消除了生成过程中键值缓存带来的沉重内存I/O开销。我们的方法带来了显著的效率提升，与传统基线相比，将视觉编码器的量化误差降低了高达7倍，端到端延迟降低了14倍。AutoNeural还提供了比基线快3倍的解码速度和长4倍的上下文窗口。我们通过在高通SA8295P SoC上进行的真实世界汽车案例研究验证了这些改进，展示了其在座舱应用中的实时性能。我们的结果强调，针对NPU限制重新思考模型拓扑结构是实现鲁棒多模态边缘智能的先决条件。|
|**2025-11-28**|[Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models](http://arxiv.org/abs/2511.23478)|**[link](https://github.com/mbzuai-oryx/Video-R2)**|对动态视觉内容进行推理仍然是多模态大型语言模型的核心挑战。近期思维模型生成显式推理轨迹以提高可解释性；然而，它们的推理结果往往看似令人信服，但在逻辑上不一致或视觉证据支持不足。我们通过两种诊断指标识别并形式化了这些问题：思维答案一致性 (TAC) 衡量推理与答案之间的一致性，以及视频注意力分数 (VAS) 捕捉推理在多大程度上依赖于视觉而非文本线索。对11个视频推理基准的分析表明，当前模型严重依赖语言先验知识而非视觉内容。为了解决这个问题，我们提出了一种强化学习方法，该方法能同时增强时间精度和推理一致性。我们的方法将时间戳感知监督微调与由新颖的时间对齐奖励 (TAR) 指导的群组相对策略优化 (GRPO) 相结合。这种双步后训练阶段鼓励实现时间上对齐且因果连贯的视频推理。得到的模型Video R2在多个基准上持续实现更高的TAC、VAS和准确性，证明了时间对齐和推理连贯性的改进能够带来更准确、更值得信赖的视频理解。我们的代码、数据集和模型将会开源。|
|**2025-11-28**|[Video-CoM: Interactive Video Reasoning via Chain of Manipulations](http://arxiv.org/abs/2511.23477)|**[link](https://github.com/mbzuai-oryx/Video-CoM)**|近期的多模态大语言模型（MLLMs）在视频理解方面取得了进展，但大多数模型仍停留在“思考视频”的阶段，即视频一旦编码，推理便完全在文本中展开，将视觉输入视为静态上下文。这种被动范式造成了语义瓶颈：模型无法重新观看、重新聚焦或验证证据，导致在需要细粒度时空理解的任务上表现出浅层视觉推理。在这项工作中，我们引入了交互式视频推理，这是一种将视频转化为活跃认知工作空间的新范式，使模型能够“与视频一起思考”。我们的模型Video CoM通过操纵链（CoM）进行推理，执行迭代视觉动作来收集和完善证据。为了支持这种行为，我们构建了Video CoM Instruct，一个包含1.8万个指令的微调数据集，专门用于多步操纵推理。除了监督学习，我们还通过强化学习，结合具备推理意识的群组相对策略优化（GRPO）来进一步优化操纵策略。与仅依赖稀疏答案奖励的先前工作不同，我们的方法引入了步级推理奖励，引导模型进行有依据且一致的推理。Video CoM在九个视频推理基准上取得了优异结果，相较于近期的最先进模型，平均性能提升了3.6%，而训练仅使用了2.5万个监督微调（SFT）和3千个GRPO视频样本，显著少于可比较的大规模模型。消融研究表明，具备推理意识的奖励能同时提高准确性和可解释性。代码：https://github.com/mbzuai-oryx/Video-CoM|
|**2025-11-28**|[Visual Generation Tuning](http://arxiv.org/abs/2511.23469)|**[link](https://github.com/ali-vilab/FreeScale)**|大型视觉语言模型（VLMs）通过大规模预训练有效地弥合了模态鸿沟，学习了与语言对齐的复杂视觉表示。然而，这些为多模态理解任务优化的表示是否蕴藏着视觉生成的内在潜力，这一点尚未得到充分探索。在本文中，我们提出了VGT（视觉生成微调），这是一种旨在激发任何视觉语言模型中潜在视觉生成能力的新范式。通过对预训练良好的VLM进行高效的视觉生成微调，我们显著降低了对齐成本，并加速了连续空间中自回归建模的收敛（20倍加速）。具体来说，我们摒弃了为扩散Transformer设计的纠缠像素级VAE，并通过将预训练VLM中的语义编码器与像素解码器的潜在表示对齐来构建VGT-AE。在图像重建任务中，我们在28倍压缩比下实现了26.67的PSNR和0.50的rFID，优于专门的VAE；在视觉生成任务中，我们在自回归模型中取得了最先进的结果，在GenEval上达到0.77，在DPG-Bench上达到78.73。此外，我们提出的VGT展现了显著的扩展潜力，并且能够灵活地赋予任何为多模态理解训练的VLM以视觉生成能力，这为探索下一代统一多模态基础模型开辟了新途径。模型和代码可在https://github.com/hustvl/VGT 获取。|
|**2025-11-28**|[LFM2 Technical Report](http://arxiv.org/abs/2511.23404)|null|我们提出了LFM2，一个流动基础模型家族，专为高效设备端部署和强大的任务能力而设计。通过在边缘延迟和内存约束下使用硬件在环架构搜索，我们获得了一个紧凑的混合骨干网络，它结合了门控短卷积和少量分组查询注意力块，与同等大小的模型相比，在CPU上预填充和解码速度提高了高达2倍。LFM2家族涵盖3.5亿至83亿参数，包括密集模型（3.5亿、7亿、12亿、26亿）和专家混合（MoE）变体（总参数83亿，活跃参数15亿），所有模型均具有32K的上下文长度。LFM2的训练流程包括一个经过调整的、解耦的Top-K知识蒸馏目标，以避免分布不匹配；采用难度排序数据的课程学习；以及一个三阶段后训练方案，包括有监督微调、长度归一化偏好优化和模型合并。经过10-12万亿（T）tokens的预训练，LFM2模型在各种基准测试中取得了强大成果；例如，LFM2-2.6B在IFEval上达到79.56%，在GSM8K上达到82.41%。我们进一步构建了多模态和检索变体：用于视觉-语言任务的LFM2-VL、用于语音的LFM2-Audio和用于检索的LFM2-ColBERT。LFM2-VL通过令牌高效的视觉处理支持可调的准确性-延迟权衡，而LFM2-Audio分离了音频输入和输出路径，实现了与大3倍模型媲美的实时语音到语音交互。LFM2-ColBERT为查询和文档提供了低延迟编码器，实现了多语言高性能检索。所有模型均以开放权重和ExecuTorch、llama.cpp、vLLM的部署包发布，使LFM2成为需要快速、内存高效推理和强大任务能力的边缘应用的实用基础。|
|**2025-11-28**|[Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning](http://arxiv.org/abs/2511.23402)|null|拆分学习是一种广为人知的方法，通过在分布式设备上训练模型来解决数据隐私问题，从而避免了引发隐私问题的数据共享。然而，高昂的网络通信成本始终是拆分学习的一个障碍，特别是对于需要传输大量高维数据的大型基础模型。为了解决这个问题，我们提出了一种新的多模态模型结构，它结合了基于学习的数据压缩方法，将模型嵌入压缩成低位整数，同时保持了模型的性能，从而大幅降低了分区间的传输成本。然后，我们基于熵编码的扎实理论基础，确定了离散表示级别的最佳数量。|
|**2025-11-28**|[VQRAE: Representation Quantization Autoencoders for Multimodal Understanding, Generation and Reconstruction](http://arxiv.org/abs/2511.23386)|null|在单个分词器中统一多模态理解、生成和重建表示仍然是构建统一模型的一个关键挑战。此前研究主要尝试在双编码器范式中解决此问题，例如分别利用独立的编码器进行理解和生成，或通过对比损失平衡语义表示和低级特征。在本文中，我们提出了VQRAE，一种表示自编码器的矢量量化版本，它首次探索在统一的分词器内生成用于图像理解的连续语义特征和用于视觉生成的离散token的统一表示。具体而言，我们基于预训练的视觉基础模型，采用对称的ViT解码器，并采用两阶段训练策略：首先，它冻结编码器并以像素重建为目标学习高维语义VQ码本；然后联合优化编码器并施加自蒸馏约束。这种设计使得语义信息损失可忽略不计，从而保持多模态理解能力，并能生成兼容生成的离散token和进行细粒度重建。此外，我们发现在量化语义编码器中存在一个有趣的特性，即它们依赖于高维码本，这与此前图像重建中常用的低维码本实践形成对比。语义VQ码本可以在1536维下实现100%的利用率。VQRAE在视觉理解、生成和重建的多个基准测试中表现出有竞争力的性能，并因其离散的优点在自回归范式中展现出良好的扩展性。|
|**2025-11-28**|[DEAL-300K: Diffusion-based Editing Area Localization with a 300K-Scale Dataset and Frequency-Prompted Baseline](http://arxiv.org/abs/2511.23377)|**[link](https://github.com/ymhzyj/DEAL-300K)**|基于扩散的图像编辑使普通用户能够轻松进行语义级图像操纵，但它也使得难以定位的真实局部伪造成为可能。现有基准主要侧重于生成图像的二分类检测或手动编辑区域的定位，未能反映基于扩散的编辑特性，这些编辑通常与原始内容平滑融合。我们提出了基于扩散的图像编辑区域定位数据集（DEAL-300K），这是一个用于基于扩散的图像操纵定位（DIML）的大规模数据集，包含超过300,000张带标注的图像。我们通过使用多模态大型语言模型生成编辑指令、无掩码扩散编辑器生成被操纵图像以及主动学习变化检测流程获取像素级标注来构建DEAL-300K。在此数据集的基础上，我们提出了一个定位框架，该框架结合了冻结的视觉基础模型（VFM）和多频提示调优（MFPT），以捕获编辑区域的语义和频域线索。在DEAL-300K上训练后，我们的方法在我们的测试集上达到了82.56%的像素级F1分数，并在外部CoCoGlide基准上达到了80.97%，为未来的DIML研究提供了强大的基线和实用基础。该数据集可通过https://github.com/ymhzyj/DEAL-300K访问。|
|**2025-11-28**|[Optimizing Multimodal Language Models through Attention-based Interpretability](http://arxiv.org/abs/2511.23375)|null|现代大型语言模型变得多模态，能够分析文本和图像等各种数据格式。尽管微调对于使多模态语言模型（MLM）适应下游任务非常有效，但全量微调的计算成本很高。参数高效微调（PEFT）方法通过仅训练模型权重的一小部分来解决此问题。然而，MLM难以解释，这使得识别哪些组件对于训练最有效以平衡效率和性能变得具有挑战性。我们提出了一种基于注意力的MLM可解释性方法，通过分析相对于图像token的注意力分数来实现。核心思想是识别专注于图像关键对象的注意力头。我们利用这些信息来选择多模态模型中用于PEFT的最优模型组件。我们的贡献包括一种识别与图像关键对象相关的注意力头的方法、其在图像字幕PEFT中的应用，以及创建一个包含图像、关键对象掩码及其文本描述的新数据集。我们在具有2-30亿参数的MLM上进行了实验，以验证该方法的有效性。通过计算头影响力（HI）分数，我们量化了一个注意力头对关键对象的关注程度，表明其在图像理解中的重要性。我们的微调实验表明，与预训练的、随机选择的或HI分数最低的层相比，调整具有最高HI分数的层会导致指标最显著的变化。这表明，在这些关键层中微调一小部分（约0.01%）参数可以显著影响图像理解能力。|
|**2025-11-28**|[Chart2Code-MoLA: Efficient Multi-Modal Code Generation via Adaptive Expert Routing](http://arxiv.org/abs/2511.23321)|null|图表到代码生成是自动化数据可视化中的一项关键任务，它将复杂的图表结构转换为可执行程序。尽管最近的多模态大语言模型（MLLMs）提升了图表表示能力，但现有方法在实现跨类型泛化、内存效率和模块化设计方面仍面临挑战。为解决这些挑战，本文提出了 C2C-MoLA，这是一个结合了专家混合（MoE）和低秩适应（LoRA）的多模态框架。MoE 组件采用复杂度感知路由机制，通过领域专业专家和负载均衡的稀疏门控，根据可学习的结构度量（如元素数量和图表复杂度）动态分配输入。LoRA 实现了参数高效的更新，适用于资源受限的微调，并通过量身定制的训练策略进一步支持，该策略使路由稳定性与语义准确性保持一致。在 Chart2Code-160k 上的实验表明，与标准微调和仅 LoRA 基线相比，所提出的模型将生成准确率提高了高达 17%，峰值 GPU 内存减少了 18%，收敛速度加快了 20%，尤其是在复杂图表上表现更佳。消融研究验证了最优设计，例如 8 个专家和秩为 8 的 LoRA，并证实了其在真实世界多模态代码生成中的可扩展性。|
|**2025-11-28**|[Toward Automatic Safe Driving Instruction: A Large-Scale Vision Language Model Approach](http://arxiv.org/abs/2511.23311)|null|大规模视觉语言模型（LVLMs）在需要视觉信息的任务（包括目标检测）中展现出先进能力。这些能力在各种工业领域（例如自动驾驶）中具有广阔的应用前景。例如，LVLMs可以生成由面向道路的摄像头捕获的视频的面向安全的描述。然而，确保全面安全也需要监控面向驾驶员的视图，以检测危险事件，例如驾驶时使用手机。因此，处理来自面向驾驶员和面向道路的摄像头同步输入的能力是必要的。在本研究中，我们通过构建一个数据集并在该数据集上评估LVLMs的性能，从而开发了模型并研究了LVLMs的能力。我们的实验结果表明，尽管预训练的LVLMs效果有限，但微调后的LVLMs可以生成准确且具有安全意识的驾驶指令。尽管如此，仍然存在一些挑战，尤其是在视频中检测细微或复杂的事件方面。我们的发现和错误分析提供了宝贵的见解，可以促进该领域基于LVLM的系统的改进。|
|**2025-11-26**|[Canvas-to-Image: Compositional Image Generation with Multimodal Controls](http://arxiv.org/abs/2511.21691)|**[link](https://github.com/snap-research/canvas-to-image)**|尽管现代扩散模型在生成高质量和多样化图像方面表现出色，但它们在实现高保真构图和多模态控制方面仍然面临挑战，尤其是在用户同时指定文本提示、主体参考、空间布局、姿态约束和布局标注时。我们引入了Canvas-to-Image，这是一个统一的框架，它将这些异构控制整合到一个单一的画布界面中，使用户能够生成忠实反映其意图的图像。我们的核心思想是将多样化的控制信号编码到一个单一的复合画布图像中，模型可以直接解释该图像以实现集成的视觉空间推理。我们进一步整理了一套多任务数据集，并提出了一种多任务画布训练策略，该策略优化扩散模型，使其在一个统一的学习范式内联合理解并将异构控制整合到文本到图像生成中。这种联合训练使Canvas-to-Image能够跨多个控制模态进行推理，而不是依赖于特定任务的启发式方法，并且它在推理过程中能够很好地泛化到多控制场景。大量实验表明，Canvas-to-Image在身份保留和控制依从性方面显著优于最先进的方法，并在包括多人构图、姿态控制构图、布局约束生成和多控制生成等具有挑战性的基准测试中表现出色。|
|**2025-11-26**|[G $^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning](http://arxiv.org/abs/2511.21688)|null|视觉-语言模型（VLM）在空间智能方面仍然缺乏鲁棒性，在空间理解和推理任务上表现不佳。我们将这一差距归因于缺乏能够从2D图像重建3D空间的视觉几何学习过程。我们提出了G$^2$VLM，一个基于几何的视觉-语言模型，它弥合了空间智能的两个基本方面：空间3D重建和空间理解。G$^2$VLM原生利用学习到的3D视觉几何特征，直接预测3D属性，并通过上下文学习和交错推理增强空间推理任务。我们统一的设计对于空间理解具有高度可扩展性：它在丰富的多视图图像和视频数据上进行训练，同时利用通常只能从难以收集的标注中获得的3D视觉先验的优势。实验结果表明，G$^2$VLM在这两项任务中都表现出色，取得了与最先进的前馈3D重建模型相当的结果，并在空间理解和推理任务中取得了更好或具有竞争力的结果。通过将语义强大的VLM与低级3D视觉任务相结合，我们希望G$^2$ VLM能为社区提供一个强大的基线，并开启更多未来的应用，例如3D场景编辑。|
|**2025-11-26**|[Agentic Learner with Grow-and-Refine Multimodal Semantic Memory](http://arxiv.org/abs/2511.21678)|**[link](https://github.com/weihao-bo/ViLoMem)**|多模态大语言模型（MLLM）在独立查询上展现出强大的推理能力，但它们通常从头开始运行——独立解决每个问题，并经常重复犯同样的错误。现有的记忆增强型智能体主要存储过去的轨迹以供重用。然而，基于轨迹的记忆存在简洁性偏差，会逐渐丢失重要的领域知识。更关键的是，即使在真正的多模态问题解决场景中，它也只记录了过去行为的单模态痕迹，未能保留视觉注意力和逻辑推理如何共同促成解决方案。这与人类认知从根本上不符：语义记忆既是多模态的又是整合的，通过协调但独立的表征流保留视觉和抽象知识。因此，我们引入了ViLoMem，一个双流记忆框架，它构建紧凑的、基于模式的记忆。它分别编码视觉干扰模式和逻辑推理错误，使多模态大语言模型能够从其成功和失败的经验中学习。遵循增长-精炼原则，该系统逐步积累和更新多模态语义知识——在保留稳定、可泛化策略的同时，避免了灾难性遗忘。在六个多模态基准测试中，ViLoMem持续提升了pass@1准确率，并大幅减少了重复的视觉和逻辑错误。消融实验证实了具有明确干扰-幻觉分离的双流记忆的必要性，展示了错误感知的多模态记忆对于终身和跨领域智能体学习的价值。我们的项目页面将发布在 https://weihao-bo.github.io/ViLoMeo-page。|
|**2025-11-26**|[Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models](http://arxiv.org/abs/2511.21663)|null|近年来，具身智能领域的视觉-语言-动作（VLA）模型发展迅速。然而，现有的对抗攻击方法需要成本高昂的端到端训练，并且通常会产生明显的扰动补丁。为解决这些局限性，我们提出了ADVLA，一个直接将从视觉编码器投影到文本特征空间的特征施加对抗性扰动的框架。ADVLA在低幅度约束下能有效扰乱下游动作预测，并且通过注意力引导使扰动既集中又稀疏。我们引入了三种策略来增强敏感性、强制稀疏性并集中扰动。实验表明，在 $L_{\infty}=4/255$ 约束下，ADVLA结合Top-K掩码修改了不到10%的补丁，同时实现了近100%的攻击成功率。这些扰动集中在关键区域，在整体图像中几乎不可察觉，并且单步迭代仅需约0.06秒，显著优于传统的基于补丁的攻击。总之，ADVLA在低幅度和局部稀疏条件下有效削弱了VLA模型的下游动作预测，避免了传统补丁攻击的高训练成本和显眼扰动，并展示了攻击VLA特征空间的独特有效性和实用价值。|
|**2025-11-26**|[Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following](http://arxiv.org/abs/2511.21662)|**[link](https://github.com/multi-crit/multi-crit.github.io)**|大型多模态模型（LMMs）因其强大的指令遵循能力和与人类偏好的一致性，正越来越多地被采纳为多模态评估系统中的评判员。然而，它们遵循多样化、细粒度评估标准的能力仍未得到充分探索。我们开发了Multi-Crit，一个用于评估多模态评判员遵循多元化标准并产生可靠标准级判断能力的基准。Multi-Crit涵盖了开放式生成和可验证推理任务，通过一个严格的数据整理流程构建，该流程收集了带有多个标准人工标注的具有挑战性的响应对。它进一步引入了三个新颖的指标，用于系统地评估多元化遵循能力、标准切换灵活性以及识别标准级偏好冲突的能力。对25个LMM进行全面分析表明：1）专有模型在维持对多元化标准的一致遵循方面仍然面临困难——尤其是在开放式评估中；2）开源模型在灵活遵循多样化标准方面进一步落后；3）使用整体判断信号的评判器微调增强了视觉基础能力，但未能泛化到多元化标准级判断。对推理微调、测试时扩展以及开源模型和专有模型之间边界一致性的额外分析，进一步探究了当前多模态评判员的局限性。作为一项开创性研究，Multi-Crit为构建可靠且可控的多模态AI评估奠定了基础。|
|**2025-11-26**|[Qwen3-VL Technical Report](http://arxiv.org/abs/2511.21631)|null|我们介绍了Qwen3-VL，它是迄今为止通义千问系列中最强大的视觉语言模型，在广泛的多模态基准测试中取得了卓越性能。它原生支持高达256K词元的交错上下文，无缝整合文本、图像和视频。该模型家族包含稠密型（2B/4B/8B/32B）和专家混合（30B-A3B/235B-A22B）两种变体，以适应不同的延迟-质量权衡需求。Qwen3-VL具备三大核心支柱：(i) 显著更强的纯文本理解能力，在某些情况下超越了可比的纯文本骨干模型；(ii) 强大的长上下文理解能力，为文本和交错多模态输入提供原生256K词元窗口，能够忠实地保留、检索和交叉引用长文档和视频；以及(iii) 跨单图、多图和视频任务的高级多模态推理能力，在MMMU和视觉-数学基准（例如MathVista和MathVision）等综合评估中表现出领先性能。在架构上，我们引入了三项关键升级：(i) 增强型交错MRoPE，用于在图像和视频中实现更强的时空建模；(ii) DeepStack集成，有效利用多层ViT特征来加强视觉-语言对齐；以及(iii) 基于文本的视频时间对齐，从T-RoPE发展为显式文本时间戳对齐，以实现更精确的时间定位。在可比的词元预算和延迟限制下，Qwen3-VL在稠密和专家混合（MoE）两种架构中均实现了卓越性能。我们设想Qwen3-VL将作为实际工作流中基于图像的推理、智能体决策和多模态代码智能的基础引擎。|
|**2025-11-26**|[Automated Protein Motif Localization using Concept Activation Vectors in Protein Language Model Embedding Space](http://arxiv.org/abs/2511.21614)|null|我们提出了一种自动化方法，用于识别和注释蛋白质序列中的基序和结构域，该方法使用预训练蛋白质语言模型（PLM）和概念激活向量（CAV），后者借鉴自计算机视觉领域的可解释性研究。我们将基序视为概念实体，并通过训练简单的线性分类器来区分包含基序的序列和不含基序的序列，从而在PLM嵌入空间中通过学习到的CAV来表示这些基序。为了识别基序出现位置，我们提取重叠序列窗口的嵌入，并计算它们与基序CAV的内积。这种评分机制量化了每个序列区域表达基序概念的强度，并能自然地检测出同一蛋白质中同一基序的多个实例。使用一个包含六十九个特征明确的基序数据集，该数据集带有经过整理的阳性和阴性样本，我们的方法对于强烈表达该概念的片段实现了超过85%的F1分数，并能准确地定位跨越不同蛋白质家族的基序位置。由于每个基序都由一个单一向量编码，基序检测仅需要预训练PLM和一个轻量级的CAV字典，从而为自动化序列注释提供了一个可扩展、可解释且计算高效的框架。|
|**2025-11-26**|[Multimodal Robust Prompt Distillation for 3D Point Cloud Models](http://arxiv.org/abs/2511.21574)|**[link](https://github.com/eminentgu/MRPD)**|对抗性攻击对基于学习的3D点云模型构成了重大威胁，严重损害了它们在安全敏感应用中的可靠性。现有防御方法普遍存在(1)高计算开销和(2)对多样化攻击类型泛化能力差的问题。为弥补这些不足，我们提出了一种新颖而高效的教师-学生框架，即多模态鲁棒提示蒸馏（MRPD），用于蒸馏鲁棒3D点云模型。它通过将学生点云模型的特征与来自三个不同教师模型的鲁棒嵌入对齐来学习轻量级提示，这三个教师模型分别是：一个处理深度投影的视觉模型、一个高性能3D模型和一个文本编码器。为确保可靠的知识迁移，这种蒸馏由一个置信度门控机制引导，该机制动态平衡所有输入模态的贡献。值得注意的是，由于蒸馏完全在训练阶段进行，推理时没有额外的计算开销。大量实验表明，MRPD在应对广泛的白盒和黑盒攻击方面显著优于最先进的防御方法，甚至在干净数据上实现了更好的性能。我们的工作提出了一种通过高效利用多模态知识构建鲁棒3D视觉系统的新颖实用范式。|
|**2025-11-26**|[VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation](http://arxiv.org/abs/2511.21557)|null|视觉-语言-动作模型通过利用大规模预训练的视觉和语言表征，显著推动了通用机器人操作的发展。在现有方法中，大多数当前的VLA系统采用平行双指夹持器作为其默认末端执行器。然而，此类夹持器在处理某些现实世界任务时面临固有局限性，例如擦拭玻璃表面或打开无把手抽屉，原因在于接触面积不足或缺乏附着力。为了克服这些挑战，我们提出了一种低成本的集成硬件设计，它将机械双指夹持器与真空吸盘单元相结合，在单个末端执行器内实现了双模态操作。我们的系统支持两种模态的灵活切换或协同使用，扩展了可行任务的范围。我们在DexVLA和Pi0这两个最先进的VLA框架中验证了我们设计的效率和实用性。实验结果表明，采用所提出的混合末端执行器，机器人可以成功执行多个仅靠传统双指夹持器无法完成的复杂任务。所有硬件设计和控制系统都将被发布。|
|**2025-11-26**|[ $\mathcal{E}_0$ : Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion](http://arxiv.org/abs/2511.21542)|null|视觉-语言-动作 (VLA) 模型通过整合视觉感知、语言理解和控制生成，为机器人操作提供了一个统一框架。然而，现有VLA模型在泛化到不同任务、场景和摄像机视角方面仍面临挑战，并且经常产生粗糙或不稳定的动作。我们引入了E0，一个连续化的离散扩散框架，它将动作生成表述为对量化动作令牌的迭代去噪。与连续扩散策略相比，E0具有两个关键优势：(1) 离散动作令牌与预训练VLM/VLA骨干网络的符号结构自然对齐，从而实现更强的语义条件作用；(2) 离散扩散与真实世界机器人控制的固有量化特性相匹配——其硬件约束（例如，编码器分辨率、控制频率、执行延迟）本质上离散化了连续信号——因此受益于能够建模正确离散动作分布的贝叶斯最优去噪器，从而实现更强的泛化能力。与离散自回归和基于掩码的离散扩散模型相比，E0支持显著更大、更细粒度的动作词汇，并避免了基于掩码的损坏引入的分布不匹配，从而实现更精确的细粒度动作控制。我们进一步引入了一种球形视角扰动增强方法，以在不使用额外数据的情况下提高对摄像机位移的鲁棒性。在LIBERO、VLABench和ManiSkill上的实验表明，E0在14个不同环境中均实现了最先进的性能，平均超越强大基线10.7%。在Franka机械臂上的真实世界评估证实，E0提供了精确、鲁棒和可迁移的操作，将离散扩散确立为可泛化VLA策略学习的一个有前景的方向。|
|**2025-11-25**|[RubricRL: Simple Generalizable Rewards for Text-to-Image Generation](http://arxiv.org/abs/2511.20651)|null|强化学习（RL）近期已成为一种很有前途的方法，用于使文本到图像生成模型与人类偏好对齐。然而，一个关键挑战在于设计有效且可解释的奖励。现有方法通常依赖于具有固定权重的复合指标（例如，CLIP、OCR和真实感分数），或者从人类偏好模型中提炼出的单一标量奖励，这会限制可解释性和灵活性。我们提出了RubricRL，一个简单且通用的基于评分标准的奖励设计框架，它提供了更强的可解释性、可组合性和用户控制。RubricRL没有使用黑盒标量信号，而是为每个提示动态构建一个结构化的评分标准——一个可分解的细粒度视觉标准清单，例如物体正确性、属性准确性、OCR保真度和真实感——并根据输入文本量身定制。每个标准都由一个多模态判断器（例如o4-mini）独立评估，并且一个提示自适应的加权机制强调最相关的维度。这种设计不仅为策略优化（例如GRPO或PPO）产生了可解释和模块化的监督信号，而且还使用户能够直接调整奖励或惩罚哪些方面。使用自回归文本到图像模型进行的实验表明，RubricRL改进了提示忠实度、视觉细节和泛化能力，同时为跨文本到图像架构的可解释RL对齐提供了一个灵活且可扩展的基础。|
|**2025-11-25**|[MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities](http://arxiv.org/abs/2511.20650)|**[link](https://github.com/toobatehreem/MedROV)**|传统的医学影像目标检测模型在封闭集范式下运行，限制了它们检测新标签对象的能力。开放词汇目标检测（OVOD）解决了这一限制，但由于数据集稀缺和弱文本-图像对齐，其在医学影像领域仍未得到充分探索。为了弥合这一差距，我们引入了MedROV，这是首个用于医学影像的实时开放词汇检测模型。为了实现开放词汇学习，我们构建了一个大规模数据集Omnis，包含九种成像模态的60万个检测样本，并引入了一种伪标签策略来处理多源数据集中缺失的标注。此外，我们通过整合来自大型预训练基础模型的知识来增强泛化能力。通过利用对比学习和跨模态表示，MedROV能够有效检测已知和新颖的结构。实验结果表明，MedROV的平均绝对提升达到40 mAP50，优于先前最先进的医学图像检测基础模型，并且超越封闭集检测器3 mAP50以上，同时以70 FPS的速度运行，在医学检测领域树立了新的基准。我们的源代码、数据集和训练模型可在https://github.com/toobatehreem/MedROV获取。|
|**2025-11-25**|[LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight](http://arxiv.org/abs/2511.20648)|null|模型若要在世界中行动，必须能够识别其所见，并了解其在3D空间中的位置。当前的视觉-语言模型 (VLM) 擅长开放式2D描述和定位，但多目标3D检测在VLM工具箱中仍大部分缺失。我们提出了LocateAnything3D，这是一种VLM原生方案，将3D检测视为一个下一词元预测问题。关键在于一个简短、明确的“视觉链 (Chain-of-Sight, CoS)”序列，它模仿了人类从图像中推理的方式：在2D中找到一个物体，然后推断其距离、大小和姿态。解码器首先输出2D检测结果作为“视觉思维链”，然后在一个由易到难的课程下预测3D边界框：对于不同物体，采用从近到远的顺序减少早期歧义并符合以自我为中心的实用性；在每个物体内部，通过“从相机中心、尺寸和旋转”的分解，根据稳定性和可学习性对信息进行排序。这种VLM原生接口保留了开放词汇和视觉提示能力，无需专门的头部。在富有挑战性的Omni3D基准测试中，我们的模型取得了最先进的结果，达到49.89 AP_3D，绝对提升了15.51，超越了此前的最佳成绩，即使基线模型提供了真实2D边界框。它还能够零样本泛化到未见过的类别，具有强大的鲁棒性。通过将3D检测转化为一个规范的下一词元问题，LocateAnything3D为模型在3D空间中感知提供了实用的基础。|
|**2025-11-25**|[Vision-Language Memory for Spatial Reasoning](http://arxiv.org/abs/2511.20644)|null|空间推理是智能机器人的一个关键能力，然而，当前的视觉-语言模型（VLM）在基于视频的空间推理方面仍未达到人类水平的性能。这种差距主要源于两个挑战：阻碍了一致3D理解的语义-几何错位，以及缺乏持久记忆以随时间推移保留3D表示和理解。为了解决这些局限性，我们提出了VLM $^2$，一个具有持久记忆的视觉-语言模型，用于空间推理，它纯粹从2D视频中学习到视图一致的、3D感知的表示。具体而言，为了增强长距离推理，我们引入了一个双记忆模块，该模块由一个作为滑动窗口运行以专注于即时上下文的工作记忆，以及一个整合并存储关键长期信息的情景记忆组成。这种设计使得在固定计算成本下能够进行高效且长距离的空间推理。在多个基准测试中的大量实验表明，VLM$^2$ 在纯视频模型中实现了最先进的性能，显著推动了视觉-空间智能的前沿。|
|**2025-11-25**|[Concept-Aware Batch Sampling Improves Language-Image Pretraining](http://arxiv.org/abs/2511.20643)|null|视觉语言模型应该在哪些数据上进行训练？为了回答这个问题，许多数据整理工作都集中在数据集的质量上。然而，现有的大多数方法都是 (i) 离线的，即它们根据一组预设的过滤标准生成静态数据集；(ii) 概念无关的，即它们使用基于模型的过滤器，这会引入额外的数据偏差。在这项工作中，我们超越了这些离线、概念无关的方法，提倡更灵活、任务自适应的在线、基于概念的数据整理。我们的首个贡献是DataConcept，这是一个包含1.28亿网络爬取图像-文本对的集合，并标注了关于其概念构成的细粒度信息。基于DataConcept，我们引入了概念感知批次采样（CABS），这是一个简单而有效的批次采样框架，能够根据特定的目标分布灵活地实时构建批次。我们提出了两种变体：(i) 多样性最大化（CABS-DM），用于整理出覆盖广泛可用概念的批次；以及 (ii) 频率最大化（CABS-FM），用于整理出具有高对象多重性的批次。通过在28个基准测试中进行的大量评估，我们证明了CABS方法显著有益于CLIP/SigLIP模型类别，并能产生高性能模型。总而言之，CABS是专有在线数据整理算法的强大开源替代方案，使实践者能够定义自定义概念分布，从而优化特定下游任务。|
|**2025-11-25**|[Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition](http://arxiv.org/abs/2511.20641)|null|长尾多标签视觉识别是一个重大挑战，因为图像通常包含多个标签，且类别分布高度不平衡，导致模型产生偏向性，偏爱头部类别而对尾部类别表现不佳。最近的研究利用预训练的视觉-语言模型（如CLIP）结合长尾学习技术，以利用丰富的视觉-文本先验知识来提升性能。然而，现有方法通常直接从不平衡数据集中推导语义类间关系，由于数据稀缺导致尾部类别的相关性不可靠。此外，CLIP的零样本范式是针对单标签图像-文本匹配进行优化的，这使其对多标签任务来说并非最优。为了解决这些问题，我们提出了相关性自适应提示网络（CAPNET），这是一个新颖的端到端框架，它显式地从CLIP的文本编码器中建模标签相关性。该框架结合了图卷积网络用于标签感知传播，以及可学习的软提示用于精炼嵌入。它利用带有类别感知重加权的分布平衡Focal损失，以优化在不平衡条件下的训练。此外，它通过测试时集成提高了泛化能力，并使用参数高效微调重新对齐视觉-文本模态，从而避免了尾部类别过拟合，同时不损害头部类别性能。在包括VOC-LT、COCO-LT和NUS-WIDE在内的基准数据集上进行的大量实验和消融研究表明，CAPNET在最先进的方法上取得了显著提升，验证了其在真实世界长尾多标签视觉识别中的有效性。|
|**2025-11-25**|[Reinforcing Action Policies by Prophesying](http://arxiv.org/abs/2511.20633)|null|视觉-语言-动作 (VLA) 策略在对齐语言、感知和机器人控制方面表现出色。然而，大多数 VLA 纯粹通过模仿进行训练，这会导致对演示过度拟合，并在分布偏移下表现脆弱。强化学习 (RL) 直接优化任务奖励，从而解决了这种不对齐问题，但真实机器人交互成本高昂，且传统模拟器难以工程化和迁移。我们通过一个学习型世界模型和一种针对基于流的动作头量身定制的强化学习过程，解决了 VLA 后训练中的数据效率和优化稳定性问题。具体来说，我们引入了 Prophet，这是一种统一的动作到视频机器人驱动模型，它在海量异构机器人数据上进行预训练，以学习可重用的动作-结果动态。它能够进行少样本适应，以适应新的机器人、物体和环境，从而产生了一个可用于推演的模拟器。基于 Prophet，我们使用流动作-GRPO (FA-GRPO) 强化动作策略，FA-GRPO 适配 Flow-GRPO 以在 VLA 动作上操作；同时使用 FlowScale，这是一种分步重新加权方法，可重新缩放流头中每步的梯度。Prophet、FA-GRPO 和 FlowScale 共同构成了 ProphRL，这是一种实用、数据和计算高效的 VLA 后训练途径。实验表明，在公共基准上成功率提高了 5-17%，在不同 VLA 变体下的真实机器人上取得了 24-30% 的提升。|
|**2025-11-25**|[MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models](http://arxiv.org/abs/2511.20629)|null|结合奖励模型的人类反馈强化学习 (RLHF) 推动了生成模型与人类审美和感知偏好的对齐。然而，联合优化多个奖励常常带来对齐代价，即提升一个维度却损害其他维度。为解决此问题，我们引入了两种互补方法：MapReduce LoRA 和奖励感知词元嵌入 (RaTE)。MapReduce LoRA 并行训练偏好特定的 LoRA 专家模型，并迭代地合并它们以优化共享的基础模型；RaTE 学习奖励特定的词元嵌入，这些嵌入在推理时组合以实现灵活的偏好控制。在文本到图像生成任务上进行的实验（使用 Stable Diffusion 3.5 Medium 和 FLUX.1-dev 模型）显示，GenEval、PickScore 和 OCR 指标分别提升了 36.1%、4.6% 和 55.7%，以及 32.7%、4.3% 和 67.1%。在文本到视频生成任务上（使用 HunyuanVideo 模型），视觉和运动质量分别提升了 48.1% 和 90.0%。在语言任务“有用助手”上，使用 Llama-2 7B 模型，有用性和无害性分别提升了 43.4% 和 136.7%。我们的框架确立了一种新的跨模态最先进多偏好对齐方案。|
|**2025-11-25**|[Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems](http://arxiv.org/abs/2511.20627)|null|AI组件，特别是深度神经网络（DNN），集成到航空航天和自动驾驶汽车等安全关键系统中，给保障带来了根本性挑战。AI系统的黑箱特性，结合高层级需求与低层级网络表示之间的语义鸿沟，阻碍了传统验证方法。这些AI特有的挑战，因需求工程中长期存在的问题而加剧，包括自然语言规范的模糊性以及形式化过程中的可扩展性瓶颈。我们提出了一种方法，利用AI本身通过两个互补的组件来解决这些挑战。REACT（基于AI的需求工程，旨在实现一致性和测试）采用大型语言模型（LLMs）来弥合非正式自然语言需求与形式化规范之间的鸿沟，从而实现早期验证和确认。SemaLens（使用大型多模态模型进行视觉感知的语义分析）利用视觉语言模型（VLMs），使用人类可理解的概念对基于DNN的感知系统进行推理、测试和监控。这些组件共同提供了一个从非正式需求到经过验证的实现的全面流程。|
|**2025-11-25**|[The Consistency Critic: Correcting Inconsistencies in Generated Images via Reference-Guided Attentive Alignment](http://arxiv.org/abs/2511.20614)|null|以往工作探索了给定参考图像的各种定制化生成任务，但在生成一致的细粒度细节方面仍面临局限性。本文旨在通过应用一种参考引导的后编辑方法来解决生成图像的不一致性问题，并提出了我们的ImageCritic。我们首先构建了一个通过基于VLM的选择和显式降质获得的参考-降质-目标三元组数据集，该数据集有效模拟了现有生成模型中常见的误差或不一致性。此外，在彻底检查模型注意力机制和内在表示的基础上，我们相应地设计了一种注意力对齐损失和一个细节编码器，以精确纠正不一致性。ImageCritic可以集成到代理框架中，以在复杂场景中通过多轮和局部编辑自动检测并纠正不一致性。大量实验表明，ImageCritic能有效解决各种定制化生成场景中的细节相关问题，相较于现有方法提供了显著改进。|
|**2025-11-21**|[RynnVLA-002: A Unified Vision-Language-Action and World Model](http://arxiv.org/abs/2511.17502)|null|我们引入RynnVLA-002，一个统一的视觉-语言-动作 (VLA) 和世界模型。世界模型利用动作和视觉输入来预测未来的图像状态，学习环境的底层物理规律以优化动作生成。反之，VLA模型基于图像观测生成后续动作，增强了视觉理解并支持了世界模型的图像生成。RynnVLA-002的统一框架实现了环境动力学和动作规划的联合学习。我们的实验表明，RynnVLA-002超越了单独的VLA模型和世界模型，证明了它们之间的相互增强。我们在模拟和现实世界的机器人任务中评估了RynnVLA-002。RynnVLA-002在未经预训练的情况下，在LIBERO模拟基准测试中取得了97.4%的成功率，而在现实世界的LeRobot实验中，其集成的世界模型将整体成功率提高了50%。|
|**2025-11-21**|[Native 3D Editing with Full Attention](http://arxiv.org/abs/2511.17501)|null|指令引导的3D编辑是一个快速兴起的领域，具有拓宽3D内容创作途径的潜力。然而，现有方法面临关键局限：基于优化的方法速度慢得令人望而却步，而依赖多视角2D编辑的前馈方法则常遭受几何不一致和视觉质量下降的问题。为解决这些问题，我们提出了一种新颖的原生3D编辑框架，能够在一次高效的前馈过程中直接操作3D表示。具体而言，我们创建了一个用于指令引导的3D编辑的大规模多模态数据集，涵盖了多种添加、删除和修改任务。该数据集经过精心策划，以确保编辑后的对象忠实遵循指令性更改，同时保持未编辑区域与源对象的一致性。基于此数据集，我们探索了两种不同的模型条件化策略：传统的交叉注意力机制和一种新颖的3D token拼接方法。我们的结果表明，token拼接方法参数效率更高并实现了卓越的性能。大量评估显示，我们的方法优于现有2D提升方法，在生成质量、3D一致性和指令保真度方面设定了新基准。|
|**2025-11-21**|[Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination](http://arxiv.org/abs/2511.17490)|null|理解富文本视频需要阅读细小、短暂的文本线索，这些线索通常需要反复检查。然而，大多数视频问答模型依赖于对固定帧的单次感知，这导致了幻觉和在细粒度证据上的失败。受人类暂停、放大和重读关键区域方式的启发，我们引入了Video-R4（通过视觉反刍强化富文本视频推理），这是一个执行视觉反刍的视频推理大规模多模态模型：它迭代选择帧、放大信息区域、重新编码检索到的像素并更新其推理状态。我们构建了两个包含可执行反刍轨迹的数据集：用于监督训练的Video-R4-CoT-17k和用于强化学习的Video-R4-RL-30k。我们提出了一种多阶段反刍学习框架，该框架通过监督微调（SFT）和基于GRPO的强化学习逐步微调一个7B大规模多模态模型，以学习原子和混合视觉操作。Video-R4-7B在M4-ViteVQA上取得了最先进的结果，并进一步泛化到多页文档问答、幻灯片问答和通用视频问答，这表明迭代反刍是一种有效的像素级多模态推理范式。|
|**2025-11-21**|[Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models](http://arxiv.org/abs/2511.17487)|**[link](https://github.com/markendo/downscaling_intelligence)**|扩大多模态模型规模已在视觉理解和推理方面取得了显著进展，但实际需求呼唤更小、更高效的系统。在这项工作中，我们对多模态模型中的智能缩减进行了系统性分析，考察了大型语言模型（LLM）容量缩减如何影响多模态能力。我们的初步发现揭示了一个有趣的趋势：LLM的缩减不成比例地影响视觉能力，而非从LLM继承的能力。我们随后考察了这一下降是否主要反映了视觉推理的预期下降，亦或是感知能力的更根本性丧失。在隔离LLM缩减对感知的影响后，我们发现性能仍急剧下降，其影响往往与对推理的影响相当或甚至超过。为解决这一瓶颈，我们引入了视觉提取微调，它明确训练模型在不同任务中一致地提取与指令相关的视觉细节。利用这些提取出的视觉细节，我们随后应用逐步推理来生成答案。这些组件共同构成了我们的“提取+思考”（Extract+Think）方法，在该领域为效率和性能设定了新标准。|
|**2025-11-21**|[Enhancing Quranic Learning: A Multimodal Deep Learning Approach for Arabic Phoneme Recognition](http://arxiv.org/abs/2511.17477)|null|多模态深度学习的最新进展极大地增强了语音分析和发音评估系统的能力。准确的发音检测在阿拉伯语中仍然是一个关键挑战，特别是在《古兰经》诵读的语境下，因为细微的语音差异可能改变含义。为解决这一挑战，本研究提出了一个基于Transformer的多模态框架，用于阿拉伯语音素错读检测，该框架结合了声学和文本表示，以实现更高的精度和鲁棒性。该框架集成了源自UniSpeech的声学嵌入和从Whisper转录中提取的基于BERT的文本嵌入，创建了一个能够同时捕捉语音细节和语言上下文的统一表示。为了确定最有效的集成策略，本研究实施并评估了早期、中期和晚期融合方法，并在包含29个阿拉伯语音素（包括八个哈菲兹音）的两个数据集上进行了验证，这些音素由11位母语使用者发音。本研究还纳入了从公开的YouTube录音中收集的额外语音样本，以增强数据多样性和泛化能力。模型性能通过准确率、精确率、召回率和F1分数等标准评估指标进行评估，从而能够对融合策略进行详细比较。实验结果表明，UniSpeech-BERT多模态配置表现出优异性能，并且基于融合的Transformer架构对于音素级别的错读检测是有效的。本研究有助于开发智能的、与说话人无关的、多模态的计算机辅助语言学习(CALL)系统，为技术支持的《古兰经》发音训练和更广泛的基于语音的教育应用迈出了实用的一步。|
|**2025-11-21**|[MMT-ARD: Multimodal Multi-Teacher Adversarial Distillation for Robust Vision-Language Models](http://arxiv.org/abs/2511.17448)|null|视觉-语言模型 (VLMs) 越来越多地部署在安全关键应用中，这使得它们的对抗鲁棒性成为一个至关重要的问题。尽管对抗知识蒸馏在将鲁棒性从教师模型迁移到学生模型方面展现出潜力，但传统的单教师方法面临知识多样性有限、收敛速度慢以及难以平衡鲁棒性和准确性等问题。为解决这些挑战，我们提出了MMT-ARD：一个多模态多教师对抗鲁棒蒸馏框架。我们的关键创新是一个双教师知识融合架构，它协同优化干净特征保留和鲁棒特征增强。为了更好地处理具有挑战性的对抗样本，我们引入了一种基于教师置信度的动态权重分配策略，从而能够自适应地关注更难的样本。此外，为了减轻教师之间的偏差，我们设计了一种自适应的基于sigmoid的加权函数，以平衡跨模态知识迁移的强度。在ImageNet和零样本基准测试上进行的广泛实验表明，MMT-ARD在ViT-B-32模型上将鲁棒准确性提高了4.32%，零样本准确性提高了3.5%，同时相较于传统的单教师方法，训练效率提升了2.3倍。这些结果突出了MMT-ARD在增强多模态大模型对抗鲁棒性方面的有效性和可扩展性。我们的代码可在https://github.com/itsnotacie/MMT-ARD获取。|
|**2025-11-21**|[REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing](http://arxiv.org/abs/2511.17442)|null|基础模型（FMs）正越来越多地应用于遥感（RS）领域，执行环境监测、灾害评估和土地利用测绘等任务。这些模型包括在单一数据模态上训练的单模态视觉编码器，以及在合成孔径雷达、多光谱、高光谱和图像-文本数据组合上训练的多模态架构。它们支持各种遥感任务，包括语义分割、图像分类、变化检测和视觉问答。然而，由于文档分散、格式异构和部署约束多样，选择合适的遥感基础模型（RSFM）仍然困难。我们引入了RSFM数据库（RS-FMD），这是一个结构化资源，涵盖了超过150个RSFM，跨越多种数据模态、分辨率和学习范式。基于RS-FMD，我们提出了REMSA，这是首个基于LLM的智能体，用于从自然语言查询中自动化选择RSFM。REMSA能够解释用户需求、解决缺失约束、利用上下文学习对候选模型进行排序，并提供透明的理由。我们还提出了一个包含75个专家验证的遥感查询场景的基准，在以专家为中心的评估协议下生成了900种配置。REMSA优于多个基线，包括朴素智能体、密集检索和非结构化RAG（检索增强生成）的LLM。它完全基于公开可用的元数据运行，不访问私有或敏感数据。|
|**2025-11-21**|[SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding](http://arxiv.org/abs/2511.17411)|null|机器人基础模型（RFM）作为通用型、端到端的机器人控制系统，具有巨大的潜力。然而，它们在新环境、任务和具身形态之间的泛化能力仍然有限。我们认为一个主要瓶颈在于它们的基础：大多数RFM是通过微调互联网预训练的视觉-语言模型（VLM）构建的。然而，这些VLM是在2D图像-语言任务上训练的，缺乏3D世界中具身控制固有需要的3D空间推理能力。直接使用大规模机器人数据来弥合这一差距成本高昂且难以扩展。相反，我们提出通过3D标注来丰富易于收集的非机器人图像数据，并增强预训练VLM的3D理解能力。遵循这一策略，我们训练了SPEAR-VLM，这是一个能够从单个2D图像中推断3D空间中物体坐标的3D感知VLM。在SPEAR-VLM的基础上，我们介绍了我们的主要贡献SPEAR-1：一个将基础3D感知与语言指令具身控制相结合的机器人基础模型。SPEAR-1在约4500万帧来自24个Open X-Embodiment数据集上进行训练，其性能超越或匹敌了 $π_0$-FAST和$π_{0.5}$ 等最先进的模型，同时它使用的机器人演示数据量减少了20倍。这种精心设计的训练策略释放了新的VLM能力，因此提高了具身控制的可靠性，超越了仅使用机器人数据所能达到的水平。我们公开了我们的模型权重和3D标注数据集。|
|**2025-11-21**|[Beyond Multiple Choice: A Hybrid Framework for Unifying Robust Evaluation and Verifiable Reasoning Training](http://arxiv.org/abs/2511.17405)|null|多项选择题问答（MCQA）一直是评估和强化微调（RFT）现代多模态语言模型的流行格式。其受限的输出格式允许进行简化、确定性的自动验证。然而，我们发现选项可能会泄露可利用的信号，这使得准确性指标在指示真实能力方面不可靠，并鼓励在RFT期间产生显性或隐性的答案猜测行为。我们提出了ReVeL（通过LLM重写和验证），这是一个将多项选择题重写为开放式问题，并在可能的情况下保持答案可验证的框架。该框架根据不同的答案类型对问题进行分类，并分别应用不同的重写和验证方案。当应用于RFT时，我们转换了2万个MCQA示例，并使用GRPO微调了Qwen2.5-VL模型。在ReVeL-开放式问答（OpenQA）上训练的模型在多项选择基准测试中与MCQA准确率匹配，并将OpenQA准确率提高了约六个百分点，表明比基于MCQA的训练具有更好的数据效率和更鲁棒的奖励信号。当用于评估时，ReVeL还揭示了MCQA基准测试中高达20个百分点的分数膨胀（相对于OpenQA），提高了判断准确性，并降低了成本和延迟。我们将公开发布代码和数据。|
|**2025-11-21**|[MCMoE: Completing Missing Modalities with Mixture of Experts for Incomplete Multimodal Action Quality Assessment](http://arxiv.org/abs/2511.17397)|**[link](https://github.com/XuHuangbiao/MCMoE)**|多模态动作质量评估 (AQA) 近来已成为一种有前景的范式。通过利用共享上下文线索中的互补信息，它增强了对高度相似动作序列中细微类内变化的判别性评估。然而，在现实中，部分模态在推理阶段常常不可用。任何模态的缺失常常导致现有的多模态模型无法运行。此外，它还会因跨模态交互中断而引发灾难性的性能下降。为了解决这个问题，我们提出了一种新颖的缺失补全与专家混合框架（MCMoE），它在单阶段训练中统一了单模态和联合表示学习。具体来说，我们提出了一种自适应门控模态生成器，它动态融合可用信息以重建缺失模态。然后，我们设计了模态专家来学习单模态知识，并动态混合所有专家的知识以提取跨模态联合表示。通过专家混合，缺失模态得到进一步细化和补充。最后，在训练阶段，我们挖掘完整的多模态特征和单模态专家知识，以指导模态生成和基于生成的联合表示提取。广泛的实验表明，我们的MCMoE在三个公共AQA基准上，在完整和不完整多模态学习方面均取得了最先进的成果。代码可在 https://github.com/XuHuangbiao/MCMoE 获取。|
|**2025-11-20**|[EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards](http://arxiv.org/abs/2511.16672)|null|大型多模态模型（LMM）的近期进展使其具备了令人印象深刻的推理和感知能力，然而，大多数现有训练流水线仍然依赖人工标注数据或外部验证的奖励模型，这限制了它们的自主性和可扩展性。在这项工作中，我们致力于以纯无监督方式（不依赖任何标注数据或奖励蒸馏）提升LMM的推理能力。为此，我们提出了一个名为EvoLMM的自演化框架，该框架从单个骨干模型实例化出两个协作代理：一个提问器（Proposer），负责生成多样化的、基于图像的问题；一个解答器（Solver），通过内部一致性来解决这些问题，其中学习过程通过持续的自我奖励机制进行。这种动态反馈既促进了信息丰富的查询生成，又促进了结构化推理的完善，而不依赖于真实标签或人工判断。当使用流行的Qwen2.5-VL作为基础模型时，我们的EvoLMM仅使用原始训练图像，在包括ChartQA、MathVista和MathVision在内的多模态数学推理基准上取得了高达约3%的持续提升。我们希望我们这种简单而有效的方法将成为一个坚实的基础，从而促进未来在全无监督自改进LMM方面的研究。我们的代码和模型可在https://github.com/mbzuai-oryx/EvoLMM获取。|
|**2025-11-20**|[Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation](http://arxiv.org/abs/2511.16671)|null|视觉生成领域的近期进展越来越多地探索推理能力的融合。它们在生成过程之前（作为预规划）或之后（作为后细化）整合文本推理，即“思考”，但在生成过程中缺乏即时多模态交互。在这项初步研究中，我们引入了“边生成边思考”（TwiG），这是首个交错框架，它实现了文本推理在整个视觉生成过程中协同演进。随着视觉内容的逐步生成，文本推理被交错地融入，既能指导即将生成的局部区域，也能反思之前合成的区域。这种动态的相互作用产生了更具上下文感知能力和语义丰富的视觉输出。为了揭示该框架的潜力，我们研究了三种候选策略：零样本提示、在我们精心策划的TwiG-50K数据集上进行的监督微调（SFT），以及通过定制的TwiG-GRPO策略进行的强化学习（RL），每种策略都为交错推理的动态性提供了独特的见解。我们希望这项工作能启发进一步的研究，探索将文本推理交错融入以增强视觉生成。代码将在此发布：https://github.com/ZiyuGuo99/Thinking-while-Generating。|
|**2025-11-20**|[Learning to Think Fast and Slow for Visual Language Models](http://arxiv.org/abs/2511.16670)|null|面对复杂问题时，我们倾向于慢速思考；反之，对于简单问题，我们快速思考。这种双系统思维机制使我们能够有效分配认知资源，从而对简单问题快速做出决策，同时将更深层次的分析性思维留给更复杂的挑战。然而，现有面向推理的视觉语言模型（VLM），无论是通过显式思维链标注训练还是基于规则的强化学习（RL）奖励，主要追求冗长、详细的推理链，这通常导致过高的计算成本。在这项工作中，我们提出了一种简单的强化学习方法，该方法使VLM能够根据任务难度自动切换快慢思维模式。该方法包括两个阶段：在第一阶段，我们根据模型输出长度将数据标注为需要快思维或慢思维，这一灵感来源于预训练VLM通常针对不同类型问题产生不同长度答案的观察；在第二阶段，我们使用GRPO结合思维模式标签训练模型，以发展双模式思维。尽管其简单，我们的模型DualMindVLM显著优于基础模型，并达到了与最先进的视觉推理模型相当的性能，同时保持了极高的token效率。|
|**2025-11-20**|[Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO](http://arxiv.org/abs/2511.16669)|**[link](https://github.com/KlingTeam/VANS)**|虽然语言模型已在许多实际应用中产生深远影响，但视频生成仍主要局限于娱乐。受视频固有的能力启发，即能够展示仅通过语言难以传达的物理世界信息（例如，想象只用文字教别人打领带），我们识别出一个未充分利用的机会，将视频扩展为下一事件预测（NEP）的一种新型回答模态，并将其正式化为视频下一事件预测（VNEP）。既有的NEP任务以带有程序性或预测性问题的视频作为输入，以文本形式预测下一事件，而VNEP则需要动态视频响应。这种从“告知”到“展示”的转变，为程序性学习和创造性探索解锁了更直观、更个性化的答案。然而，这项任务对现有模型来说仍具挑战性，因为它要求理解多模态输入、指令条件推理以及生成具有视觉和语义一致性的视频。为解决此问题，我们引入了VANS模型，该模型利用强化学习将视觉语言模型（VLM）与视频扩散模型（VDM）对齐，以实现VNEP。VANS的核心是我们提出的Joint-GRPO，它协调VLM和VDM作为一个整体运作。在各自输出的共享奖励驱动下，Joint-GRPO优化VLM以生成既准确又易于可视化的字幕，同时指导VDM生成忠实于这些字幕和输入视觉上下文的视频。为了实现这种学习，我们构建了VANS-Data-100K，一个专用于VNEP任务的数据集。在程序性和预测性基准上的实验表明，VANS在视频事件预测和可视化方面均达到了最先进的性能。代码已发布在https://github.com/KlingTeam/VANS。|
|**2025-11-20**|[Cognitive Foundations for Reasoning and Their Manifestation in LLMs](http://arxiv.org/abs/2511.16660)|null|大型语言模型能够解决复杂问题，却在更简单的变体上失败，这表明它们获得正确输出依赖于与人类推理根本不同的机制。我们综合认知科学研究，形成包含28个认知元素的分类体系，涵盖计算约束、元认知控制、知识表示和转换操作，然后分析它们在推理痕迹中的行为表现。我们提出了一个细粒度的认知评估框架，并首次对来自文本、视觉和音频模态的17个模型的17万条推理痕迹以及54条人类出声思考痕迹进行了大规模分析，这些痕迹已公开。我们的分析揭示了系统性的结构差异：人类采用分层嵌套和元认知监控，而模型则依赖于浅层前向链式推理，这种差异在非结构化问题上最为显著。对1598篇大型语言模型推理论文的元分析表明，研究界侧重于易于量化的行为（如顺序组织：55%，分解：60%），而忽视了与成功相关的元认知控制（如自我意识：16%，评估：8%）。模型拥有与成功相关的行为储备，但未能自发地运用它们。利用这些模式，我们开发了测试时推理引导，能够自动搭建成功结构，将复杂问题的性能提升高达60%。通过连接认知科学和大型语言模型研究，我们为开发通过有原则的认知机制进行推理的模型奠定了基础，而非脆弱的虚假推理捷径或记忆，这为提升模型能力和大规模验证人类认知理论开辟了新方向。|
|**2025-11-20**|[Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](http://arxiv.org/abs/2511.16654)|null|检索增强生成 (RAG) 的近期进展已使大型语言模型 (LLM) 能够访问包含文本和视觉信息（如金融文档中的图表、示意图和表格）的多模态知识库。然而，现有的多模态 RAG 系统在预处理阶段依赖于基于 LLM 的摘要来将图像转换为文本，仅在向量数据库中存储文本表示，这导致了上下文信息和视觉细节的丢失，而这些信息和细节对后续检索和问答至关重要。为了解决这一局限性，我们对多模态 RAG 系统的两种检索方法进行了全面的比较分析，包括基于文本块的检索（其中图像在嵌入前被摘要为文本）和直接多模态嵌入检索（其中图像以原生形式存储在向量空间中）。我们在一个新创建的金融财报电话会议基准上评估了所有三种方法，该基准包含 40 对问答，每对问答都配有 2 份文档（1 份图像和 1 个文本块），并使用 6 个 LLM 模型和两个多模态嵌入模型进行了测试。实验结果表明，直接多模态嵌入检索显著优于基于 LLM 摘要的方法，在平均精度均值 (mAP@5) 上实现了 13% 的绝对提升，并在归一化折现累积增益上实现了 11% 的绝对提升。这些提升对应于在 mAP@5 上 32% 和在 nDCG@5 上 20% 的相对提升，为它们的实际影响提供了更有力的证据。我们还发现，通过 LLM-as-a-judge 成对比较进行衡量，直接多模态检索能够产生更准确和事实一致的答案。我们证明，LLM 摘要在预处理阶段引入了信息损失，而直接多模态嵌入则保留了视觉上下文，用于检索和推理。|
|**2025-11-20**|[InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy](http://arxiv.org/abs/2511.16651)|null|近期工作探讨了真实数据和合成数据如何促进视觉-语言-动作（VLA）模型的泛化能力。当前VLA模型已显示出大规模真实机器人预训练的强大有效性，但合成数据此前尚未展示出可比的大规模能力。本文首次提供了证据，表明仅凭合成数据即可在VLA模型预训练中匹配最强的 $π$数据集的性能，揭示了大规模模拟的巨大价值。所产生的模型还在多项挑战性任务上展现出令人惊讶的零样本仿真到真实迁移能力。我们的合成数据集InternData-A1包含超过63万条轨迹和7433小时的数据，涵盖4种具身形态、18种技能、70项任务和227个场景，涉及刚体、关节、可变形和流体对象操作。该数据集通过一个高度自主、完全解耦且组合式的模拟管道生成，该管道支持长周期技能组合、灵活任务组装和异构具身形态，且仅需最少的手动调整。我们使用与$π_0$相同的架构，完全在InternData-A1上预训练了一个模型，并发现其在49项模拟任务、5项真实世界任务和4项长周期灵巧任务上匹配了官方$π_0$ 的性能。我们发布了该数据集，并将开源其生成管道，以扩大对大规模机器人数据的获取，并降低具身AI研究中可扩展数据创建的门槛。|
|**2025-11-20**|[Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](http://arxiv.org/abs/2511.16602)|null|开发通用且多功能的具身智能系统面临两大主要挑战：关键的具身数据瓶颈（即真实世界数据稀缺且昂贵），以及现有方法算法效率低下（资源消耗巨大）。为解决这些局限，我们引入了刻意练习策略优化（DPPO），这是一种元认知“元循环”（Metaloop）训练框架，它动态地在监督微调（能力扩展）和强化学习（技能精炼）之间交替。这使得自动识别弱点和有针对性的资源分配成为可能，专门旨在最大化从稀疏有限数据中学习的效率。从理论上讲，DPPO可以被形式化为一个统一的偏好学习框架。在实践中，使用DPPO训练一个命名为Pelican-VL 1.0的视觉-语言具身模型，相比基础模型性能提升了20.3%，并超越了1000亿参数规模的开源模型10.6%。我们正在开源模型和代码，提供了第一个系统性框架，缓解了数据和资源瓶颈，并使社区能够高效地构建多功能具身智能体。|
|**2025-11-20**|[You Only Forward Once: An Efficient Compositional Judging Paradigm](http://arxiv.org/abs/2511.16600)|null|多模态大语言模型（MLLMs）作为评判者展现出巨大潜力。然而，现有方法面临一个根本性权衡：调整MLLMs输出单一分数与MLLMs的生成特性不符，并限制了对细粒度需求的理解；而自回归地生成评判分析在高吞吐量场景中速度极其缓慢。鉴于观察到评判可以简化为验证输入是否满足一组结构化要求，我们提出了YOFO，一种模板条件方法，可在单次前向传播中判断所有要求。YOFO基于自回归模型，接受一个结构化要求模板，并在一次推理步骤中，通过读取与每个要求相关的最终token的logits，为每个要求生成一个二元的是/否决策。这种设计实现了数量级的速度提升，同时保留了可解释性。大量实验表明，YOFO不仅在标准推荐数据集上取得了最先进的结果，而且还支持依赖感知分析——其中后续判断以前续判断为条件——并进一步受益于事后链式思考（CoT）。|
|**2025-11-20**|[TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding](http://arxiv.org/abs/2511.16595)|**[link](https://github.com/xiaomi-research/timeviper)**|我们引入了TimeViper，这是一种混合视觉-语言模型，旨在解决长视频理解的挑战。处理长视频既需要高效的模型架构，也需要处理扩展时间上下文的有效机制。为此，TimeViper采用了混合Mamba-Transformer骨干网络，结合了状态空间模型的效率和注意力机制的表达能力。通过这种混合设计，我们揭示了视觉到文本的信息聚合现象，其中信息随着LLM深度的增加逐渐从视觉token流向文本token，导致严重的视觉token冗余。受此观察启发，我们提出了TransV，一个token信息传输模块，它能将视觉token传输并压缩到指令token中，同时保持多模态理解能力。这种设计使TimeViper能够处理超过10,000帧、长达数小时的视频。在多个基准上的大量实验表明，TimeViper在扩展帧数的同时能与最先进的模型竞争。我们进一步分析了Mamba层和Transformer层的注意力行为，为混合模型可解释性提供了新见解。这项工作代表着在开发、解释和压缩混合Mamba-Transformer架构方面迈出的第一步。|
|**2025-11-18**|[ARC Is a Vision Problem!](http://arxiv.org/abs/2511.14761)|**[link](https://github.com/rprokap/pset-9)**|抽象推理语料库 (ARC) 旨在促进对抽象推理的研究，这是人类智能的一个基本方面。常见的ARC方法将其视为一个面向语言的问题，通过大型语言模型 (LLM) 或循环推理模型来解决。然而，尽管ARC中的谜题式任务本质上是视觉的，现有研究却很少从视觉中心视角来处理该问题。在这项工作中，我们将ARC问题形式化为视觉范式，将其表述为图像到图像翻译问题。为了融入视觉先验知识，我们将输入表示在一个“画布”上，该“画布”可以像自然图像一样进行处理。因此，我们很自然地应用标准视觉架构，例如朴素Vision Transformer (ViT)，来执行图像到图像映射。我们的模型仅使用ARC数据从零开始训练，并通过测试时训练泛化到未见任务。我们的框架，称为Vision ARC (VARC)，在ARC-1基准上达到了60.4%的准确率，大幅优于其他同样从零开始训练的现有方法。我们的结果与领先的LLM具有竞争力，并缩小了与人类平均表现的差距。|
|**2025-11-18**|[UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning](http://arxiv.org/abs/2511.14760)|null|我们提出UniGen-1.5，一个统一的多模态大语言模型（MLLM），用于高级图像理解、生成和编辑。在UniGen的基础上，我们全面增强了模型架构和训练流程，以加强图像理解和生成能力，同时解锁强大的图像编辑能力。特别地，我们提出了一种统一的强化学习（RL）策略，通过共享奖励模型共同改进图像生成和图像编辑。为了进一步提高图像编辑性能，我们提出了一种轻量级的编辑指令对齐阶段，该阶段显著提高了编辑指令的理解能力，这对于RL训练的成功至关重要。实验结果表明，UniGen-1.5展现出具有竞争力的理解和生成性能。具体而言，UniGen-1.5在GenEval和ImgEdit上分别取得了0.89和4.31的综合分数，超越了BAGEL等最先进模型，并达到了与GPT-Image-1等专有模型相当的性能。|
|**2025-11-18**|[ $π^{*}_{0.6}$: a VLA That Learns From Experience](http://arxiv.org/abs/2511.14759)|null|我们研究视觉-语言-动作 (VLA) 模型如何通过强化学习 (RL) 在真实世界部署中得到提升。我们提出了一种通用方法，即基于优势条件策略的经验与修正强化学习 (RECAP)，它通过优势条件化实现VLA的强化学习训练。我们的方法将异构数据整合到自我提升过程中，包括演示数据、在策略收集数据以及在自主执行期间提供的专家远程操作干预。RECAP首先使用离线RL预训练一个通用VLA模型，我们称之为 $π^{*}_{0.6}$，该模型随后可以通过机器人的数据收集进行专门化，以在下游任务中获得高性能。我们展示了使用完整RECAP方法训练的 $π^{*}_{0.6}$ 模型能够在真实家庭中叠洗衣服、可靠地组装盒子，以及使用专业意式咖啡机制作意式咖啡饮品。在一些最困难的任务上，RECAP使任务吞吐量增加一倍以上，任务失败率大约减半。|
|**2025-11-18**|[Vision Large Language Models Are Good Noise Handlers in Engagement Analysis](http://arxiv.org/abs/2511.14749)|null|与传统的图像分类任务不同，视频数据集中的参与度识别尤其受到主观标签和噪声的挑战，这些因素限制了模型性能。为了克服主观和噪声参与度标签带来的挑战，我们提出了一个利用视觉大语言模型（VLM）来精炼标注并指导训练过程的框架。我们的框架使用问卷提取行为线索，并将数据分为高可靠性和低可靠性子集。我们还引入了一种结合课程学习和软标签精炼的训练策略，逐步纳入模糊样本，同时调整监督以反映不确定性。我们证明，在精炼的高可靠性子集上训练并结合我们课程策略增强的经典计算机视觉模型显示出改进，突出了使用VLM解决标签主观性的益处。该方法超越了EngageNet等参与度基准测试中的现有最先进水平（六个特征设置中的三个，最大提升1.21%），并在DREAMS / PAFE上的F1分数分别提高了0.22 / 0.06。|
|**2025-11-18**|[Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge](http://arxiv.org/abs/2511.14744)|null|深度学习自2010年代初兴起以来，已彻底改变了计算机视觉和自然语言处理等领域，并对生物医学研究产生了深远影响。具体到药物发现领域，一个关键的转折点（类似于计算机视觉领域的“ImageNet时刻”）于2015年到来，当时深度神经网络在Tox21数据挑战赛中超越了传统方法。这一里程碑加速了深度学习在整个制药行业的采用，如今大多数主要公司已将这些方法整合到其研究管线中。Tox21挑战赛结束后，其数据集被纳入了几个已建立的基准，如MoleculeNet和Open Graph Benchmark。然而，在这些整合过程中，数据集被修改，标签被估算或伪造，导致不同研究之间可比性的丧失。因此，生物活性和毒性预测方法在过去十年中的改进程度仍不明确。为此，我们引入了一个可复现的排行榜，该排行榜托管在Hugging Face上，使用了原始的Tox21挑战赛数据集，并包含一组基线和代表性方法。排行榜的当前版本表明，原始Tox21冠军（基于集成的DeepTox方法）以及2017年引入的基于描述符的自归一化神经网络，持续保持竞争力并位列毒性预测的顶级方法之列，这使得在过去十年中毒性预测是否取得了实质性进展仍不明确。作为这项工作的一部分，我们通过对Hugging Face Spaces进行标准化API调用，使所有基线和评估模型可公开用于推理。|
|**2025-11-18**|[Seeing Beyond the Image: ECG and Anatomical Knowledge-Guided Myocardial Scar Segmentation from Late Gadolinium-Enhanced Images](http://arxiv.org/abs/2511.14702)|null|从钆增强心脏磁共振成像（LGE-MRI）中精确分割心肌瘢痕对于评估组织活力至关重要，但由于对比度不一和成像伪影，这仍然具有挑战性。心电图（ECG）信号提供了补充的生理信息，因为传导异常可以帮助定位或提示瘢痕心肌区域。在这项工作中，我们提出了一种新颖的多模态框架，该框架将ECG衍生的电生理信息与AHA-17图谱中的解剖学先验知识相结合，以实现生理学上一致的基于LGE的瘢痕分割。由于ECG和LGE-MRI并非同时采集，我们引入了一种时间感知特征融合（TAFF）机制，该机制根据采集时间差动态地加权并融合特征。我们的方法在一个临床数据集上进行了评估，并相较于最先进的仅基于图像的基线模型（nnU-Net）取得了显著提升，将瘢痕的平均Dice分数从0.6149提高到0.8463，并在精确率（0.9115）和敏感性（0.9043）方面均达到高水平性能。这些结果表明，整合生理学和解剖学知识使模型能够“超越图像”进行观察，为鲁棒且生理学上可靠的心脏瘢痕分割开辟了新方向。|
|**2025-11-18**|[HyMAD: A Hybrid Multi-Activity Detection Approach for Border Surveillance and Monitoring](http://arxiv.org/abs/2511.14698)|null|地震传感已成为边境监视和监测的一种有前景的解决方案；地震传感器通常埋在地下，体积小，不易被察觉，使入侵者难以检测、避开或破坏。与高度可见的摄像头或围栏相比，这显著增强了它们的有效性。然而，由于地震信号的复杂性和噪声特性，准确检测和区分同时发生的重叠活动（例如人类入侵、动物移动和车辆隆隆声）仍然是一个主要挑战。正确识别同时发生的活动至关重要，因为未能将其分离可能导致错误分类、漏检以及对情况理解不完整，从而降低监控系统的可靠性。为了解决这个问题，我们提出了HyMAD（混合多活动检测），这是一种基于时空特征融合的深度神经网络架构。该框架集成了使用SincNet提取的频谱特征和由循环神经网络（RNN）建模的时间依赖性。此外，HyMAD采用了自注意力层来增强模态内表示，并使用跨模态融合模块来实现地震事件的鲁棒多标签分类。我们在一个由在边境监视和监测背景下收集的真实世界现场记录构建的数据集上评估了我们的方法，证明了其泛化到涉及人类、动物和车辆的复杂、同时活动场景的能力。我们的方法实现了具有竞争力的性能，并为在现实世界安全应用中扩展基于地震的活动识别提供了模块化框架。|
|**2025-11-18**|[Talk, Snap, Complain: Validation-Aware Multimodal Expert Framework for Fine-Grained Customer Grievances](http://arxiv.org/abs/2511.14693)|null|现有投诉分析方法主要依赖于单模态、短形式内容，例如推文或产品评论。本工作通过利用多模态、多轮客户支持对话推进了该领域，用户在对话中通常会分享文本投诉和视觉证据（例如，截图、产品照片），从而实现投诉方面和严重性的细粒度分类。我们引入了VALOR，一个具有专家路由的验证感知学习器，专为此多模态设置量身定制。它采用多专家推理设置，使用大规模生成模型结合思维链（CoT）提示，以实现细致的决策。为确保模态之间的一致性，计算语义对齐分数并通过元融合策略集成到最终分类中。与联合国可持续发展目标（UN SDGs）保持一致，所提出的框架通过推进人工智能驱动的工具，支持健壮、可扩展和上下文感知的服务基础设施，从而支持可持续发展目标9（产业、创新和基础设施）。此外，通过实现投诉叙述和视觉上下文的结构化分析，它促进了响应性更强的产品设计并提高了消费者服务的问责制，从而有助于可持续发展目标12（负责任消费和生产）。我们在一个标注有细粒度方面和严重性标签的精选多模态投诉数据集上评估了VALOR，结果表明它始终优于基线模型，尤其是在信息分布在文本和图像之间的复杂投诉场景中。这项研究强调了多模态交互和专家验证在实际投诉理解系统中的价值。数据和代码相关资源可在此处获取：https://github.com/sarmistha-D/VALOR|
|**2025-11-18**|[Hyperbolic Graph Embeddings Reveal the Host-Pathogen Interactome](http://arxiv.org/abs/2511.14669)|null|感染依赖于病原体与宿主蛋白之间的相互作用，但全面绘制这些相互作用图谱具有挑战性且劳动密集。许多生物网络具有分层、无标度结构，因此我们开发了一个深度学习框架ApexPPI，该框架在双曲黎曼空间中表示蛋白质网络以捕捉这些特征。我们的模型整合了多模态生物数据（蛋白质序列、基因扰动实验和互补相互作用网络），通过多任务双曲图神经网络来预测病原体和宿主蛋白之间可能存在的相互作用。将蛋白质特征映射到双曲空间，在预测宿主-病原体相互作用方面，相比于以前的方法获得了更高的准确性。从数千万种可能的蛋白质对中，我们的模型识别出数千个高置信度相互作用，其中许多涉及人类G蛋白偶联受体（GPCRs）。我们使用AlphaFold 3结构建模验证了数十个这些预测的复合物，支持了我们预测的准确性。这张宿主-病原体蛋白质相互作用的综合图谱为发现新疗法提供了资源，并阐明了先进人工智能如何能够揭示复杂的生物系统。|
|**2025-11-18**|[M-CALLM: Multi-level Context Aware LLM Framework for Group Interaction Prediction](http://arxiv.org/abs/2511.14661)|null|本文探讨了大型语言模型如何利用多级上下文信息预测协作式混合现实环境中的群体协作模式。我们证明，将个体行为档案、群体结构属性和时间动态编码为自然语言，能够使大型语言模型突破统计模型的性能上限。我们构建了M-CALLM框架，该框架将多模态传感器流转换为分层上下文，用于基于大型语言模型的预测，并在干预模式（实时预测）和模拟模式（自回归预测）下，针对统计基线模型评估了三种范式（零样本提示、少样本学习和有监督微调）。对16个群体（64名参与者，约25小时）的直接比较表明，上下文感知的大型语言模型在对话预测方面实现了96%的准确率，比LSTM基线模型提高了3.2倍，同时保持低于35毫秒的延迟。然而，模拟模式显示出脆弱性，由于级联错误导致性能下降83%。对模态特定性能的深入分析表明，对话依赖于时间模式，接近度受益于群体结构（提高了6%），而共享注意力则完全失败（召回率为0%），暴露出架构限制。我们希望这项工作能催生新想法，用于构建能够平衡语义推理能力与基本约束的智能协作感知系统。|
|**2025-11-14**|[DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding](http://arxiv.org/abs/2511.11552)|null|理解长篇视觉文档，即信息分布在大量的文本页和视觉元素中的文档，是现代视觉-语言模型 (VLMs) 一项关键但具有挑战性的任务。现有方法在一个基本挑战上表现不佳：证据定位。它们难以检索相关页面并忽略视觉元素中的细粒度细节，导致性能受限和模型幻觉。为解决此问题，我们提出 DocLens，一个工具增强型多智能体框架，能够像镜头一样有效“聚焦”于证据。它首先从整个文档导航到相关页面上的特定视觉元素，然后采用采样-裁决机制生成一个单一、可靠的答案。结合 Gemini-2.5-Pro，DocLens 在 MMLongBench-Doc 和 FinRAGBench-V 上取得了最先进的性能，甚至超越了人类专家。该框架的优越性在以视觉为中心和无法回答的查询上尤为明显，证明了其增强定位能力的强大。|
|**2025-11-14**|[Bridging Hidden States in Vision-Language Models](http://arxiv.org/abs/2511.11526)|null|视觉-语言模型 (VLM) 是一类新型模型，旨在将图像内容与自然语言对齐。现有方法通常通过以下两种方式进行融合：(a) 早期融合：在编码器内部混合tokens/特征；或 (b) 晚期融合：通过比较池化后的嵌入。许多方法还将融合与自回归解码器绑定。然而，两种模态的隐藏状态已携带丰富的模态特定结构（视觉中的空间布局；文本中的句法和语义），因此直接对齐这些状态是一种自然的方式来匹配两种模态所表征的内容。我们提出了一种轻量级融合模块：在两个编码器顶部附近放置几个仅进行跨模态的双向注意力层。每个层将视觉和文本编码器隐藏状态序列投影到共享空间，进行跨模态注意力，并发送门控残差更新，辅以简单的稳定器以改善对齐。编码器保持非因果性并具有强大的理解能力，而生成则通过可选解码器保持干净地解耦。在标准检索、VQA（视觉问答）和视觉推理基准测试中，BRIDGE的性能优于同类VLM，同时保留了对比模型双编码器的效率。我们已将代码公开在https://github.com/jfeinashley/BRIDGE。|
|**2025-11-14**|[Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities](http://arxiv.org/abs/2511.11512)|null|触觉感知为视觉和语言提供了丰富且互补的信息，使机器人能够感知细粒度的物体属性。然而，现有触觉传感器缺乏标准化，导致冗余特征阻碍了跨传感器泛化。此外，现有方法未能充分整合触觉、语言和视觉模态之间的中间通信。为此，我们提出了TLV-CoRe，一种基于CLIP的触觉-语言-视觉协作表示学习方法。TLV-CoRe引入了传感器感知调制器来统一不同传感器之间的触觉特征，并采用触觉无关解耦学习来解耦不相关的触觉特征。此外，还引入了统一桥接适配器，以增强共享表示空间内的三模态交互。为了公平评估触觉模型的有效性，我们进一步提出了RSS评估框架，关注不同方法之间的鲁棒性、协同性和稳定性。实验结果表明，TLV-CoRe显著提高了传感器无关表示学习和跨模态对齐能力，为多模态触觉表示提供了新方向。|
|**2025-11-14**|[SynthSoM-Twin: A Multi-Modal Sensing-Communication Digital-Twin Dataset for Sim2Real Transfer via Synesthesia of Machines](http://arxiv.org/abs/2511.11503)|null|本文构建了一个新颖的多模态感知-通信数字孪生数据集，命名为SynthSoM-Twin，该数据集与真实世界在时空上保持一致，用于通过机器联觉（SoM）实现Sim2Real（从仿真到真实）迁移。为了构建SynthSoM-Twin数据集，我们提出了一种新颖的框架，该框架能够扩展现有真实世界多模态感知-通信数据集的数量并补齐缺失模态。具体来说，我们利用多模态感知辅助的目标检测和跟踪算法，以确保真实世界和仿真环境中静态物体和动态物体的时空一致性。构建的场景被导入到三个高保真模拟器中，即AirSim、WaveFarer和Sionna RT。SynthSoM-Twin数据集包含与真实世界时空一致的数据，包括66,868个合成RGB图像快照、深度图、光探测和测距（LiDAR）点云、毫米波（mmWave）雷达点云以及大尺度和小尺度信道衰落数据。为了验证SynthSoM-Twin数据集的实用性，我们通过借助跨模态生成模型（CMGM）实现两个跨模态下游任务，即跨模态信道生成模型和多模态感知辅助波束生成模型，进行了Sim2Real迁移研究。基于这些下游任务，我们探索了真实世界数据注入的阈值，该阈值能够在真实世界数据使用量和模型的实际性能之间实现良好的权衡。实验结果表明，在SynthSoM-Twin数据集上训练的模型取得了良好的实际性能，并且真实世界数据的注入进一步促进了Sim2Real迁移能力。基于SynthSoM-Twin数据集，注入不到15%的真实世界数据，与仅使用所有真实世界数据进行训练相比，可以达到相似甚至更好的性能。|
|**2025-11-14**|[PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models](http://arxiv.org/abs/2511.11502)|null|大规模视觉-语言模型（LVLM）功能强大，但由于物体幻觉，其可靠性仍有不足。在这项工作中，我们发现，在许多幻觉预测中，LVLM有效地忽略了图像，而是依赖于先前生成的输出（prelim）token来推断新物体。我们通过图像与预测物体之间以prelim为条件的互信息来量化这种行为，结果表明弱图像依赖性与幻觉强烈相关。基于这一发现，我们引入了Prelim注意力分数（PAS），这是一种轻量级、无需训练的信号，通过预生成token上的注意力权重计算得出。PAS不需要额外的正向传播，并且可以在推理过程中即时计算。利用这一先前被忽视的信号，PAS在多个模型和数据集上实现了最先进的物体幻觉检测，从而实现了实时过滤和干预。|
|**2025-11-14**|[Multimodal Posterior Sampling-based Uncertainty in PD-L1 Segmentation from H&E Images](http://arxiv.org/abs/2511.11486)|null|PD-L1表达的准确评估对于指导免疫疗法至关重要，然而当前基于免疫组织化学（IHC）的方法是资源密集型的。我们提出了nnUNet-B：一个贝叶斯分割框架，它利用多模态后验采样（MPS）直接从H&E染色组织病理图像中推断PD-L1表达。我们的方法以nnUNet-v2为基础，在循环训练期间采样多样化的模型检查点以近似后验，通过熵和标准差实现准确分割和认知不确定性估计。在肺鳞状细胞癌数据集上进行评估，我们的方法相对于已有基线取得了具有竞争力的性能，平均Dice系数和平均IoU分别为0.805和0.709，同时提供了像素级不确定性图。不确定性估计与分割误差显示出强相关性，尽管校准仍不完善。这些结果表明，考虑不确定性的基于H&E的PD-L1预测是迈向临床工作流程中可扩展、可解释的生物标志物评估的有前景的一步。|
|**2025-11-14**|[ImAgent: A Unified Multimodal Agent Framework for Test-Time Scalable Image Generation](http://arxiv.org/abs/2511.11483)|null|近期的文生图（T2I）模型在生成视觉真实且语义连贯的图像方面取得了显著进展。然而，它们仍然存在与给定提示词的随机性和不一致性问题，尤其当文本描述模糊或不明确时。现有方法，例如提示词重写、N选一采样和自优化，能够缓解这些问题，但通常需要额外的模块并独立运行，这阻碍了测试时扩展效率并增加了计算开销。在本文中，我们引入了ImAgent，一个无需训练的统一多模态智能体，它将推理、生成和自评估集成到单一框架中，以实现高效的测试时扩展。在策略控制器引导下，多个生成动作动态交互并自组织，以提高图像保真度和语义对齐，而无需依赖外部模型。在图像生成和编辑任务上的大量实验表明，ImAgent始终优于骨干模型，甚至在骨干模型失效的情况下超越了其他强大的基线，这突显了统一多模态智能体在测试时扩展下实现自适应和高效图像生成方面的潜力。|
|**2025-11-14**|[Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective](http://arxiv.org/abs/2511.11478)|null|随着具身智能体在日益复杂的环境中运行，感知、跟踪并推理单个对象实例随时间变化的能力变得至关重要，尤其是在需要与视觉上相似的对象进行序列化交互的任务中。在这些非马尔可夫设置中，关键决策线索通常隐藏在对象特定的历史记录中，而非当前场景。如果没有对先前交互（交互过什么、它在哪里、或它如何变化）的持久记忆，视觉运动策略可能会失败、重复过去的动作或忽略已完成的动作。为了凸显这一挑战，我们引入了LIBERO-Mem，这是一个用于在对象级部分可观察性下对机器人操作进行压力测试的非马尔可夫任务套件。它结合了短期和长期对象跟踪以及时间序列子目标，需要超越当前帧进行推理。然而，视觉-语言-动作（VLA）模型在此类设置中常常表现不佳，令牌扩展即使对于仅跨越几百帧的任务也会迅速变得难以处理。我们提出了Embodied-SlotSSM，一个专为时间可扩展性构建的以槽为中心的VLA框架。它保持时空一致的槽位标识，并通过两种机制利用它们：(1) 槽位状态空间建模以重建短期历史，以及 (2) 一个关系编码器，用于将输入令牌与动作解码对齐。这些组件共同实现了基于时间的、上下文感知的动作预测。实验表明Embodied-SlotSSM在LIBERO-Mem和通用任务上的基线性能，为以对象为中心的机器人策略中的非马尔可夫推理提供了一个可扩展的解决方案。|
|**2025-11-14**|[Sat2RealCity: Geometry-Aware and Appearance-Controllable 3D Urban Generation from Satellite Imagery](http://arxiv.org/abs/2511.11470)|null|生成建模的最新进展大幅提升了三维城市生成能力，使其能够应用于数字孪生、虚拟城市和大规模模拟等领域。然而，现有方法面临两个主要挑战：(1) 监督训练所需的大规模三维城市资产获取困难且成本高昂；(2) 依赖于语义图或高度图，这些图仅用于在虚拟世界中生成建筑物，缺乏与真实世界外观的联系，从而限制了生成城市的真实感和泛化能力。为解决这些局限性，我们提出了Sat2RealCity，一个从真实世界卫星图像生成三维城市的几何感知和外观可控框架。与以往的城市级生成方法不同，Sat2RealCity基于单个建筑实体进行生成，使得能够利用三维物体生成领域丰富的先验知识和预训练知识，同时大幅减少对大规模三维城市资产的依赖。具体而言，(1) 我们引入了基于OSM的空间先验策略，以实现从空间拓扑到建筑实例的可解释几何生成；(2) 我们设计了一种外观引导的可控建模机制，用于实现细粒度的外观真实感和风格控制；(3) 我们构建了一个由MLLM驱动的语义引导生成管道，弥合了语义解释与几何重建之间的鸿沟。大量定量和定性实验表明，Sat2RealCity在结构一致性和外观真实感方面显著超越了现有基线，为与真实世界对齐的三维城市内容创建奠定了坚实基础。代码即将发布。|
|**2025-11-14**|[Rethinking Efficient Mixture-of-Experts for Remote Sensing Modality-Missing Classification](http://arxiv.org/abs/2511.11460)|null|遥感中的多模态分类常受环境干扰、传感器故障或大气效应引起的模态缺失困扰，这严重降低了分类性能。现有的两阶段自适应方法计算开销大，且假设训练期间数据模态完整，限制了它们在真实世界不完整数据上的泛化能力。为了解决这些问题，我们提出了一种缺失感知型LoRa混合（MaMOL）框架，将模态缺失重构为多任务学习问题。MaMOL引入了一种双路由机制：一个任务导向的动态路由器，自适应地激活针对不同缺失模式的专家；以及一个模态特异性共享的静态路由器，维持稳定的跨模态知识共享。与以往为每种缺失配置训练独立网络的方法不同，MaMOL通过轻量级专家更新和共享专家复用实现了参数高效的自适应。在多个遥感基准数据集上的实验证明，MaMOL在不同缺失率下展现出卓越的鲁棒性和泛化能力，且计算开销极小。此外，在自然图像数据集上的迁移实验验证了其可扩展性和跨领域适用性，突显MaMOL是解决不完整多模态学习问题的通用且高效的解决方案。|
|**2025-11-07**|[Visual Spatial Tuning](http://arxiv.org/abs/2511.05491)|**[link](https://github.com/Yangr116/VST)**|从视觉输入中捕捉空间关系是类人通用智能的基石。之前的几项研究试图通过添加额外的专家编码器来增强视觉-语言模型（VLMs）的空间感知能力，但这带来了额外的开销，并且通常会损害通用能力。为了增强通用架构中的空间能力，我们引入了视觉空间调优（VST），这是一个全面的框架，旨在培养VLMs具备从空间感知到空间推理的类人视觉空间能力。我们首先尝试通过构建一个名为VST-P的大规模数据集来增强VLMs的空间感知能力，该数据集包含410万个样本，涵盖了单视图、多图像和视频中的19种技能。随后，我们提出了VST-R，这是一个包含13.5万个样本的精心策划的数据集，用于指导模型进行空间推理。特别地，我们采用了一种渐进式训练流程：首先通过监督微调建立基础空间知识，然后通过强化学习进一步提高空间推理能力。在不影响通用能力的情况下，所提出的VST在多个空间基准测试中持续取得最先进的成果，包括MMSI-Bench上的34.8%和VSIBench上的61.2%。结果表明，采用所提出的空间调优范式，视觉-语言-动作模型可以得到显著增强，为更具物理基础的AI铺平了道路。|
|**2025-11-07**|[Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments](http://arxiv.org/abs/2511.05404)|null|鲁棒的闭环检测是GNSS受限环境（例如行星探索场景）中同步定位与建图（SLAM）算法的关键组成部分。在这些环境下，视觉地点识别常因混叠和弱纹理而失效，而基于激光雷达的方法则存在稀疏性和模糊性问题。本文提出了MPRF，一个多模态流程，它利用基于Transformer的视觉和激光雷达模态基础模型，在严重非结构化环境中实现鲁棒的闭环。与之前仅限于检索的工作不同，MPRF整合了两阶段视觉检索策略和显式的6自由度位姿估计，结合DINOv2特征与SALAD聚合进行高效的候选筛选，并使用基于SONATA的激光雷达描述符进行几何验证。在S3LI数据集和S3LI Vulcano数据集上的实验表明，MPRF在精度方面优于最先进的检索方法，同时增强了低纹理区域的位姿估计鲁棒性。通过提供适用于SLAM后端的、可解释的对应关系，MPRF在准确性、效率和可靠性之间取得了有利的权衡，展示了基础模型统一地点识别和位姿估计的潜力。代码和模型将发布在github.com/DLR-RM/MPRF。|
|**2025-11-07**|[PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization](http://arxiv.org/abs/2511.05393)|null|视觉质量评估（QA）旨在预测人类对视觉保真度的感知判断。尽管最近的多模态大型语言模型（MLLMs）在图像和视频质量推理方面展现出潜力，但现有方法主要依赖于监督微调或仅基于排序的目标，导致推理肤浅、分数校准差以及跨域泛化能力有限。我们提出了PreResQ-R1，一个偏好-响应解耦强化学习框架，它在单一的推理驱动优化方案中统一了绝对分数回归和相对排序一致性。与先前的QA方法不同，PreResQ-R1引入了一种双分支奖励公式，分别建模样本内响应一致性和样本间偏好对齐，并通过组相对策略优化（GRPO）进行优化。这种设计鼓励对感知质量进行细粒度、稳定且可解释的思维链推理。为了扩展到静态图像之外，我们进一步为视频质量评估设计了一种全局时间与局部空间数据流策略。值得注意的是，仅通过对6K图像和28K视频进行强化微调，PreResQ-R1在10个IQA和5个VQA基准上，在SRCC和PLCC指标下均取得了最先进的结果，在IQA任务中分别超越了5.30%和2.15%。除了定量增益之外，它还生成了与人类对齐的推理轨迹，揭示了质量判断背后的感知线索。代码和模型均已提供。|
|**2025-11-07**|[A multimodal multiplex of the mental lexicon for multilingual individuals](http://arxiv.org/abs/2511.05361)|null|历史上，双语现象常被视为一种额外的认知负荷，可能阻碍语言和智力发展。然而，在过去的三十年间，这一观点已发生显著变化。大量研究旨在建模和理解双语词汇识别系统的架构 (Dijkstra 和 van Heuven, 2002)，探究并行激活在大脑中如何运作以及一种语言如何影响另一种语言 (Kroll 等, 2015)。越来越多的证据表明，多语者（即会说三种或更多语言的个体）在各种语言和认知任务中，例如学习一门额外的语言 (Abu-Rabia 和 Sanitsky, 2010)，表现优于单语者。本研究提案侧重于心理词典的研究及其在多语者中的可能结构。基于 Stella 等人 (2018) 使用心理词典多重模型研究人类爆发式学习的工作，以及 Dijkstra 和 van Heuven (2002) 提出的双语交互激活 (BIA+) 框架，本研究应用了 Kivela 等人 (2014) 引入的相同多层网络原理。我们的实验设计通过将多模态整合到多重模型中来扩展先前的研究，引入一个额外的层，该层将视觉输入连接到心理词典的多语层中对应的词汇表征。在本研究中，我们旨在探究传承语如何影响另一种语言的习得。具体而言，我们提出问题：在翻译任务中，与纯文本条件相比，视觉输入的存在是否会影响参与者的熟练度和准确性？|
|**2025-11-07**|[Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval](http://arxiv.org/abs/2511.05325)|null|电商平台中的多模态商品检索系统依赖于有效结合视觉和文本信号来提高搜索相关性和用户体验。然而，CLIP等视觉-语言模型易受排版攻击，即图像中嵌入的误导性或不相关文本会扭曲模型预测。在这项工作中，我们提出了一种新方法，通过将相关文本内容（例如，标题、描述）直接渲染到商品图片上以执行视觉-文本压缩，从而逆转排版攻击的逻辑，增强图像-文本对齐并提升多模态商品检索性能。我们使用六个最先进的视觉基础模型，在三个垂直领域的电商数据集（运动鞋、手袋和交易卡）上评估了我们的方法。我们的实验表明，在不同类别和模型家族中，单模态和多模态检索精度均持续得到改进。我们的发现表明，视觉化渲染商品元数据是电商应用中零样本多模态检索的一种简单而有效的增强方法。|
|**2025-11-07**|[psiUnity: A Platform for Multimodal Data-Driven XR](http://arxiv.org/abs/2511.05304)|null|扩展现实 (XR) 研究越来越依赖于在头戴式设备和沉浸式应用之间流式传输和同步多模态数据，以实现数据驱动的交互和实验。然而，开发者面临一个关键的空白：擅长确定性时间对齐和多模态数据管理的情境智能平台 (psi)，在用于 HoloLens 开发的主流 Unity/MRTK 生态系统中，大部分时间都无法访问。我们引入 psiUnity，这是一个开源 C# 集成，它将 psi 的 .NET 库与 Unity 2022.3 和 MRTK3 连接起来，用于 HoloLens 2。psiUnity 实现了头部姿态、手部追踪、凝视、惯性测量单元 (IMU)、音频以及深度传感器数据（AHAT 和长程）的双向实时流式传输，具有微秒级时间精度，从而允许 Unity 应用程序既可以消费又可以生成同步的多模态数据流。通过将 psi 的原生序列化、日志记录和时间协调直接嵌入到 Unity 的架构中，psiUnity 将 psi 的应用范围扩展到其之前的 StereoKit 限制之外，并赋能人机交互 (HRI)、人机界面 (HCI) 和具身人工智能 (embodied-AI) 社区在熟悉的 Unity 环境中开发可复现的、数据驱动的 XR 交互和实验。该集成可在 https://github.com/sailgt/psiUnity 获取。|
|**2025-11-07**|[Cross-domain EEG-based Emotion Recognition with Contrastive Learning](http://arxiv.org/abs/2511.05293)|null|基于脑电图 (EEG) 的情绪识别对情感计算至关重要，但在特征利用和跨域泛化方面面临挑战。本工作引入了EmotionCLIP，它在CLIP框架内将情绪识别重新定义为一种脑电图-文本匹配任务。一个定制的骨干网络SST-LegoViT使用多尺度卷积和Transformer模块捕获空间、频谱和时间特征。在SEED和SEED-IV数据集上的实验显示，其跨被试准确率分别为88.69%和73.50%，跨时间准确率分别为88.46%和77.54%，优于现有模型。结果表明多模态对比学习对于鲁棒的脑电图情绪识别的有效性。|
|**2025-11-07**|[DeepEyesV2: Toward Agentic Multimodal Model](http://arxiv.org/abs/2511.05271)|null|智能体多模态模型不仅应理解文本和图像，还应主动调用外部工具，如代码执行环境和网络搜索，并将这些操作整合到推理中。在这项工作中，我们引入了DeepEyesV2，并从数据构建、训练方法和模型评估的角度探索如何构建一个智能体多模态模型。我们观察到，仅凭直接强化学习无法诱导鲁棒的工具使用行为。这种现象促使我们采用两阶段训练流程：一个冷启动阶段以建立工具使用模式，以及一个强化学习阶段以进一步优化工具调用。我们整理了一个多样化、中等难度的训练数据集，特别包括工具使用有益的示例。我们进一步引入了RealX-Bench，一个旨在评估真实世界多模态推理的全面基准，这本身就需要整合多种能力，包括感知、搜索和推理。我们在RealX-Bench和其他有代表性的基准上评估了DeepEyesV2，展示了其在真实世界理解、数学推理和搜索密集型任务中的有效性。此外，DeepEyesV2表现出任务自适应的工具调用，倾向于将图像操作用于感知任务，将数值计算用于推理任务。强化学习进一步实现了复杂的工具组合，并允许模型根据上下文选择性地调用工具。我们希望我们的研究能为社区在开发智能体多模态模型方面提供指导。|
|**2025-11-07**|[Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy](http://arxiv.org/abs/2511.05169)|null|肽受体放射性核素治疗 (PRRT) 是转移性神经内分泌肿瘤 (NETs) 的一种成熟治疗方法，但仅在部分患者中实现长期疾病控制。预测无进展生存期 (PFS) 有助于支持个性化治疗方案。本研究评估了实验室、影像学和多模态深度学习模型在PRRT治疗患者中预测PFS的能力。在这项回顾性单中心研究中，纳入了116名接受177Lu-DOTATOC治疗的转移性NETs患者。收集了临床特征、实验室指标和治疗前生长抑素受体正电子发射断层扫描/计算机断层扫描 (SR-PET/CT) 数据。共训练了七个模型来区分低PFS组和高PFS组，包括单模态（实验室、SR-PET或CT）和多模态融合方法。通过特征重要性分析和梯度图评估了模型的可解释性。四十二名患者（36%）的PFS较短（<1年），七十四名患者的PFS较长（>1年）。除了短PFS患者的基线嗜铬粒蛋白A较高 (p = 0.003)、γ-GT升高 (p = 0.002) 和PRRT周期数较少 (p < 0.001) 外，两组在大多数特征上相似。仅基于实验室生物标志物训练的随机森林模型达到了0.59 ± 0.02的AUROC。使用SR-PET或CT的单模态三维卷积神经网络表现较差（AUROC分别为0.42 ± 0.03和0.54 ± 0.01）。结合实验室指标、SR-PET和CT并辅以预训练CT分支的多模态融合模型取得了最佳结果（AUROC 0.72 ± 0.01，AUPRC 0.80 ± 0.01）。结合SR-PET、CT和实验室生物标志物的多模态深度学习在PRRT后PFS预测方面优于单模态方法。经过外部验证后，此类模型可支持风险适应的随访策略。|
|**2025-11-07**|[Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study](http://arxiv.org/abs/2511.05106)|null|使用光学相干断层扫描（OCT）可测量的视网膜层厚度改变与阿尔茨海默病（AD）等神经退行性疾病相关。既往研究主要关注分割层厚度测量，而本研究则探索了OCT B扫描图像的直接分类，用于阿尔茨海默病的早期检测。据我们所知，这是文献中首次将深度学习应用于原始OCT B扫描以进行阿尔茨海默病预测。与传统医学图像分类任务不同，早期检测比诊断更具挑战性，因为影像学检查早于临床诊断数年。我们使用来自英国生物样本库队列中匹配了年龄、性别和影像学实例的受试者层面交叉验证数据集，对多个预训练模型（包括基于ImageNet的网络和OCT专用RETFound Transformer）进行了微调和评估。为减少这一小型高维度数据集中的过拟合，我们采用了标准和OCT专用数据增强技术，并结合使用了一种年份加权损失函数，该函数优先考虑影像学检查后四年内诊断的病例。ResNet-34产生了最稳定的结果，在4年队列中实现了0.62的AUC。尽管低于临床应用阈值，但我们的可解释性分析证实了阿尔茨海默病组和对照组之间黄斑中心区存在局部结构差异。这些发现为基于OCT的阿尔茨海默病预测提供了基线，强调了在阿尔茨海默病诊断前数年检测细微视网膜生物标志物的挑战，并指出需要更大的数据集和多模态方法。|
|**2025-11-06**|[Cambrian-S: Towards Spatial Supersensing in Video](http://arxiv.org/abs/2511.04670)|**[link](https://github.com/cambrian-mllm/cambrian-s)**|我们认为，真正的多模态智能的进步需要从反应式、任务驱动型系统和暴力长上下文转向更广泛的超感知范式。我们将空间超感知定义为超越仅基于语言理解的四个阶段：语义感知（命名所见之物），流式事件认知（在连续经验中保持记忆），隐式三维空间认知（推断像素背后的世界），以及预测性世界建模（创建内部模型以过滤和组织信息）。当前基准测试主要只测试早期阶段，对空间认知的覆盖范围狭窄，并且很少以需要真正世界建模的方式挑战模型。为了推动空间超感知的进步，我们提出了VSI-SUPER，一个包含两部分的基准测试：VSR（长时程视觉空间回忆）和VSC（连续视觉空间计数）。这些任务需要任意长度的视频输入，但又能抵抗暴力上下文扩展。我们通过整理VSI-590K并训练Cambrian-S来测试数据扩展限制，在VSI-Bench上实现了30%的绝对提升，同时不牺牲通用能力。然而，VSI-SUPER上的性能仍然有限，这表明仅凭规模不足以实现空间超感知。我们提出预测感知作为前进方向，并展示了一个概念验证，其中一个自监督下一潜在帧预测器利用惊喜（预测误差）来驱动记忆和事件分割。在VSI-SUPER上，这种方法大幅超越了领先的专有基线，表明空间超感知需要模型不仅能看，还能预测、选择和组织经验。|
|**2025-11-06**|[SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](http://arxiv.org/abs/2511.04668)|null|尽管多模态语言模型在高级视频理解方面表现出色，但在跨时间和空间的空间推理方面仍面临挑战。当前的空间训练方法依赖于真实世界视频数据，但获取具有精确空间标注的多样化视频素材仍然是一个瓶颈。为了缓解这一瓶颈，我们提出了SIMS-V——一个系统的数据生成框架，它利用3D模拟器的特权信息为多模态语言模型创建空间丰富的视频训练数据。利用这一框架，我们通过对问题类型、组合和规模的系统消融实验，研究了模拟数据的哪些特性能够有效促进真实世界迁移。我们确定了三个最小问题类别（度量测量、依赖视角的推理和时间跟踪），这些类别被证明对发展可迁移的空间智能最有效，尽管使用了较少的问题类型，但其性能优于全面覆盖的方法。这些发现使得高效训练成为可能：我们的70亿参数视频LLM仅用2.5万个模拟示例进行微调，其性能优于更大的720亿参数基线模型，并在严格的真实世界空间推理基准测试中与专有模型具有竞争力。我们的方法展示了强大的泛化能力，在通用视频理解方面保持了性能，同时在具身和真实世界空间任务上显示出显著改进。|
|**2025-11-06**|[SAFe-Copilot: Unified Shared Autonomy Framework](http://arxiv.org/abs/2511.04664)|null|自动驾驶系统在罕见、模糊和分布外场景中仍然表现出脆弱性，而人类驾驶员通过情境推理能够成功应对。共享自主已成为一种有前景的方法，通过在自主系统不确定时融入人类输入来减轻此类故障。然而，大多数现有方法将仲裁限制在低级轨迹，这些轨迹仅代表几何路径，因此未能保留潜在的驾驶意图。我们提出了一个统一的共享自主框架，它在更高抽象层次上整合了人类输入和自主规划器。我们的方法利用视觉语言模型（VLM）从多模态线索——例如驾驶员行为和环境上下文——中推断驾驶员意图，并综合出连贯的策略，以协调人类和自主控制。我们首先在一个模拟人类环境中研究了该框架，它实现了完美的召回率以及高准确率和高精确率。一项人类主体调查进一步显示了高度一致性，92%的参与者同意仲裁结果。最后，在Bench2Drive基准上的评估表明，与纯自主系统相比，碰撞率大幅降低，整体性能得到提升。在语义、基于语言的表示层面的仲裁成为共享自主的一个设计原则，使系统能够进行常识推理并与人类意图保持连续性。|
|**2025-11-06**|[Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](http://arxiv.org/abs/2511.04655)|null|鲁棒性基准对于评估多模态大型语言模型（MLLM）至关重要。然而我们发现，模型无需强大的视觉理解能力，便可在许多多模态基准测试中取得优异成绩，而是利用偏差、语言先验知识和肤浅的模式。这对于旨在需要视觉输入的以视觉为中心的基准测试尤为成问题。我们采纳了一个用于基准设计的诊断原则：如果一个基准可以被钻空子，它就一定会被钻空子。因此，设计者应首先尝试“钻自己基准的空子”，使用诊断和去偏程序来系统地识别并缓解非视觉偏差。有效的诊断需要直接“在测试集上训练”——探测已发布的测试集以发现其内在的、可利用的模式。我们通过两个组成部分将这一标准付诸实践。首先，我们使用“测试集压力测试”（TsT）方法诊断基准的敏感性。我们的主要诊断工具涉及通过k折交叉验证，专门针对测试集中非视觉的文本输入对一个强大的大型语言模型进行微调，以揭示捷径性能并为每个样本分配一个偏差分数 $s(x)$ 。我们辅以一个在手工设计的特征上运行的轻量级基于随机森林的诊断方法，用于快速、可解释的审计。其次，我们使用“迭代偏差剪枝”（IBP）程序过滤高偏差样本，从而对基准进行去偏。将此框架应用于VSI-Bench、CV-Bench、MMMU和VideoMME这四个基准，我们揭示了普遍存在的非视觉偏差。作为一个案例研究，我们应用我们的完整框架创建了VSI-Bench-Debiased，证明其非视觉可解性降低，并且其视觉盲性能差距比原始基准更宽。|
|**2025-11-06**|[PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning](http://arxiv.org/abs/2511.04601)|null|尽管对比语言-图像预训练（CLIP）模型在各种下游视觉语言理解任务中取得了显著成功，但增强其细粒度图像-文本对齐能力仍然是一个活跃的研究热点。为此，大多数现有工作采用显式提高视觉信息处理粒度的策略，例如，通过引入视觉提示来引导模型关注图像中的特定局部区域。同时，多模态大语言模型（MLLMs）的研究表明，使用冗长而详细的文本描述进行训练可以有效提升模型的细粒度视觉-语言对齐能力。然而，CLIP文本编码器固有的token长度限制从根本上限制了CLIP处理长文本序列中嵌入的更细粒度文本信息的能力。为了协同利用提升视觉和文本内容处理粒度的优势，我们提出了PixCLIP，这是一个旨在同时容纳视觉提示输入并处理冗长文本描述的新颖框架。具体而言，我们首先建立了一个自动化标注流程，能够为图像生成像素级局部化的长文本描述。利用此流程，我们构建了LongGRIT，一个包含近150万个样本的高质量数据集。其次，我们用LLM替换了CLIP的原始文本编码器，并提出了一个三分支像素-文本对齐学习框架，以促进图像区域与相应文本描述之间任意粒度的细粒度对齐。实验表明，PixCLIP在像素级交互和处理长文本方面取得了突破，实现了最先进的性能。|
|**2025-11-06**|[Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm](http://arxiv.org/abs/2511.04570)|null|“文本思维”和“图像思维”范式显著提升了大语言模型（LLMs）和视觉语言模型（VLMs）的推理能力。然而，这些范式存在固有限制：(1) 图像仅捕获单一时刻，未能表示动态过程或连续变化；(2) 文本与视觉作为独立模态的分离，阻碍了统一的多模态理解和生成。为克服这些限制，我们引入了“视频思维”这一新范式，它利用Sora-2等视频生成模型，在统一的时间框架内弥合视觉和文本推理。为支持这一探索，我们开发了视频思维基准 (VideoThinkBench)。VideoThinkBench包含两类任务：(1) 视觉中心任务（例如，目测谜题），以及 (2) 文本中心任务（例如，GSM8K和MMMU的子集）。我们的评估表明Sora-2是一个有能力的推理器。在视觉中心任务上，Sora-2通常与最先进的（SOTA）视觉语言模型相当，甚至在目测游戏等几项任务上超越了视觉语言模型。在文本中心任务上，Sora-2在MATH上达到了92%的准确率，在MMMU上达到了75.53%的准确率。此外，我们系统分析了这些能力的来源。我们还发现自我一致性和上下文学习可以提高Sora-2的性能。总而言之，我们的发现表明视频生成模型是潜在的统一多模态理解和生成模型，并将“视频思维”定位为一种统一的多模态推理范式。|
|**2025-11-06**|[Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](http://arxiv.org/abs/2511.04555)|**[link](https://github.com/MINT-SJTU/Evo-1)**|视觉-语言-动作 (VLA) 模型已成为一个强大的框架，它统一了感知、语言和控制，使机器人能够通过多模态理解执行多样化任务。然而，当前的VLA模型通常包含海量参数，并严重依赖大规模机器人数据预训练，这导致训练期间计算成本高昂，以及实时推理部署能力有限。此外，大多数训练范式经常会损害视觉-语言骨干网络的感知表示，导致过拟合和对下游任务泛化能力差。在这项工作中，我们提出了Evo-1，一个轻量级VLA模型，它在无需机器人数据预训练的情况下，减少了计算并提高了部署效率，同时保持了强大的性能。Evo-1构建于一个原生多模态视觉-语言模型 (VLM) 之上，结合了新颖的交叉调制扩散Transformer和一个优化的集成模块，共同形成一个有效的架构。我们进一步引入了一种两阶段训练范式，该范式逐步将动作与感知对齐，从而保留了VLM的表示。值得注意的是，Evo-1仅用7.7亿参数就在Meta-World和RoboTwin套件上取得了最先进的结果，分别超越了之前最佳模型12.4%和6.9%，并在LIBERO上获得了94.8%的竞争性结果。在实际世界评估中，Evo-1以高推理频率和低内存开销取得了78%的成功率，优于所有基线方法。我们发布了代码、数据和模型权重，以促进未来在轻量级和高效VLA模型方面的研究。|
|**2025-11-06**|[CardioPHON: Quality assessment and self-supervised pretraining for screening of cardiac function based on phonocardiogram recordings](http://arxiv.org/abs/2511.04533)|null|远程监测心血管疾病在早期发现心脏功能异常方面发挥着至关重要的作用，能够实现及时干预、改善预防性护理和个性化患者治疗。心音异常可通过计算机辅助决策支持系统自动检测，并用作筛查心血管问题或监测治疗和干预效果的一线工具。本文提出了CardioPHON，这是一种集成的心音质量评估和分类工具，可用于从心音图记录中筛查心脏功能异常。该模型以自监督方式在六个中小型心音数据集上进行预训练，能够自动去除低质量记录，以确保心脏异常的细微声音不被误诊，并为心音分类任务提供了最先进的性能。结合音频和社会人口学特征的多模态模型表现出卓越性能，在2022年George B. Moody PhysioNet心音挑战赛的官方排行榜上获得了最佳排名，而仅基于心音图记录的单模态模型在单模态方法中位居第一（总排名第四），超越了利用多模态的模型。CardioPHON是心音记录领域首个公开发布的预训练模型，促进了数据高效的人工智能模型的开发，这些模型能够泛化到心血管诊断中的各种下游任务。|
|**2025-11-06**|[ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai](http://arxiv.org/abs/2511.04479)|null|我们提出了ThaiOCRBench，这是第一个用于评估视觉-语言模型（VLM）在泰语文本丰富的视觉理解任务上的综合基准。尽管多模态建模取得了最新进展，但现有基准主要集中于高资源语言，导致泰语代表性不足，尤其是在需要文档结构理解的任务中。ThaiOCRBench通过提供一个多样化的人工标注数据集来解决这一空白，该数据集包含2,808个样本，涵盖13个任务类别。我们在零样本设置下评估了广泛的最先进VLM，涵盖了专有系统和开源系统。结果显示存在显著的性能差距，其中专有模型（例如Gemini 2.5 Pro）优于开源对应模型。值得注意的是，在开源模型中，细粒度文本识别和手写内容提取表现出最显著的性能下降。通过详细的错误分析，我们识别出语言偏差、结构不匹配和幻觉内容等关键挑战。ThaiOCRBench为在低资源、脚本复杂的环境中评估VLM提供了一个标准化框架，并为改进泰语文档理解提供了可操作的见解。|
|**2025-11-06**|[V-Thinker: Interactive Thinking with Images](http://arxiv.org/abs/2511.04460)|null|赋能大型多模态模型 (LMM) 深度融合图像交互与长周期推理能力，在该领域仍是一个长期存在的挑战。近期以视觉为中心的推理研究进展为 LMM 探索了一种有前景的“与图像思考”范式，标志着从图像辅助推理向图像交互式思考的转变。尽管这一里程碑使模型能够关注细粒度图像区域，但进展仍受限于有限的视觉工具空间和任务特定的工作流设计。为弥合这一差距，我们提出了 V-Thinker，一个通用的多模态推理助手，它通过端到端强化学习实现交互式、以视觉为中心的思考。V-Thinker 包含两个关键组件：(1) 一个数据演化飞轮，它从多样性、质量和难度三个维度自动合成、演化和验证交互式推理数据集；(2) 一个视觉渐进式训练课程，它首先通过点级监督对齐感知，然后通过两阶段强化学习框架整合交互式推理。此外，我们引入了 VTBench，一个经过专家验证的、针对以视觉为中心的交互式推理任务的基准。大量实验表明，V-Thinker 在通用和交互式推理场景中始终优于强大的基于 LMM 的基线，为推进图像交互式推理应用提供了宝贵见解。|
|**2025-11-04**|[Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything](http://arxiv.org/abs/2511.02834)|null|多模态大语言模型（MLLMs）已展现出强大能力，但仍局限于固定的模态对，并需要使用大规模对齐数据集进行昂贵的微调。构建能够整合文本、图像、音频和视频的完全全能模型仍然不切实际，并且缺乏强大的推理支持。在本文中，我们提出了一个Agent-Omni框架，该框架通过主代理系统协调现有基础模型，从而无需重新训练即可实现灵活的多模态推理。主代理负责解释用户意图，将子任务委托给特定模态的代理，并将它们的输出整合为连贯的响应。在文本、图像、音频、视频和全能基准上的大量实验表明，Agent-Omni始终能达到最先进的性能，尤其是在需要复杂跨模态推理的任务上。其基于代理的设计实现了专用基础模型的无缝集成，确保了对多样化输入的适应性，同时保持了透明度和可解释性。此外，该框架具有模块化且易于扩展的特点，允许未来随着更强大模型的出现进行改进。|
|**2025-11-04**|[When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning](http://arxiv.org/abs/2511.02794)|null|尽管多模态大语言模型（MLLMs）发展迅速，但其推理轨迹仍不透明：通常不清楚是哪种模态驱动了预测，冲突如何解决，或者某个信息流何时占据主导。本文引入了模态破坏现象，这是一种诊断性失效模式，其中高置信度单模态错误会覆盖其他证据并误导融合结果。为了分析这种动态，我们提出了一种轻量级、模型无关的评估层，该层将每种模态视为一个智能体，生成候选标签和用于审计的简短自我评估。一个简单的融合机制聚合这些输出，揭示了贡献者（支持正确结果的模态）和破坏者（误导的模态）。将我们的诊断层应用于使用基础模型进行多模态情感识别基准的案例研究中，揭示了系统的可靠性概况，深入了解了故障是源于数据集伪影还是模型局限性。更广泛地说，我们的框架为多模态推理提供了一个诊断框架，支持对融合动态进行原则性审计并为可能的干预措施提供信息。|
|**2025-11-04**|[When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought](http://arxiv.org/abs/2511.02779)|**[link](https://github.com/MIRA-Benchmark/MIRA-Benchmark.github.io)**|我们提出了MIRA，这是一个旨在评估模型在生成中间视觉图像对成功推理至关重要的场景中的新基准。与仅依赖文本的传统思维链（CoT）方法不同，MIRA中的任务要求模型生成并利用草图、结构图或路径图等中间图像来指导其推理过程。这种设置与人类通过“边画边思考”来解决复杂问题的方式非常相似。为此，MIRA侧重于本质上具有挑战性且涉及复杂的结构、空间关系或仅凭语言难以表达的推理步骤的任务。为了确保我们的评估数据具有高质量，我们包含了546个标注了中间视觉图像和最终答案的多模态问题。我们还提出了MIRA的统一评估协议，该协议涵盖了三个级别的评估输入：仅包含图像和问题的直接输入、包含图像和思维提示的纯文本CoT输入，以及包含标注图像线索和文本思维提示的视觉CoT输入。为了探究模型在我们基准上的能力上限，我们还报告了在不同k设置下的pass@k和多数投票准确率。实验结果表明，现有的多模态大型语言模型，包括最强的私有模型和强大的开源模型，在仅依赖文本提示时表现不佳。然而，当提供中间视觉线索时，模型性能持续提高，在所有模型和任务中平均相对增益达到33.7%。我们还通过扩展搜索空间和设计与视觉CoT对齐的文本提示来探究上限，但与我们的视觉CoT设置相比，两者都只带来了有限的改进。这些结果强调了想象的视觉信息在促成MIRA上成功推理中的关键作用。|
|**2025-11-04**|[VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation](http://arxiv.org/abs/2511.02778)|**[link](https://github.com/CSU-JPG/VCode)**|在智能体时代，代码已成为进行推理和行动的精确且可执行的媒介。然而，进展主要集中在以语言为中心的任务上，例如程序合成和调试，使得以视觉为中心的编码尚未得到充分探索。受人类如何对草图进行推理的启发，我们提倡将SVG代码作为一种紧凑、可解释且可执行的视觉表示。我们引入了VCode，这是一个将多模态理解重新定义为代码生成的基准：给定一张图像，模型必须生成SVG，以保留符号意义用于后续推理。VCode涵盖三个领域：通用常识 (MM-Vet)、专业学科 (MMMU) 和以视觉为中心的感知 (CV-Bench)。为了评估符号保真度，我们提出了CodeVQA，这是一种新颖的评估协议，其中策略模型对渲染的SVG回答问题；正确答案表明忠实的符号保留。经验上，前沿VLM难以生成忠实的SVG，揭示了以语言为中心和以视觉为中心的编码之间持续存在的差距。为了弥合这一差距，我们引入了VCoder，这是一个沿两个轴增强VLM的智能体框架：(i) 带有修正的思考，它迭代分析差异并完善SVG代码；以及 (ii) 使用视觉工具进行行动，其中检测器和解析器提供超出模型内在能力的对象、形状和文本等结构化线索。在各项基准测试中，具有强大推理能力的前沿VLM总体得分较高，但在专业知识和3D推理方面仍有限。VCoder相较于表现最佳的Claude-4-Opus实现了12.3分的总体提升。人类研究表明，人类和VLM在渲染的SVG上表现更差，而它们的一致性揭示了符号视觉表示的潜力。基准测试和代码可在 https://github.com/CSU-JPG/VCode 获取。|
|**2025-11-04**|[XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations](http://arxiv.org/abs/2511.02776)|null|大规模机器人数据集和视觉语言模型（VLM）的最新进展推动了视觉-语言-动作（VLA）模型的研究。然而，现有VLA模型仍面临两个基本挑战：(i) 从高维观测中生成精确的低级动作，以及 (ii) 弥合异构数据源（包括不同机器人形态和人类演示）之间的领域鸿沟。现有方法通常从视觉动态或机器人动作中编码潜在变量以指导策略学习，但它们未能充分利用大规模异构数据集中存在的互补多模态知识。在这项工作中，我们提出了X机器人模型1 (XR-1)，一个新颖的框架，用于在不同机器人、任务和环境中进行通用且可扩展的VLA学习。XR-1引入了统一视觉-运动编码 (UVMC)，这是一种通过双分支VQ-VAE学习的离散潜在表示，它联合编码视觉动态和机器人运动。UVMC通过 (i) 作为观测和动作之间的中间表示，以及 (ii) 对齐来自异构数据源的多模态动态信息以捕获互补知识，从而解决了这些挑战。为了有效利用UVMC，我们提出了一种三阶段训练范式：(i) 自监督UVMC学习，(ii) 在大规模跨形态机器人数据集上进行UVMC引导的预训练，以及 (iii) 任务特定的后训练。我们通过广泛的真实世界实验验证了XR-1，包括在六种不同机器人形态上进行超过14,000次运行，涵盖120多种不同的操作任务。XR-1始终优于最先进的基线方法，例如 $\pi_{0.5}$、$\pi_0$ 、RDT、UniVLA和GR00T-N1.5，同时展示了对新颖物体、背景变化、干扰物和照明变化的强大泛化能力。我们的项目网址是https://xr-1-vla.github.io/。|
|**2025-11-04**|[Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query Retrieval](http://arxiv.org/abs/2511.02770)|null|大多数文本检索器生成一个查询向量来检索相关文档。然而，查询相关文档的条件分布可能是多模态的，例如代表查询的不同解释。我们首先量化了现有检索器的局限性。我们评估的所有检索器在目标文档嵌入之间的距离增大时表现更差。为了解决这一局限性，我们开发了一种新的检索器架构，即自回归多嵌入检索器 (AMER)。我们的模型自回归地生成多个查询向量，并且所有预测的查询向量都用于从语料库中检索文档。我们表明，在合成向量化数据上，所提出的方法可以完美地捕获多个目标分布，性能比单嵌入模型提高4倍。我们还在实际的多答案检索数据集上微调了我们的模型，并在域内进行了评估。AMER 在我们评估的两个数据集上相较于单嵌入基线模型分别取得了4%和21%的相对增益。此外，我们始终在目标文档嵌入彼此之间相似度较低的数据集子集上观察到更大的增益。我们展示了使用多查询向量检索器的潜力，并为未来的工作开辟了新的方向。|
|**2025-11-04**|[LLEXICORP: End-user Explainability of Convolutional Neural Networks](http://arxiv.org/abs/2511.02720)|null|卷积神经网络（CNNs）是许多现代计算机视觉系统的基础。随着其应用范围从常见领域扩展到关键领域，解释和理解模型及其决策（XAI）的需求应运而生。先前的工作表明，在CNN的顶层中，各个通道可以归因于对人类可理解概念的分类。概念相关性传播（CRP）方法可以将预测回溯到这些通道，并找到最能激活这些通道的图像。然而，当前的CRP工作流程主要是手动的：专家必须检查激活图像来命名发现的概念，并必须从相关性图中综合出冗长的解释，这限制了解释的可访问性和可扩展性。为了解决这些问题，我们引入了大型语言模型解释概念相关性传播（LLEXICORP），这是一个模块化管道，将CRP与多模态大型语言模型结合起来。我们的方法自动为概念原型分配描述性名称，并生成自然语言解释，将定量相关性分布转化为直观的叙述。为了确保忠实性，我们精心设计了提示，通过示例教授语言模型CRP的语义，并强制命名和解释任务之间的分离。生成的文本可以根据不同的受众进行定制，为专家提供低级别的技术描述，并为非技术利益相关者提供高级别的总结。我们使用VGG16模型，对ImageNet中的各种图像定性评估了我们的方法。我们的发现表明，将基于概念的归因方法与大型语言模型相结合，可以显著降低解释深度神经网络的门槛，为更透明的AI系统铺平道路。|
|**2025-11-04**|[Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models](http://arxiv.org/abs/2511.02650)|null|大规模多模态模型 (LMMs) 常常面临严重的推理效率低下问题，这主要是由于图像编码器引入了大量的视觉 token。尽管近期的 token 压缩方法，例如剪枝和合并，在减少冗余方面展现出潜力，但它们的评估仍然分散且不一致。在这项工作中，我们提出了 UniPruneBench，一个统一且可扩展的基准，用于多模态大语言模型 (LLMs) 中的视觉 token 剪枝。UniPruneBench 提供了标准化的协议，涵盖六个能力维度和十个数据集，覆盖十种代表性的压缩算法以及三大家族的 LMMs (LLaVA-v1.5、Intern-VL3 和 Qwen2.5-VL)。除了任务准确性，它还包含了系统级指标，例如运行时间和预填充延迟，以提供一个全面的视角。我们的实验揭示了几个关键发现：(1) 随机剪枝是一个出人意料的强大基线，(2) 没有哪种单一方法能在所有场景中始终优于其他方法，(3) 剪枝敏感性在不同任务中差异显著，其中 OCR 最为脆弱，以及 (4) 剪枝率是影响性能下降的主导因素。我们相信 UniPruneBench 将为未来高效多模态建模的研究奠定可靠基础。|
|**2025-11-04**|[Model Parameter Reconstruction of Electroweak Phase Transition with TianQin and LISA: Insights from the Dimension-Six Model](http://arxiv.org/abs/2511.02612)|null|我们考察了天琴和LISA重构新物理情景拉格朗日量中模型参数的能力，这些情景能够产生强一阶电弱相变。我们以标准模型维度六希格斯算符拓展作为一大类新物理模型的代表性情景，建立了模型参数 $\Lambda$与随机引力波背景可观测谱特征之间的映射关系。我们首先生成了包含时延干涉通道噪声、天体物理前景以及维度六模型信号的模拟数据。随后，数据经过压缩和优化，并利用费雪矩阵分析和采用PolyChord的贝叶斯嵌套采样进行几何参数推断，PolyChord能有效处理高维、多峰的后验分布。最后，我们采用机器学习技术实现模型参数$\Lambda$的精确重构。对于产生强信号的基准点，天琴和LISA的参数重构在信号幅度上产生了约20%-30%的相对不确定性，并在模型参数$\Lambda$ 上达到了亚百分比精度。天琴的灵敏度仅限于其最佳频率带内的更强信号，而LISA可以在更广的信号强度范围内重构参数。我们的结果表明，重构精度取决于信号强度、天体物理前景和仪器噪声特性。|
|**2025-11-04**|[UniChange: Unifying Change Detection with Multimodal Large Language Model](http://arxiv.org/abs/2511.02607)|null|变化检测（CD）是监测和分析土地覆盖动态的一项基础任务。尽管近期高性能模型和高质量数据集显著推动了该领域的发展，但一个关键局限性依然存在。当前模型通常从单一类型的标注数据中获取有限知识，并且无法同时利用多样化的二元变化检测（BCD）和语义变化检测（SCD）数据集。这种限制导致了泛化能力差和适用性有限。多模态大语言模型（MLLMs）的最新进展为统一的CD框架带来了新的可能性。我们利用MLLMs的语言先验和统一能力开发了UniChange，这是首个基于MLLM的统一变化检测模型。UniChange集成了生成式语言能力与专门的CD功能。我们的模型通过引入三个特殊标记：[T1]、[T2]和[CHANGE]，成功统一了BCD和SCD两种任务。此外，UniChange利用文本提示来指导变化类别的识别，消除了对预定义分类头的依赖。这种设计使UniChange能够有效地从多源数据集中获取知识，即使它们的类别定义存在冲突。在四个公共基准（WHU-CD、S2Looking、LEVIR-CD+和SECOND）上的实验证明了SOTA性能，分别取得了90.41、53.04、78.87和57.62的IoU分数，超越了所有现有方法。代码已在 https://github.com/Erxucomeon/UniChange 提供。|
|**2025-10-31**|[PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting](http://arxiv.org/abs/2510.27680)|null|视觉-语言模型 (VLM) 的最新进展实现了令人印象深刻的多模态推理，但大多数医疗应用仍限于2D成像。在这项工作中，我们将VLM扩展到3D正电子发射断层扫描和计算机断层扫描 (PET/CT)，这是一个以大体积数据、微小分散的病灶和冗长放射学报告为特点的领域。我们引入了一个大规模数据集，包含超过11,000个病灶层面描述，与来自5,000多次PET/CT检查的3D分割配对，并通过混合规则基和大语言模型 (LLM) 流水线进行提取。基于此数据集，我们提出了PETAR-4B，一个3D掩膜感知视觉-语言模型，它整合了PET、CT和病灶轮廓，用于空间定位的报告生成。PETAR将全局上下文推理与细粒度病灶感知相结合，生成临床连贯且局部化的发现。全面的自动化和人工评估表明，PETAR显著提升了PET/CT报告生成质量，推动了3D医学视觉-语言理解。|
|**2025-10-31**|[Teaching competencies in physics for engineering education: A qualitative analysis from teaching practice](http://arxiv.org/abs/2510.27674)|null|工程专业中的物理教学提出了学科特有的要求，这些要求将概念建模、实验探究和计算分析交织在一起。本研究考察了九项物理教学能力，这些能力源自国际和区域框架，并在工程背景下进行解读。托卢卡理工学院的19位大学教师完成了一份开放式问卷；使用扎根理论方法（开放编码和主轴编码）对答复进行了分析，并辅以描述性频率分析。结果表明，教师在技术掌握、方法论/数字整合、技术介导的沟通和创新（C1、C2、C6、C9）方面发展较强，而在数字内容创建/改编的信息素养以及数字伦理/安全（C7、C8）方面仍有待发展。研究发现了一个反复出现的理解-应用差距，揭示了从概念认知到实际课堂实践的不均衡转化。我们得出结论，推进工程师的物理教育需要机构支持的、学科特定的专业发展，将建模、实验工作和计算与伦理且可复现的数字实践相结合；这种结合可以促使教师从采纳/适应转向在多模态环境中的持续运用和创新。|
|**2025-10-31**|[NegoCollab: A Common Representation Negotiation Approach for Heterogeneous Collaborative Perception](http://arxiv.org/abs/2510.27647)|**[link](https://github.com/scz023/NegoCollab)**|协同感知通过智能体间的信息共享来扩展感知范围，从而提高了任务性能。不可变异构性给协同感知带来了巨大挑战，因为参与的智能体可能采用不同且固定的感知模型。这导致了智能体间共享的中间特征存在域间隙，从而降低了协同性能。将所有智能体的特征对齐到一个共同表示，可以以较低的训练成本消除域间隙。然而，在现有方法中，共同表示被指定为特定智能体的表示，这使得与该特定智能体存在显著域差异的智能体难以实现适当的对齐。本文提出了NegoCollab，一种基于协商的共同表示的异构协同方法。它在训练期间引入了一个协商器，用于从每个模态智能体的局部表示中导出共同表示，从而有效减少了与各种局部表示之间固有的域间隙。在NegoCollab中，局部表示空间和共同表示空间之间的特征相互转换由一对发送器和接收器实现。为了更好地将局部表示对齐到包含多模态信息的共同表示，除了分布对齐损失之外，我们还引入了结构对齐损失和实用对齐损失来监督训练。这使得共同表示中的知识能够充分提取到发送器中。|
|**2025-10-31**|[Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation](http://arxiv.org/abs/2510.27632)|null|图形布局生成是一个新兴的研究领域，专注于生成从海报设计到文档等各种美观布局。尽管最近的研究探索了结合用户约束来指导布局生成的方法，但这些约束通常需要复杂的规范，从而降低了可用性。我们引入了一种创新方法，利用用户提供的草图作为直观约束，并通过实验证明了这种新指导方法的有效性，将草图到布局（sketch-to-layout）问题确立为一个有前景但目前尚未充分探索的研究方向。为了解决草图到布局问题，我们提出了一种基于多模态Transformer的解决方案，使用草图和内容资产作为输入来生成高质量布局。由于从人工标注者那里收集草图训练数据来训练我们的模型成本非常高，我们引入了一种新颖高效的方法来大规模合成生成训练草图。我们在三个公开可用的数据集（PubLayNet、DocLayNet和SlidesVQA）上训练和评估了我们的模型，结果表明它优于最先进的基于约束的方法，同时提供了更直观的设计体验。为了促进未来的草图到布局研究，我们为上述公共数据集发布了约20万（O(200k)）个合成生成的草图。这些数据集可在https://github.com/google-deepmind/sketch_to_layout获取。|
|**2025-10-31**|[Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning](http://arxiv.org/abs/2510.27623)|null|多模态大语言模型（MLLM）通过使具身智能体能够直接从视觉输入进行感知、推理和规划面向任务的行动，从而推动了具身智能体的发展。然而，这种视觉驱动的具身智能体开启了一个新的攻击面：视觉后门攻击，即智能体在场景中出现视觉触发器之前表现正常，一旦触发器出现，便持续执行攻击者指定的多步策略。我们引入了BEAT，这是首个利用环境中的物体作为触发器，向基于MLLM的具身智能体注入此类视觉后门的框架。与文本触发器不同，物体触发器在不同视角和光照下表现出广泛的变化，使其难以可靠地植入。BEAT通过(1) 构建一个涵盖多样化场景、任务和触发器放置的训练集，以使智能体暴露于触发器变异性，以及(2) 引入一个两阶段训练方案来解决这一挑战，该方案首先应用监督微调（SFT），然后是我们新颖的对比触发器学习（CTL）。CTL将触发器判别表述为存在触发器和无触发器输入之间的偏好学习，明确地锐化决策边界，以确保精确的后门激活。在各种具身智能体基准和MLLM上，BEAT实现了高达80%的攻击成功率，同时保持了强大的良性任务性能，并可靠地泛化到分布外触发器放置。值得注意的是，与简单的SFT相比，在有限的后门数据下，CTL将后门激活准确率提高了多达39%。这些发现揭示了基于MLLM的具身智能体中一个关键但尚未探索的安全风险，强调了在实际部署之前对鲁棒防御的需求。|
|**2025-10-31**|[Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model](http://arxiv.org/abs/2510.27607)|null|近来，将视觉-语言-动作模型（VLA）与世界建模相结合，在改进机器人策略学习方面显示出前景。然而，由于这两种模态之间固有的差异，联合预测下一步状态观测和动作序列仍然具有挑战性。为了解决这个问题，我们提出了双流扩散模型（DUST），这是一个世界模型增强的VLA框架，能够处理模态冲突并提升VLA在各种任务中的性能。具体而言，我们提出了一种多模态扩散Transformer架构，它显式地保持独立的模态流，同时仍然能够实现跨模态知识共享。此外，我们为每种模态引入了独立的噪声扰动以及一种解耦的流匹配损失。这种设计使模型能够以双向方式学习联合分布，同时避免了对统一潜在空间的需求。基于训练期间的模态解耦，我们还引入了一种支持测试时缩放的联合采样方法，其中动作和视觉令牌以不同的速率异步演化。通过在RoboCasa和GR-1等模拟基准上的实验，DUST比基线方法获得了高达6%的提升，而我们的测试时缩放方法提供了额外的2-5%的提升。在使用Franka Research 3进行的真实世界任务中，DUST将成功率提高了13%，证实了其在模拟之外的有效性。此外，在来自BridgeV2的无动作视频上进行预训练，在RoboCasa上产生了显著的迁移增益，强调了DUST在大规模VLA预训练方面的潜力。|
|**2025-10-31**|[Image Hashing via Cross-View Code Alignment in the Age of Foundation Models](http://arxiv.org/abs/2510.27584)|**[link](https://github.com/ilyassmoummad/CroVCA)**|高效的大规模检索需要同时具有紧凑性和判别性的表示。基础模型提供了强大的视觉和多模态嵌入，但在这些高维空间中进行最近邻搜索的计算开销很大。哈希通过使用二进制码实现快速汉明距离搜索，提供了一种高效的替代方案，然而，现有方法通常依赖于复杂的流水线、多项目标函数、针对单一学习范式设计的方案以及漫长的训练时间。我们引入了CroVCA（跨视图编码对齐），这是一个用于学习在语义对齐视图间保持一致的二进制码的简单而统一的原则。单一的二元交叉熵损失强制执行对齐，而编码率最大化则作为一种抗崩溃正则化器，以促进平衡和多样化的编码。为实现这一点，我们设计了HashCoder，一个带有最终批量归一化层以强制生成平衡编码的轻量级MLP哈希网络。HashCoder可以用作冻结嵌入上的探测头，或通过LoRA微调高效地适应编码器。在各项基准测试中，CroVCA 仅用5个训练周期就取得了最先进的结果。在16比特下，它表现尤为出色——例如，在单个GPU上，COCO数据集上的无监督哈希在2分钟内完成，ImageNet100数据集上的有监督哈希在大约3分钟内完成。这些结果突出了CroVCA的效率、适应性以及广泛适用性。|
|**2025-10-31**|[Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs](http://arxiv.org/abs/2510.27558)|null|本文提出了一个框架，该框架利用预训练基础模型进行机器人操作，而无需领域特定训练。该框架集成了现成模型，将来自基础模型的多模态感知与能够实现鲁棒任务序列规划的通用推理模型相结合。框架内动态维护的场景图提供了空间感知能力，并支持对环境进行一致的推理。通过一系列桌面机器人操作实验对该框架进行了评估，结果突出了其在直接基于现成基础模型构建机器人操作系统方面的潜力。|
|**2025-10-31**|[Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation](http://arxiv.org/abs/2510.27508)|**[link](https://github.com/arco-group/vMambaX)**|准确的肺肿瘤分割对于改善诊断和治疗规划至关重要，而有效结合PET和CT的解剖学和功能性信息仍然是一个重大挑战。在这项研究中，我们提出了vMambaX，一个轻量级多模态框架，通过一个上下文门控跨模态感知模块（CGM）整合PET和CT扫描图像。vMambaX基于Visual Mamba架构构建，能够自适应地增强模态间特征交互，强调信息丰富的区域同时抑制噪声。在PCLT20K数据集上进行评估，该模型在保持较低计算复杂度的同时优于基线模型。这些结果突出了自适应跨模态门控在多模态肿瘤分割中的有效性，并展示了vMambaX作为用于高级肺癌分析的高效且可扩展框架的潜力。代码可在https://github.com/arco-group/vMambaX获取。|
|**2025-10-31**|[GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language](http://arxiv.org/abs/2510.27448)|null|多模态大型语言模型（MLLMs）因其处理多模态任务的能力而在学术界和工业界获得了广泛关注。然而，由于高质量几何数据的稀缺性，这些模型在数学几何推理方面面临挑战。为解决这一问题，合成几何数据已成为一项关键策略。当前生成合成几何数据的方法涉及改写或扩展现有问题，并利用预定义规则和模板来创建几何图像和问题。然而，这些方法通常生成缺乏多样性或容易产生噪声的数据。此外，现有方法合成的几何图像往往变化有限，并且与真实的几何图表存在显著偏差。为了克服这些局限性，我们提出了GeoFM，一种合成几何数据的新颖方法。GeoFM使用形式语言在度量空间中探索条件的组合，生成不同于原始问题的高保真几何问题，同时通过符号引擎确保其正确性。实验结果表明，我们的合成数据显著优于现有方法。使用我们数据训练的模型在MathVista的几何问题解决任务中超越了专有的GPT-4o模型18.7%，在GeoQA上超越了16.5%。此外，它在MathVista上超过了领先的开源模型5.7%，在GeoQA上超过了2.7%。|
|**2025-10-30**|[OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes](http://arxiv.org/abs/2510.26800)|**[link](https://github.com/HKU-MMLab/OmniX)**|构建3D场景有两种流行方式：程序生成和2D提升。其中，基于全景图的2D提升已成为一种有前景的技术，它利用强大的2D生成先验来生成沉浸式、真实且多样化的3D环境。在这项工作中，我们推进了这项技术，以生成适用于基于物理的渲染（PBR）、重照明和模拟的渲染就绪3D场景。我们的关键见解是重新利用2D生成模型，实现几何形状、纹理和PBR材质的全景感知。与现有强调外观生成而忽略内在属性感知的2D提升方法不同，我们提出了OmniX，一个通用且统一的框架。OmniX基于轻量高效的跨模态适配器结构，将2D生成先验重用于广泛的全景视觉任务，包括全景感知、生成和补全。此外，我们构建了一个大规模合成全景图数据集，其中包含来自多样化室内外场景的高质量多模态全景图。大量实验证明了我们模型在全景视觉感知和渲染就绪3D场景生成方面的有效性，为沉浸式和物理真实的虚拟世界生成开辟了新的可能性。|
|**2025-10-30**|[The Quest for Generalizable Motion Generation: Data, Model, and Evaluation](http://arxiv.org/abs/2510.26794)|**[link](https://github.com/oneScotch/ViMoGen)**|尽管3D人体动作生成（MoGen）在标准基准上取得了近期进展，但现有模型在泛化能力方面仍面临根本瓶颈。相比之下，相邻的生成领域，最值得注意的是视频生成（ViGen），在建模人类行为方面展现出显著的泛化能力，突出了MoGen可以借鉴的可迁移见解。受此观察启发，我们提出了一个综合框架，该框架系统地将ViGen的知识迁移到MoGen，涵盖数据、建模和评估三个关键支柱。首先，我们引入了ViMoGen-228K，这是一个包含228,000个高质量动作样本的大规模数据集，它整合了高保真光学动作捕捉（MoCap）数据、来自网络视频的语义标注动作以及由最先进的ViGen模型生成的合成样本。该数据集包含文本-动作对和文本-视频-动作三元组，大幅扩展了语义多样性。其次，我们提出了ViMoGen，一个基于流匹配的扩散Transformer，它通过门控多模态条件作用统一了来自MoCap数据和ViGen模型的先验知识。为了提高效率，我们进一步开发了ViMoGen-light，这是一个蒸馏变体，它消除了视频生成依赖，同时保持强大的泛化能力。最后，我们提出了MBench，一个旨在进行细粒度评估的分层基准，涵盖动作质量、提示词保真度和泛化能力。大量实验表明，我们的框架在自动评估和人工评估中均显著优于现有方法。代码、数据和基准将公开发布。|
|**2025-10-30**|[ChartAB: A Benchmark for Chart Grounding & Dense Alignment](http://arxiv.org/abs/2510.26781)|null|图表在人类的可视化、推理、数据分析和思想交流中扮演着重要角色。然而，现有的视觉-语言模型（VLM）仍然缺乏对细节的准确感知，并且难以从图表中提取细粒度结构。这种在图表接地方面的局限性也阻碍了它们比较多个图表并进行推理的能力。在本文中，我们引入了一个新颖的“图表对齐基准（ChartAB）”，旨在对VLM在图表接地任务中的表现进行全面评估，这些任务包括从不同类型和复杂度的图表中提取表格数据、定位可视化元素和识别各种属性。我们设计了一个JSON模板，以方便计算专门为每个接地任务定制的评估指标。通过整合一个新颖的两阶段推理工作流，该基准可以进一步评估VLM对齐和比较两个图表之间元素/属性的能力。我们对几个近期VLM的评估分析揭示了它们在图表理解中的感知偏差、弱点、鲁棒性和幻觉方面的新见解。这些发现突出了VLM在图表理解任务中的细粒度差异，并指出了当前模型中需要加强的特定技能。|
|**2025-10-30**|[SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models](http://arxiv.org/abs/2510.26769)|null|这项工作引入了SteerVLM，一个轻量级引导模块，旨在引导视觉-语言模型（VLM）生成更符合预期指令的输出。我们的方法从编码目标行为和反向行为的成对提示的潜在嵌入中学习，以动态调整连接语言模态与图像上下文的激活。这使得在不修改模型权重的情况下，实现对复杂输出语义的细粒度、推理时控制，同时保持在非目标任务上的性能。我们的引导模块所需的学习参数仅为原始VLM大小的0.14%。我们的引导模块通过维度级激活调制和跨层的自适应引导获得模型控制能力，无需预先提取静态向量或手动调整干预点。此外，我们引入了VNIA（视觉叙事意图对齐），一个专门为促进VLM引导技术发展和评估而创建的多模态数据集。我们的方法在VLM的引导和幻觉缓解基准上优于现有干预技术，并通过激活工程为多模态模型控制提出了一种鲁棒的解决方案。|
|**2025-10-30**|[Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis](http://arxiv.org/abs/2510.26721)|null|多模态大语言模型（MLLM）在处理视觉-语言数据时表现出对文本输入的显著偏好，限制了它们从视觉证据进行有效推理的能力。与以往将这种文本偏置归因于数据不平衡或指令微调等外部因素的研究不同，我们提出这种偏置源于模型内部架构。具体来说，我们假设视觉键向量（Visual Keys）相对于在仅语言预训练期间学习到的文本键空间处于分布外（OOD）。因此，这些视觉键在注意力计算期间系统地接收到较低的相似性分数，导致它们在上下文表示中未被充分利用。为了验证这一假设，我们从LLaVA和Qwen2.5-VL中提取键向量，并使用定性（t-SNE）和定量（Jensen-Shannon散度）方法分析它们的分布结构。结果提供了直接证据，表明视觉和文本键在注意力空间中占据着明显不同的子空间。模态间差异具有统计学意义，超过模态内变异几个数量级。这些发现揭示文本偏置源于注意力键空间内的内在错位，而不仅仅是外部数据因素。|
|**2025-10-30**|[All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles](http://arxiv.org/abs/2510.26641)|null|自动驾驶汽车 (AVs) 正通过智能感知、决策和控制系统的进步，改变着交通运输的未来。然而，它们的成功取决于一项核心能力，即在复杂多模态环境中的可靠目标检测。尽管计算机视觉 (CV) 和人工智能 (AI) 的最新突破推动了显著进展，但该领域仍面临一个严峻挑战，即知识在多模态感知、上下文推理和协同智能方面仍然分散。本综述通过对自动驾驶汽车中的目标检测进行前瞻性分析来弥补这一空白，重点强调视觉-语言模型 (VLMs)、大语言模型 (LLMs) 和生成式人工智能等新兴范式，而非重新审视过时技术。我们首先系统地回顾了自动驾驶汽车传感器的基本范围（摄像头、超声波、激光雷达和雷达）及其融合策略，不仅强调了它们在动态驾驶环境中的能力和局限性，还指出了它们与LLM/VLM驱动的感知框架最新进展相结合的潜力。接下来，我们介绍了一种超越简单收集的自动驾驶汽车数据集的结构化分类，定位了自车、基于基础设施和协同数据集（例如，车-车V2V、车-基础设施V2I、车-万物V2X、基础设施-基础设施I2I），并随后对数据结构和特征进行了交叉分析。最后，我们分析了前沿检测方法，范围从2D和3D管道到混合传感器融合，并特别关注由视觉Transformer (ViTs)、大语言模型 (LLMs) 和小语言模型 (SLMs) 以及视觉-语言模型 (VLMs) 驱动的新兴Transformer方法。通过综合这些观点，本综述提供了一份关于当前能力、开放挑战和未来机遇的清晰路线图。|
|**2025-10-30**|[Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications](http://arxiv.org/abs/2510.26628)|null|物联网（IoT）网络的普及对可持续能源解决方案产生了迫切需求，尤其对于电池受限的空间分布式物联网节点。虽然搭载无线能量传输（WPT）能力的低空无人机（UAV）提供了一种有前景的解决方案，但有助于高效能量传输的视距信道也将敏感操作数据暴露给攻击者。本文提出了一种新颖的低空无人机携带的可移动天线增强传输系统，联合无线能量传输（WPT）和隐蔽通信，该系统通过利用无线能量信号作为天然掩护，同时为物联网节点补充能量并与隐蔽用户建立传输链路。然后，我们建立了一个多目标优化问题，旨在联合最大化物联网节点的总收集能量和隐蔽用户的总可达速率，同时最小化低空无人机的推进能量消耗。为了解决非凸和时间耦合的优化问题，我们提出了一种专家混合增强型软演员-评论家（MoE-SAC）算法，该算法采用稀疏Top-K门控浅层专家混合架构来表示源于冲突优化目标的多模态策略分布。我们还引入了一个动作投影模块，明确强制执行每时隙功率预算约束和天线位置约束。仿真结果表明，所提出的方法显著优于某些基线方法和其他最先进的深度强化学习算法。|
|**2025-10-30**|[Emu3.5: Native Multimodal Models are World Learners](http://arxiv.org/abs/2510.26583)|null|我们引入了Emu3.5，一个大规模多模态世界模型，能够原生预测视觉和语言的下一个状态。Emu3.5通过统一的下一词元预测目标进行端到端预训练，其训练语料库包含超过10万亿词元的视觉-语言交错数据，这些数据主要来源于互联网视频的连续帧和文本记录。该模型自然地接受交错的视觉-语言输入并生成交错的视觉-语言输出。Emu3.5还通过大规模强化学习进行后训练，以增强多模态推理和生成能力。为了提高推理效率，我们提出了离散扩散适配（DiDA）方法，它将逐词元解码转换为双向并行预测，在不牺牲性能的情况下将每图像推理速度提升了约20倍。Emu3.5展现出强大的原生多模态能力，包括长时程视觉-语言生成、任意到图像（X2I）生成以及复杂富文本图像生成。它还展现出可泛化的世界建模能力，支持在多样化场景和任务中进行时空一致的世界探索和开放世界具身操控。对比而言，Emu3.5在图像生成和编辑任务上取得了与Gemini 2.5 Flash Image (Nano Banana)相当的性能，并在一系列交错生成任务上展现出更优异的结果。我们在https://github.com/baaivision/Emu3.5开源了Emu3.5，以支持社区研究。|
|**2025-10-30**|[Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition](http://arxiv.org/abs/2510.26466)|null|物体-上下文捷径仍然是视觉-语言模型中一个持续存在的挑战，当测试时场景与熟悉的训练共现情况不同时，这会损害零样本可靠性。我们将此问题重新定义为因果推断问题并提出疑问：如果物体出现在不同的环境中，预测是否会保持不变？为了在推理时回答这个问题，我们估计CLIP表征空间内的物体和背景期望，并通过将物体特征与从外部数据集、批次邻居或文本描述中采样的多样化替代上下文重新组合来合成反事实嵌入。通过估计总直接效应和模拟干预，我们进一步减去仅背景的激活，从而保留有益的物体-上下文交互，同时减轻幻觉分数。无需重新训练或提示设计，我们的方法在上下文敏感基准上显著提高了最差组和平均准确率，建立了新的零样本SOTA。除了性能之外，我们的框架提供了一种轻量级的表征层面的反事实方法，为去偏且可靠的多模态推理提供了一条实用的因果途径。|
|**2025-10-30**|[Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection](http://arxiv.org/abs/2510.26464)|null|小样本异常检测（FSAD）方法通过少量已知正常样本识别异常区域。大多数现有方法依赖于预训练视觉-语言模型（VLM）的泛化能力，通过文本描述和图像之间的特征相似性来识别潜在异常区域。然而，由于缺乏详细的文本描述，这些方法只能预定义图像级描述来匹配每个视觉块令牌以识别潜在异常区域，这导致图像描述与块级视觉异常之间的语义错位，从而实现次优的定位性能。为了解决上述问题，我们提出了多级细粒度语义标注（MFSC），通过自动化构建管道为现有异常检测数据集提供多级和细粒度的文本描述。基于MFSC，我们提出了一个名为FineGrainedAD的新颖框架，以提高异常定位性能，该框架由两个组件组成：多级可学习提示（MLLP）和多级语义对齐（MLSA）。MLLP通过自动替换和拼接机制将细粒度语义引入多级可学习提示中，而MLSA设计了区域聚合策略和多级对齐训练，以促进可学习提示更好地与相应视觉区域对齐。实验表明，所提出的FineGrainedAD在MVTec-AD和VisA数据集的小样本设置中取得了优异的整体性能。|
|**2025-10-28**|[Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](http://arxiv.org/abs/2510.24650)|null|作物精准病害管理（SSDM）通过机器学习和深度学习（ML和DL）在实时计算机视觉方面取得了快速进展。研究已从手工特征提取发展到大规模自动化特征学习。借助基础模型（FM），作物病害数据集现正以根本性的新方式进行处理。与传统神经网络不同，FM整合视觉和文本数据，以文本形式解释症状，推理症状与管理之间的关系，并支持为种植者和教育工作者提供交互式问答。机器人技术中的自适应学习和模仿学习进一步实现了田间病害管理。本综述筛选了约40篇关于FM在SSDM中应用的文章，重点关注大语言模型（LLM）和视觉-语言模型（VLM），并讨论了它们在自适应学习（AL）、强化学习（RL）和用于精准喷洒的数字孪生框架中的作用。主要发现包括：(a) FM在2023-24年文献数量激增，正获得关注；(b) VLM的发展速度超过LLM，发表数量增加了5-10倍；(c) RL和AL在智能喷洒方面仍处于萌芽阶段；(d) 结合RL的数字孪生可以虚拟模拟精准喷洒；(e) 解决模拟与现实的差距对于实际部署至关重要；(f) 人机协作仍然有限，尤其是在机器人检测早期症状、人类验证不确定情况的人在环方法中；(g) 具有实时反馈的多模态FM将推动下一代SSDM。如需获取更新、资源和贡献，请访问https://github.com/nitin-dominic/AgriPathogenDatabase，提交论文、代码或数据集。|
|**2025-10-28**|["Mm, Wat?" Detecting Other-initiated Repair Requests in Dialogue](http://arxiv.org/abs/2510.24628)|null|维持相互理解是人际对话中避免对话中断的关键组成部分，其中修复，尤其是他方发起式修复（OIR，当一方发出疑难信号并促使另一方解决时），起着至关重要的作用。然而，对话代理（CAs）仍然未能识别用户发起的修复，导致对话中断或脱离。本工作提出一个多模态模型，通过整合基于会话分析的语言和韵律特征，自动检测荷兰语对话中的修复发起。结果表明，韵律线索补充了语言特征，并显著提高了预训练文本和音频嵌入的结果，提供了关于不同特征如何相互作用的见解。未来方向包括整合视觉线索，探索多语言和跨语境语料库，以评估其鲁棒性和泛化能力。|
|**2025-10-28**|[OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents](http://arxiv.org/abs/2510.24563)|null|随着决策和推理能力的进步，多模态智能体在计算机应用场景中展现出巨大潜力。过去的评估主要评估了图形用户界面（GUI）交互技能，而工具调用能力，例如由模型上下文协议（MCP）支持的能力，却在很大程度上被忽视了。将集成工具调用的智能体与仅在GUI交互方面进行评估的智能体进行比较，本质上是不公平的。我们提出了OSWorld-MCP，这是首个用于在真实世界环境中评估计算机使用智能体的工具调用、GUI操作和决策能力的全面且公平的基准。我们设计了一种新颖的自动化代码生成管道来创建工具，并将其与从现有工具中精心挑选的部分相结合。严格的手动验证产生了158个高质量工具（涵盖7种常用应用程序），每个工具都经过验证，确保了其正确的功能性、实际适用性和多功能性。对OSWorld-MCP上最先进多模态智能体进行的广泛评估表明，MCP工具普遍提高了任务成功率（例如，OpenAI o3在15步时从8.3%提高到20.4%，Claude 4 Sonnet在50步时从40.1%提高到43.3%），这强调了评估工具调用能力的重要性。然而，即使是最强的模型也具有相对较低的工具调用率，仅为36.3%，这表明仍有改进空间，并凸显了该基准的挑战性。通过明确衡量MCP工具使用技能，OSWorld-MCP加深了对多模态智能体的理解，并为评估其在复杂的、工具辅助环境中的性能设定了新标准。我们的代码、环境和数据可在https://osworld-mcp.github.io公开获取。|
|**2025-10-28**|[Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives](http://arxiv.org/abs/2510.24551)|null|生成式人工智能 (GenAI) 正在席卷全球。它为推进和颠覆现有实践（包括医疗保健）带来了变革性机遇。从用于临床笔记综合和对话辅助的大语言模型 (LLMs) 到整合医学影像、电子健康记录和基因组数据以提供决策支持的多模态系统，GenAI 正在改变医学实践和医疗保健服务（例如诊断和个性化治疗），在减轻临床医生认知负担方面具有巨大潜力，从而改善整体医疗保健服务。然而，GenAI 在医疗保健领域的部署需要深入理解医疗保健任务以及可以实现什么和不能实现什么。在本文中，我们提出了一种以数据为中心的范式，用于医疗保健领域 GenAI 系统的设计和部署。具体而言，我们通过将医疗数据生态系统作为生成式医疗保健系统的基础底层，重新定位了数据生命周期。该生态系统旨在可持续地支持多样化医疗数据和知识的整合、表示和检索。通过有效且高效的数据处理管道（例如语义向量搜索和上下文查询），它支持上游模型组件和下游临床应用的 GenAI 驱动操作。最终，它不仅为基础模型提供高质量、多模态数据，用于大规模预训练和领域特定微调，而且还作为知识检索后端，通过代理层支持任务特定推理。该生态系统使得GenAI能够用于高质量和有效的医疗保健服务。|
|**2025-10-28**|[Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs](http://arxiv.org/abs/2510.24514)|null|多模态大型语言模型（MLLM）在视觉理解方面表现出色，但在需要视觉规划和想象的复杂场景中常常表现不佳。受人类将草图作为一种视觉思维形式来发展和交流想法的启发，我们引入了Latent Sketchpad，一个为MLLM配备内部视觉草稿本的框架。MLLM的内部视觉表示传统上局限于感知理解，我们对其进行了重新利用，以支持生成式视觉思维，同时不损害推理能力。基于前沿MLLM，我们的方法将视觉生成直接融入其原生的自回归推理过程，允许模型将文本推理与视觉潜在表示的生成交织在一起。这些潜在表示引导内部思维过程，并可以被转换为草图图像以提高可解释性。为实现这一点，我们引入了两个组件：一个上下文感知视觉头部自回归地生成视觉表示，以及一个预训练的草图解码器将这些渲染成人类可解释的图像。我们通过我们新的MazePlanning数据集评估了该框架。跨不同MLLM的实验表明，Latent Sketchpad提供了与它们骨干模型相当甚至更优的推理性能。它进一步泛化到不同的前沿MLLM，包括Gemma3和Qwen2.5-VL。通过将模型的文本推理扩展到视觉思维，我们的框架为更丰富的人机交互和更广泛的应用开辟了新的机会。更多详细信息和资源可在我们的项目页面获取：https://latent-sketchpad.github.io/。|
|**2025-10-28**|[SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space](http://arxiv.org/abs/2510.24446)|null|多模态大语言模型（MLLM）在推理分割等视觉-语言任务中展现出令人印象深刻的能力，这些任务中模型根据文本查询生成分割掩码。尽管先前的工作主要集中于扰动图像输入，但语义等效的文本释义（在用户以不同方式表达相同意图的实际应用中至关重要）仍未得到充分探索。为解决这一空白，我们引入了一种新颖的对抗性释义任务：生成语法正确、保留原始查询含义但能降低分割性能的释义。为评估对抗性释义的质量，我们开发了一套全面的自动评估协议，并通过人工研究进行了验证。此外，我们引入了SPARTA，这是一种黑盒、句子级优化方法，它在文本自编码器的低维语义潜在空间中运行，并由强化学习指导。SPARTA取得了显著更高的成功率，在ReasonSeg和LLMSeg-40k数据集上，其性能比现有方法高出2倍。我们使用SPARTA和有竞争力的基线来评估先进推理分割模型的鲁棒性。我们揭示了即使在严格的语义和语法约束下，这些模型仍然容易受到对抗性释义的攻击。所有代码和数据将在论文接收后公开发布。|
|**2025-10-28**|[OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows](http://arxiv.org/abs/2510.24411)|null|由视觉-语言模型 (VLM) 驱动的计算机使用智能体在操作移动平台等数字环境方面展现了类人能力。尽管这些智能体在推进数字自动化方面具有巨大潜力，但它们可能进行的不安全操作（例如系统入侵和隐私泄露）正引起重大担忧。在移动环境广阔而复杂的运行空间中检测这些安全问题，是一个艰巨且仍未得到充分探索的挑战。为了为移动智能体安全研究奠定基础，我们引入了 MobileRisk-Live，这是一个动态沙盒环境，并附带一个包含具有细粒度标注的真实轨迹的安全检测基准。在此基础上，我们提出了 OS-Sentinel，这是一种新颖的混合安全检测框架，它协同结合了一个用于检测显式系统级违规的形式化验证器和一个基于VLM的上下文判断器，用于评估上下文风险和智能体行为。实验表明，OS-Sentinel 在多个指标上相较于现有方法实现了 10%-30% 的改进。进一步的分析提供了关键见解，有助于开发更安全、更可靠的自主移动智能体。|
|**2025-10-28**|[Self-Normalized Quantile Empirical Saddlepoint Approximation](http://arxiv.org/abs/2510.24352)|null|我们提出了一种用于总体分位数频率推断的无密度方法，称作自归一化分位数经验鞍点近似 (SNQESA)。该方法从固定分位数阈值的指示得分构建自归一化枢轴量，然后采用受约束经验鞍点近似来获得高精度的尾部概率。反演这些尾部区域可以产生置信区间和检验，而无需估计目标分位数处的未知密度，从而消除了带宽选择以及影响基于核的Wald/Hall-Sheather区间的边界问题。在温和的局部正则性条件下，所得程序在反演后能达到高阶尾部精度和二阶覆盖率。由于枢轴量基于有界伯努利归约，该方法对于偏斜和重尾分布以及极端分位数仍然可靠。跨轻尾、重尾和多峰分布的大量蒙特卡罗实验表明，SNQESA 在小到中等样本量下提供稳定的覆盖率和有竞争力的区间长度，同时比大B重采样方案快几个数量级。一项采用滚动窗口的风险价值 (VaR) 实证研究进一步突出了其在尾部性能和计算效率方面的优势。该框架自然地扩展到两样本分位数差异和回归类型设置，为无分布分位数推断提供了一种实用、分析透明的替代方案，可替代核方法、自举法和经验似然法。|
|**2025-10-28**|[A Unified Geometric Space Bridging AI Models and the Human Brain](http://arxiv.org/abs/2510.24342)|null|数十年来，神经科学家和计算机科学家一直怀揣着一个共同的抱负：理解智能并构建它。现代人工神经网络在语言、感知和推理方面已能与人类匹敌，然而，这些人工系统是否像大脑一样组织信息，在很大程度上仍是未知数。现有的脑-AI对齐研究已经揭示了这两个系统之间惊人的对应关系，但这类比较仍局限于特定的输入和任务，未能提供一个通用基础来比较具有不同模态（视觉、语言或多模态）的AI模型是如何内在组织起来的。在此，我们引入了一个开创性的概念——类脑空间：这是一个统一的几何空间，无论输入模态、任务或感觉域如何，每个AI模型都可以通过将其内在的空间注意力拓扑组织映射到规范的人类功能性脑网络上，从而在这个空间中被精确地定位和比较。我们对151个Transformer模型进行了广泛分析，这些模型涵盖了最先进的大型视觉模型、大型语言模型和大型多模态模型，结果揭示了这个空间内存在一个连续的弧形几何结构，反映了类脑性的逐渐增强；不同模型在这个几何结构中呈现出与不同类脑程度相关的独特分布模式，这些模式不仅受到其模态的影响，还受到预训练范式是否强调全局语义抽象以及位置编码方案是否促进了跨不同模态的深度融合的影响。此外，模型的类脑程度及其下游任务性能并非“同卵双胞胎”。类脑空间提供了首个统一框架，用于跨领域定位、量化和比较智能，揭示了连接机器与大脑的深层组织原则。|
|**2025-10-28**|[Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes](http://arxiv.org/abs/2510.24332)|null|目的：手术场景理解是推进计算机辅助和智能手术系统的关键。当前方法主要依赖于视觉数据或端到端学习，这限制了细粒度上下文建模。本工作旨在通过整合三维声学信息来增强手术场景表示，从而实现对手术环境在时间上和空间上感知的多模态理解。方法：我们提出了一种新颖的框架，通过将相控麦克风阵列的声学定位信息投影到RGB-D相机生成的动态点云上，从而生成手术场景的四维视听表示。一个基于Transformer的声学事件检测模块识别包含工具-组织交互的相关时间段，这些交互在视听场景表示中被空间定位。该系统在专家执行模拟手术过程的真实手术室设置中进行了实验评估。结果：所提出的方法成功地在三维空间中定位了手术声学事件，并将其与视觉场景元素关联起来。实验评估表明了准确的空间声音定位和多模态数据的鲁棒融合，提供了手术活动的全面、动态表示。结论：这项工作首次提出了在动态手术场景中进行空间声音定位的方法，标志着朝着多模态手术场景表示方向的重大进展。通过整合声学和视觉数据，所提出的框架能够实现更丰富的上下文理解，并为未来的智能和自主手术系统奠定基础。|
|**2025-10-23**|[Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation](http://arxiv.org/abs/2510.20812)|**[link](https://github.com/Tinaliu0123/speculative-verdict)**|大型视觉-语言模型（VLM）在多模态理解方面取得了显著进展，但在对信息密集型图像进行推理时仍面临挑战，这类图像将文本标注与细粒度图形元素密集交织在一起。主要挑战在于精确识别密集布局中的关键线索以及进行多跳推理以整合分散的证据。我们提出了推测裁决（SV），一个受推测解码启发的无需训练的框架，它将多个轻量级草稿专家与一个大型裁决模型相结合。在草稿阶段，小型VLM充当草稿专家以生成推理路径，提供多样化的定位候选；在裁决阶段，一个强大的VLM合成这些路径以生成最终答案，最大限度地降低计算成本同时恢复正确答案。为了进一步提高效率和准确性，SV引入了一种共识专家选择机制，仅将高一致性的推理路径转发给裁决模型。实验结果表明，SV在具有挑战性的信息密集型和高分辨率视觉问答基准（包括InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K）上取得了持续的提升。通过从多个部分准确的推理路径中综合出正确见解，与大型专有模型或训练流程相比，SV实现了错误纠正和成本效益。代码可在https://github.com/Tinaliu0123/speculative-verdict获取。|
|**2025-10-23**|[ARGenSeg: Image Segmentation with Autoregressive Image Generation Model](http://arxiv.org/abs/2510.20803)|null|我们提出了一种新颖的基于自回归生成范式（ARGenSeg）的图像分割方法，在一个统一的框架内实现了多模态理解和像素级感知。先前将图像分割集成到多模态大语言模型（MLLM）中的工作通常采用边界点表示或专用的分割头。这些方法依赖于离散表示或馈入到任务特定解码器中的语义提示，这限制了 MLLM 捕捉细粒度视觉细节的能力。为了解决这些挑战，我们引入了一个基于图像生成的 MLLM 分割框架，它能够自然地为目标对象生成密集的掩码。我们利用 MLLM 输出视觉 token，并使用一个通用的 VQ-VAE 将它们去 token 化为图像，使分割完全依赖于 MLLM 的像素级理解。为了减少推理延迟，我们采用了一种下一尺度预测策略，以并行方式生成所需的视觉 token。大量实验表明，我们的方法在多个分割数据集上超越了先前最先进的方法，推理速度显著提升，同时保持了强大的理解能力。|
|**2025-10-23**|[Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations](http://arxiv.org/abs/2510.20743)|null|我们提出了“共情提示”，这是一种新颖的多模态人机交互框架，它通过融入隐式非语言上下文来丰富大型语言模型（LLM）对话。该系统集成了一项商用面部表情识别服务，以捕获用户的情绪线索，并在提示过程中将其作为上下文信号嵌入。与传统多模态界面不同，共情提示无需用户显式控制；相反，它以非侵入式方式将情感信息融入文本输入，以实现对话的连贯性和流畅性对齐。该架构是模块化和可扩展的，允许集成额外的非语言模块。我们描述了通过本地部署的DeepSeek实例实现的系统设计，并报告了一项初步的服务和可用性评估（N=5）。结果显示，非语言输入被一致地整合到连贯的LLM输出中，参与者特别强调了对话的流畅性。除了这一概念验证之外，共情提示也指向了聊天机器人介导的通信中的应用，特别是在医疗保健或教育等领域，这些领域中用户的情绪信号至关重要，但在口头交流中却常常不透明。|
|**2025-10-23**|[Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process](http://arxiv.org/abs/2510.20736)|**[link](https://github.com/KaedeGo/DPMM)**|开发有效的多模态融合方法在许多现实世界场景中变得越来越重要，例如医疗保健和金融。关键挑战在于如何在学习跨模态交互的同时，保留每种模态的特征表达能力。现有方法主要关注跨模态对齐，然而，过分强调模态边际分布的对齐可能会施加过度的正则化，并阻碍每种模态中有意义的表示学习。狄利克雷过程（DP）混合模型是一种强大的贝叶斯非参数方法，它通过其富者愈富特性（即为最显著特征分配不断增加的权重）来放大这些最显著特征。受DP这一独特特性的启发，我们提出了一种新的DP驱动的多模态学习框架，该框架能够自动在显著的模态内表示学习和跨模态对齐之间实现最佳平衡。具体而言，我们假设每种模态都遵循多元高斯混合分布，并进一步采用DP来计算所有分量的混合权重。这种范式允许DP动态分配特征的贡献并选择最显著的特征，利用其富者愈富特性，从而促进多模态特征融合。在多个多模态数据集上进行的大量实验证明了我们模型优于其他竞争对手的卓越性能。消融分析进一步验证了DP在对齐模态分布方面的有效性及其对关键超参数变化的鲁棒性。代码已匿名公开于 https://github.com/HKU-MedAI/DPMM.git|
|**2025-10-23**|[Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward](http://arxiv.org/abs/2510.20696)|null|整合了视觉和文本推理的多模态大语言模型 (MLLMs) 利用思维链 (CoT) 提示来处理复杂的视觉任务，但仍表现出视觉幻觉以及对文本先验知识的过度依赖。我们使用一个三阶段评估框架对最先进的视觉-语言模型进行了系统性诊断，揭示了关键的故障模式。为解决这些问题，我们提出了一种基于智能体的架构，该架构结合了LLM推理和轻量级视觉模块，从而实现了细粒度分析以及对推理链的迭代优化。我们的结果强调，未来的视觉推理模型应侧重于整合更广泛的专用工具来分析视觉内容。我们的系统取得了显著的提升（在MMMU上提升10.3，在MathVista上提升6.0，相对于7B基线），媲美甚至超越了更大的模型。我们将发布我们的框架和评估套件，以促进未来的研究。|
|**2025-10-23**|[Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges](http://arxiv.org/abs/2510.20637)|null|大语言模型 (LLM) 和大多模态模型 (LMM) 取得了前所未有的突破，在自然语言理解、生成和复杂推理方面展示出卓越的能力。这种变革性潜力使其成为机器、车辆和类人机器人之间6G自主通信的关键使能技术。在本文中，我们概述了借助LLM/LMM实现面向任务的自主通信，重点关注多模态感知集成、自适应重配置以及用于无线任务的提示/微调策略。我们通过三个案例研究展示了该框架：基于LMM的交通控制、基于LLM的机器人调度以及基于LMM的环境感知信道估计。实验结果表明，所提出的LLM/LMM辅助自主系统显著优于传统的判别式深度学习 (DL) 模型技术，在动态目标、变化的输入参数和异构多模态条件下仍能保持鲁棒性，而传统静态优化在这些条件下性能会下降。|
|**2025-10-23**|[Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications](http://arxiv.org/abs/2510.20632)|null|大语言模型（LLMs）在通用NLP基准测试中表现出色，但它们在专业领域的能力仍未得到充分探索。在电子商务领域，现有评估，如EcomInstruct、ChineseEcomQA、eCeLLM和Shopping MMLU，存在任务多样性有限（例如，缺乏产品指导和售后问题）、任务模态有限（例如，缺乏多模态数据）、使用合成或人工整理的数据以及狭隘地关注英语和汉语等问题，使得从业者缺乏可靠工具来在复杂、真实的购物场景中评估模型。我们引入了EcomEval，一个综合性的多语言多模态基准，用于评估电子商务领域的大语言模型。EcomEval涵盖六个类别和37项任务（包括8项多模态任务），主要来源于真实的客户查询和交易日志，反映了真实业务交互中嘈杂和异构的性质。为确保参考答案的质量和可扩展性，我们采用半自动化流程，其中大模型起草候选回复，随后由超过50名具有强大电子商务和多语言专业知识的专家标注员审查和修改。我们通过平均不同规模和能力模型的评估分数来定义每个问题和任务类别的难度级别，从而实现以挑战为导向的细粒度评估。EcomEval还涵盖七种语言，包括五种低资源东南亚语言，提供了先前工作中没有的多语言视角。|
|**2025-10-23**|[Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences](http://arxiv.org/abs/2510.20595)|null|自监督学习已成为表征学习的核心策略，但用于编码数据的大多数架构仅在图像、音频和视频等规则采样的输入上得到验证。在许多科学领域，数据则以长、不规则和多模态序列的形式出现。为了从这些数据中提取语义信息，我们引入了带有Perceiver的扩散自编码器（daep）。daep对异构测量进行标记化，使用Perceiver编码器对其进行压缩，并使用Perceiver-IO扩散解码器进行重建，从而在多样化的数据设置中实现可扩展学习。为了对daep架构进行基准测试，我们将掩码自编码器适配到Perceiver编码器/解码器设计中，并在与daep同属一个架构家族中建立了一个强大的基线（maep）。在各种光谱和光度天文数据集上，daep比VAE和maep基线实现了更低的重建误差，生成了更具区分性的潜在空间，并更好地保留了精细尺度结构。这些结果确立了daep作为数据以不规则、异构序列形式出现的科学领域的有效框架。|
|**2025-10-23**|[EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence](http://arxiv.org/abs/2510.20578)|null|通用人工智能（AGI）的实现需要具身AI智能体能够在物理环境中进行鲁棒的空间感知、有效的任务规划和自适应执行。然而，当前用于具身任务的大语言模型（LLMs）和多模态大语言模型（MLLMs）存在主要局限性，包括模型设计与智能体需求之间的显著差距、实时延迟与性能之间不可避免的权衡，以及使用不真实、离线的评估指标。为解决这些挑战，我们提出了EmbodiedBrain，这是一种新颖的视觉语言基础模型，提供7B和32B两种参数规模。我们的框架具有智能体对齐的数据结构，并采用强大的训练方法，该方法将大规模有监督微调（SFT）与步增强组相对策略优化（Step-GRPO）相结合，通过将先行步骤整合为引导前兆，从而提升长程任务成功率。此外，我们整合了一个全面的奖励系统，包括一个在基础设施层面加速的生成式奖励模型（GRM），以提高训练效率。为实现彻底的验证，我们建立了一个由三部分组成的评估系统，涵盖通用、规划和端到端模拟基准，其突出特点是提出了一个新颖且具有挑战性的模拟环境并将其开源。实验结果表明，EmbodiedBrain在所有指标上均取得了卓越性能，为具身基础模型树立了新的最先进水平。为下一代通用具身智能体铺平道路，我们开源了所有数据、模型权重和评估方法，可在https://zterobot.github.io/EmbodiedBrain.github.io获取。|
|**2025-10-23**|[SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment](http://arxiv.org/abs/2510.20540)|null|传统多模态对齐方法假设所有模态之间存在相互冗余，这种假设在真实世界的分布式场景中失效。我们提出了 SheafAlign，一个用于去中心化多模态对齐的基于层论的框架，它用多个比较空间取代了单一空间对齐。这种方法通过层结构建模成对模态关系，并利用基于去中心化对比学习的目标进行训练。SheafAlign 克服了现有方法的局限性，因为它不要求所有模态之间存在相互冗余，同时保留了共享信息和独特信息。在多模态感知数据集上的实验表明，SheafAlign 具有优越的零样本泛化能力、跨模态对齐能力以及对缺失模态的鲁棒性，且通信成本比最先进的基线降低了 50%。|
|**2025-10-21**|[Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs](http://arxiv.org/abs/2510.18876)|**[link](https://github.com/Haochen-Wang409/Grasp-Any-Region)**|尽管多模态大语言模型（MLLMs）擅长整体理解，但它们在捕捉包含复杂场景的密集世界时面临挑战，这需要对复杂细节和对象间的相互关系进行细粒度分析。区域级MLLMs一直是一个有希望的方向。然而，先前的尝试通常被优化为孤立地理解给定区域，忽略了关键的全局上下文。为解决这个问题，我们引入了Grasp Any Region (GAR)，以实现全面的区域级视觉理解。凭借一种有效的RoI对齐特征重放技术，GAR支持 (1) 通过利用必要的全局上下文实现精确感知，以及 (2) 建模多个提示之间的交互。综合来看，它自然实现了 (3) 高级组合推理，以回答关于任何区域的特定自由形式问题，将范式从被动描述转变为主动对话。此外，我们构建了GAR-Bench，它不仅为单区域理解提供了更准确的评估，而且更重要的是，衡量了多区域间的交互和复杂推理能力。大量实验表明，GAR-1B不仅保持了最先进的图像描述能力（例如，在DLC-Bench上超越DAM-3B +4.5），而且在建模多个提示之间的关系以及高级理解能力方面表现出色，甚至在GAR-Bench-VQA上超越了InternVL3-78B。更重要的是，我们的零样本GAR-8B甚至在VideoRefer-BenchQ上超越了同领域的VideoRefer-7B，表明其强大的能力可以很容易地迁移到视频领域。|
|**2025-10-21**|[DSI-Bench: A Benchmark for Dynamic Spatial Intelligence](http://arxiv.org/abs/2510.18873)|null|推理动态空间关系至关重要，因为观察者和物体常常同时移动。尽管视觉-语言模型（VLM）和视觉专业模型在2D任务和静态场景中表现出色，但它们全面理解动态3D场景的能力仍然有限。我们引入了动态空间智能，并提出了DSI-Bench，这是一个包含近1,000个动态视频和超过1,700个人工标注问题的基准，涵盖了观察者和物体的九种解耦运动模式。空间和时间对称设计减少了偏差，并实现了对模型关于自身运动和物体运动推理的系统评估。我们对14个VLM和专业模型的评估揭示了主要局限性：模型经常混淆观察者和物体的运动，表现出语义偏差，并且未能准确推断动态场景中的相对关系。我们的DSI-Bench为未来开发具备动态空间智能的通用模型和专业模型提供了有价值的发现和见解。|
|**2025-10-21**|[See the Text: From Tokenization to Visual Reading](http://arxiv.org/abs/2510.18840)|**[link](https://github.com/lhai36366/lhai36366)**|人们看到文本。人类通过将单词识别为视觉对象，包括其形状、布局和模式，然后将其与意义联系起来进行阅读，这使我们能够有效地处理拼写错误、扭曲字体和各种书写系统。然而，现代大型语言模型（LLMs）依赖于子词分词，将文本从固定词汇表中分割成片段。尽管这种方法对高资源语言有效，但它会过度分割低资源语言，产生冗长、语言上无意义的序列，并增加计算量。在这项工作中，我们挑战了这种根深蒂固的范式，并转向了一种以视觉为中心的替代方案。我们的方法SeeTok将文本渲染为图像（视觉文本），并利用预训练的多模态大型语言模型来解释它们，复用从大规模多模态训练中学习到的强大OCR和文本-视觉对齐能力。在三种不同的语言任务中，SeeTok与子词分词器持平或超越它们，同时所需的词元减少了4.43倍，并将FLOPs减少了70.5%，并在跨语言泛化、对排版噪声的鲁棒性以及语言层次结构方面取得了额外收益。SeeTok标志着从符号分词向类人视觉阅读的转变，并朝着更自然和认知启发式语言模型迈进了一步。|
|**2025-10-21**|[Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation](http://arxiv.org/abs/2510.18751)|null|气候变化正在加剧有害藻华（HAB）的发生，尤其是蓝藻，它们通过氧气耗尽、毒素释放以及海洋生物多样性紊乱来威胁水生生态系统和人类健康。传统监测方法，如人工水样采集，仍然劳动密集且在空间和时间覆盖范围上有限。遥感领域视觉-语言模型（VLM）的最新进展已显示出可扩展的AI驱动解决方案的潜力，但在图像推理和藻华严重程度量化方面仍存在挑战。在这项工作中，我们引入了藻类观测与分割（ALGOS），这是一个结合遥感图像理解与严重程度估计的有害藻华监测分割与推理系统。我们的方法整合了GeoSAM辅助的人工评估以精选高质量分割掩码，并使用NASA的蓝藻聚合人工标签（CAML）微调视觉语言模型进行严重程度预测。实验表明，ALGOS在分割和严重程度估计两方面都取得了鲁棒性能，为实用和自动化的蓝藻监测系统铺平了道路。|
|**2025-10-21**|[IF-VidCap: Can Video Caption Models Follow Instructions?](http://arxiv.org/abs/2510.18726)|null|尽管多模态大语言模型（MLLM）在视频字幕生成方面已展现出熟练度，但实际应用需要遵循特定用户指令的字幕，而非生成详尽、无限制的描述。然而，当前基准测试主要评估描述的全面性，而在很大程度上忽视了指令遵循能力。为了弥补这一差距，我们引入了IF-VidCap，一个用于评估可控视频字幕生成的新基准，包含1,400个高质量样本。与现有视频字幕生成或通用指令遵循基准不同，IF-VidCap采用了一个系统性框架，从两个维度评估字幕：格式正确性和内容正确性。我们对20多个知名模型的全面评估揭示了一个细致入微的局面：尽管专有模型持续占据主导地位，但性能差距正在缩小，顶级开源解决方案如今已接近与专有模型持平。此外，我们发现专门用于密集字幕生成的模型在复杂指令下表现不如通用型MLLM，这表明未来的工作应同时推进描述的丰富性和指令遵循的忠实度。|
|**2025-10-21**|[Exploring a Unified Vision-Centric Contrastive Alternatives on Multi-Modal Web Documents](http://arxiv.org/abs/2510.18703)|null|CLIP等对比视觉-语言模型通过学习对齐的图像-文本对，在广泛的多模态任务中展现出强大性能。然而，它们处理复杂、真实世界网络文档的能力仍然有限，尤其是在文本和图像交错、松散对齐或以视觉形式嵌入的场景中。为解决这些挑战，我们提出了以视觉为中心的对比学习（VC2L），这是一个统一框架，使用单一视觉Transformer对文本、图像及其组合进行建模。VC2L通过将所有输入（无论是文本、视觉还是组合）渲染为图像，完全在像素空间中操作，从而消除了对OCR、文本分词或模态融合策略的需求。为了捕获多模态网络文档中复杂的跨模态关系，VC2L采用片段级对比学习目标来对齐连续的多模态片段，利用文档固有的连贯性，而无需明确配对的图像-文本数据。为了评估这种方法的有效性，我们引入了三个检索基准：AnyCIR、SeqCIR和CSR，旨在分别评估跨模态检索、细粒度序列理解以及对未见数据的泛化能力。实验结果表明，VC2L在所提出的基准以及M-BEIR和MTEB等已建立的数据集上，与CLIP风格模型相比，取得了竞争性或卓越的性能。这些发现强调了多模态网络数据作为对比学习宝贵训练资源的潜力，并说明了统一的、以视觉为中心的方法在多模态表示学习中的可扩展性。代码和模型可在以下网址获取：https://github.com/showlab/VC2L。|
|**2025-10-21**|[UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation](http://arxiv.org/abs/2510.18701)|**[link](https://github.com/CodeGoat24/UniGenBench)**|文本到图像（T2I）生成领域的最新进展强调了可靠基准的重要性，用于评估生成图像如何准确反映其文本提示的语义。然而，(1) 现有基准缺乏提示场景的多样性和多语言支持，这两者对于实际应用性至关重要；(2) 它们仅在主要维度上提供粗略评估，涵盖的子维度范围狭窄，并且在细粒度子维度评估方面存在不足。为解决这些局限性，我们引入了UniGenBench++，一个用于T2I生成的统一语义评估基准。具体而言，它包含600个提示，这些提示按层次结构组织，以确保覆盖范围和效率：(1) 涵盖多样化的真实世界场景，即5个主要提示主题和20个子主题；(2) 全面探查T2I模型在10个主要和27个次要评估标准上的语义一致性，每个提示评估多个测试点。为了严格评估模型对语言和提示长度变化的鲁棒性，我们为每个提示提供了英文和中文的短形式和长形式版本。利用闭源多模态大型语言模型（MLLM）Gemini-2.5-Pro的通用世界知识和细粒度图像理解能力，我们开发了一个有效的流程，用于可靠的基准构建和精简的模型评估。此外，为进一步促进社区使用，我们训练了一个鲁棒的评估模型，能够实现T2I模型输出的离线评估。通过对开源和闭源T2I模型的全面基准测试，我们系统地揭示了它们在各个方面的优势和劣势。|
|**2025-10-21**|[Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views](http://arxiv.org/abs/2510.18632)|**[link](https://github.com/zhangquanchen/3DThinker)**|尽管视觉-语言模型（VLM）的最新进展在广泛的多模态任务中取得了显著进步，但从有限视角理解三维空间关系仍然是一个重大挑战。先前的推理方法通常依赖于纯文本（例如，拓扑认知图）或二维视觉线索。然而，它们有限的表示能力阻碍了在需要三维空间想象力的特定任务中的性能。为解决这一局限性，我们提出了3DThinker，一个能够在推理时像人类一样有效利用图像中嵌入的丰富几何信息的框架。我们的框架首次在推理过程中无需任何三维先验输入即可实现三维心智构建，并且不依赖于显式标注的三维数据进行训练。具体而言，我们的训练包含两个阶段。首先，我们进行有监督训练，以对齐VLM在推理时生成的三维潜在表示与三维基础模型（例如，VGGT）的潜在表示。然后，我们仅基于结果信号优化整个推理轨迹，从而细化潜在的三维心智构建。在多个基准测试中进行的大量实验表明，3DThinker持续优于强基线模型，并为将三维表示统一到多模态推理中提供了一个新视角。我们的代码将发布于https://github.com/zhangquanchen/3DThinker。|
|**2025-10-21**|[VAR: Visual Attention Reasoning via Structured Search and Backtracking](http://arxiv.org/abs/2510.18619)|null|尽管多模态大语言模型（MLLMs）取得了进展，但其高幻觉倾向以及对脆弱线性推理过程的严重依赖阻碍了它们的发展，导致在复杂任务中表现不佳。为解决这些局限性，我们引入了视觉注意力推理（VAR），这是一个新颖的框架，它将基础推理重构为在推理轨迹空间上的结构化搜索。VAR将推理过程分解为两个关键阶段：可追溯证据锚定和基于搜索的思维链（CoT）生成，其中结合了用于自我纠正的回溯机制。该搜索由一个多方面奖励函数引导，该函数包含语义和几何自验证组件，对未忠实地基于视觉输入的输出进行惩罚。我们对我们的搜索策略进行了理论分析，验证了其以高概率找到正确解决方案的能力。实验结果表明，我们的7B模型VAR-7B在一套全面的幻觉和安全基准测试上创造了新的最先进水平，显著优于现有的开源模型，并展现出与领先的专有系统相匹敌的性能。|
|**2025-10-21**|[CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent](http://arxiv.org/abs/2510.18596)|null|计算机使用智能体（CUAs）通过与操作系统和软件界面进行自然交互来实现任务完成。尽管基于脚本的验证器被广泛用于评估，但它们面临可扩展性有限和无法提供逐步评估的问题。奖励模型提供了有前景的替代方案，但它们在CUA评估上的有效性仍未得到充分探索。为弥补这一空白，我们提出了CUARewardBench，包含四项主要贡献：(1) 首个全面的CUA奖励基准：我们引入了首个用于评估CUA任务中结果奖励模型（ORM）和过程奖励模型（PRM）的基准，实现了轨迹级和步骤级的系统评估。(2) 多样化、实用且可靠的数据集：CUARewardBench包含来自10个软件类别和7种智能体架构的轨迹，这些轨迹具有不同的性能水平（成功率介于25.9%至50.8%）。所有轨迹均通过精心设计的协议进行专家标注，并进行严格的质量控制，以确保其可靠性和实用性。(3) 全面分析与见解：通过对7种视觉-语言模型和3种提示模板进行广泛实验，我们揭示了当前CUA奖励模型的关键局限性，包括视觉推理能力不足、知识缺陷，以及通用视觉-语言模型在奖励评估方面优于专用CUA模型。(4) 一致提示集成（UPE）：基于我们全面分析的见解，我们提出了UPE，这是一种新颖的集成方法，通过严格的一致投票和战略性的提示模板配置，显著提高了奖励模型的可靠性。UPE在ORM上达到了89.8%的精度和93.3%的负预测值（NPV），在PRM上达到了81.7%的精度和85.1%的负预测值（NPV），显著优于单一视觉-语言模型和传统集成方法。|
|**2025-10-16**|[From Pixels to Words -- Towards Native Vision-Language Primitives at Scale](http://arxiv.org/abs/2510.14979)|null|原生视觉-语言模型（VLM）的体系，在不断发展的模型架构和训练范式塑造下，已成为典型模块化VLM日益增长的竞争者。然而，两朵挥之不去的阴云笼罩着其广泛的探索和推广：(-) 是什么基本限制使原生VLM与模块化VLM区别开来，以及这些障碍能在多大程度上被克服？(-) 如何使原生VLM的研究更易于获取和民主化，从而加速该领域的进展？在本文中，我们阐明了这些挑战，并概述了构建原生VLM的指导原则。具体而言，一个原生VLM基元应：(i) 在共享语义空间内有效对齐像素和词表示；(ii) 无缝整合以前分离的视觉和语言模块的优势；(iii) 内在地体现支持统一视觉-语言编码、对齐和推理的各种跨模态特性。因此，我们推出了NEO，这是一个从第一性原理构建的新颖原生VLM系列，能够在多样化的现实世界场景中与顶级模块化对应物媲美。仅使用3.9亿图像-文本示例，NEO便能从零开始高效发展视觉感知，同时缓解由我们精心设计的基元构建的密集且单一模型内部的视觉-语言冲突。我们将NEO定位为可扩展且强大的原生VLM的基石，并搭配一套丰富的可重用组件，以促进一个成本效益高且可扩展的生态系统。我们的代码和模型已公开发布于：https://github.com/EvolvingLMMs-Lab/NEO。|
|**2025-10-16**|[Learning an Image Editing Model without Image Editing Pairs](http://arxiv.org/abs/2510.14978)|**[link](https://github.com/Sfedfcv/redesigned-pancake)**|最近的图像编辑模型在遵循自然语言编辑指令方面取得了令人印象深刻的成果，但它们依赖于使用大量输入-目标对数据集进行监督微调。这是一个关键瓶颈，因为此类自然存在的配对难以大规模收集。当前的权宜之计是使用利用现有模型零样本能力的合成训练对。然而，这可能会将预训练模型的伪影传播并放大到最终训练模型中。在这项工作中，我们提出了一种新的训练范式，完全消除了对配对数据的需求。我们的方法通过在训练过程中展开少步扩散模型并利用视觉-语言模型（VLM）的反馈来直接优化它。对于每个输入和编辑指令，VLM评估编辑是否符合指令并保留未更改的内容，从而为端到端优化提供直接梯度。为了确保视觉保真度，我们引入了分布匹配损失（DMD），它约束生成的图像保持在预训练模型学习到的图像流形内。我们在标准基准上评估了我们的方法，并进行了广泛的消融研究。在没有任何配对数据的情况下，我们的方法在少步设置下，性能与各种在大量监督配对数据上训练的图像编辑扩散模型相当。在给定相同VLM作为奖励模型的情况下，我们还优于Flow-GRPO等基于强化学习（RL）的技术。|
|**2025-10-16**|[RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks](http://arxiv.org/abs/2510.14968)|**[link](https://github.com/rdd-neurips/rdd-neurips.github.io)**|为解决长周期任务，最近的分层视觉-语言-动作 (VLA) 框架采用基于视觉-语言模型 (VLM) 的规划器，将复杂的操纵任务分解成低级视觉运动策略能够轻松处理的更简单的子任务。通常，VLM 规划器会经过微调以学习如何分解目标任务。这种微调需要将目标任务演示通过人工标注或启发式规则分割成子任务。然而，启发式子任务可能与视觉运动策略的训练数据显著偏离，从而降低任务性能。为解决这些问题，我们提出了一种基于检索的演示分解器 (RDD)，它通过将分解后的子任务区间的视觉特征与低级视觉运动策略训练数据中的视觉特征进行对齐，从而自动将演示分解成子任务。我们的方法在模拟和真实世界任务中均优于最先进的子任务分解器，证明了其在不同设置下的鲁棒性。代码和更多结果可在 rdd-neurips.github.io 获取。|
|**2025-10-16**|[MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning](http://arxiv.org/abs/2510.14958)|**[link](https://github.com/shiwk24/MathCanvas)**|尽管大语言模型（LLMs）在文本推理方面表现出色，但在几何等本质上依赖视觉辅助的数学领域中却面临挑战。现有的视觉思维链（VCoT）方法常受限于僵化的外部工具，或未能生成复杂问题解决所需的高保真、策略性及时的图示。为了弥合这一鸿沟，我们引入了MathCanvas，这是一个旨在赋予统一的大型多模态模型（LMMs）针对数学问题的内在VCoT能力的全面框架。我们的方法包含两个阶段。首先，在视觉操作阶段，我们使用一个新颖的1520万对语料库预训练模型，该语料库包含1000万个文本描述到图示的对（MathCanvas-Imagen）和520万个分步编辑轨迹（MathCanvas-Edit），以使模型掌握图示的生成和编辑。其次，在策略性视觉辅助推理阶段，我们使用MathCanvas-Instruct（一个包含21.9万个交错视觉-文本推理路径的新数据集）微调模型，教导模型何时以及如何利用视觉辅助。为了促进严格的评估，我们引入了MathCanvas-Bench，这是一个包含3000个挑战性问题的基准，要求模型生成交错的视觉-文本解决方案。我们的模型BAGEL-Canvas在此框架下训练，在MathCanvas-Bench上相较于强大的LMM基线模型实现了86%的相对提升，并展示了对其他公开数学基准的出色泛化能力。我们的工作提供了一个完整的工具包——包括框架、数据集和基准——以解锁LMMs中复杂、类人的视觉辅助推理能力。项目页面：https://mathcanvas.github.io/|
|**2025-10-16**|[OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression](http://arxiv.org/abs/2510.14954)|null|全身多模态人体运动生成面临两大主要挑战：一是创建有效的运动生成机制，二是将文本、语音和音乐等各种模态整合到一个统一的框架中。与以往通常采用离散掩码建模或自回归建模的方法不同，我们开发了一种连续掩码自回归运动变换器，该变换器在考虑人体运动中的序列特性时执行因果注意力。在该变换器中，我们引入了门控线性注意力和RMSNorm模块，它们促使变换器关注关键动作并抑制由异常运动或多模态内异构分布引起的不稳定性。为了进一步增强运动生成和多模态泛化能力，我们采用DiT结构将来自变换器的条件扩散到目标。为融合不同模态，AdaLN和交叉注意力被用于注入文本、语音和音乐信号。实验结果表明，我们的框架在所有模态上均优于以往方法，包括文本到运动、语音到手势和音乐到舞蹈。我们的方法代码将公开。|
|**2025-10-16**|[DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation](http://arxiv.org/abs/2510.14949)|null|像英语这样的接触语言表现出丰富的地域变体，即方言，方言使用者在与生成模型交互时经常使用这些方言。然而，多模态生成模型在给定方言文本输入的情况下能否有效生成内容？在这项工作中，我们通过构建一个涵盖六种常见英语方言的新大规模基准来研究这个问题。我们与方言使用者合作，收集并验证了超过4200个独特的提示，并在17个图像和视频生成模型上进行了评估。我们的自动和人工评估结果表明，当提示中只使用一个方言词时，当前最先进的多模态生成模型表现出32.26%到48.17%的性能下降。常见的缓解方法，例如微调和提示重写，只能将方言性能提高很小的幅度（< 7%），同时可能导致标准美式英语（SAE）性能的显著下降。为此，我们设计了一种通用的基于编码器的多模态生成模型缓解策略。我们的方法教导模型识别新的方言特征，同时保持SAE性能。在Stable Diffusion 1.5等模型上的实验表明，我们的方法能够同时将五种方言的性能提升至与SAE持平（+34.4%），同时对SAE性能造成接近零的损失。|
|**2025-10-16**|[TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](http://arxiv.org/abs/2510.14922)|null|抑郁症是一种广泛存在的精神健康障碍，但其自动检测仍然具有挑战性。先前的工作探索了单模态和多模态方法，其中多模态系统通过利用互补信号展现出潜力。然而，现有研究在范围上存在局限性，缺乏对特征的系统比较，并且评估协议不一致。我们通过系统地探索脑电图（EEG）以及语音和文本的特征表示和建模策略来弥补这些不足。我们评估了手工特征与预训练嵌入，评估了不同神经网络编码器的有效性，比较了单模态、双模态和三模态配置，并分析了融合策略，特别关注了脑电图（EEG）的作用。我们采用了受试者独立的一致划分，以确保稳健且可复现的基准测试。我们的结果表明：(i) 脑电图、语音和文本模态的组合增强了多模态检测，(ii) 预训练嵌入优于手工特征，以及 (iii) 精心设计的三模态模型实现了最先进的性能。我们的工作为多模态抑郁症检测的未来研究奠定了基础。|
|**2025-10-16**|[MaskCaptioner : Learning to Jointly Segment and Caption Object Trajectories in Videos](http://arxiv.org/abs/2510.14904)|null|密集视频目标字幕生成 (DVOC) 是一项在视频中联合检测、跟踪和生成目标轨迹字幕的任务，需要理解时空细节并用自然语言描述它们的能力。由于任务的复杂性以及手动标注的高昂成本，以往的方法通常采用分离的训练策略，这可能导致次优的性能。为了解决这个问题，我们提出利用最先进的VLM生成关于时空局部化实体的字幕。通过使用我们合成的字幕（LVISCap和LV-VISCap）扩展LVIS和LV-VIS数据集，我们训练了MaskCaptioner，这是一个能够联合检测、分割、跟踪和生成目标轨迹字幕的端到端模型。此外，经过LVISCap和LV-VISCap上的预训练，MaskCaptioner在三个现有基准测试（VidSTG、VLN和BenSMOT）上取得了最先进的DVOC成果。数据集和代码可在 https://www.gabriel.fiastre.fr/maskcaptioner/ 获取。|
|**2025-10-16**|[Leveraging Multimodal LLM Descriptions of Activity for Explainable Semi-Supervised Video Anomaly Detection](http://arxiv.org/abs/2510.14896)|null|现有半监督视频异常检测 (VAD) 方法常常难以检测涉及对象交互的复杂异常，并且通常缺乏可解释性。为了克服这些局限性，我们提出了一种利用多模态大语言模型 (MLLMs) 的新颖VAD框架。与以往基于MLLM的方法在帧级别进行直接异常判断不同，我们的方法侧重于提取和解释随时间变化的对象活动和交互。通过使用不同时刻对象对的视觉输入查询一个MLLM，我们从正常视频中生成活动和交互的文本描述。这些文本描述作为视频中对象活动和交互的一种高层次表示。它们在测试时用于检测异常，通过将它们与在正常训练视频中发现的文本描述进行比较。我们的方法本质上提供了可解释性，并且可以与许多传统的VAD方法结合以进一步增强它们的可解释性。在基准数据集上进行的广泛实验表明，我们的方法不仅能有效检测复杂的基于交互的异常，而且在不含交互异常的数据集上也能达到最先进的性能。|
|**2025-10-16**|[You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction](http://arxiv.org/abs/2510.14885)|null|尽管多模态大语言模型（MLLMs）的兴起重新激发了对零样本视觉分类的兴趣，但评估自回归模型自由形式响应的问题仍然是一个持续存在的挑战。大多数现有工作专注于纯语言任务，或者没有考虑超过5个选项的多项选择题（MCQs），而这两者都是解决细粒度视觉分类（FGVC）任务的关键能力，因为在FGVC中选项数量可达数百到数千，且选项之间高度相关。此外，在这种高度多选的MCQ设置中，尚不清楚如何将大语言模型（LLM）的选项提取扩展到基于检索的问题，因为计算选项集上的概率在计算上是昂贵的。在这项工作中，我们研究了nlg2choice，这是一种简单的两阶段方法，它首先以最少的约束向多模态大语言模型（MLLM）提出任务的开放式问题，然后使用纯文本约束解码来预测最可能的选项。在检索设置中，我们通过一种早期停止方法计算约束响应选择该选项的概率，以显著提高吞吐量。我们的结果显示，在七个细粒度视觉数据集上，当在分类和检索方面进行评估时，性能有所提升，并表明这种性能在LLM用户可以通过自然语言实现任务的各种方式中都保持稳定。|
|**2025-10-14**|[DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search](http://arxiv.org/abs/2510.12801)|null|多模态大型语言模型（MLLMs）在实际应用中需要访问外部知识源，并且必须对动态且不断变化的现实世界信息保持响应，以解决信息查询和知识密集型用户查询。现有方法，例如检索增强生成（RAG）方法、搜索代理和配备搜索功能的MLLMs，常常面临死板的流程、过多的搜索调用以及构建不佳的搜索查询，这些问题导致效率低下和次优结果。为了解决这些局限性，我们提出了DeepMMSearch-R1，这是首个能够执行按需、多轮网络搜索，并为图像和文本搜索工具动态生成查询的多模态大型语言模型。具体而言，DeepMMSearch-R1可以基于输入图像的相关裁剪区域发起网络搜索，使图像搜索更有效，并且可以根据检索到的信息迭代调整文本搜索查询，从而实现自我反思和自我纠正。我们的方法依赖于一个两阶段训练流程：首先是冷启动监督微调阶段，随后是在线强化学习优化。为了训练，我们引入了DeepMMSearchVQA，这是一个通过自动化流程创建的新颖多模态VQA数据集，其中融合了来自网络搜索工具的现实世界信息。该数据集包含多样化的多跳查询，整合了文本和视觉信息，教导模型何时搜索、搜索什么、使用哪个搜索工具以及如何对检索到的信息进行推理。我们在一系列知识密集型基准测试中进行了广泛的实验，以证明我们方法的优越性。最后，我们分析了结果并提供了对推进多模态网络搜索具有宝贵价值的见解。|
|**2025-10-14**|[Detect Anything via Next Point Prediction](http://arxiv.org/abs/2510.12798)|**[link](https://github.com/IDEA-Research/Rex-Omni)**|目标检测长期以来由YOLO、DETR和Grounding DINO等传统的基于坐标回归的模型主导。尽管最近的努力试图利用多模态大语言模型（MLLMs）来解决这项任务，但它们面临着低召回率、重复预测、坐标未对齐等挑战。在这项工作中，我们弥合了这一差距，并提出了Rex-Omni，一个30亿参数规模的多模态大语言模型，它实现了最先进的目标感知性能。在COCO和LVIS等基准测试中，Rex-Omni在零样本设置下取得了与基于回归的模型（例如DINO、Grounding DINO）相当或超越的性能。这得益于三项关键设计：1) 任务表述：我们使用特殊token表示0到999的量化坐标，降低了模型的学习难度，并提高了坐标预测的token效率；2) 数据引擎：我们构建了多个数据引擎，以生成高质量的接地、指代和指向数据，为训练提供了语义丰富的监督；3) 训练流程：我们采用了两阶段训练过程，将2200万数据的监督微调与基于GRPO的强化后训练相结合。这种强化学习后训练利用了几何感知的奖励，有效弥合了离散到连续坐标预测的鸿沟，提高了边界框精度，并减轻了源于初始SFT阶段教师指导性质的不良行为，例如重复预测。除了传统的检测，Rex-Omni固有的语言理解能力使其具备了多功能能力，例如目标指代、指向、视觉提示、GUI接地、空间指代、光学字符识别（OCR）和关键点检测，所有这些能力都在专用基准上进行了系统评估。我们相信Rex-Omni为更通用、语言感知的视觉感知系统铺平了道路。|
|**2025-10-14**|[ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution](http://arxiv.org/abs/2510.12793)|null|现有的多模态大语言模型（MLLMs）由于图像输入引入了额外的视觉tokens，导致推理成本增加。在这项工作中，我们提出了一种新颖的训练算法——视觉一致性学习（ViCO），该算法使模型能够使用不同数量的视觉tokens来表示具有不同语义复杂度的图像。我们方法的核心思想是采用多个MLP连接器，每个连接器具有不同的图像压缩率，根据图像的语义复杂度对视觉tokens进行下采样。在训练过程中，我们最小化了在不同MLP连接器条件下产生的响应之间的KL散度。在推理时，我们引入了一个图像路由器，称为视觉分辨率路由器（ViR），它能自动为每个图像块选择适当的压缩率。与现有根据图像分辨率调整视觉tokens数量的动态高分辨率策略相比，我们的方法根据语义复杂度动态调整视觉tokens的数量。实验结果表明，我们的方法可以将视觉tokens的数量减少多达50%，同时保持模型的感知、推理和OCR能力。我们希望这项工作能促进更高效MLLMs的发展。代码和模型将发布以促进未来的研究。|
|**2025-10-14**|[UniFusion: Vision-Language Model as Unified Encoder in Image Generation](http://arxiv.org/abs/2510.12789)|null|尽管视觉生成领域最近取得了显著进展，但大多数现有架构仍然依赖于独立的图像和文本编码器。这种分离限制了扩散模型执行跨模态推理和知识迁移的能力。此前弥合这一鸿沟的尝试通常利用VLM的最后一层信息、采用多个视觉编码器，或联合训练用于文本和图像生成的大型统一模型，但这需要大量的计算资源和大规模数据，从而限制了其可访问性。我们提出了UniFusion，这是一种基于扩散的生成模型，以冻结的大型视觉-语言模型（VLM）为条件，该模型充当统一的多模态编码器。UniFusion的核心是层级注意力池化（LAP）机制，它从冻结VLM的文本和视觉token中提取高层语义和低层细节，以条件化扩散生成模型。我们证明LAP在用于生成的文本-图像对齐以及将视觉信息从VLM忠实地传输到扩散模型方面优于其他浅层融合架构，这对于编辑至关重要。我们提出了VLM赋能的灵活推理重写注入（VERIFI），它在模型内提示重写过程中，仅以VLM生成的文本token为条件来控制扩散Transformer（DiT）。VERIFI结合了条件分布的对齐与VLM的推理能力，从而增加了推理时的能力和灵活性。此外，在编辑任务上进行微调不仅改进了用于生成的文本-图像对齐，表明了跨模态知识迁移，而且还展现出巨大的泛化能力。我们的模型在单图像编辑上训练后，能够零样本泛化到多个图像引用，进一步证明了UniFusion统一编码器设计的合理性。|
|**2025-10-14**|[SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models](http://arxiv.org/abs/2510.12784)|**[link](https://github.com/WayneJin0918/SRUM)**|近年来，统一多模态模型（UMMs）取得了显著进展，它们将视觉-语言生成和理解能力整合到单一框架中。然而，一个显著的差距在于，模型强大的视觉理解能力往往无法迁移到其视觉生成能力上。模型可能根据用户指令正确理解图像，却无法根据文本提示生成逼真的图像。这种现象直接提出了一个引人深思的问题：模型能否通过使用其理解模块来奖励其生成模块，从而实现自我提升？为了弥合这一差距并实现自我提升，我们引入了SRUM，这是一种自我奖励的后训练框架，可直接应用于现有各种设计的UMMs。SRUM创建一个反馈循环，其中模型的理解模块充当内部“评估器”，提供纠正信号以改进其生成模块，而无需额外的人工标注数据。为确保这种反馈是全面的，我们设计了一个全局-局部双重奖励系统。为了解决图像固有的结构复杂性，该系统提供了多尺度指导：全局奖励确保了整体视觉语义和布局的正确性，而局部奖励则细化了细粒度的对象级保真度。SRUM带来了强大的能力并展现出强大的泛化性，将T2I-CompBench上的性能从82.18提升到88.37，并将T2I-ReasonBench上的性能从43.82提升到46.75。总体而言，我们的工作建立了一个强大的新范式，使UMMs的理解模块能够通过自我奖励来指导和增强其自身的生成。|
|**2025-10-14**|[VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage](http://arxiv.org/abs/2510.12750)|null|多模态大语言模型（MLLMs）在视觉与语言联合任务中展现出显著能力。然而，现有的视觉问答（VQA）基准测试通常无法评估深度语义理解，尤其是在视觉艺术分析等复杂领域。这些问题局限于简单的句法结构和表面层面的属性，未能捕捉人类视觉探究的多样性和深度。这种局限性促使模型利用统计捷径而非进行视觉推理。为弥补这一空白，我们引入了VQArt-Bench，一个针对文化遗产领域的新型大规模VQA基准测试。该基准测试采用新颖的多智能体管道构建，其中专门的智能体协同生成细致入微、经过验证且语言多样的问题。由此产生的基准测试根据相关的视觉理解维度进行构建，旨在探究模型解释符号意义、叙事和复杂视觉关系的能力。我们对14个最先进的MLLMs在该基准测试上的评估揭示了当前模型的显著局限性，包括在简单计数任务中出人意料的弱点，以及专有模型与开源模型之间明显的性能差距。|
|**2025-10-14**|[HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions](http://arxiv.org/abs/2510.12733)|null|在复杂的城市环境中，安全且可解释的运动规划需要推理双向多智能体交互。这种推理需要估计潜在自车驾驶机动的成本。许多现有规划器通过基于采样的方法生成初始轨迹，并通过对学习到的未来环境状态预测进行优化来对其进行细化，这需要一个编码期望车辆行为的成本函数。设计这样的成本函数可能非常具有挑战性，尤其是当必须考虑广泛复杂的城市场景时。我们提出了HYPE：结合自车提案条件预测的混合规划，这是一个将来自学习到的提案模型的多模态轨迹提案作为启发式先验整合到蒙特卡洛树搜索（MCTS）细化中的规划器。为了建模双向交互，我们引入了一个自车条件占用预测模型，从而实现了一致的、场景感知的推理。我们的设计通过考虑提案驱动的指导，仅需要极简的基于网格的成本项，显著简化了细化中的成本函数设计。在nuPlan和DeepUrban这两个大规模真实世界基准上的评估表明，HYPE有效地实现了最先进的性能，尤其是在安全性和适应性方面。|
|**2025-10-14**|[Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception](http://arxiv.org/abs/2510.12720)|null|多模态信息的细粒度感知对于推动人机交互至关重要。随着音视频技术的最新进展，能够并行处理音频和视频信号的全能语言模型（OLMs）已成为实现更丰富理解和推理的一种有前景的范式。然而，它们捕获和描述细粒度细节的能力仍未得到充分探索。在这项工作中，我们从数据管道、模型和基准的角度对全能细致感知进行了系统而全面的调查。我们首先识别出当前OLMs中细节与幻觉之间固有的“共生”现象。为解决此问题，我们提出了Omni-Detective，这是一种集成工具调用的代理式数据生成管道，旨在自主生成高度详细但幻觉最少的多模态数据。基于Omni-Detective生成的数据，我们训练了两个字幕生成模型：用于仅音频细致感知的Audio-Captioner，以及用于音视频细致感知的Omni-Captioner。在级联评估协议下，Audio-Captioner在MMAU和MMAR上取得了所有开源模型中的最佳性能，超越了Gemini 2.5 Flash，并提供了与Gemini 2.5 Pro相当的性能。在现有细致字幕生成基准上，Omni-Captioner在VDC上创下了新的最先进水平，并在video-SALMONN 2测试集上实现了细节与幻觉之间的最佳权衡。鉴于缺乏全能细致感知的专用基准，我们设计了Omni-Cloze，这是一种新颖的完形填空式评估方法，用于细致的音频、视觉和音视频字幕生成，可确保稳定、高效和可靠的评估。实验结果和分析证明了Omni-Detective在生成高质量细致字幕方面的有效性，以及Omni-Cloze在评估此类细致字幕方面的优越性。|
|**2025-10-14**|[Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning](http://arxiv.org/abs/2510.12712)|null|多模态大语言模型（MLLMs）正越来越多地应用于现实世界场景，其中用户提供的图像通常不完美，需要主动的图像操作（例如裁剪、编辑或增强）以揭示显著的视觉线索。除了静态视觉感知之外，MLLMs还必须“与图像一起思考”：动态地转换视觉内容并将其与其他工具集成以解决复杂任务。然而，这种从将视觉视为被动上下文到可操作的认知工作空间的转变仍未得到充分探索。大多数现有基准仍然遵循“思考图像”范式，其中图像被视为静态输入。为了弥补这一空白，我们引入了IRIS（与图像和系统交互推理），旨在评估MLLMs在“与图像一起思考”范式下，在复杂的视觉-文本任务中进行感知、转换和推理的能力。IRIS包含1,204个具有挑战性的开放式视觉任务（603个单轮任务，601个多轮任务），涵盖五个不同领域，每个任务都配有详细的评分标准以实现系统评估。我们的评估表明，当前的MLLMs在需要视觉与通用工具有效集成的任务中表现不佳。即使是最强的模型（GPT-5-think）也仅达到18.68%的通过率。我们进一步观察到不同的工具使用行为，OpenAI模型从多样化的图像操作中获益，而Gemini-2.5-pro则没有显示出改进。通过引入第一个围绕“与图像一起思考”的基准，IRIS为推进MLLMs中的视觉智能提供了关键见解。|
|**2025-10-14**|[Reflection-Based Task Adaptation for Self-Improving VLA](http://arxiv.org/abs/2510.12710)|null|预训练视觉-语言-动作（VLA）模型代表着通用机器人领域的一大飞跃，然而，如何有效地将它们就地适应新颖的特定任务，仍然是一个重大障碍。尽管强化学习（RL）是实现这种适应性的一种有前景的途径，但其过程通常效率低下，阻碍了任务的快速掌握。我们引入了反思性自适应（Reflective Self-Adaptation），一个无需人工干预即可实现快速、自主任务适应的框架。我们的框架建立了一个自我改进循环，在此循环中，智能体从自身经验中学习，以增强策略和执行。我们框架的核心是一个双路径架构，它解决了完整的适应生命周期。首先，一个故障驱动的反思性强化学习（Failure-Driven Reflective RL）路径，通过利用VLM的因果推理能力，从故障分析中自动合成有针对性的密集奖励函数，从而实现快速学习。这提供了一个集中的学习信号，显著加速了策略探索。然而，优化此类代理奖励引入了“奖励欺骗”（reward hacking）的潜在风险，即智能体掌握了奖励函数但未能完成实际任务。为了抵消这种风险，我们的第二条路径，成功驱动的质量引导微调（Success-Driven Quality-Guided SFT），将策略建立在整体成功的基础上。它识别并选择性地模仿高质量的成功轨迹，确保智能体与最终任务目标保持一致。该路径通过一个条件课程机制得到强化，以辅助初始探索。我们在具有挑战性的操作任务中进行了实验。结果表明，我们的框架实现了更快的收敛，并与代表性基线相比，获得了更高的最终成功率。我们的工作提出了一种稳健的解决方案，用于创建能够高效、可靠地适应新环境的自我改进智能体。|
|**2025-10-10**|[StreamingVLM: Real-Time Understanding for Infinite Video Streams](http://arxiv.org/abs/2510.09608)|**[link](https://github.com/mit-han-lab/streaming-vlm)**|视觉语言模型（VLMs）可以为实时助手和自主智能体提供支持，但它们面临一个关键挑战：在不增加延迟和内存使用量的情况下，理解接近无限的视频流。对整个视频进行全注意力处理会导致二次方的计算成本，并在长视频上表现不佳。同时，简单的滑动窗口方法也存在缺陷，因为它们要么破坏连贯性，要么因冗余的重复计算而导致高延迟。在本文中，我们引入了StreamingVLM，一个旨在对无限视觉输入进行实时、稳定理解的模型。我们的方法是一个统一框架，将训练与流式推理对齐。在推理过程中，我们通过重用注意力汇聚点（attention sinks）的状态、一个短窗口的近期视觉令牌和一个长窗口的近期文本令牌来维护一个紧凑的KV缓存。这种流式处理能力是通过一个简单的监督微调（SFT）策略灌输的，该策略对短的、重叠的视频块应用全注意力，从而有效地模仿了推理时的注意力模式，而无需在过长的上下文中进行训练。为了进行评估，我们构建了Inf-Streams-Eval，这是一个新的基准，其中视频平均时长超过两小时，并且要求帧与文本之间进行密集的、每秒对齐。在Inf-Streams-Eval上，StreamingVLM对GPT-4O mini取得了66.18%的胜率，并在单个NVIDIA H100上以高达8 FPS的速度保持稳定、实时的性能。值得注意的是，我们的SFT策略还在没有任何针对VQA的微调的情况下增强了通用的VQA能力，将LongVideoBench上的性能提高了+4.30，将OVOBench Realtime上的性能提高了+5.96。代码可在https://github.com/mit-han-lab/streaming-vlm获取。|
|**2025-10-10**|[VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation](http://arxiv.org/abs/2510.09607)|null|视觉-语言-动作（VLA）模型通过利用预训练视觉-语言模型（VLM）强大的感知能力，显著推动了机器人操作的发展。通过将动作模块集成到这些预训练模型中，VLA方法展现出更好的泛化能力。然而，从头开始训练它们成本高昂。在这项工作中，我们提出了一种简单而有效的基于蒸馏的框架，通过从预训练的小型动作模型转移知识，使VLM具备动作执行能力。我们的架构保留了原始VLM结构，仅添加了一个动作token和一个状态编码器以整合物理输入。为了蒸馏动作知识，我们采用了两阶段训练策略。首先，我们通过将VLM隐藏状态映射到小型动作模型的动作空间，执行轻量级对齐，从而有效重用其预训练的动作解码器并避免昂贵的预训练。其次，我们选择性地微调语言模型、状态编码器和动作模块，使系统能够整合多模态输入并生成精确的动作。具体来说，动作token为VLM提供了一个预测未来动作的直接句柄，而状态编码器则允许模型整合仅凭视觉无法捕捉到的机器人动力学。这种设计相较于从头开始训练大型VLA模型，实现了显著的效率提升。与现有最先进方法相比，我们的方法在LIBERO上取得了97.3%的平均成功率（提升11.8%），在LIBERO-LONG上取得了93.5%（提升24.5%）。在涵盖五项操作任务的实际世界实验中，我们的方法始终优于教师模型，达到了82.0%的成功率（提升17%），这表明动作蒸馏有效使VLM能够生成精确的动作，同时大幅降低了训练成本。|
|**2025-10-10**|[SpaceVista: All-Scale Visual Spatial Reasoning from mm to km](http://arxiv.org/abs/2510.09606)|**[link](https://github.com/PeiwenSun2000/SpaceVista)**|随着当前空间推理探索的激增，研究人员在理解室内场景方面取得了显著进展，但在机器人和自动驾驶等多样化应用中仍面临挑战。本文旨在通过解决两个关键挑战来推进多样化场景下的全尺度空间推理：1) 数据集构建过度依赖室内3D扫描和劳动密集型手动标注；2) 缺乏有效的全尺度场景建模，这常导致对单个场景的过拟合。在本文中，我们引入了一个整体解决方案，该方案集成了结构化空间推理知识系统、尺度感知建模和渐进式训练范式，据我们所知，这是首次尝试拓宽多模态大语言模型（MLLMs）的全尺度空间智能。利用任务特定、专家驱动的自动化流程，我们在5个空间尺度上收集了超过38K的视频场景，以创建SpaceVista-1M，这是一个包含约1M空间问答对、涵盖19种不同任务类型的数据集。尽管专家模型可以注入有用的领域知识，但它们在评估方面不可靠。然后，我们通过手动录制、检索和组装视频数据，构建了一个具有精确标注的全尺度基准。然而，由于潜在的知识冲突，使用SpaceVista-1M进行朴素训练常导致次优结果。因此，我们引入了SpaceVista-7B，这是一个接受语义之外的密集输入的空间推理模型，并使用尺度作为尺度感知专家和渐进式奖励的锚点。最后，在包括我们的SpaceVista-Bench在内的5个基准上的广泛评估表明了有竞争力的性能，展示了在所有尺度和场景下的强大泛化能力。我们的数据集、模型和基准将发布在https://peiwensun2000.github.io/mm2km。|
|**2025-10-10**|[Vision Language Models: A Survey of 26K Papers](http://arxiv.org/abs/2510.09586)|null|我们对2023-2025年CVPR、ICLR和NeurIPS的26,104篇录用论文进行了透明、可复现的研究趋势测量。我们对论文标题和摘要进行规范化和词组保护处理，并与手工构建的词典进行匹配，以分配多达35个主题标签，并挖掘有关任务、架构、训练方案、目标函数、数据集以及共同提及模态的细粒度线索。分析量化了三个宏观转变：(1) 多模态视觉-语言-大型语言模型（LLM）工作的急剧增长，这类工作越来越多地将经典感知重构为指令遵循和多步推理；(2) 生成方法稳步扩展，其中扩散模型研究集中在可控性、蒸馏和速度方面；(3) 3D和视频活动的持续活跃，其构成表示从NeRFs转向高斯泼溅，并越来越重视以人-和智能体-为中心的理解。在视觉-语言模型（VLM）内部，提示、适配器、LoRA等参数高效适应技术以及轻量级视觉-语言桥接占据主导地位；训练实践从从头构建编码器转向指令微调和微调强大的骨干网络；对比学习目标相对于交叉熵/排序和蒸馏有所减少。跨会议比较显示，CVPR在3D领域影响力更强，ICLR拥有最高的VLM份额，而效率或鲁棒性等可靠性主题则在各领域中扩散。我们发布了词典和方法，以方便审计和扩展。局限性包括词典召回率和仅限于摘要的范围，但纵向信号在不同会议和年份之间保持一致。|
|**2025-10-10**|[AutoPR: Let's Automate Your Academic Promotion!](http://arxiv.org/abs/2510.09558)|**[link](https://github.com/LightChen233/AutoPR)**|随着同行评审研究数量的激增，学者们越来越依赖社交平台进行发现，而作者则投入大量精力推广其工作以确保可见性和被引用。为了简化这一过程并减少对人力投入的依赖，我们引入了自动推广（AutoPR），这是一项新颖的任务，旨在将研究论文转化为准确、引人入胜且及时的公共内容。为了实现严格的评估，我们发布了PRBench，这是一个多模态基准，将512篇同行评审文章与高质量推广帖文关联起来，从三个维度评估系统：忠实度（准确性和语气）、参与度（受众定位和吸引力）和对齐度（时间选择和渠道优化）。我们还引入了PRAgent，一个多智能体框架，它分三阶段自动化AutoPR：多模态准备下的内容提取、协作合成以生成精炼输出，以及平台特定适应以优化规范、语气和标签，从而实现最大覆盖。在PRBench上与直接LLM（大型语言模型）管线相比，PRAgent展现了显著的改进，包括总观看时长增加604%、点赞数增长438%，以及整体参与度至少提升2.9倍。消融研究表明，平台建模和定向推广对这些提升贡献最大。我们的结果将AutoPR定位为一个可处理、可衡量的研究问题，并为可扩展、有影响力的自动化学术交流提供了路线图。|
|**2025-10-10**|[MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval](http://arxiv.org/abs/2510.09510)|null|我们引入了MRMR，这是首个需要密集推理的专家级多学科多模态检索基准。MRMR包含1,502个查询，涵盖23个领域，其正向文档均经过人类专家仔细验证。与之前的基准相比，MRMR引入了三个关键进展。首先，它在不同专业领域对检索系统提出挑战，从而实现跨领域的细粒度模型比较。其次，查询是推理密集型的，图像需要更深层次的解读，例如诊断显微镜切片。我们进一步引入了矛盾检索，这是一项要求模型识别冲突概念的新颖任务。最后，查询和文档被构建为图像-文本交错序列。与早期仅限于单张图像或单模态文档的基准不同，MRMR提供了一个具有多图像查询和混合模态语料库文档的现实设置。我们在MRMR上对4类多模态检索系统和14个前沿模型进行了广泛评估。结合大型语言模型生成的图像描述的文本嵌入模型Qwen3-Embedding取得了最高性能，凸显了多模态检索模型仍有巨大的改进空间。尽管最新的多模态模型（例如Ops-MM-Embedding）在专家领域查询上表现出竞争力，但在推理密集型任务上表现不足。我们相信MRMR为在更现实和更具挑战性的场景中推进多模态检索铺平了道路。|
|**2025-10-10**|[PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs](http://arxiv.org/abs/2510.09507)|**[link](https://github.com/EnVision-Research/PhysToolBench)**|使用、理解和创造工具的能力是人类智能的标志，使人类能够与物理世界进行复杂的互动。任何通用智能体若要实现真正的多功能性，也必须掌握这些基本技能。尽管现代多模态大语言模型 (MLLM) 在具身智能和下游视觉-语言-动作 (VLA) 模型中利用其广泛的常识进行高层规划，但它们对物理工具的真实理解程度仍未被量化。为了弥合这一差距，我们提出了 PhysToolBench，这是首个专门用于评估 MLLM 对物理工具理解能力的基准。我们的基准被构建为一个包含超过 1,000 对图像-文本对的视觉问答 (VQA) 数据集。它评估了三个不同难度级别的能力：(1) 工具识别：要求识别工具的主要功能。(2) 工具理解：测试掌握工具操作基本原理的能力。(3) 工具创造：挑战模型在常规选项不可用时，利用周围物体制造新工具。我们对 32 种 MLLM（涵盖了专有模型、开源模型、专用具身模型以及 VLA 中的骨干模型）进行的全面评估揭示了它们在工具理解方面存在的显著缺陷。此外，我们提供了深入分析并提出了初步解决方案。代码和数据集已公开可用。|
|**2025-10-10**|[Unsupervised full-field Bayesian inference of orthotropic hyperelasticity from a single biaxial test: a myocardial case study](http://arxiv.org/abs/2510.09498)|null|在传统的均质组织测试中，充分捕捉这种行为需要激发多种变形模式，即组合三轴剪切测试和双轴拉伸测试。本质上，这种多模式实验方案需要多个组织样本和大量的样本操作。内在的样本间变异性和操作引起的组织损伤可能会对逆向识别的组织行为产生不利影响。在这项工作中，我们旨在通过将注意力集中在参数估计问题中异质变形剖面的使用来弥补这一空白。更具体地说，我们改进了EUCLID（一种用于自动发现本构模型的无监督方法），以利用贝叶斯推断方法和三维连续体单元，对高度非线性、正交各向异性本构模型进行参数识别。我们展示了它在不同噪声水平下，从单一异质双轴拉伸测试中量化推断合成心肌组织薄片材料模型参数的强大能力。该方法与真值模拟以及相应的可信区间表现出良好的一致性。我们的工作突出了从单一双轴拉伸测试中表征高度非线性、正交各向异性材料模型并进行不确定性量化的潜力。|
|**2025-10-10**|[Multimodal Policy Internalization for Conversational Agents](http://arxiv.org/abs/2510.09474)|**[link](https://github.com/MikeWangWZHL/TriMPI)**|ChatGPT和Alexa+等现代对话代理依赖于指定元数据、响应风格和工具使用规则的预定义策略。随着这些基于大型语言模型的系统扩展以支持多样化的业务和用户查询，此类策略（通常以上下文提示的形式实现）正变得日益复杂和冗长，使得忠实遵循变得困难并带来了高昂的固定计算成本。随着多模态代理的兴起，管理视觉和多模态行为的策略至关重要但仍未得到充分研究。先前的提示压缩工作主要缩短任务模板和示例，而现有的策略对齐研究仅关注基于文本的安全规则。我们引入了多模态策略内化（MPI），这是一项新任务，旨在将推理密集型多模态策略内化到模型参数中，从而在推理时无需包含策略即可实现更强的策略遵循能力。MPI带来了独特的数据和算法挑战。我们构建了两个数据集，涵盖合成和真实世界的决策制定与工具使用任务，并提出了TriMPI，一个三阶段训练框架。TriMPI首先通过持续预训练注入策略知识，接着执行有监督微调，最后应用PolicyRollout，这是一种GRPO风格的强化学习扩展，通过策略感知响应来增强rollout，以实现有根据的探索。TriMPI在端到端准确性、泛化能力和抗遗忘性方面取得了显著提升。作为多模态策略内化领域的首项工作，我们提供了数据集、训练方案和全面的评估，以促进未来的研究。项目页面：https://mikewangwzhl.github.io/TriMPI。|
|**2025-10-10**|[D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models](http://arxiv.org/abs/2510.09473)|null|测试时适应范式通过对源模型产生的未标记目标数据进行即时适应，为域偏移提供了灵活性。视觉-语言模型（VLMs）利用其泛化能力处理多样化的下游任务，而测试时提示调优已成为适应VLMs的一个突出解决方案。在这项工作中，我们探索了对比式视觉-语言模型，并识别出由跨模态的单一主导特征维度引起的模态鸿沟。我们观察到文本和图像模态中的主导维度均表现出高预测敏感性，并且限制其影响可以改善校准误差。基于这一洞察，我们提出了维度熵最大化方法，该方法通过将文本特征的分布规范化趋向均匀性，以减轻主导维度的依赖性。我们的方法缓解了测试时提示调优中校准性能的下降，为增强视觉-语言模型在实际部署场景中的可靠性提供了一个简单而有效的解决方案。|
|**2025-10-09**|[MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning](http://arxiv.org/abs/2510.08567)|null|视觉语言模型（VLMs）正越来越多地被部署为控制器，能够访问外部工具进行复杂推理和决策，然而，其有效性仍受限于高质量多模态轨迹的稀缺性以及手动标注的成本。我们通过一个以视觉为中心的智能体微调框架来解决这一挑战，该框架自动合成多模态轨迹，生成分步偏好对，并训练一个VLM控制器以实现稳健的工具使用推理。我们的管道首先构建了M-TRACE，一个包含2.85万个多模态任务和17.7万条经过验证轨迹的大规模数据集，从而实现基于模仿的轨迹微调。在此基础上，我们开发了MATRIX智能体，一个在M-TRACE上进行微调的控制器，用于分步工具推理。为实现更精细的对齐，我们进一步引入了Pref-X，一组包含1.1万个自动生成的偏好对，并在此基础上通过分步偏好学习优化MATRIX。在Agent-X、GTA和GAIA这三个基准测试中，MATRIX持续超越开源和闭源VLM，展示了可扩展且有效的多模态工具使用能力。我们的数据和代码可在https://github.com/mbzuai-oryx/MATRIX获取。|
|**2025-10-09**|[NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints](http://arxiv.org/abs/2510.08565)|null|组合式训练一直是现有多模态大语言模型（MLLM）中事实上的范式，其中预训练视觉编码器通过连续多模态预训练与预训练大语言模型连接。然而，由于训练分离，这种范式的多模态扩展特性仍然难以探索。在本文中，我们关注以端到端方式对 MLLM 进行原生训练，并在实际设置（即数据约束）下系统地研究其设计空间和扩展特性。通过仔细研究 MLLM 中的各种选择，我们获得了能够最佳平衡性能和训练成本的最优元架构。之后，我们进一步探索了原生 MLLM 的扩展特性，并指出了视觉编码器和 LLM 之间正相关的扩展关系。基于这些发现，我们提出了一个名为 NaViL 的原生 MLLM，并结合了一个简单且经济高效的方案。在 14 个多模态基准测试上的实验结果证实了 NaViL 相对于现有 MLLM 具有竞争力的性能。除此之外，我们的发现和结果为未来原生 MLLM 的研究提供了深入的见解。|
|**2025-10-09**|[How to Teach Large Multimodal Models New Skills](http://arxiv.org/abs/2510.08564)|**[link](https://github.com/jessemelpolio/LMM_CL)**|我们如何在不抹除其先前能力的情况下，教授大型多模态模型 (LMMs) 新技能？我们研究了在五种目标技能上进行的序贯微调，同时监测了跨越三种模型家族的八个保留基准上的通用能力。我们观察到，在窄范围微调后，保留任务上出现的“遗忘”可以在后期阶段部分恢复。我们将这种行为归因于输出词元分布中可测量的偏移，这通过一个与遗忘共同变化的简单计数偏差探测器体现出来。受此启发，我们确定了两种简单、稳健的微调方案，它们在强力学习的同时限制了漂移：(i) 仅更新自注意力投影层，以及 (ii) 仅更新多层感知机 (MLP) 的门控和向上投影 (Gate&Up)，同时冻结向下投影 (Down projection)。跨模型和任务，这些选择带来了强大的目标增益，同时在很大程度上保留了保留性能。代码可在 https://github.com/jessemelpolio/LMM_CL 获取。|
|**2025-10-09**|[SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models](http://arxiv.org/abs/2510.08559)|null|大规模多模态模型（LMMs）在各种能力上取得了显著进展；然而，科学领域中复杂的视频推理仍然是一个重要且充满挑战的前沿。当前的视频基准主要针对高度依赖感知/识别的通用场景，而推理任务相对简单，这导致了饱和，从而未能有效评估先进的多模态认知技能。为了弥补这一关键空白，我们引入了SciVideoBench，一个专门用于评估科学背景下先进视频推理能力的严格基准。SciVideoBench包含1000个精心制作的多项选择题，这些问题来源于前沿的科学实验视频，涵盖超过25个专业学术领域，并经过半自动系统验证。每个问题都要求精深的领域特定知识、精准的时空感知和复杂的逻辑推理，有效地挑战了模型的更高阶认知能力。我们的评估突出显示了最先进的专有和开源LMMs（包括Gemini 2.5 Pro和Qwen2.5-VL）中存在显著的性能缺陷，这表明在视频推理能力方面仍有巨大的进步空间。对推理复杂性和视觉基础等关键因素的详细分析，为LMMs的未来发展提供了宝贵的见解和明确的方向，从而推动真正有能力的多模态AI合作科学家的演变。我们希望SciVideoBench能够符合社区的兴趣，并帮助推动前沿AI在科学前沿领域的进步和应用。|
|**2025-10-09**|[MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](http://arxiv.org/abs/2510.08540)|**[link](https://github.com/PhoenixZ810/MM-HELIX)**|尽管当前多模态大语言模型（MLLMs）已在数学和逻辑等推理任务中展现出熟练的能力，但它们在长链式反思推理方面的能力（这是解决复杂现实世界问题的先决条件）仍未得到充分探索。在这项工作中，我们首先进行了一项广泛的实证研究以评估这种能力。利用精心设计的数据合成引擎，我们构建了MM-HELIX，这是一个包含1,260个样本的多模态基准，涵盖42个需要迭代思考和回溯的挑战性合成任务。在此基准上的实证结果表明，现有MLLMs在长链式反思推理方面存在显著的性能不足。为解决这一局限性，我们生成了后训练数据，并进一步探索了利用这些数据的学习范式。我们首先开发了逐步启发式响应生成流程，以创建MM-HELIX-100K，这是一个包含10万条高质量反思推理轨迹的大规模数据集，用于指令微调阶段。考虑到标准强化学习在复杂任务上因稀疏的奖励信号以及在监督微调后出现的灾难性遗忘而表现不佳，我们提出了自适应混合策略优化（AHPO），这是一种新颖的训练策略，它将离线监督和在线优化动态统一到一个阶段中。这种策略使模型能够在奖励稀疏时从专家数据中学习，并在熟练后进行独立探索。将其应用于Qwen2.5-VL-7B基线模型时，我们的方法在MM-HELIX基准上取得了+18.6%的准确率提升，并在一般数学和逻辑任务上展现出强大的泛化能力，平均性能提升了+5.7%。我们的工作表明，MLLMs中的反思推理可以被有效地学习和泛化，为开发更强大的MLLMs铺平了道路。|
|**2025-10-09**|[SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models](http://arxiv.org/abs/2510.08531)|**[link](https://github.com/ZJU-REAL/SpatialLadder)**|空间推理仍然是视觉-语言模型（VLM）面临的一个基本挑战，尽管近期有所进展，但当前方法仍难以实现鲁棒性能。我们发现这一局限性源于一个关键空白：现有方法试图直接学习空间推理，而未建立感知和理解的层次化基础。为解决这一挑战，我们提出了一种逐步构建空间智能的全面方法论。我们引入了SpatialLadder-26k，这是一个包含26,610个样本的多模态数据集，涵盖目标定位、单图像、多视角和视频空间推理任务，该数据集通过标准化流程构建，确保了跨模态的系统性覆盖。基于该数据集，我们设计了一个三阶段渐进式训练框架：(1) 通过目标定位建立空间感知，(2) 通过多维空间任务发展空间理解，(3) 通过带有可验证奖励的强化学习强化复杂推理。这种方法产生了SpatialLadder，这是一个30亿参数模型，在空间推理基准测试中取得了最先进的性能，比基础模型平均提升23.4%，超过GPT-4o 20.8%，并超过Gemini-2.0-Flash 10.1%。值得注意的是，SpatialLadder在域外基准测试中保持了强大的泛化能力，提升了7.2%，这证明了从感知到推理的渐进式训练对于鲁棒的空间智能至关重要。|
|**2025-10-09**|[MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration](http://arxiv.org/abs/2510.08508)|**[link](https://github.com/MediaX-SJTU/MoA-VR)**|真实世界视频由于多样的采集和传输条件，常遭受复杂的退化，例如噪声、压缩伪影和低光照失真。现有恢复方法通常需要专业人员手动选择专用模型，或依赖于难以泛化到不同退化类型的单一架构。受专家经验启发，我们提出了MoA-VR，这是首个智能体混合视频恢复系统，通过三个协调智能体（退化识别、路由与恢复、恢复质量评估）模仿人类专业人员的推理和处理过程。具体而言，我们构建了一个大规模高分辨率视频退化识别基准，并建立了一个由视觉-语言模型（VLM）驱动的退化识别器。我们进一步引入了一个由大语言模型（LLM）驱动的自适应路由器，该路由器通过观察工具使用模式自主学习有效的恢复策略。为了评估中间和最终处理的视频质量，我们构建了恢复视频质量（Res-VQ）数据集，并设计了一个专为恢复任务定制的基于VLM的视频质量评估（VQA）模型。大量实验表明，MoA-VR能有效处理多样和复合退化，在客观指标和感知质量方面持续优于现有基线。这些结果突出了在通用视频恢复系统中整合多模态智能和模块化推理的潜力。|
|**2025-10-09**|[Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models](http://arxiv.org/abs/2510.08492)|null|传统多模态学习器为诸如视觉问答等任务寻找统一表示，但严重依赖成对数据集。然而，一个被忽视但却可能很有潜力的问题是：能否利用辅助的未成对多模态数据直接增强目标模态中的表示学习？我们引入了UML（Unpaired Multimodal Learner，未成对多模态学习器），这是一种模态无关的训练范式，其中单一模型交替处理来自不同模态的输入，并在它们之间共享参数。这种设计利用了不同模态是共享底层现实的投影这一假设，使模型能够从跨模态结构中受益，而无需明确的成对数据。理论上，在线性数据生成假设下，我们表明未成对的辅助数据可以产生比单模态训练对数据生成过程严格更具信息量的表示。经验上，我们表明使用来自辅助模态（例如文本、音频或图像）的未成对数据，可以持续提高跨越不同单模态目标（例如图像和音频）的下游性能。我们的项目页面：https://unpaired-multimodal.github.io/|
|**2025-10-09**|[InstructX: Towards Unified Visual Editing with MLLM Guidance](http://arxiv.org/abs/2510.08485)|null|随着多模态大语言模型（MLLMs）在视觉理解和推理方面展现出强大能力，人们对利用它们提升扩散模型编辑性能的兴趣日益增长。尽管取得了快速进展，但大多数研究缺乏对MLLM设计选择的深入分析。此外，MLLMs与扩散模型的集成在某些困难任务（如视频编辑）中仍是一个开放性挑战。在本文中，我们提出了InstructX，一个用于图像和视频编辑的统一框架。具体而言，我们对集成MLLMs和扩散模型以实现指令驱动的跨多样任务编辑进行了全面研究。在此研究的基础上，我们分析了统一建模中图像和视频之间的协作与区别。(1) 我们展示了在图像数据上进行训练可以在没有明确监督的情况下产生涌现的视频编辑能力，从而缓解了稀缺视频训练数据带来的限制。(2) 通过整合模态特定的MLLM特征，我们的方法有效地将图像和视频编辑任务统一到一个单一模型中。大量实验表明，我们的方法可以处理广泛的图像和视频编辑任务，并取得了最先进的性能。|
|**2025-10-09**|[The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping](http://arxiv.org/abs/2510.08482)|null|象似性，即语言形式与意义之间的相似性，在手语中普遍存在，为视觉基础提供了一个天然的试验平台。对于视觉-语言模型（VLM）而言，挑战在于从动态的人体动作而非静态上下文中恢复这些基本映射。我们引入了“视觉象似性挑战赛”，这是一个新颖的基于视频的基准，它调整了心理语言学测量方法，用于评估VLM在三个任务上的表现：(i) 语音手语形式预测（例如，手形、位置），(ii) 透明度（从视觉形式推断意义），以及(iii) 分级象似性评级。我们在零样本和少样本设置下，使用荷兰手语评估了13个最先进的VLM，并将其与人类基线进行比较。在语音形式预测方面，VLM能够恢复一些手形和位置细节，但仍低于人类表现；在透明度方面，它们远低于人类基线；并且只有顶级模型与人类的象似性评级适度相关。有趣的是，具有更强语音形式预测能力的模型与人类象似性判断的相关性更好，这表明它们对视觉基础结构具有共同的敏感性。我们的发现验证了这些诊断任务，并启发了以人为中心的信号和具身学习方法，以用于建模象似性并改善多模态模型中的视觉基础。|
|**2025-10-07**|[EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark](http://arxiv.org/abs/2510.06218)|null|现有的大多数第一人称视角理解基准主要关注白天场景，却忽视了实际应用中不可避免的低光照条件。为了弥补这一空白，我们提出了EgoNight，这是首个针对夜间第一人称视角的综合基准，以视觉问答（VQA）作为核心任务。EgoNight的一个关键特征是引入了昼夜对齐视频，这些视频利用白天数据提高了夜间标注质量，并揭示了不同光照条件之间明显的性能差距。为实现这一目标，我们收集了Blender渲染的合成视频和真实世界录像，确保场景和动作在视觉上和时间上对齐。利用这些配对视频，我们构建了EgoNight-VQA，它由一个新颖的昼间增强夜间自动标注引擎支持，并通过大量人工验证进行了完善。每个问答对都经过标注员的二次检查以确保可靠性。EgoNight-VQA总计包含3658个问答对，涵盖90个视频和12种不同的问答类型，耗费超过300小时的人工工作。对最先进多模态大语言模型（MLLMs）的评估揭示了从白天到夜晚迁移时性能的显著下降，这强调了在低光照条件下进行推理的挑战。除了VQA，EgoNight还引入了两项辅助任务：昼夜对应关系检索和夜间第一人称深度估计，以进一步探索现有模型的边界。我们相信EgoNight-VQA为推动应用驱动的第一人称视角研究以及开发能够在不同光照领域泛化的模型提供了坚实的基础。所有数据和代码将在论文接收后公开。|
|**2025-10-07**|[Bimanual 3D Hand Motion and Articulation Forecasting in Everyday Images](http://arxiv.org/abs/2510.06145)|**[link](https://github.com/ap229997/forehand4d)**|我们解决了在日常场景中从单张图像预测双手3D手部运动与姿态的问题。为了解决多样化场景中3D手部标注不足的问题，我们设计了一个标注流程，该流程包含一个扩散模型，用于将2D手部关键点序列提升为4D手部运动。对于预测模型，我们采用了一种扩散损失，以解释手部运动分布中的多模态性。在6个数据集上进行的广泛实验表明，相较于最佳基线模型，在具有推断标签的多样化数据上进行训练具有优势（14%的提升），并且我们的提升（42%更好）和预测（16.4%的增益）模型是有效的，尤其是在对日常图像的零样本泛化能力方面。|
|**2025-10-07**|[Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation](http://arxiv.org/abs/2510.06131)|null|生成式医疗模型在模态特异性场景中受限，这阻碍了来自影像、病理和临床记录的互补证据的整合。这种碎片化限制了它们发展成为能够在生物医学数据全谱范围内学习和推理的基础模型。我们提出了MeDiM，这是首个医疗离散扩散模型，它无需模态特异性组件即可学习跨模态的共享分布。MeDiM统一了多种生成任务：在图像和文本之间进行翻译，并响应提示联合生成跨领域的图像-报告对。MeDiM基于离散扩散框架构建，通过共享概率空间弥合了视觉和语言表示。为了实现统一和灵活的医疗生成，我们采用多模态大语言模型（MLLM）作为扩散骨干，利用其先验知识和跨模态推理能力。我们引入了两个关键设计：（1）移除因果注意力掩码以实现双向上下文，以及（2）注入连续时间步嵌入以增强扩散感知。实验表明MeDiM实现了高保真医疗生成（在MIMIC-CXR上FID为16.60，在PathGen上FID为24.19）和准确的报告生成（METEOR分别为0.2650和0.2580）。联合生成的图像-报告对进一步提升了下游性能（BLEU-1提高6.43%，BLEU-2提高18.57%，BLEU-3提高31.58%，METEOR提高4.80%），表明MeDiM支持连贯且具有临床依据的多模态输出。|
|**2025-10-07**|[Multimodal Feature Prototype Learning for Interpretable and Discriminative Cancer Survival Prediction](http://arxiv.org/abs/2510.06113)|null|生存分析在临床决策中发挥着至关重要的作用。然而，当前使用的模型往往难以解释，这降低了它们在临床环境中的实用性。原型学习提供了一个潜在的解决方案，但传统方法侧重于局部相似性和静态匹配，忽略了更广泛的肿瘤背景，并缺乏与基因组数据的强大语义对齐。为了克服这些问题，我们引入了一种创新的基于原型的多模态框架FeatProto，旨在通过解决病理学中当前原型学习方法学的重大局限性来增强癌症生存预测。我们的框架建立了一个统一的特征原型空间，该空间将全玻片图像（WSI）的全局和局部特征与基因组图谱相结合。这种整合促进了可追溯和可解释的决策制定过程。我们的方法包括三项主要创新：(1) 一种鲁棒的表型表示，它将关键斑块与全局上下文融合，并与基因组数据协调以最小化局部偏差。(2) 一种指数原型更新策略（EMA ProtoUp），它维持稳定的跨模态关联，并采用漂移机制使原型灵活适应肿瘤异质性。(3) 一种分层原型匹配方案，旨在捕捉全局中心性、局部典型性和群体水平趋势，从而完善原型推断。对四个公开可用的癌症数据集进行的全面评估表明，我们的方法在准确性和互操作性方面均超越了当前领先的单模态和多模态生存预测技术，为关键医疗应用的原型学习提供了新视角。我们的源代码可在https://github.com/JSLiam94/FeatProto获取。|
|**2025-10-07**|[When Thinking Drifts: Evidential Grounding for Robust Video Reasoning](http://arxiv.org/abs/2510.06077)|null|视频推理，即使机器能够通过多步逻辑从动态视觉内容中进行推理的任务，对于高级人工智能至关重要。尽管思维链（CoT）机制已增强了基于文本任务中的推理能力，但其在视频理解中的应用仍未得到充分探索。本文进行了一项系统分析，揭示了CoT在视频推理中往往会降低性能，产生冗长但具有误导性的内部独白，并导致视觉细节的幻觉和对正确直觉的覆盖——我们称此现象为“视觉思维漂移”。我们通过贝叶斯视角解释这种漂移，认为CoT轨迹往往偏离实际视觉证据，转而放大内部偏见或语言先验，导致模型更倾向于编造故事而非进行基于证据的推理。为了解决这个问题，我们引入了视觉证据奖励（VER），这是一种新颖的强化学习框架，它明确奖励生成可验证地基于视觉证据的推理轨迹。在10个不同的视频理解基准上进行的全面评估表明，我们的Video-VER始终能取得顶尖性能。我们的工作揭示了以视频为中心的推理所面临的独特挑战，并鼓励开发能够稳健地将其推理建立在视觉证据之上的AI——这对于大型多模态模型而言，不仅意味着“先思考再回答”，更意味着“边看边思考”。|
|**2025-10-07**|[Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA](http://arxiv.org/abs/2510.06067)|null|验证码（CAPTCHA）最初旨在区分人类和机器人，现已演变为一个真实世界的基准，用于评估视觉语言模型（VLMs）的空间推理能力。在这项工作中，我们首先展示了循序渐进的推理对于视觉语言模型（VLMs）解决代表高难度空间推理任务的验证码至关重要，并且当前的商业视觉语言模型在此类推理方面仍然面临困难。具体而言，我们观察到大多数商业视觉语言模型（例如Gemini、Claude、GPT等）未能有效解决验证码，因此准确率较低（约21.9%）。然而，我们的发现表明，在生成最终坐标之前要求模型执行循序渐进的推理，可以显著提高其解决准确率，凸显了这一差距的严重性。为了系统地研究这个问题，我们引入了CAPTCHA-X，这是首个包含推理的真实世界验证码基准，涵盖七类验证码（例如五子棋、hCaptcha等），并提供了循序渐进的动作解决方案和基础标注。我们进一步定义了五个面向推理的指标，能够对模型的推理能力进行全面评估。为了验证推理的有效性，我们还提出了一个通用的基于代理式视觉语言模型（VLM）的框架，该框架融入了模型固有的推理能力。我们的方法在五种高难度验证码类型上取得了最先进的性能，平均解决准确率达到83.9%，显著超越了现有基线。这些结果揭示了当前模型的局限性，并强调了推理在未来推进视觉空间挑战方面的重要性。|
|**2025-10-07**|[Detection and Measurement of Hailstones with Multimodal Large Language Models](http://arxiv.org/abs/2510.06008)|null|本研究考察了利用预训练多模态大语言模型，通过社交媒体和新闻图像检测和测量冰雹。本研究的数据集包含474张众包冰雹图像，这些图像来自2022年1月至2024年9月期间奥地利有记录的冰雹事件。这些冰雹的最大直径范围为2到11厘米。我们估计了冰雹直径，并比较了利用单阶段和双阶段提示策略的四种不同模型。后者利用图像中参照物（例如人手）提供的额外尺寸线索。我们的结果表明，预训练模型已经具备从图像中测量冰雹直径的潜力，其中最佳模型的平均平均绝对误差为1.12厘米。与单阶段提示相比，双阶段提示提高了大多数模型的可靠性。我们的研究表明，这些现成的模型即使未经微调，也能通过从社交媒体图像中提取有意义且空间密集的信息，补充传统的冰雹传感器，从而实现对恶劣天气事件更快、更详细的评估。从社交媒体和其他来源自动实时获取图像仍然是一项开放任务，但它将使我们的方法直接适用于未来的冰雹事件。|
|**2025-10-07**|[Diffusion Models for Low-Light Image Enhancement: A Multi-Perspective Taxonomy and Performance Analysis](http://arxiv.org/abs/2510.05976)|null|微光图像增强（LLIE）对于监控、自动导航和医学成像等安全关键型应用至关重要，因为在这些应用中，可见性下降会损害下游任务性能。近期，扩散模型因其通过迭代去噪建模复杂图像分布的能力，已成为LLIE领域一种有前景的生成范式。本综述对用于LLIE的扩散模型提供了最新批判性分析，其突出特点是对生成对抗网络和基于Transformer的最新方法进行了深入的比较性能评估，全面考察了实际部署挑战，并对基础模型等新兴范式的作用提出了前瞻性视角。我们提出了一种多视角分类法，涵盖六个类别：内在分解、光谱与潜在、加速、引导、多模态和自主；该分类法根据物理先验、条件方案和计算效率来映射增强方法。我们的分类法基于模型机制和条件信号的混合视角。我们评估了定性失效模式、基准不一致性以及解释性、泛化性与推理效率之间的权衡。我们还讨论了实际部署限制（例如，内存、能源消耗）和伦理考量。本综述旨在通过突出趋势和提出开放研究问题（包括新颖条件化、实时适应和基础模型的潜力），指导下一代基于扩散的LLIE研究。|
|**2025-10-07**|[Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density](http://arxiv.org/abs/2510.05949)|null|联合嵌入预测架构（JEPAs）学习到的表征能够开箱即用地解决众多下游任务。JEPAs结合了两个目标：(i) 一个潜在空间预测项，即轻微扰动样本的表征必须可以从原始样本的表征中预测出来；以及 (ii) 一个抗坍塌项，即并非所有样本都应具有相同的表征。尽管 (ii) 通常被认为是表征坍塌的显而易见的补救措施，但我们发现JEPAs的抗坍塌项作用远不止于此——它可证明地估计数据密度。简而言之，任何成功训练的JEPA都可以用来获取样本概率，例如用于数据整理、异常检测，或仅仅用于密度估计。我们的理论发现与所使用的数据集和架构无关——无论如何，都可以使用模型在 $x$ 处的雅可比矩阵，高效地以封闭形式计算样本 $x$ 的学习概率。我们的发现经过了经验验证，涵盖了不同数据集（合成数据集、受控数据集和ImageNet），以及属于JEPA家族的不同自监督学习方法（I-JEPA和DINOv2），并在多模态模型（如MetaCLIP）上进行了验证。我们将提取JEPA学习到的密度的方法命名为JEPA-SCORE。|
|**2025-10-07**|[BioAutoML-NAS: An End-to-End AutoML Framework for Multimodal Insect Classification via Neural Architecture Search on Large-Scale Biodiversity Data](http://arxiv.org/abs/2510.05888)|null|昆虫分类对于农业管理和生态研究至关重要，因为它直接影响作物健康和生产。然而，由于昆虫的复杂特征、类别不平衡和大规模数据集，这项任务仍然具有挑战性。为解决这些问题，我们提出了BioAutoML-NAS，这是首个使用多模态数据（包括图像和元数据）的BioAutoML模型，它将神经架构搜索（NAS）应用于图像，以自动学习每个单元内每个连接的最佳操作。多个单元堆叠形成完整网络，每个单元提取详细的图像特征表示。多模态融合模块将图像嵌入与元数据结合，使模型能够利用视觉和类别生物信息对昆虫进行分类。交替双层优化训练策略联合更新网络权重和架构参数，同时零操作移除不重要的连接，从而生成稀疏、高效且高性能的架构。在BIOSCAN-5M数据集上的大量评估表明，BioAutoML-NAS实现了96.81%的准确率、97.46%的精确率、96.81%的召回率和97.05%的F1分数，分别比最先进的迁移学习、Transformer、AutoML和NAS方法高出约16%、10%和8%。在Insects-1M数据集上的进一步验证获得了93.25%的准确率、93.71%的精确率、92.74%的召回率和93.22%的F1分数。这些结果表明BioAutoML-NAS提供了准确、可靠的昆虫分类，支持现代可持续农业。|
|**2025-10-03**|[LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models](http://arxiv.org/abs/2510.03232)|null|多模态大语言模型 (MLLMs) 在通用视觉基准上表现出色，但在医学影像等专业领域面临分布外 (OOD) 任务挑战，这些领域的标注数据有限且昂贵。我们提出了LEAML，一个标签高效的适应框架，它利用稀缺的标注VQA样本和大量的未标注图像。我们的方法通过由标题蒸馏正则化的问答生成器，为未标注数据生成领域相关的伪问答对。重要的是，我们仅选择性地更新与问答最相关的神经元，使问答生成器能够在蒸馏过程中高效获取领域特定知识。在胃肠内窥镜和体育VQA上的实验表明，在最少监督下，LEAML始终优于标准微调，突显了我们提出的LEAML框架的有效性。|
|**2025-10-03**|[Improving GUI Grounding with Explicit Position-to-Coordinate Mapping](http://arxiv.org/abs/2510.03230)|null|GUI接地，即将自然语言指令映射到像素坐标的任务，对自主代理至关重要，但对当前视觉-语言模型（VLMs）来说仍然很困难。核心瓶颈是可靠的块到像素映射，当外推到训练期间未见过的高分辨率显示器时，这种映射就会失效。当前方法直接从视觉特征中将坐标生成为文本标记，这迫使模型隐式地推断复杂的位置到像素映射；结果是，在新分辨率下，准确性下降，故障增多。我们通过两种互补的创新来解决这个问题。首先，RULER标记作为显式坐标标记，让模型能够像参考地图上的网格线一样参考位置，并进行调整而不是从头生成坐标。其次，交错式MRoPE (I-MRoPE) 通过确保宽度和高度维度被平等地表示来改进空间编码，解决了标准位置编码方案的不对称性。在ScreenSpot、ScreenSpot-V2和ScreenSpot-Pro上的实验显示，接地准确性持续提升，在高分辨率界面上的提升最大。通过提供显式空间指导而非依赖隐式学习，我们的方法实现了跨越不同分辨率和平台的更可靠的GUI自动化。|
|**2025-10-03**|[Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner](http://arxiv.org/abs/2510.03206)|null|扩散语言模型，特别是掩码离散扩散模型，最近取得了巨大成功。尽管有一些理论和初步的实证结果表明循环Transformer或连续思维链在潜在推理方面具有优势，但连续扩散模型的性能通常不如其离散对应物。在本文中，我们认为扩散语言模型不一定需要在离散空间中。具体来说，我们证明了连续扩散模型比离散扩散和循环Transformer具有更强的表达能力。我们将理论表达能力与经验性能之间的矛盾归因于它们的实际可训练性：虽然连续扩散提供了循环Transformer所缺乏的中间监督，但它们在将连续表示空间中的令牌解码到离散令牌空间时引入了额外的困难。因此，我们提出了协同演化连续离散扩散（CCDD），它在连续表示空间和离散令牌空间的并集上定义了一个联合多模态扩散过程，利用单个模型在联合空间中同时去噪。通过结合两种模态，CCDD在潜在空间中具有丰富的语义表达能力，并且借助显式离散令牌，具有良好的可训练性和样本质量。我们还为CCDD提出了有效的架构和先进的训练/采样技术，这在真实世界任务的广泛语言建模实验中展现出强大的经验性能。|
|**2025-10-03**|[Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning](http://arxiv.org/abs/2510.03182)|null|视觉语言模型 (VLM) 在视觉规划方面展现出强大潜力，但在精确的空间推理和长程推理方面表现不足。相比之下，规划领域定义语言 (PDDL) 规划器擅长长程形式化规划，但无法解释视觉输入。近期工作通过使 VLM 能够将视觉规划问题转化为 PDDL 文件用于形式化规划，从而结合了这些互补优势。然而，尽管 VLM 可以令人满意地生成 PDDL 问题文件，但它们却难以准确生成描述所有规划规则的 PDDL 领域文件。因此，先前方法依赖人类专家预定义领域文件，或依赖持续的环境访问进行细化。我们提出了 VLMFP，一个双 VLM 引导的框架，能够自主生成 PDDL 问题文件和领域文件，以实现形式化视觉规划。VLMFP 引入了两个 VLM 以确保可靠的 PDDL 文件生成：一个 SimVLM 根据输入的规则描述模拟行动后果，另一个 GenVLM 则通过比较 PDDL 和 SimVLM 的执行结果来生成并迭代细化 PDDL 文件。VLMFP 释放了多层次的泛化能力：相同的生成 PDDL 领域文件适用于同一问题下的所有不同实例，并且 VLM 可以泛化到具有不同外观和规则的不同问题。我们使用 6 个网格世界领域评估了 VLMFP，并测试了其对未见实例、外观和游戏规则的泛化能力。平均而言，SimVLM 分别针对已见和未见外观，准确描述了 95.5%、82.6% 的情景，模拟了 85.5%、87.8% 的行动序列，并判断了 82.4%、85.6% 的目标达成率。在 SimVLM 的指导下，VLMFP 可以生成 PDDL 文件，分别针对已见和未见外观中的未见实例，实现 70.0%、54.1% 的有效规划。项目页面：https://sites.google.com/view/vlmfp。|
|**2025-10-03**|[SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus](http://arxiv.org/abs/2510.03160)|null|脊柱疾病影响全球6.19亿人，是主要致残原因，然而，AI辅助诊断仍受限于缺乏具备椎体层面感知能力的多模态数据集。脊柱疾病的临床决策需要在特定椎体层面，跨X射线、CT和MRI进行复杂的推理。然而，进展一直受制于缺乏可追溯、基于临床的指令数据以及标准化、脊柱专用基准。为此，我们推出了SpineMed，一个与执业脊柱外科医生共同设计的生态系统。其包含SpineMed-450k，这是首个专门为跨影像模态的椎体层面推理而设计的大规模数据集，包含超过45万条指令实例，以及SpineBench，一个基于临床的评估框架。SpineMed-450k数据源自多种途径，包括教科书、临床指南、开放数据集和约1000例去身份化的医院病例，并采用临床医生参与的循环流程，结合两阶段大语言模型生成方法（草稿和修订），以确保高质量、可追溯的数据，用于问答、多轮会诊和报告生成。SpineBench从临床关键维度评估模型，包括椎体层面识别、病理评估和手术规划。我们对SpineBench上近期几种先进的大型视觉语言模型（LVLMs）进行的综合评估，揭示了它们在细粒度、特定层面推理方面的系统性弱点。相比之下，我们在SpineMed-450k上微调的模型在所有任务上都表现出持续显著的改进。临床医生评估证实了我们模型输出的诊断清晰度和实用性。|
|**2025-10-03**|[Focal-plane wavefront sensing with moderately broadband light using a short multi-mode fiber](http://arxiv.org/abs/2510.03058)|null|我们提出了一种基于短多模光纤（MMF）的焦平面波前传感器（FPWFS），能够在适度宽带照明下工作。通过将畸变的焦平面场耦合到长度小于1厘米的MMF中，我们在近红外波长处实现了10纳米带宽范围内的模式干涉保持。产生的输出强度图样编码了瞳孔相位信息，从而可以通过神经网络实现波前恢复。我们的方法解决了偶次瞳孔相位像差固有的符号模糊性，并使用现成的计算硬件在毫秒级时间尺度上运行，适用于实时自适应光学。与传统瞳孔平面传感器不同，所提出的FPWFS与科学光束共享光路，通过实现波前和焦平面强度同时重建，消除了非共路像差。其简洁性、紧凑性、灵敏度和低成本使其成为下一代天文仪器的有吸引力的候选者。|
|**2025-10-03**|[TIT-Score: Evaluating Long-Prompt Based Text-to-Image Alignment via Text-to-Image-to-Text Consistency](http://arxiv.org/abs/2510.02987)|null|随着大型多模态模型（LMMs）的迅速发展，近期的文本到图像（T2I）模型能够生成高质量图像，并对短提示词表现出良好的对齐性。然而，它们在有效理解和遵循长而详细的提示词方面仍然面临挑战，表现出生成不一致的问题。为解决这一挑战，我们引入了LPG-Bench，一个用于评估基于长提示词的文本到图像生成的综合基准。LPG-Bench包含200个精心设计的提示词，平均长度超过250词，接近了几个领先商业模型的输入容量。利用这些提示词，我们从13个最先进的模型中生成了2,600张图像，并进一步进行了全面的人工排序标注。基于LPG-Bench，我们发现最先进的T2I对齐评估指标在基于长提示词的图像生成上与人类偏好表现出较差的一致性。为弥补这一差距，我们引入了一种新颖的零样本度量，称为TIT，它基于文本到图像再到文本的一致性，用于评估长提示词生成的图像。TIT的核心概念是通过直接比较原始提示词与LMM对生成图像产生的描述之间的一致性来量化T2I对齐性，它包括一个高效的基于分数的实现TIT-Score和一个基于大型语言模型（LLM）的实现TIT-Score-LLM。大量实验表明，与CLIP-score、LMM-score等相比，我们的框架与人类判断表现出卓越的一致性，其中TIT-Score-LLM在成对准确率上比最强的基线实现了7.31%的绝对提升。LPG-Bench和TIT方法共同为T2I模型的基准测试和发展提供了更深入的视角。所有资源都将公开可用。|
|**2025-10-03**|[Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights](http://arxiv.org/abs/2510.02922)|null|颈动脉粥样斑块疾病的可靠风险评估仍然是一个主要的临床挑战，因为它需要以对临床医生透明且可解释的方式整合多样化的临床和影像信息。本研究通过将超声成像 (USI) 与结构化的临床、人口统计学、实验室和蛋白质生物标志物数据相结合，探讨了最先进和近期的大型视觉-语言模型 (LVLM) 在多模态颈动脉斑块评估中的潜力。研究提出了一种通过访谈式问题序列模拟真实诊断场景的框架，并比较了一系列开源LVLM，包括通用型和医学专业调优模型。零样本实验表明，即使LVLM功能强大，也并非所有模型都能准确识别成像模态和解剖结构，同时所有模型在准确的风险分类方面表现不佳。为解决这一局限性，本研究使用低秩适应 (LoRA) 将LLaVa-NeXT-Vicuna适应到超声领域，从而显著改善了卒中风险分层。以文本形式整合多模态表格数据进一步提高了特异性和平衡准确度，与在相同数据集上训练的先前卷积神经网络 (CNN) 基线模型相比，取得了具有竞争力的性能。我们的研究结果突出了LVLM在基于超声的心血管风险预测中的潜力和局限性，强调了多模态整合、模型校准和领域适应对于临床转化的重要性。|
|**2025-10-03**|[SALSA-V: Shortcut-Augmented Long-form Synchronized Audio from Videos](http://arxiv.org/abs/2510.02916)|null|我们提出了SALSA-V，一个多模态视频到音频生成模型，能够从无声视频内容中合成高度同步、高保真的长格式音频。我们的方法引入了一个掩码扩散目标，从而实现音频条件下的生成以及无约束长度音频序列的无缝合成。此外，通过在训练过程中集成一个快捷损失，我们能够在最少八个采样步内快速生成高质量音频样本，为无需专门微调或重新训练的近实时应用铺平了道路。在定量评估和人类听觉研究中，我们证明SALSA-V在视听对齐和与视频内容同步方面显著优于现有最先进的方法。此外，我们在训练过程中使用随机掩码，使我们的模型能够匹配参考音频样本的频谱特征，拓宽了其在拟音生成和声音设计等专业音频合成任务中的适用性。|
|**2025-10-03**|[Don't Just Chase "Highlighted Tokens" in MLLMs: Revisiting Visual Holistic Context Retention](http://arxiv.org/abs/2510.02912)|**[link](https://github.com/obananas/HoloV)**|尽管多模态大型语言模型（MLLM）具有强大的能力，但由于它们依赖海量的视觉token，因此面临巨大的计算开销。最近的研究探索了token剪枝来缓解这一问题，这些方法通常利用文本-视觉交叉注意力或[\texttt{CLS}]注意力来评估并丢弃冗余的视觉token。在这项工作中，我们指出了这种注意力优先剪枝方法的关键局限性，即它们倾向于保留语义相似的token，从而在高剪枝率下导致性能显著下降。为此，我们提出了{HoloV}，这是一种简单而有效、即插即用的视觉token剪枝框架，用于高效推理。与以往的注意力优先方案不同，HoloV从整体角度重新思考了token保留。通过将剪枝预算自适应地分配到不同的空间裁剪区域，HoloV确保所保留的token能够捕获全局视觉上下文，而非孤立的显著特征。这种策略最大限度地减少了表示崩溃，并即使在激进的剪枝下也能保持任务相关信息。实验结果表明，与SOTA方法相比，我们的HoloV在各种任务、MLLM架构和剪枝率上都取得了卓越的性能。例如，搭载HoloV的LLaVA1.5在剪枝88.9%的视觉token后仍保留了95.8%的原始性能，实现了优越的效率-准确性权衡。|
|**2025-10-02**|[Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions](http://arxiv.org/abs/2510.02313)|null|模型能否区分勺子撞击硬木地板和地毯所发出的声音？日常物体交互会产生与所涉物体相关的独特声音。我们引入发声物体检测任务，以评估模型将这些声音与直接相关的物体关联起来的能力。受人类感知启发，我们的多模态物体感知框架从野外第一视角视频中学习。为了鼓励以物体为中心的方法，我们首先开发了一个自动化流程来计算所涉物体的分割掩码，以在训练期间引导模型的注意力转向交互中最具信息量的区域。一个槽注意力视觉编码器被用于进一步施加物体先验。我们在我们的新任务以及现有的多模态动作理解任务上展示了最先进的性能。|
|**2025-10-02**|[Inferring Dynamic Physical Properties from Video Foundation Models](http://arxiv.org/abs/2510.02311)|null|我们研究从视频中预测动态物理属性的任务。更具体地说，我们考虑需要时间信息才能推断的物理属性：弹跳物体的弹性、流动液体的粘度以及物体在表面滑动时的动摩擦力。为此，我们做出了以下贡献：(i) 我们为每种物理属性收集了一个新的视频数据集，该数据集包含合成训练和测试划分，以及用于真实世界评估的真实划分。(ii) 我们探索了从视频中推断物理属性的三种方法：(a) 一种预言机方法，我们使用经典计算机视觉技术提供本质上反映该属性的视觉线索；(b) 一种简单的读取机制，该机制利用视觉提示和可训练提示向量，在预训练的视频生成和自监督模型上进行交叉注意力；(c) 以及多模态大语言模型（MLLMs）的提示策略。(iii) 我们表明，以生成式或自监督方式训练的视频基础模型取得了相似的性能，尽管落后于预言机方法，并且多模态大语言模型（MLLMs）目前不如其他模型，尽管通过适当的提示可以提高其性能。|
|**2025-10-02**|[VideoNSA: Native Sparse Attention Scales Video Understanding](http://arxiv.org/abs/2510.02295)|**[link](https://github.com/Espere-1119-Song/VideoNSA)**|多模态语言模型中的视频理解仍受限于上下文长度：模型经常错过关键的过渡帧，并且难以在长时间尺度上保持连贯性。为解决此问题，我们将原生稀疏注意力（NSA）应用于视频-语言模型。我们的方法VideoNSA通过在一个包含21.6万视频指令的数据集上进行端到端训练，对Qwen2.5-VL进行了改进。我们采用了一种硬件感知的混合注意力方法，为文本保留密集注意力，同时为视频采用NSA。与令牌压缩和免训练稀疏基线相比，VideoNSA在长视频理解、时间推理和空间基准测试上取得了改进的性能。进一步的消融分析揭示了四个关键发现：(1) 可靠地扩展到128K个令牌；(2) 在固定预算下的最佳全局-局部注意力分配；(3) 任务相关的分支使用模式；以及 (4) 可学习的组合稀疏注意力有助于产生动态注意力汇聚点。|
|**2025-10-02**|[From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens](http://arxiv.org/abs/2510.02292)|null|我们推出VLM-Lens，这是一个旨在通过支持从开源VLM前向传播过程中任意层提取中间输出，从而实现对视觉-语言模型（VLM）进行系统性基准测试、分析和解释的工具包。VLM-Lens提供了一个统一的、可YAML配置的接口，该接口屏蔽了模型特有的复杂性，并支持跨越不同VLM的用户友好操作。它目前支持16种最先进的基础VLM及其30多种变体，并且无需改变核心逻辑即可扩展以适应新模型。该工具包易于与各种可解释性与分析方法集成。我们通过两个简单的分析实验展示了其用法，揭示了VLM隐藏表示在跨层和目标概念上的系统性差异。VLM-Lens作为一个开源项目发布，旨在加速社区在理解和改进VLM方面的努力。|
|**2025-10-02**|[MultiModal Action Conditioned Video Generation](http://arxiv.org/abs/2510.02287)|**[link](https://github.com/Aryia-Behroziuan/References)**|当前视频模型由于缺乏细粒度控制，无法胜任世界模型。通用家用机器人需要实时精细运动控制来处理精细任务和紧急情况。在这项工作中，我们引入了细粒度多模态动作来捕捉这种精确控制。我们考虑了本体感觉、动觉、力触觉和肌肉激活等感官。这种多模态感官自然地实现了细粒度交互，而这些交互难以通过文本条件生成模型进行模拟。为了有效模拟细粒度多感官动作，我们开发了一种特征学习范式，旨在对齐这些模态，同时保留每种模态提供的独特信息。我们进一步提出了一种正则化方案，以增强动作轨迹特征在表示复杂交互动态时的因果关系。实验表明，整合多模态感官可以提高模拟精度并减少时间漂移。广泛的消融研究和下游应用证明了我们工作的有效性和实用性。|
|**2025-10-02**|[VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL](http://arxiv.org/abs/2510.02282)|null|随着AI生成视频的快速发展，迫切需要有效的检测工具来缓解虚假信息和声誉损害等社会风险。除了准确分类外，检测模型提供可解释的解释以确保监管机构和最终用户的透明度也至关重要。为了应对这些挑战，我们推出了VidGuard-R1，这是首个通过使用群体相对策略优化（GRPO）微调多模态大语言模型（MLLM）的视频真实性检测器。我们的模型既能提供高精度判断，又能提供富有洞察力的推理。我们构建了一个包含14万真实和AI生成视频的挑战性数据集，这些视频由最先进的生成模型生成，并精心设计了生成过程以最大化鉴别难度。然后，我们使用GRPO和两个专门的奖励模型对Qwen-VL进行微调，这两个奖励模型分别针对时间伪影和生成复杂性。大量实验表明，VidGuard-R1在现有基准上实现了最先进的零样本性能，并通过额外训练将准确率提高到95%以上。案例研究进一步表明，VidGuard-R1能为其预测提供精确且可解释的理由。代码已公开，网址是https://VidGuard-R1.github.io。|
|**2025-10-02**|[microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification](http://arxiv.org/abs/2510.02270)|**[link](https://github.com/sathiiii/microCLIP)**|基于CLIP的视觉-语言模型（VLM）在细粒度图像分类中的无监督适应需要对微观局部线索的敏感性。尽管CLIP表现出强大的零样本迁移能力，但其对粗粒度全局特征的依赖限制了其在细粒度分类任务上的性能。先前的工作通过将大型语言模型（LLM）描述与CLIP的 $\texttt{[CLS]}$标记对齐来注入细粒度知识；然而，这种方法忽略了空间精度。我们提出了microCLIP，这是一个自训练框架，它利用细粒度线索联合优化CLIP的视觉和文本表示。其核心是轻量级TokenFusion模块中的显著性导向注意力池化（SOAP），该模块从图像块嵌入中构建一个显著性引导的$\texttt{[FG]}$标记，并将其与全局$\texttt{[CLS]}$ 标记融合以实现粗粒度-细粒度对齐。为了稳定适应过程，我们引入了一个双头LLM派生分类器：一个冻结分类器，通过多视图对齐为伪标签生成提供稳定的基于文本的先验；以及一个可学习分类器，该分类器从LLM描述初始化并使用TokenFusion进行微调。我们进一步开发了动态知识聚合，它将固定的LLM/CLIP先验与TokenFusion不断演进的逻辑值进行凸组合，以迭代地细化伪标签。这些组件共同作用，揭示了CLIP中潜在的细粒度信号，在13个细粒度基准测试中实现了平均2.90%的持续准确率提升，同时仅需轻量级适应。我们的代码可在https://github.com/sathiiii/microCLIP获取。|
|**2025-10-02**|[From Frames to Clips: Efficient Key Clip Selection for Long-Form Video Understanding](http://arxiv.org/abs/2510.02262)|null|视频大语言模型（VLMs）在各种视觉语言任务上取得了显著成果，然而，其实际应用受限于“大海捞针”问题：原始视频帧产生的大量视觉token会耗尽模型的上下文窗口。现有解决方案通过选择稀疏帧集来缓解此问题，从而减少token数量，但这种逐帧选择丢弃了重要的时间动态信息，导致对运动和事件连续性的推理次优。在这项工作中，我们系统地探讨了时间信息的影响，并证明将选择从孤立的关键帧扩展到关键片段（即短而时间连贯的片段）能够提高视频理解能力。为了在保持固定计算预算的同时适应片段更大的token占用，我们提出了一种自适应分辨率策略，该策略动态平衡空间分辨率和片段长度，确保每个视频的token数量恒定。在三个长视频基准测试上的实验表明，我们免训练的方法F2C在Video-MME、LongVideoBench和MLVU基准测试上分别优于均匀采样高达8.1%、5.6%和10.3%。这些结果强调了在帧选择中保持时间连贯性的重要性，并为将视频大语言模型扩展到真实世界的视频理解应用提供了一条实用的途径。项目网页可在https://guangyusun.com/f2c获取。|
|**2025-10-02**|[DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing](http://arxiv.org/abs/2510.02253)|null|拖拽式图像编辑长期以来一直存在目标区域失真的问题，这主要是因为早期基础模型（如Stable Diffusion）的先验知识不足以将优化的潜在变量投射回自然图像流形上。随着从基于UNet的DDPMs转向具有流匹配的更具可扩展性的DiT（例如SD3.5、FLUX），生成式先验已显著增强，从而推动了各种编辑任务的进展。然而，拖拽式编辑尚未从这些更强的先验中受益。本工作提出了首个有效利用FLUX丰富先验进行拖拽式编辑的框架，命名为DragFlow，并取得了超越基线的显著提升。我们首先发现，直接将基于点的拖拽编辑应用于DiT效果不佳：与UNet高度压缩的特征不同，DiT特征的结构不足以提供可靠的点对点运动监督指导。为了克服这一局限性，DragFlow引入了一种基于区域的编辑范式，其中仿射变换能够实现更丰富、更一致的特征监督。此外，我们集成了预训练的开放域个性化适配器（例如IP-Adapter）以增强主体一致性，同时通过梯度掩码硬约束保留背景保真度。多模态大语言模型（MLLMs）被进一步用于解决任务歧义。为了进行评估，我们构建了一个新颖的基于区域的拖拽基准（ReD Bench），其特点是具有区域级拖拽指令。在DragBench-DR和ReD Bench上的大量实验表明，DragFlow超越了基于点和基于区域的基线，在拖拽式图像编辑领域树立了新的最先进水平。代码和数据集将在发表后公开。|
|**2025-10-02**|[RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning](http://arxiv.org/abs/2510.02240)|**[link](https://github.com/fscdc/RewardMap)**|细粒度视觉推理仍然是多模态大语言模型（MLLM）的核心挑战。最近引入的ReasonMap数据集通过展示即使是先进的MLLM也难以在交通地图等结构化且信息丰富的场景中进行空间推理，凸显了这一差距，这是一项具有明确实践和科学重要性的任务。然而，在这种任务上，标准强化学习（RL）受到稀疏奖励和不稳定优化的阻碍。为了解决这个问题，我们首先构建了ReasonMap-Plus，这是一个通过视觉问答（VQA）任务引入密集奖励信号的扩展数据集，从而能够有效冷启动细粒度视觉理解技能的训练。接着，我们提出了RewardMap，一个旨在提高MLLM视觉理解和推理能力的多阶段RL框架。RewardMap包含两项关键设计。首先，我们引入了一种难度感知奖励设计，该设计整合了细节奖励，直接解决了稀疏奖励问题，同时提供了更丰富的监督。其次，我们提出了一种多阶段RL方案，该方案将训练从简单感知引导至复杂推理任务，提供了一种比传统监督微调（SFT）更有效的冷启动策略。在ReasonMap和ReasonMap-Plus上的实验表明，RewardMap的每个组件都有助于持续的性能提升，而它们的组合产生了最佳结果。此外，使用RewardMap训练的模型在涵盖空间推理、细粒度视觉推理以及超越交通地图的通用任务的6个基准测试中平均提高了3.47%，这强调了其增强的视觉理解和推理能力。|
|**2025-09-30**|[MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation](http://arxiv.org/abs/2509.26642)|null|视觉-语言-动作模型（VLA）通过继承视觉-语言模型（VLM）并学习动作生成，在机器人操作任务中展现了泛化能力。大多数VLA模型侧重于解释视觉和语言以生成动作，而机器人必须在空间-物理世界中感知和交互。这一差距凸显了对机器人特有多感官信息进行全面理解的需求，这对于实现复杂且富接触的控制至关重要。为此，我们引入了一种多感官语言-动作（MLA）模型，该模型协同感知异构感官模态并预测未来的多感官目标，以促进物理世界建模。具体而言，为了增强感知表示，我们提出了一种无编码器的多模态对齐方案，该方案创新性地将大型语言模型本身重新用作感知模块，通过位置对应将2D图像、3D点云和触觉标记对齐，从而直接解释多模态线索。为了进一步增强MLA对物理动力学的理解，我们设计了一种未来多感官生成后训练策略，该策略使MLA能够推理语义、几何和交互信息，为动作生成提供更稳健的条件。在评估中，MLA模型在复杂、富接触的真实世界任务中分别以12%和24%的幅度超越了先前最先进的2D和3D VLA方法，同时还展示了对未见配置的改进泛化能力。项目网站：https://sites.google.com/view/open-mla|
|**2025-09-30**|[Query-Kontext: An Unified Multimodal Model for Image Generation and Editing](http://arxiv.org/abs/2509.26641)|null|统一多模态模型 (UMMs) 在文本到图像生成 (T2I) 和编辑 (TI2I) 方面表现出卓越的性能，无论是作为将强大的视觉-语言模型 (VLM) 与基于扩散的生成器耦合的组装式统一框架，还是作为理解和生成模态早期融合的朴素统一多模态模型。我们认为，在当前的统一框架中，多模态生成推理的关键能力（包括指令理解、接地以及用于身份保持和忠实重建的图像引用）与高保真合成本质上纠缠在一起。在这项工作中，我们引入了 Query-Kontext，这是一种新颖的方法，它通过由从多模态输入中编码的语义线索和粗粒度图像条件组成的多模态“kontext”来连接 VLM 和扩散模型。这种设计将多模态生成推理的复杂能力委托给强大的 VLM，同时保留扩散模型用于高质量视觉合成的作用。为此，我们提出了一种三阶段渐进式训练策略。首先，我们通过多模态 kontext token 将 VLM 连接到一个轻量级扩散头部，以释放 VLM 的生成推理能力。其次，我们将此头部扩展到一个大型预训练扩散模型，以增强视觉细节和真实感。最后，我们引入一个低级图像编码器以提高图像保真度，并在下游任务上执行指令微调。此外，我们构建了一个全面的数据管道，整合了真实、合成和开源数据集，涵盖了各种多模态参考到图像场景，包括图像生成、指令驱动编辑、定制生成和多主体组合。实验表明，我们的方法与强大的统一基线相当，甚至在某些情况下优于任务特定的最先进方法。|
|**2025-09-30**|[AccidentBench: Benchmarking Multimodal Understanding and Reasoning in Vehicle Accidents and Beyond](http://arxiv.org/abs/2509.26636)|**[link](https://github.com/SafeRL-Lab/AccidentBench)**|多模态模型的快速发展需要能够严格评估其在安全关键、动态真实世界环境中理解和推理能力的基准。我们提出了AccidentBench，一个大规模基准，它结合了车辆事故场景与超越领域（空中和水中的安全关键设置），这些设置强调空间和时间推理（例如，导航、方向、多车辆运动）。该基准包含大约2000个视频和超过19000个人工标注的问答对，涵盖多种视频长度（短/中/长）和难度级别（易/中/难）。任务系统地探究核心能力：时间、空间和意图的理解与推理。通过统一以事故为中心的交通场景与更广泛的空中和水中的安全关键场景，AccidentBench提供了一个全面、物理基础的测试平台，用于评估模型在真实世界变异性下的表现。对最先进模型（例如Gemini-2.5 Pro和GPT-5）的评估表明，即使是最强的模型也仅在最难的任务和最长的视频上达到约18%的准确率，揭示了在真实世界的时间、空间和意图推理方面存在的巨大差距。AccidentBench旨在揭示这些关键差距，并推动多模态模型的发展，使其更安全、更鲁棒，并更好地应对真实世界的安全关键挑战。代码和数据集可在以下链接获取：https://github.com/SafeRL-Lab/AccidentBench|
|**2025-09-30**|[Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training](http://arxiv.org/abs/2509.26625)|null|大语言模型（LLM）尽管仅通过文本进行训练，却出人意料地发展出丰富的视觉先验，这些先验使得潜在的视觉能力得以解锁，仅需相对少量多模态数据即可用于视觉任务，在某些情况下甚至无需见过图像就能执行视觉任务。通过系统分析，我们揭示了视觉先验——即在语言预训练期间获得的关于视觉世界的隐式、涌现知识——由可分离的感知先验和推理先验组成，它们具有独特的扩展趋势和来源。我们发现大语言模型潜在的视觉推理能力主要通过在以推理为中心的数据（如代码、数学、学术文本）上进行预训练而发展，并逐步扩展。这种从语言预训练中获得的推理先验是可迁移的，并且普遍适用于视觉推理。相比之下，感知先验更广泛地从通用语料库中涌现，且感知能力对视觉编码器和视觉指令微调数据更为敏感。同时，描述视觉世界的文本也至关重要，尽管其性能影响会迅速饱和。借鉴这些见解，我们提出了一种以数据为中心的方法来预训练具有视觉感知能力的大语言模型，并在1万亿（1T）token规模的预训练中进行了验证。我们的发现基于超过100项消耗50万GPU小时的对照实验，涵盖了多模态大语言模型（MLLM）构建的完整流程——从大语言模型预训练到视觉对齐和监督式多模态微调——跨越五种模型规模、多种数据类别和混合方式以及多种适应性设置。除了我们的主要发现，我们还提出并研究了若干假设，并引入了多级存在基准（MLE-Bench）。综上所述，这项工作提供了一种从语言预训练中有意培养视觉先验的新方法，为下一代多模态大语言模型铺平了道路。|
|**2025-09-30**|[Video Object Segmentation-Aware Audio Generation](http://arxiv.org/abs/2509.26604)|**[link](https://github.com/ilpoviertola/SAGANet)**|现有的多模态音频生成模型通常缺乏精确的用户控制，这限制了它们在专业拟音工作流程中的适用性。具体而言，这些模型侧重于整个视频，没有提供精确的方法来优先处理场景中的特定对象，从而生成不必要的背景声音或将焦点放在错误的对象上。为了解决这一空白，我们引入了新颖的视频对象分割感知音频生成任务，该任务明确地将声音合成条件设定在对象级别的分割图上。我们提出了SAGANet，这是一个新的多模态生成模型，它通过利用视觉分割掩码以及视频和文本线索，实现了可控的音频生成。我们的模型为用户提供了对音频生成的细粒度且视觉局部化的控制。为了支持这项任务并进一步研究分割感知的拟音，我们提出了Segmented Music Solos，这是一个包含分割信息的乐器演奏视频基准数据集。我们的方法相比当前最先进的方法显示出显著改进，并为可控、高保真的拟音合成设定了新标准。代码、示例和Segmented Music Solos可在https://saganet.notion.site获取。|
|**2025-09-30**|[Exploring Large Language Model as an Interactive Sports Coach: Lessons from a Single-Subject Half Marathon Preparation](http://arxiv.org/abs/2509.26593)|null|大型语言模型（LLMs）正在成为日常助手，但它们作为长期虚拟教练的角色尚未得到充分探索。这项为期两个月的单受试者案例研究记录了LLM指导的半程马拉松准备过程（2025年7月至9月）。通过基于文本的交互和消费者应用日志，LLM充当了规划者、解释者和偶尔的激励者。表现从以每公里7分54秒的速度维持2公里提高到以每公里6分30秒的速度完成21.1公里，并在步频、配速心率耦合和效率指数趋势方面有所提高。尽管缺乏对照组限制了因果归因，结果仍表明取得了安全且可衡量的进展。同时，也存在明显的不足，包括没有实时传感器集成、仅限文本反馈、用户主动发起的激励支持以及有限的个性化或安全防护措施。我们提出了下一代系统的设计要求，包括带有明确防护措施的持久运动员模型、设备上的多模态传感、音频、触觉、视觉反馈、主动激励支架以及保护隐私的个性化。这项研究提供了扎实的证据，并为LLM从回顾性建议者发展为闭环指导伙伴提供了一个设计议程。|
|**2025-09-30**|[OceanGym: A Benchmark Environment for Underwater Embodied Agents](http://arxiv.org/abs/2509.26536)|**[link](https://github.com/OceanGPT/OceanGym)**|我们引入OceanGym，这是首个针对海洋水下具身智能体的综合性基准，旨在推动人工智能在最具挑战性的真实世界环境之一中发展。与陆地或空中领域不同，水下环境带来了极端的感知和决策挑战，包括低能见度、动态洋流，使得智能体的有效部署异常困难。OceanGym包含八个真实的任务领域和一个由多模态大语言模型（MLLMs）驱动的统一智能体框架，该框架集成了感知、记忆和序贯决策。智能体需要在这些严苛条件下理解光学和声纳数据，自主探索复杂环境，并完成长周期目标。大量实验揭示了最先进的MLLM驱动智能体与人类专家之间存在的显著差距，凸显了海洋水下环境中感知、规划和适应性的持续困难。通过提供一个高保真、严格设计的平台，OceanGym为开发鲁棒的具身人工智能并将其能力迁移到真实的自主海洋水下航行器建立了测试平台，标志着向能够在地球上最后未探索的边疆之一中运行的智能智能体迈出了决定性一步。代码和数据可在https://github.com/OceanGPT/OceanGym获取。|
|**2025-09-30**|[STaR-Attack: A Spatio-Temporal and Narrative Reasoning Attack Framework for Unified Multimodal Understanding and Generation Models](http://arxiv.org/abs/2509.26473)|null|统一多模态理解与生成模型（UMM）在理解和生成任务中均展现出卓越的能力。然而，我们发现UMM中生成与理解耦合产生了一个漏洞。攻击者可以利用生成功能制作一个信息丰富的对抗性图像，然后利用理解功能在单次传递中吸收该图像，我们称之为跨模态生成注入（CMGI）。当前针对恶意指令的攻击方法通常局限于单一模态，并且依赖于带有语义漂移的提示重写，导致UMM的独特漏洞尚未被探索。我们提出了STaR-Attack，这是首个利用UMM独特安全弱点且不产生语义漂移的多轮越狱攻击框架。具体来说，我们的方法在时空上下文中定义了一个与目标查询强相关的恶意事件。STaR-Attack利用三幕叙事理论，生成事件前和事件后场景，同时将恶意事件隐藏为高潮。执行攻击策略时，最初两轮利用UMM的生成能力为这些场景生成图像。随后，通过利用其理解能力引入了一个基于图像的问题猜测和回答游戏。STaR-Attack将原始恶意问题嵌入到良性候选项中，迫使模型根据叙事上下文选择并回答最相关的问题。大量实验表明，STaR-Attack持续超越现有方法，在Gemini-2.0-Flash上攻击成功率（ASR）高达93.06%，并超过了最强的现有基线FlipAttack。我们的工作揭示了一个关键但尚未充分开发的漏洞，并强调了UMM中安全对齐的必要性。|
|**2025-09-30**|[PANDA: Towards Generalist Video Anomaly Detection via Agentic AI Engineer](http://arxiv.org/abs/2509.26386)|**[link](https://github.com/showlab/PANDA)**|视频异常检测（VAD）是一项关键但极具挑战性的任务，原因在于真实世界场景的复杂性和多样性。先前方法通常依赖于领域特定的训练数据和手动调整，在应用于新场景和未曾见过的异常类型时，导致高昂的人力成本和有限的泛化能力。因此，我们旨在实现通用型VAD，即无需训练数据或人工干预即可自动处理任何场景和任何异常类型。在这项工作中，我们提出了PANDA，一种基于多模态大语言模型（MLLMs）的智能体AI工程师。具体而言，我们通过全面设计四项关键能力来构建PANDA：(1) 自适应场景感知策略规划，(2) 目标驱动的启发式推理，(3) 工具增强的自我反思，以及(4) 自我改进的记忆链。具体来说，我们开发了一种自适应场景感知RAG（检索增强生成）机制，使PANDA能够检索异常特异性知识用于异常检测策略规划。接着，我们引入了一种潜在异常引导的启发式提示策略以提高推理精度。此外，PANDA采用了一种渐进式反思机制，结合一套上下文感知工具，以在复杂场景中迭代地优化决策。最后，一种记忆链机制使PANDA能够利用历史经验以持续改进性能。大量实验表明，PANDA在多场景、开放集和复杂场景设置下无需训练和人工干预即可达到最先进的性能，验证了其通用且鲁棒的异常检测能力。代码已发布于https://github.com/showlab/PANDA。|
|**2025-09-30**|[MR $^2$-Bench: Going Beyond Matching to Reasoning in Multimodal Retrieval](http://arxiv.org/abs/2509.26378)|null|多模态检索正成为现代AI应用的关键组成部分，然而其评估却滞后于更真实和更具挑战性场景的需求。现有基准主要探究浅层语义对应（例如，物体-文本匹配），未能评估捕捉视觉和文本信息之间复杂关系所需的更深层次推理。为解决这一差距，我们引入了MR$^2$-Bench，一个用于多模态检索的推理密集型基准。MR$^2$-Bench具有以下关键价值：1) 所有任务均由推理驱动，超越了浅层匹配，有效评估模型进行逻辑、空间和因果推理的能力；2) 它包含多样化的多模态数据，例如自然图像、图表和视觉谜题，从而实现对不同内容类型的全面评估；3) 它支持包含多张图像的复杂查询和文档，并涵盖多样化的检索场景，更准确地反映现实世界应用。我们的基准包含1,309个精心策划的查询，来源于手动收集和标注，或对公开数据集的筛选整合。尽管在现有基准上取得了良好结果，但当前最先进的模型在MR$^2$-Bench上仍然表现不佳：例如，领先的Seed1.6-Embedding模型在MMEB上达到77.78的Recall@1，但在MR$^2$ -Bench上仅为9.91。这一巨大的性能差距凸显了我们的基准带来的更大挑战，以及推理密集型多模态检索领域进一步发展的迫切需求。数据集和评估代码将公开提供在https://github.com/VectorSpaceLab/MR2-Bench。|
|**2025-09-26**|[See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation](http://arxiv.org/abs/2509.22653)|**[link](https://github.com/Hu-chih-yao/see-point-fly)**|我们提出了视、指、飞 (SPF) 框架，这是一个基于视觉-语言模型 (VLM) 的免训练航空视觉-语言导航 (AVLN) 框架。SPF 能够基于任何形式的自由指令在任何类型的环境中导航到任何目标。与将动作预测视为文本生成任务的现有基于 VLM 的方法不同，我们的关键见解是将用于 AVLN 的动作预测视为一个 2D 空间定位任务。SPF 利用 VLM 将模糊的语言指令分解为在输入图像上的 2D 路点的迭代标注。结合预测的行进距离，SPF 将预测的 2D 路点转换为 3D 位移向量，作为无人机 (UAV) 的动作指令。此外，SPF 还自适应地调整行进距离，以促进更高效的导航。值得注意的是，SPF 以闭环控制方式执行导航，使无人机能够在动态环境中跟踪动态目标。SPF 在 DRL 仿真基准中创造了新的技术水平，其性能比之前最好的方法高出 63% 的绝对优势。在广泛的真实世界评估中，SPF 大幅超越了强大的基线方法。我们还进行了全面的消融研究，以突出我们设计选择的有效性。最后，SPF 对不同的 VLM 展现出显著的泛化能力。项目页面：https://spf-web.pages.dev|
|**2025-09-26**|[VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing](http://arxiv.org/abs/2509.22651)|null|大型语言模型和多模态系统日益增强的能力激发了人们对语音优先AI助手的兴趣，然而现有基准不足以评估这些系统的全部能力。我们引入了VoiceAssistant-Eval，这是一个综合基准，旨在评估AI助手在听觉、口语和视觉方面的能力。VoiceAssistant-Eval包含10,497个精选示例，涵盖13个任务类别。这些任务包括用于听觉的自然声音、音乐和口语对话；用于口语的多轮对话、角色扮演模仿和各种场景；以及用于视觉的高度异构图像。为了展示其效用，我们评估了21个开源模型和GPT-4o-Audio，测量了响应内容和语音的质量及其一致性。结果揭示了三个关键发现：(1) 专有模型并非普遍优于开源模型；(2) 大多数模型擅长口语任务但在音频理解方面滞后；(3) 精心设计的小型模型可以与大得多的模型相媲美。值得注意的是，中型Step-Audio-2-mini (7B) 的听觉准确率是LLaMA-Omni2-32B-Bilingual的两倍多。然而，挑战依然存在：多模态（音频加视觉）输入和角色扮演语音模仿任务对当前模型来说仍然困难，并且在鲁棒性和安全对齐方面仍然存在显著差距。VoiceAssistant-Eval识别了这些差距，并为评估和指导下一代AI助手的开发建立了严格的框架。代码和数据将发布在https://mathllm.github.io/VoiceAssistantEval/。|
|**2025-09-26**|[Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs](http://arxiv.org/abs/2509.22646)|null|人类能否识别AI生成（伪造）的视频并提供有根据的理由？尽管视频生成模型已快速发展，但一个关键维度——人类能否在生成的视频中检测到深度伪造痕迹，即揭示视频为机器生成的时空有据的视觉伪影——却在很大程度上被忽视了。我们引入了DeeptraceReward，首个细粒度、时空感知基准，用于标注人类感知的伪造痕迹以作为视频生成奖励。该数据集包含4.3K条详细标注，涵盖3.3K个高质量生成视频。每条标注都提供了自然语言解释，精确指出包含感知痕迹的边界框区域，并标记了精确的开始和结束时间戳。我们将这些标注整合为9个主要类别的深度伪造痕迹，这些痕迹使人类将视频识别为AI生成，并训练多模态语言模型（LMs）作为奖励模型以模仿人类的判断和定位。在DeeptraceReward上，我们的7B奖励模型在伪造线索识别、定位和解释方面平均优于GPT-5 34.7%。有趣的是，我们观察到一个一致的难度梯度：二元真伪分类比细粒度深度伪造痕迹检测容易得多；在后者中，性能从自然语言解释（最容易）到空间定位，再到时间标注（最难）逐渐下降。通过突出人类感知的深度伪造痕迹，DeeptraceReward提供了一个严谨的测试平台和训练信号，用于实现具有社会意识和值得信赖的视频生成。|
|**2025-09-26**|[WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning](http://arxiv.org/abs/2509.22644)|null|由大型语言模型（LLM）驱动的智能体系统在仓库级别代码生成任务上表现出了令人印象深刻的性能。然而，对于严重依赖视觉效果和用户交互反馈的网站代码库生成等任务，当前的代码智能体仅依赖简单的代码执行进行反馈和验证。这种方法未能捕捉生成代码的实际质量。在本文中，我们提出了WebGen-Agent，这是一种新颖的网站生成智能体，它利用全面多层次的视觉反馈来迭代生成和完善网站代码库。视觉语言模型（VLM）会生成关于网站截图和GUI智能体测试的详细且富有表现力的文本描述和建议，以及量化其质量的分数。截图和GUI智能体分数进一步与回溯和择优机制相结合，从而提升了智能体的性能。利用WebGen-Agent工作流中固有的准确视觉分数，我们进一步引入了带有截图和GUI智能体反馈的Step-GRPO，以提高LLM作为WebGen-Agent推理引擎的能力。通过将每一步的截图和GUI智能体分数用作Step-GRPO中的奖励，我们提供了一个密集且可靠的过程监督信号，有效地提高了模型的网站生成能力。在WebGen-Bench数据集上，WebGen-Agent将Claude-3.5-Sonnet的准确率从26.4%提高到51.9%，并将其外观得分从3.0提高到3.9，超越了之前最先进的智能体系统。此外，我们的Step-GRPO训练方法将Qwen2.5-Coder-7B-Instruct的准确率从38.9%提高到45.4%，并将其外观得分从3.4提高到3.7。|
|**2025-09-26**|[LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision](http://arxiv.org/abs/2509.22631)|null|高质量、领域专用数据集的构建是部署鲁棒视觉系统的主要瓶颈，在探索庞大、未标注的数据湖时，需要在数据质量、多样性和成本之间进行复杂的权衡。我们引入了Labeling Copilot，这是首个用于计算机视觉的数据策划深度研究智能体。一个由大型多模态语言模型驱动的中央编排智能体，利用多步推理执行涵盖三项核心能力的专用工具：(1) 校准发现从大型数据存储库中获取相关的、分布内的数据；(2) 可控合成通过鲁棒过滤为稀有场景生成新数据；(3) 共识标注通过结合非极大值抑制和投票的新颖共识机制编排多个基础模型，生成准确的标签。我们的大规模验证证明了Labeling Copilot各组件的有效性。共识标注模块在目标发现方面表现出色：在密集的COCO数据集上，它平均每图像生成14.2个候选提议——几乎是7.4个真实目标的两倍——最终标注mAP达到37.1%。在网络规模的Open Images数据集上，它解决了极端的类别不平衡问题，发现了903个新的边界框类别，将其能力扩展到总计超过1500个类别。同时，我们的校准发现工具在千万级样本规模上进行测试，采用一种主动学习策略，在样本效率相同的情况下，计算效率比替代方案高出40倍。这些实验验证了结合优化、可扩展工具的智能体工作流为策划工业规模数据集提供了坚实的基础。|
|**2025-09-26**|[Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting](http://arxiv.org/abs/2509.22615)|null|现代视觉语言流水线由在大规模图像文本语料库上训练的RGB视觉编码器驱动。尽管这些流水线实现了令人印象深刻的零样本能力和强大的跨任务迁移，但它们仍然继承了像素域的两种结构性低效：(i) 从边缘设备向云端传输密集RGB图像耗能且成本高昂，以及 (ii) 基于图像块的标记化导致序列长度爆炸式增长，给注意力预算和上下文限制带来压力。我们探索2D高斯溅射(2DGS)作为一种用于对齐的替代视觉基底：它是一种紧凑、空间自适应的表示，通过一组彩色各向异性高斯函数来参数化图像。我们开发了一个采用结构化初始化、亮度感知剪枝和批处理CUDA核函数的可扩展2DGS流水线，相比于之前的实现，实现了超过90倍的拟合速度提升和大约97%的GPU利用率。我们通过重用一个冻结的基于RGB的Transformer主干网络，配合一个轻量级溅射感知输入分支和一个Perceiver重采样器，将对比语言图像预训练(CLIP)进一步适应到2DGS，仅训练了总参数的大约7%。在大型DataComp子集上，GS编码器取得了有意义的ImageNet-1K零样本性能，同时相对于像素压缩输入3到20倍。尽管目前准确性落后于RGB编码器，但我们的结果将2DGS确立为一种可行的多模态基底，明确了架构瓶颈，并为未来在边缘云学习中实现既具有强大语义能力又传输高效的表示开辟了一条道路。|
|**2025-09-26**|[MINT-RVAE: Multi-Cues Intention Prediction of Human-Robot Interaction using Human Pose and Emotion Information from RGB-only Camera Data](http://arxiv.org/abs/2509.22573)|null|高效检测人类与普适机器人交互的意图对于有效的人机交互（HRI）和协作至关重要。过去十年中，深度学习在该领域获得了广泛关注，大多数现有方法依赖多模态输入，例如RGB结合深度（RGB-D），将感知数据的时间序列窗口分类为交互或非交互。与此不同的是，我们提出了一种新颖的仅基于RGB的管道，用于以帧级精度预测人类交互意图，从而实现更快的机器人响应和更高的服务质量。意图预测的一个关键挑战是真实世界HRI数据集中固有的类别不平衡，这会阻碍模型的训练和泛化能力。为解决这个问题，我们引入了MINT-RVAE，一种合成序列生成方法，以及新的损失函数和训练策略，从而增强了模型在样本外数据上的泛化能力。我们的方法实现了最先进的性能（AUROC: 0.95），优于现有工作（AUROC: 0.90-0.912），同时仅需要RGB输入并支持精确的帧起始预测。最后，为了支持未来的研究，我们公开了我们的新数据集，其中包含人类交互意图的帧级标注。|
|**2025-09-26**|[UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration](http://arxiv.org/abs/2509.22570)|null|大型多模态模型（LMMs）和云端AI代理的快速进展正在将人机协作转变为双向、多模态的交互。然而，现有编解码器仍针对单模态、单向通信进行优化，导致在传统压缩-传输-重建流水线中反复降质。为解决这一局限性，我们提出了UniMIC，一个统一的基于token的多模态交互编码框架，它连接了边缘设备和云端AI代理。UniMIC不传输原始像素或纯文本，而是采用紧凑的token化表示作为通信介质，实现了高效的低比特率传输，同时保持与LMM的兼容性。为进一步增强压缩，轻量级基于Transformer的熵模型具有场景特定的设计——通用、掩码和文本条件——有效地最小化了token间的冗余。在文本到图像生成、文本引导的图像修复、图像扩展和视觉问答等任务上的大量实验表明，UniMIC实现了显著的比特率节省，并且在超低比特率（<0.05bpp）下仍保持鲁棒性，而不影响下游任务性能。这些结果确立了UniMIC作为下一代多模态交互通信的一种实用且前瞻性的范式。|
|**2025-09-26**|[JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation](http://arxiv.org/abs/2509.22548)|**[link](https://github.com/MIV-XJTU/JanusVLN)**|视觉语言导航（VLN）要求具身智能体在自然语言指令和连续视频流的引导下，在未见环境中进行导航。VLN的最新进展得益于多模态大语言模型（MLLM）强大的语义理解能力。然而，这些方法通常依赖显式语义记忆，例如构建文本认知地图或存储历史视觉帧。这类方法存在空间信息损失、计算冗余和内存膨胀等问题，阻碍了高效导航。受人类导航中隐式场景表示的启发，类似于左脑的语义理解和右脑的空间认知，我们提出了JanusVLN，一种新颖的VLN框架，其特点是采用双隐式神经记忆，将空间几何记忆和视觉语义记忆建模为独立、紧凑且固定大小的神经表示。该框架首先扩展了MLLM，以融入来自空间几何编码器的3D先验知识，从而增强了仅基于RGB输入的模型的空间推理能力。接着，将来自空间几何编码器和视觉语义编码器的历史键值缓存构建成双隐式记忆。通过仅保留初始窗口和滑动窗口中标记的键值对，避免了冗余计算，实现了高效的增量更新。大量实验表明，JanusVLN优于20多种最新方法，取得了最先进的性能。例如，与使用多种数据类型作为输入的方法相比，成功率提高了10.5-35.5；与使用更多RGB训练数据的方法相比，成功率提高了3.6-10.8。这表明所提出的双隐式神经记忆作为一种新颖范式，为未来的VLN研究探索了有前景的新方向。我们的项目页面：https://miv-xjtu.github.io/JanusVLN.github.io/。|
|**2025-09-26**|[Color Names in Vision-Language Models](http://arxiv.org/abs/2509.22524)|null|颜色是人类视觉感知的一个基本维度，也是交流物体和场景的主要方式。随着视觉语言模型（VLMs）日益普及，了解它们是否像人类一样命名颜色对于有效的人机交互至关重要。我们首次对VLMs的颜色命名能力进行了系统性评估，通过使用957个颜色样本在五个代表性模型上复现了经典的颜色命名方法。我们的结果表明，尽管VLMs在经典研究中的原型颜色上取得了高准确度，但在扩展的、非原型颜色集上的性能显著下降。我们识别出在所有模型中一致出现的21个常用颜色词，揭示了两种不同的方法：约束型模型主要使用基本术语，而扩展型模型则采用系统性明度修饰符。对九种语言的跨语言分析表明存在严重的训练不平衡，偏向英语和汉语，其中色相是颜色命名决策的主要驱动因素。最后，消融研究揭示，语言模型架构显著影响颜色命名，且独立于视觉处理能力。|
|**2025-09-25**|[Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization](http://arxiv.org/abs/2509.21301)|null|本文提出 Nova，一个实时调度框架，用于在单张 GPU 上服务代理式视觉语言模型 (VLM)，并在平衡单请求延迟和整体请求处理吞吐量方面表现出色。我们的设计首先通过利用 VLM 在执行过程中异构的资源需求，并引入弹性 GPU 空间分区到视觉编码、LLM 预填充和 LLM 解码阶段之间，实现有效的流水线化，从而最大化利用计算和内存资源。在此基础上，我们引入了一种实时调度算法，该算法根据对延迟-吞吐量权衡的帕累托最优分析，自适应校准各阶段的资源分配，使系统在动态请求负载下保持响应能力和资源效率。为了进一步缓解 GPU 内存压力，我们为视觉编码器设计了一种轻量级权重卸载策略，该策略在最小化内存开销的同时保持推理效率。在合成和真实世界代理工作负载上的广泛评估表明，Nova 始终优于最先进的基线，将最大延迟提高了高达 23.3%，同时保持了有竞争力的吞吐量。|
|**2025-09-25**|[DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding](http://arxiv.org/abs/2509.21287)|null|近期的视觉-语言模型擅长大规模图像-文本对齐，但往往忽视语言的组合结构，导致在依赖词序和谓词-论元结构的任务上表现不佳。我们引入了DisCoCLIP，一个多模态编码器，它结合了冻结的CLIP视觉Transformer和一个新颖的张量网络文本编码器，该编码器显式编码句法结构。句子通过组合范畴语法解析器进行解析，以生成分布词张量，这些张量的收缩反映了句子的语法推导。为了保持模型高效，高阶张量通过张量分解进行因式分解，将参数数量从数千万减少到不到一百万。DisCoCLIP经过自监督对比损失的端到端训练，显著提高了对动词语义和词序的敏感性：它将CLIP在SVO-Probes上的动词准确率从77.6%提高到82.4%，将ARO归因和关系分数分别提高了9%以上和4%以上，并在新引入的SVO-Swap基准测试中达到了93.7%。这些结果表明，通过张量网络嵌入显式语言结构能够产生可解释、参数高效的表示，从而大幅提高视觉-语言任务中的组合推理能力。|
|**2025-09-25**|[MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources](http://arxiv.org/abs/2509.21268)|**[link](https://github.com/LengSicong/MMR1)**|大型多模态推理模型取得了快速进展，但其发展受到两个主要限制的制约：缺乏开放的、大规模的、高质量的长链式思考（CoT）数据，以及强化学习（RL）算法在后训练中的不稳定性。群体相对策略优化（GRPO）作为RL微调的标准框架，在奖励方差较低时容易出现梯度消失，这会削弱优化信号并损害收敛性。本工作做出三项贡献：(1) 我们提出了方差感知采样（VAS），这是一种由方差促进分数（VPS）指导的数据选择策略，它结合了结果方差和轨迹多样性，以促进奖励方差并稳定策略优化。(2) 我们发布了大规模的、精心策划的资源，包含约160万条长CoT冷启动数据和约1.5万对RL问答数据，旨在确保质量、难度和多样性，以及一个完全可复现的端到端训练代码库。(3) 我们开源了一系列多尺度多模态推理模型，为社区建立了标准化基线。在数学推理基准上的实验证明了精心策划的数据和所提出的VAS的有效性。全面的消融研究和分析提供了对每个组件贡献的进一步见解。此外，我们在理论上证实奖励方差是期望策略梯度幅度的下界，而VAS作为实现这一保证的实用机制。我们的代码、数据和检查点可在https://github.com/LengSicong/MMR1获取。|
|**2025-09-25**|[Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](http://arxiv.org/abs/2509.21262)|**[link](https://github.com/nagadit/Un-Doubling-Diffusion)**|同形异义词是拼写相同但含义不同的词语，对许多生成模型构成了挑战。当提示中出现同形异义词时，扩散模型可能会同时生成该词的多个含义，这被称为同形异义词重复现象。这个问题因英语中心偏见而变得更加复杂，这种偏见在文本到图像模型流水线之前包含了一个额外的翻译步骤。结果是，即使在原始语言中不是同形异义词的词语，在翻译成英语后也可能变成同形异义词并失去其含义。在本文中，我们介绍了一种测量重复率的方法，并使用利用视觉-语言模型（VLM）的自动评估和人工评估两种方式，对不同的扩散模型进行了评估。此外，我们研究了通过提示扩展来缓解同形异义词重复问题的方法，证明了这种方法也能有效减少与英语中心偏见相关的重复现象。自动评估流水线的代码已公开提供。|
|**2025-09-25**|[Semantic Edge-Cloud Communication for Real-Time Urban Traffic Surveillance with ViT and LLMs over Mobile Networks](http://arxiv.org/abs/2509.21259)|null|实时城市交通监控对于智能交通系统（ITS）至关重要，旨在确保智慧城市中的道路安全、优化交通流量、跟踪车辆轨迹并预防碰撞。在城市环境中部署边缘摄像头是监控路况的标准做法。然而，将这些摄像头与智能模型集成需要对动态交通场景有深入理解，并需要一个响应式接口以供用户交互。尽管多模态大语言模型（LLMs）可以解释交通图像并生成信息丰富的响应，但由于其高计算需求，在边缘设备上部署它们是不可行的。因此，LLM推理必须在云端进行，这需要将视觉数据从边缘传输到云端，但这一过程受限于带宽不足，可能导致延迟，从而损害实时性能。为解决这一挑战，我们提出了一种语义通信框架，该框架显著降低了传输开销。我们的方法包括使用YOLOv11检测感兴趣区域（RoIs），裁剪相关图像片段，并使用视觉Transformer（ViT）将其转换为紧凑的嵌入向量。这些嵌入随后被传输到云端，在云端，图像解码器重建裁剪后的图像。重建后的图像由多模态LLM处理，以生成交通状况描述。与原始裁剪图像的93%准确率相比，该方法实现了99.9%的数据传输量减少，同时对重建的裁剪图像保持89%的LLM响应准确率。我们的结果表明了ViT和LLM辅助的边缘-云语义通信在实时交通监控中的效率和实用性。|
|**2025-09-25**|[Human-like Navigation in a World Built for Humans](http://arxiv.org/abs/2509.21189)|**[link](https://github.com/ReasonNav/ReasonNav)**|在未曾到访过的人造环境中导航时——例如办公楼——人类会采用阅读标志和向他人问路等行为。这些行为通过减少在大片区域中搜索的需要，帮助人类高效地到达目的地。现有的机器人导航系统缺乏执行此类行为的能力，因此在大型环境中导航效率低下。我们提出了ReasonNav，这是一个模块化导航系统，它通过利用视觉语言模型（VLM）的推理能力，集成了这些类人导航技能。我们设计了基于导航地标的紧凑输入和输出抽象，使VLM能够专注于语言理解和推理。我们在真实和模拟导航任务中评估了ReasonNav，并表明该智能体成功地运用了高阶推理，以在大型复杂建筑中高效导航。|
|**2025-09-25**|[Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy](http://arxiv.org/abs/2509.21173)|null|强大的视觉-语言模型（VLM），如CLIP，的零样本泛化能力为安全相关任务（如分布外（OOD）检测）带来了新范式。然而，对CLIP的计算高效和可靠部署至关重要的其他方面仍被忽视。特别是，量化对CLIP性能超出准确性范围的影响仍未得到充分探索。本工作对CLIP模型上的量化进行了大规模评估，不仅评估了分布内准确性，还评估了一整套全面的可靠性指标，并揭示了由预训练来源驱动的反直觉结果。我们证明，量化持续改善了通常置信度不足的预训练模型的校准性，同时经常使其在置信度过高的变体上性能下降。有趣的是，校准性的下降并不排除在其他可靠性指标上取得进展；我们发现，对于这些校准性差的模型，OOD检测仍能得到改善。此外，我们确定了特定的量化感知训练（QAT）方法，这些方法在零样本准确性、校准性和OOD鲁棒性方面实现了同步提升，挑战了严格的效率-性能权衡的观点。这些发现通过超越其传统作用地利用量化，为解决部署高效、可靠和鲁棒VLM的多目标问题提供了重要见解。|
|**2025-09-25**|[Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](http://arxiv.org/abs/2509.21151)|null|关系抽取 (RE) 旨在识别非结构化文本中实体间的语义关系。尽管最近的研究将传统的关系抽取扩展到多模态场景，但大多数方法仍采用基于分类的范式，通过融合多模态特征将关系表示为离散标签。这种范式存在两个显著局限性：(1) 它忽略了实体类型和位置线索等结构约束，以及 (2) 它缺乏语义表达能力以实现细粒度关系理解。我们提出了检索优先于分类 (ROC)，这是一种新颖的框架，它将多模态关系抽取重新表述为由关系语义驱动的检索任务。ROC通过多模态编码器集成实体类型和位置信息，使用大型语言模型将关系标签扩展为自然语言描述，并通过基于语义相似度的对比学习对齐实体-关系对。实验表明，我们的方法在基准数据集 MNRE 和 MORE 上取得了最先进的性能，并展现出更强的鲁棒性和可解释性。|
|**2025-09-25**|[CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific Tokenization](http://arxiv.org/abs/2509.21150)|null|计算机辅助设计 (CAD) 是工业原型设计的核心组成部分，其中模型并非由原始坐标定义，而是由草图和拉伸等构建序列定义。这种序列结构能够实现高效的原型初始化和后续编辑。文本引导的CAD原型设计统一了文本到CAD生成和CAD编辑，有望简化整个设计流程。然而，现有研究尚未探索这种设置，这主要是因为标准的大型语言模型 (LLM) 分词器将CAD序列分解为自然语言的词片段，未能捕获基元级别的CAD语义，从而阻碍了注意力模块对几何结构进行建模。我们推测，一种与CAD的基元和结构特性相吻合的多模态分词策略可以提供更有效的表示。为此，我们提出了CAD-Tokenizer，这是一个使用基于序列的VQ-VAE（结合基元级池化和受限解码）的框架，通过模态特定的标记来表示CAD数据。这种设计生成了紧凑的、基元感知的表示，与CAD的结构特性相符。将CAD-Tokenizer应用于统一的文本引导CAD原型设计，显著提高了指令遵循能力和生成质量，在定量和定性性能方面均优于通用LLM和任务特定基线。|
|**2025-09-25**|[Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning](http://arxiv.org/abs/2509.21126)|null|复杂任务中的在线强化学习是耗时的，因为需要大量的交互步骤来学习最优Q函数。视觉-语言动作（VLA）策略代表了解决多样化任务的一个有前景的方向；然而，它们在低层控制上的性能仍然有限，并且有效部署通常需要特定任务的专家演示进行微调。在本文中，我们提出了VARL（VLM作为在线强化学习的动作建议者），这是一个利用视觉-语言模型（VLM）领域知识为强化学习智能体提供动作建议的框架。与以往方法不同，VARL提供的是动作建议而非设计启发式奖励，从而保证了最优性和收敛性不变。所建议的动作增加了样本多样性，并最终提高了样本效率，特别是在稀疏奖励任务中。为了验证VARL的有效性，我们在多样化的环境和智能体设置中对其进行了评估。结果表明，VARL在不引入显著计算开销的情况下大幅提高了样本效率。这些优势使VARL成为一个通用的在线强化学习框架，并使得在现实世界环境中从零开始直接应用强化学习成为可能。|
|**2025-09-23**|[DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](http://arxiv.org/abs/2509.19274)|null|我们引入了DRISHTIKON，这是一个首个此类专门围绕印度文化的多模态多语言基准，旨在评估生成式人工智能系统的文化理解能力。与现有通用或全球范围的基准不同，DRISHTIKON提供了对印度多样化地区深入、细粒度的覆盖，涵盖15种语言，覆盖所有邦和联邦属地，并整合了超过64,000个对齐的文本-图像对。该数据集捕捉了丰富的文化主题，包括节日、服饰、美食、艺术形式和历史遗产等等。我们评估了广泛的视觉-语言模型（VLM），包括开源的小型和大型模型、专有系统、推理专用VLM以及面向印度的模型，涵盖零样本和思维链设置。我们的结果揭示了当前模型在对文化根植的多模态输入进行推理时的关键局限性，特别是对于低资源语言和记录较少的传统。DRISHTIKON填补了包容性人工智能研究中的一个重要空白，为推动具有文化意识、多模态能力的语言技术发展提供了一个强大的测试平台。|
|**2025-09-23**|[ConViS-Bench: Estimating Video Similarity Through Semantic Concepts](http://arxiv.org/abs/2509.19245)|null|两个视频相似意味着什么？视频如果根据其描绘的动作来判断，可能看起来相似，但如果根据拍摄地点来评估，则可能完全不同。虽然人类在比较视频时会自然地考虑不同方面，但这种能力尚未得到充分研究，并对那些通常依赖于广泛全局相似性分数的模型构成了挑战。具有视频理解能力的大型多模态模型（LMMs）为在视频比较任务中利用自然语言开辟了新机遇。我们引入了基于概念的视频相似性估计（ConViS），这是一项新颖的任务，通过计算一组预定义关键语义概念上的可解释相似性分数来比较视频对。ConViS 允许对视频相似性进行类人推理，并支持诸如概念条件视频检索等新应用。为了支持这项任务，我们还引入了ConViS-Bench，这是一个新的基准，包含跨多个领域的精心标注视频对。每对视频都附带概念级相似性分数以及差异和相似性的文本描述。此外，我们还在ConViS上对多个最先进模型进行了基准测试，深入了解它们与人类判断的一致性。我们的结果揭示了ConViS上显著的性能差异，表明某些概念在估计视频相似性方面提出了更大的挑战。我们相信ConViS-Bench将成为推动语言驱动视频理解研究的宝贵资源。|
|**2025-09-23**|[Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation](http://arxiv.org/abs/2509.19244)|null|我们提出了Lavida-O，一个统一的多模态掩码扩散模型（MDM），能够执行图像理解和生成任务。与现有仅支持简单图像级理解任务和低分辨率图像生成的多模态扩散语言模型（如MMaDa和Muddit）不同，Lavida-O展现了许多新能力，例如目标定位、图像编辑和高分辨率（1024像素）图像合成。它也是第一个利用其理解能力，通过规划和迭代自反思来改进图像生成和编辑结果的统一MDM。为了实现有效和高效的训练和采样，Lavida-O引入了许多新颖技术，例如弹性混合Transformer架构、通用文本条件化和分层采样。我们的模型在RefCOCO目标定位、GenEval文本到图像生成和ImgEdit图像编辑等广泛基准测试中取得了最先进的性能，优于现有的自回归和连续扩散模型（如Qwen2.5-VL和FluxKontext-dev），同时在推理时提供了显著的加速。|
|**2025-09-23**|[Steering Multimodal Large Language Models Decoding for Context-Aware Safety](http://arxiv.org/abs/2509.19212)|null|多模态大语言模型 (MLLMs) 越来越多地部署在实际应用中，但其做出上下文感知安全决策的能力仍然有限。现有方法往往难以平衡过度敏感性（不合理地拒绝良性查询）和欠敏感性（漏报视觉相关的风险），在安全对齐方面留下了一个持续存在的差距。为了解决这个问题，我们引入了安全感知对比解码 (SafeCoDe)，这是一种轻量级且模型无关的解码框架，它根据多模态上下文动态调整 token 生成。SafeCoDe 分为两个阶段运行：(1) 一种对比解码机制，通过对比真实图像和高斯噪声图像来突出对视觉上下文敏感的 token；(2) 一种全局感知 token 调制策略，它将场景级推理与 token 级调整相结合，以根据预测的安全判断调整拒绝行为。跨越不同 MLLM 架构和安全基准（涵盖欠敏感性、过度敏感性和一般安全评估）的大量实验表明，SafeCoDe 在保持模型有用性的同时，持续改进了上下文敏感的拒绝行为。|
|**2025-09-23**|[Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs](http://arxiv.org/abs/2509.19207)|null|对比视觉-语言模型（VLM）在关联视觉和文本信息方面取得了显著进展，但理解长而密集的描述仍然是一个悬而未决的难题。我们假设组合性，即推理对象-属性绑定和对象间关系的能力，是理解更长描述的关键。在本文中，我们研究了组合性与长描述理解之间的相互作用，探讨为一种特性进行训练是否能增强另一种特性。我们训练并评估了一系列针对这些能力的模型。我们的结果揭示了一种双向关系：组合性训练提高了长描述检索的性能，而对长描述的训练促进了组合性。然而，这些收益对数据质量和模型设计很敏感。我们发现，在结构不良的描述上进行训练，或参数更新有限，无法实现泛化。同样地，旨在保持通用对齐的策略，例如冻结位置嵌入，不能提升组合理解能力。总的来说，我们发现组合理解能力和长描述理解能力是相互交织的能力，可以通过对密集、有根据的描述进行训练来共同学习。尽管存在这些挑战，我们表明在高质量长描述数据上训练的模型可以在两项任务中实现强大的性能，为改进VLM的泛化能力提供了实用的指导。|
|**2025-09-23**|[Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions](http://arxiv.org/abs/2509.19203)|**[link](https://github.com/IoannaNti/LexiCLIP)**|对比训练的视觉-语言模型（VLMs），如CLIP，已成为学习判别性视觉-语言表征的标准方法。然而，这些模型常表现出浅层语言理解，呈现词袋行为。其双编码器设计加剧了这些局限，并引入了模态鸿沟。此外，训练过程对大量网络收集数据语料库的依赖使其计算成本高昂，并带来了重大的隐私问题。为解决这些局限性，本研究通过引入一种无视觉、单编码器检索管道，挑战了视觉编码器在检索任务中的必要性。我们摒弃了传统的文本到图像检索范式，在VLLM生成的结构化图像描述的辅助下，转向了文本到文本范式。我们证明了这种范式转变具有显著优势，包括大幅缩小模态鸿沟、提高组合性，以及在短句和长句查询上表现更优，所有这些只需在两块GPU上进行数小时校准即可实现。此外，用文本描述替代原始图像为检索引入了一种更隐私友好的替代方案。为进一步评估泛化能力并解决先前组合性基准的一些不足，我们发布了两个源自Flickr30k和COCO的基准，它们包含由短句组成的各种组合性查询，我们将其命名为subFlickr和subCOCO。我们的无视觉检索器与传统多模态模型表现相当，并常常超越它们。重要的是，我们的方法在多个检索和组合性基准上实现了最先进的零样本性能，所用模型参数量仅为0.3B。代码可在https://github.com/IoannaNti/LexiCLIP获取。|
|**2025-09-23**|[Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models](http://arxiv.org/abs/2509.19191)|null|视觉-语言模型（VLM）在各种实际任务中展现出卓越的性能。然而，现有的VLM通常通过序列化图像来处理视觉信息，这种方法与人类视觉的并行特性显著不同。此外，其不透明的内部机制阻碍了更深入的理解和架构创新。受人类视觉双流假说的启发，该假说区分了“识别什么”和“位于何处”的通路，我们将VLM中的视觉处理解构为物体识别和空间感知进行单独研究。对于物体识别，我们将图像转换为文本标记图，并发现模型对图像内容的感知呈现为从浅层到深层的两阶段过程，始于属性识别，最终实现语义消歧。对于空间感知，我们理论推导并经验验证了VLM中位置表示的底层几何结构。基于这些发现，我们引入了一种基于即插即用视觉解码器的与指令无关的标记压缩算法以提高解码效率，以及一种RoPE缩放技术以增强空间推理能力。通过严格的实验，我们的工作验证了这些分析，提供了对VLM内部机制更深入的理解，并为设计更强大的未来架构提供了清晰的原则。|
|**2025-09-23**|[A Multimodal Stochastic Planning Approach for Navigation and Multi-Robot Coordination](http://arxiv.org/abs/2509.19168)|null|本文提出了一种滚动时域、基于采样的规划器，能够对多模态策略分布进行推理。通过使用交叉熵方法在共同成本函数下优化多模态策略，我们的方法增强了对局部最优的鲁棒性，并促进了对解空间的有效探索。我们表明，我们的方法自然地扩展到多机器人无碰撞规划，使智能体能够共享多样化的候选策略以避免死锁，并允许团队在不产生集中式优化的计算复杂性的情况下最小化全局目标。数值模拟表明，采用多模态显著提高了在陷阱环境和多机器人避碰中的成功率。硬件实验进一步验证了该方法的实时可行性和实际性能。|
|**2025-09-23**|[Investigating Traffic Accident Detection Using Multimodal Large Language Models](http://arxiv.org/abs/2509.19096)|null|交通安全仍然是一个重要的全球性问题，及时准确的事故检测对于减少危害和快速应急响应至关重要。基于基础设施的视觉传感器为持续实时监测提供了可扩展且高效的解决方案，促进了直接从捕获图像中自动化检测事故。本研究调查了多模态大语言模型（MLLMs）的零样本能力，利用来自基础设施摄像头的图像检测和描述交通事故，从而最大限度地减少了对大量标注数据集的依赖。主要贡献包括：(1) 使用CARLA模拟的DeepAccident数据集对MLLM进行评估，通过受控模拟明确解决了多样化、真实、基于基础设施的事故数据稀缺问题；(2) 在未经事先微调的情况下，对Gemini 1.5和2.0、Gemma 3以及Pixtral模型在事故识别和描述能力方面进行了比较性能分析；(3) 将先进的视觉分析技术，具体来说，用于目标检测的YOLO、用于多目标跟踪的Deep SORT和用于实例分割的Segment Anything (SAM)，集成到增强的提示中，以提高模型的准确性和可解释性。关键数值结果显示，Pixtral表现最佳，F1分数为0.71，召回率为83%；而Gemini模型通过增强提示提高了精度（例如，Gemini 1.5升至90%），但F1分数和召回率显著下降。Gemma 3提供了最均衡的性能，指标波动最小。这些发现表明，将MLLM与先进视觉分析技术相结合具有巨大的潜力，增强了它们在实际自动化交通监测系统中的适用性。|
|**2025-09-23**|[Data-Free Knowledge Distillation for LiDAR-Aided Beam Tracking in MmWave Systems](http://arxiv.org/abs/2509.19092)|null|多模态感知可减少波束训练开销，但受限于机器学习复杂度和数据集需求。为解决此问题，我们提出一个无数据（DF）知识蒸馏（KD）框架，用于高效的LiDAR辅助毫米波波束跟踪，即预测当前和未来的最佳波束。具体来说，我们提出一个知识反演框架，其中一个生成器在定义于预训练教师模型特征和输出的损失函数引导下，从随机噪声合成LiDAR输入数据。学生模型随后利用合成数据和从教师模型中蒸馏的知识进行训练。生成器损失结合了称为元数据损失、激活损失和熵损失的三项。对于学生训练，除了标准的Kullback-Leibler散度损失外，我们还考虑了教师和学生logit之间的均方误差（MSE）损失。仿真结果表明，所提出的DF-KD在Top-1和Top-5准确率方面（略微）优于教师模型。此外，我们观察到元数据损失对生成器性能有显著贡献，并且学生的MSE损失可以有效替代标准的KD损失，同时需要更少的微调超参数。|
|**2025-09-19**|[MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](http://arxiv.org/abs/2509.16197)|null|统一多模态大语言模型（LLMs）能够同时理解和生成视觉内容，具有巨大潜力。然而，现有开源模型常常在这些能力之间面临性能权衡。我们提出Manzano，一个简单且可扩展的统一框架，通过结合混合图像分词器和精心设计的训练方案，大幅缓解了这种紧张关系。一个单一的共享视觉编码器驱动两个轻量级适配器，在一个共同的语义空间内，生成用于图像到文本理解的连续嵌入和用于文本到图像生成的离散令牌。一个统一的自回归大语言模型预测以文本和图像令牌形式存在的高级语义，辅以一个辅助扩散解码器随后将图像令牌转化为像素。该架构，结合跨理解和生成数据的统一训练方案，实现了这两种能力的可扩展联合学习。Manzano在统一模型中取得了最先进的结果，并与专业模型具有竞争力，尤其是在文本丰富的评估中。我们的研究表明任务冲突最小，并且随着模型规模的扩大，性能持续提升，验证了我们混合分词器的设计选择。|
|**2025-09-19**|[Are Multimodal Foundation Models All That Is Needed for Emofake Detection?](http://arxiv.org/abs/2509.16193)|null|在这项工作中，我们研究了用于情感伪造检测（EFD）的多模态基础模型（MFM），并假设它们将优于音频基础模型（AFM）。MFM由于其跨模态预训练，从多种模态中学习情感模式，而AFM仅依赖于音频。因此，MFM能更好地识别被操纵音频中不自然的情感转变和不一致性，使其在区分真实与虚假情感表达方面更有效。为了验证我们的假设，我们对最先进（SOTA）的MFM（例如LanguageBind）以及AFM（例如WavLM）进行了全面的比较分析。我们的实验证实MFM在EFD方面优于AFM。除了单个基础模型（FM）的性能之外，我们还探索了FM融合，这受到了合成语音检测和语音情感识别等相关研究领域发现的启发。为此，我们提出了SCAR，一个用于有效融合的新颖框架。SCAR引入了一种嵌套的交叉注意力机制，其中来自FM的表示在两个阶段顺序交互，以精炼信息交换。此外，一个自注意力精炼模块通过强化重要的跨FM线索同时抑制噪声，进一步增强了特征表示。通过SCAR与MFM的协同融合，我们实现了SOTA性能，超越了独立FM、传统融合方法以及之前在EFD方面的研究。|
|**2025-09-19**|[Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks](http://arxiv.org/abs/2509.16163)|null|视觉语言模型 (VLM) 在多模态理解方面表现出色，但容易受到对抗性攻击。现有防御方法通常需要昂贵的再训练或显著的架构修改。我们引入了一种利用张量分解的轻量级防御方法，适用于任何预训练的VLM，无需再训练。通过分解和重构视觉编码器表示，它能过滤对抗性噪声，同时保留语义信息。在COCO和Flickr30K数据集上对CLIP进行的实验表明鲁棒性得到改善。在Flickr30K上，它恢复了因攻击损失的12.3%的性能，将Recall@1准确率从7.5%提高到19.8%。在COCO上，它恢复了8.1%的性能，将准确率从3.8%提高到11.9%。分析表明，低秩 (8-32) 和低残差强度 ( $\alpha=0.1-0.2$ ) 的张量链分解是最优的。该方法是一种实用的即插即用解决方案，对现有VLM具有最小开销。|
|**2025-09-19**|[Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models](http://arxiv.org/abs/2509.16149)|**[link](https://github.com/ustc-mkh/MLLM_Sycophancy)**|多模态大语言模型（MLLM）在基于图像输入进行对话方面展现出非凡的能力。然而，我们观察到MLLM表现出一种显著的视觉逢迎行为。尽管在基于文本的大语言模型（LLM）中也注意到类似行为，但当MLLM处理图像输入时，这种行为变得更为突出。我们将这种现象称为“逢迎模态鸿沟”。为了更好地理解这个问题，我们进一步分析了导致这种鸿沟加剧的因素。为了缓解视觉逢迎行为，我们首先尝试使用朴素的监督微调，以帮助MLLM抵制用户误导性指令。然而，我们发现这种方法也使MLLM对纠正性指令过度抵制（即，即使错了也固执己见）。为了缓解这种权衡，我们提出了逢迎反思调优（SRT），它使MLLM能够进行反思性推理，使其能够在得出结论之前判断用户的指令是误导性的还是纠正性的。应用SRT后，我们观察到对误导性指令的逢迎行为显著减少，同时在接收纠正性指令时也不会导致过度固执。|
|**2025-09-19**|[Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning](http://arxiv.org/abs/2509.16136)|null|设计有效的奖励函数在强化学习（RL）中仍然是一个主要挑战，通常需要大量人类专业知识和迭代改进。最近的进展利用大型语言模型（LLMs）进行自动化奖励设计，但这些方法受到幻觉、对人类反馈的依赖以及处理复杂多步任务的挑战的限制。在这项工作中，我们引入了基于思维图的奖励演化（RE-GoT），这是一种新颖的双层框架，它通过结构化图基推理增强了LLMs，并整合了视觉语言模型（VLMs）用于自动化 rollout 评估。RE-GoT首先将任务分解为文本属性图，从而实现全面分析和奖励函数生成，然后利用来自VLMs的视觉反馈迭代地改进奖励，无需人类干预。在10个RoboGen和4个ManiSkill2任务上的大量实验表明，RE-GoT始终优于现有的基于LLM的基线。在RoboGen上，我们的方法将平均任务成功率提高了32.25%，在复杂多步任务上取得了显著的提升。在ManiSkill2上，RE-GoT在四个多样化的操作任务中实现了93.73%的平均成功率，显著超越了先前的基于LLM的方法，甚至超过了专家设计的奖励。我们的结果表明，结合LLMs和VLMs并配合思维图推理，为强化学习中的自主奖励演化提供了一种可扩展且有效的解决方案。|
|**2025-09-19**|[BaseReward: A Strong Baseline for Multimodal Reward Model](http://arxiv.org/abs/2509.16127)|null|多模态大语言模型（MLLMs）的快速发展使得使其与人类偏好对齐成为一个关键挑战。奖励模型（RMs）是实现这一目标的核心技术，但在学术界和工业界，目前均缺乏构建最先进多模态奖励模型（MRMs）的系统性指南。通过详尽的实验分析，本文旨在为构建高性能MRM提供一份明确的“秘籍”。我们系统地研究了MRM开发流程中的每一个关键组成部分，包括奖励建模范式（例如，朴素奖励模型、基于评论员的奖励模型和生成式奖励模型）、奖励头架构、训练策略、数据精选（涵盖十余种多模态和纯文本偏好数据集）、主干模型和模型规模，以及集成方法。基于这些实验洞察，我们引入了BaseReward，一个强大而高效的多模态奖励建模基线。BaseReward采用了一种简单而有效的架构，基于Qwen2.5-VL主干模型构建，具有优化的两层奖励头，并在精心整理的高质量多模态和纯文本偏好数据混合集上进行训练。我们的结果表明，BaseReward在MM-RLHF-Reward Bench、VL-Reward Bench和Multimodal Reward Bench等主要基准测试上建立了新的SOTA，优于之前的模型。此外，为了验证其超越静态基准测试的实用性，我们将BaseReward集成到真实的强化学习流程中，成功提升了多模态大语言模型在各种感知、推理和对话任务中的性能。这项工作不仅提供了一个顶级的MRM，更重要的是，为社区提供了一份清晰的、有实证支持的指南，用于开发下一代多模态大语言模型的稳健奖励模型。|
|**2025-09-19**|[Randomized Smoothing Meets Vision-Language Models](http://arxiv.org/abs/2509.16088)|null|随机平滑（RS）是确保机器学习模型正确性的突出技术之一，通过它可以解析推导出逐点鲁棒性证书。尽管RS在分类任务中已得到充分理解，但其在生成模型中的应用尚不明确，因为生成模型的输出是序列而非标签。我们通过将生成模型的输出与一个预言机分类任务联系起来解决了这个问题，并表明RS仍然可以启用：最终响应可以被分类为离散动作（例如，VLA中的服务机器人指令）、有害与无害（VLM中的内容审核或毒性检测），甚至可以应用预言机将答案聚类为语义等价的类别。假设预言机分类器比较的错误率有界，我们建立了将样本数量与相应鲁棒性半径关联起来的理论。我们进一步解析推导出了改进的缩放定律，将认证半径和准确性与样本数量关联起来，表明即使在较弱的假设下，早期结果（即减少2到3个数量级的样本量即可满足需求且损失最小）仍然有效。总而言之，这些进展使得鲁棒性认证对于最先进的VLM而言既明确又在计算上可行，并已针对近期越狱式对抗攻击进行了验证。|
|**2025-09-19**|[See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model](http://arxiv.org/abs/2509.16087)|null|我们引入了SEE&TREK，这是首个免训练提示框架，旨在增强多模态大语言模型（MLLM）在仅视觉约束下的空间理解能力。尽管先前的工作已通过引入深度或点云等模态来提升空间推理，但纯视觉空间理解仍未得到充分探索。SEE&TREK通过关注两个核心原则来解决这一空白：增加视觉多样性和运动重建。对于视觉多样性，我们采用最大语义丰富度采样，利用现成的感知模型提取能够捕捉场景结构的语义丰富的关键帧。对于运动重建，我们模拟视觉轨迹并将相对空间位置编码到关键帧中，以同时保持空间关系和时间连贯性。我们的方法免训练且无需GPU，仅需一次前向传播，并且可以无缝集成到现有MLLM中。在VSI-B ENCH和STI-B ENCH上进行的大量实验表明，SEE&TREK持续提升了各类MLLM在各种空间推理任务上的性能，最高提升达3.5%，为实现更强的空间智能提供了一条有前景的道路。|
|**2025-09-19**|[I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models](http://arxiv.org/abs/2509.16072)|null|开放世界环境中语言条件下的机器人操作不仅需要准确的任务执行，还需要检测故障的能力，以便在真实世界环境中进行鲁棒部署。尽管视觉-语言模型（VLM）的最新进展显著提升了机器人的空间推理和任务规划能力，但它们在识别自身故障方面的能力仍然有限。特别是一个关键但尚未充分探索的挑战在于检测语义错位错误，即机器人执行的任务在语义上有意义但与给定指令不一致。为此，我们提出了一种从现有语言条件下的操作数据集中构建针对语义错位故障检测的数据集的方法。我们还提出了I-FailSense，一个具备接地仲裁能力的开源VLM框架，专门为故障检测而设计。我们的方法依赖于对一个基础VLM进行后训练，然后训练连接到VLM不同内部层的轻量级分类头（称为FS块），并通过集成机制聚合它们的预测。实验表明，I-FailSense在检测语义错位错误方面优于最先进的VLM，无论是在规模相当还是更大的模型上。值得注意的是，尽管I-FailSense仅在语义错位检测上进行训练，但它能泛化到更广泛的机器人故障类别，并通过零样本或少量后训练有效地迁移到其他模拟环境和真实世界。相关数据集和模型已在HuggingFace上公开（网页：https://clemgris.github.io/I-FailSense/）。|
|**2025-09-19**|[Language-Instructed Reasoning for Group Activity Detection via Multimodal Large Language Model](http://arxiv.org/abs/2509.16054)|null|群体活动检测（GAD）旨在同时识别视频序列中的群体成员并对其集体活动进行分类。现有的基于深度学习的方法开发了专门的架构（例如，Transformer网络）来建模个体角色的动态以及个体与群体之间的语义依赖关系。然而，它们仅依赖于从视觉特征中进行的隐式模式识别，并在上下文推理和可解释性方面面临困难。在这项工作中，我们提出了LIR-GAD，这是一个通过多模态大语言模型（MLLM）实现GAD的语言指导推理的新颖框架。我们的方法通过引入一个活动级别的<ACT> token和多个特定于群体的<GROUP> token来扩展MLLM的原始词汇表。我们处理视频帧，同时结合两个专门设计的token和语言指令，这些随后被集成到MLLM中。嵌入在MLLM中的预训练常识知识使得<ACT> token和<GROUP> token能够分别有效捕获集体活动的语义信息并学习不同群体的独特表示特征。此外，我们引入了一种多标签分类损失，以进一步增强<ACT> token学习判别性语义表示的能力。接着，我们设计了一个多模态双对齐融合（MDAF）模块，该模块将MLLM中对应于所设计token的隐藏嵌入与视觉特征进行集成，显著提升了GAD的性能。定量和定性实验都证明了我们所提出的方法在GAD任务中的优越性能。|
|**2025-09-18**|[Calibration-Aware Prompt Learning for Medical Vision-Language Models](http://arxiv.org/abs/2509.15226)|null|医用视觉-语言模型 (Med-VLM) 通过利用大规模图像-文本预训练，在各种医学影像任务中表现出卓越的性能。然而，它们的置信度校准在很大程度上尚未被探索，因此仍然是一个重大挑战。因此，未校准的预测可能导致过度自信的错误，从而损害临床信任和决策可靠性。为解决这个问题，我们引入了CalibPrompt，这是首个在提示微调期间校准Med-VLM的框架。CalibPrompt在标记数据稀缺的情况下，通过精心设计的校准目标，优化了一组少量的可学习提示。首先，我们研究了一种旨在将平滑准确度与预测模型置信度对齐的正则化器。其次，我们引入了一种角分离损失，以最大化文本特征接近度，从而提高多模态Med-VLM置信度估计的可靠性。在四个公开可用的Med-VLM和五个不同的医学影像数据集上进行的大量实验表明，CalibPrompt在不显著影响原始准确率的情况下持续改进了校准。我们的代码可在 https://github.com/iabh1shekbasu/CalibPrompt 获取。|
|**2025-09-18**|[Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation](http://arxiv.org/abs/2509.15225)|null|我们引入VocAlign，这是一种专为开放词汇语义分割中的视觉语言模型（VLM）设计的新型无源域适应框架。我们的方法采用师生范式，并辅以词汇对齐策略，通过引入额外的类别概念来改进伪标签生成。为确保效率，我们使用低秩适应（LoRA）来微调模型，在保留其原有能力的同时最小化计算开销。此外，我们为学生模型提出了一种Top-K类别选择机制，该机制显著降低了内存需求，同时进一步提升了适应性能。我们的方法在CityScapes数据集上实现了显著的6.11 mIoU提升，并在零样本分割基准上展现出卓越性能，为开放词汇设置下的无源域适应树立了新标杆。|
|**2025-09-18**|[ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data](http://arxiv.org/abs/2509.15221)|**[link](https://github.com/YangYzzzz/ScaleCUAWebCrawler)**|视觉-语言模型（VLMs）使得能够自主操作图形用户界面（GUIs）的计算机使用智能体（CUAs）成为可能，展现出巨大潜力，然而，进展受限于缺乏大规模、开源的计算机使用数据和基础模型。在这项工作中，我们介绍了ScaleCUA，这是迈向扩展开源CUA的一步。它提供了一个大规模数据集，涵盖6个操作系统和3个任务领域，该数据集通过结合自动化智能体和人类专家的闭环管道构建而成。经过这些扩展数据的训练，ScaleCUA能够跨平台无缝操作。具体而言，它在基线上取得了显著提升（WebArena-Lite-v2上提升26.6，ScreenSpot-Pro上提升10.7），并创造了新的SOTA（最先进）结果（MMBench-GUI L1-Hard上达到94.4%，OSWorld-G上达到60.6%，WebArena-Lite-v2上达到47.4%）。这些发现强调了数据驱动扩展对于通用计算机使用智能体而言的强大能力。我们将发布数据、模型和代码以促进未来的研究：https://github.com/OpenGVLab/ScaleCUA。|
|**2025-09-18**|[Generalizable Geometric Image Caption Synthesis](http://arxiv.org/abs/2509.15217)|null|多模态大语言模型具有多种实际应用，这些应用要求强大的推理能力。尽管取得了最新进展，这些模型在解决复杂几何问题方面仍然面临困难。一个关键挑战源于缺乏用于理解几何图像的高质量图像-文本对数据集。此外，大多数基于模板的数据合成流程通常无法泛化到超出其预定义模板的问题。在本文中，我们通过将可验证奖励强化学习（RLVR）这一互补过程引入数据生成流程，弥合了这一差距。通过采用RLVR来细化从50种基本几何关系合成的几何图像的描述，并利用源自数学问题解决任务的奖励信号，我们的流程成功捕获了几何问题解决的关键特征。这使得任务泛化能力更强，并带来了显著的改进。此外，即使在分布外场景中，所生成的数据集也增强了多模态大语言模型的通用推理能力，在MathVista和MathVerse数据集中使用非几何输入图像的统计、算术、代数和数值任务中，准确率提高了2.8%-4.8%，同时在MMMU数据集的艺术、设计、技术和工程任务中，准确率提高了2.4%-3.9%。|
|**2025-09-18**|[What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques](http://arxiv.org/abs/2509.15211)|null|幻灯片演示文稿作为弥合演示幻灯片和书面文档之间鸿沟的数字报告，是学术和企业环境中普遍的信息传达媒介。它们结合了文本、图像和图表的多模态特性，给检索增强生成系统带来了挑战，其中检索质量直接影响下游性能。传统的幻灯片检索方法通常涉及对不同模态进行单独索引，这会增加复杂性并可能丢失上下文信息。本文研究了各种有效的幻灯片检索方法，包括ColPali等视觉后期交互嵌入模型、视觉重排序器的使用，以及将密集检索与BM25结合并通过文本重排序器和倒数排名融合等融合方法进一步增强的混合检索技术。本文还评估了一种新颖的基于视觉-语言模型（VLM）的字幕生成流水线，该流水线与视觉后期交互技术相比，显著降低了嵌入存储需求，同时保持了可比的检索性能。我们的分析扩展到这些方法的实际方面，评估它们的运行时性能、存储需求以及检索效率，从而为选择和开发用于实际应用的高效鲁棒幻灯片检索系统提供了实用指导。|
|**2025-09-18**|[Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding](http://arxiv.org/abs/2509.15178)|null|时空视频定位（STVG）旨在根据输入的文本查询来定位视频中的时空管。在本文中，我们利用多模态大语言模型（MLLMs）来探索STVG中的零样本解决方案。我们揭示了关于MLLMs的两个关键见解：(1) MLLMs倾向于动态分配被称为“定位token”的特殊token，用于定位文本查询；(2) MLLMs经常由于无法充分整合文本查询中的线索（例如，属性、动作）进行推理而遭受次优的定位性能。基于这些见解，我们提出了一种基于MLLM的STVG零样本框架，其中包含新颖的分解时空高亮（DSTH）和时序增强组装（TAS）策略，以释放MLLMs的推理能力。DSTH策略首先将原始查询解耦为属性和动作子查询，用于在空间和时间上查询目标的存在。它随后使用一个新颖的logit引导重注意力（LRA）模块，通过正则化每个子查询的token预测，学习潜在变量作为空间和时间提示。这些提示分别突出属性和动作线索，引导模型的注意力到可靠的空间和时间相关的视觉区域。此外，由于属性子查询的空间定位应具有时间一致性，我们引入了TAS策略，利用原始视频帧和时序增强帧作为输入来组装预测，以帮助提高时间一致性。我们在各种MLLMs上评估了我们的方法，并表明它在三个常见的STVG基准测试中超越了SOTA方法。代码将可在https://github.com/zaiquanyang/LLaVA_Next_STVG获取。|
|**2025-09-18**|[An Evaluation-Centric Paradigm for Scientific Visualization Agents](http://arxiv.org/abs/2509.15160)|null|多模态大语言模型（MLLMs）的最新进展使得日益复杂的自主可视化智能体能够将用户意图转化为数据可视化。然而，衡量进展和比较不同智能体仍然具有挑战性，尤其是在科学可视化（SciVis）领域，因为缺乏用于评估实际能力的全面、大规模基准。本立场论文探讨了SciVis智能体所需的各种评估类型，概述了相关挑战，提供了一个简单的概念验证评估示例，并讨论了评估基准如何促进智能体的自我改进。我们倡导更广泛的合作，以开发一个SciVis智能体评估基准，该基准不仅能评估现有能力，而且能推动创新并激发该领域的未来发展。|
|**2025-09-18**|[Exploring How Audio Effects Alter Emotion with Foundation Models](http://arxiv.org/abs/2509.15151)|null|音频效果（FX），如混响、失真、调制和动态范围处理，在音乐聆听过程中塑造情感反应方面发挥着关键作用。虽然先前的研究已检验了低级音频特征与情感感知之间的联系，但音频FX对情感的系统性影响仍未得到充分探索。这项工作研究了如何利用基础模型——即在多模态数据上预训练的大规模神经网络架构——来分析这些效果。这些模型编码了音乐结构、音色和情感意义之间丰富的关联，为探究声音设计技术的情感影响提供了一个强大的框架。通过对深度学习模型中的嵌入应用各种探测方法，我们检验了音频FX与估计情感之间复杂、非线性的关系，揭示了与特定效果相关的模式，并评估了基础音频模型的鲁棒性。我们的发现旨在增进对音频制作实践感知影响的理解，对音乐认知、表演和情感计算具有启示意义。|
|**2025-09-18**|[From Pixels to Urban Policy-Intelligence: Recovering Legacy Effects of Redlining with a Multimodal LLM](http://arxiv.org/abs/2509.15132)|null|本文展示了多模态大语言模型 (MLLM) 如何拓展城市测量能力并支持基于地点的政策干预措施的跟踪。GPT-4o 利用结构化的“先推理后估计”流程在街景图像上推断出社区贫困和树冠覆盖，我们将其嵌入准实验设计中以评估20世纪30年代“红线政策”的遗留影响。GPT-4o 再现了“红线政策”预期的不利社会环境遗留影响，其估计结果与权威来源统计上无显著差异，并且它优于传统的基于像素的分割基线，这与整体场景推理能够提取超越单纯对象计数的更高阶信息的观点相符。这些结果将 MLLM 定位为政策级别的社区测量工具，并促使在更广泛的政策评估场景中进行验证。|
|**2025-09-18**|[Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models](http://arxiv.org/abs/2509.15076)|null|空气污染仍然是对公众健康和环境可持续性的严峻威胁，然而传统监测系统常受限于有限的空间覆盖范围和可及性。本文提出了一种人工智能驱动的智能体，该智能体基于天空图像预测环境空气污染水平，并利用生成建模合成逼真的污染情景可视化效果。我们的方法结合了统计纹理分析与监督学习进行污染分类，并利用视觉-语言模型（VLM）引导的图像生成来生成空气质量状况的可解释表示。生成的视觉效果模拟了不同程度的污染，为用户界面提供了基础，以提高透明度并支持明智的环境决策。这些输出可以无缝集成到智能应用中，旨在增强态势感知并鼓励基于实时预测的行为响应。我们使用城市天空图像数据集验证了我们的方法，并证明了其在污染水平估计和语义一致的视觉合成方面的有效性。系统设计进一步融入了以人为中心的用户体验原则，以确保空气质量预测的可访问性、清晰度和公众参与。为支持可扩展和节能的部署，未来的迭代将整合一种通过基于FPGA的增量学习进行增强的绿色CNN架构，从而实现边缘平台上的实时推理。|
|**2025-09-15**|[Igniting VLMs toward the Embodied Space](http://arxiv.org/abs/2509.11766)|null|尽管基础模型在语言和视觉方面取得了显著进展，但现有视觉-语言模型（VLM）在空间和具身理解方面仍然有限。将VLM迁移到具身领域揭示了模态、预训练分布和训练目标之间的根本性不匹配，使得动作理解和生成成为通往通用人工智能（AGI）道路上的一个核心瓶颈。我们引入了WALL-OSS，这是一个端到端的具身基础模型，它利用大规模多模态预训练，实现了（1）具身感知的视觉-语言理解，（2）强大的语言-动作关联，以及（3）鲁棒的操控能力。我们的方法采用了紧密耦合的架构和多策略训练课程，实现了统一的跨层级思维链（CoT），在一个单一的可微分框架内无缝地统一了指令推理、子目标分解和细粒度动作合成。我们的结果表明，WALL-OSS在复杂长周期操控任务上取得了高成功率，展示了强大的指令遵循能力、复杂的理解和推理能力，并优于强大的基线模型，从而为从VLM到具身基础模型提供了一条可靠且可扩展的路径。|
|**2025-03-10**|[Taking Notes Brings Focus? Towards Multi-Turn Multimodal Dialogue Learning](http://arxiv.org/abs/2503.07002)|null|多模态大型语言模型（MLLM）构建于大规模预训练视觉编码器和语言模型之上，在多模态理解方面展现出强大的能力。然而，大多数现有 MLLM 都是在单轮视觉问答任务上进行训练的，这并不能准确反映真实世界中的人类对话。在本文中，我们引入了 MMDiag，一个多轮多模态对话数据集。该数据集通过精心设计的规则和 GPT 辅助协同生成，具有问题之间、问题与图像之间以及不同图像区域之间的高度相关性，从而更贴近真实世界场景。MMDiag 为多轮多模态对话学习提供了一个强有力的基准，并对 MLLM 的基础（grounding）和推理能力提出了更多挑战。此外，受人类视觉处理的启发，我们提出了 DiagNote，一个具备多模态基础和推理能力的 MLLM。DiagNote 由两个模块（Deliberate 和 Gaze）组成，它们在整个多轮对话过程中相互协作，分别执行思维链（Chain-of-Thought）和标注。我们通过实验证明了 DiagNote 在基础以及视觉和语言信息联合处理和推理方面相较于现有 MLLM 的优势。|
|**2024-09-24**|[Expert-level vision-language foundation model for real-world radiology and comprehensive evaluation](http://arxiv.org/abs/2409.16183)|null|放射学是现代临床工作流程中至关重要且复杂的组成部分，涵盖多项任务。近期，医学领域的视觉-语言（VL）基础模型在处理多模态信息方面展现出潜力，为各种放射学任务提供了统一的解决方案。然而，现有研究要么在自然数据上预训练VL模型，要么未能充分整合视觉-语言架构和预训练，常常忽视放射学图像及其文本语境中独特的跨模态复杂性。此外，它们在真实世界场景中的实际适用性仍未得到充分探索。在本文中，我们提出了RadFound，一个专为放射学量身定制的大型开源视觉-语言基础模型，该模型在包含超过810万张图像和25万个图像-文本对的最广泛数据集上进行训练，涵盖19个主要器官系统和10种成像模态。为建立专家级多模态感知和生成能力，RadFound引入了增强型视觉编码器以捕捉图像内部局部特征和图像间上下文信息，以及专为放射学量身定制的统一跨模态学习设计。为了全面评估模型的能力，我们构建了一个名为RadVLBench的基准，其中包括医学视觉-语言问答等放射学解读任务，以及从图像描述到报告生成等文本生成任务。我们还提出了一个人工评估框架。当在涉及2D图像（胸部X光片）、多视角图像（乳腺钼靶片）和3D图像（甲状腺CT扫描）这三种代表性模态的真实世界基准上进行评估时，RadFound在定量指标和人工评估两方面均显著优于其他VL基础模型。总之，RadFound的开发代表着放射学通才模型的一项进展，展示了其可集成到临床工作流程中的广泛适用潜力。|
|**2025-05-30**|[VITA: Towards Open-Source Interactive Omni Multimodal LLM](http://arxiv.org/abs/2408.05211)|null|GPT-4o卓越的多模态能力和交互体验突显了它们在实际应用中的必要性，然而开源模型却鲜有能在这两个方面都表现出色的。在本文中，我们介绍了VITA，这是首个能够同时处理和分析视频、图像、文本和音频模态，并拥有先进多模态交互体验的开源多模态大语言模型（MLLM）。我们以Mixtral 8x7B作为语言基础，扩展了其中文词汇量，并进行了双语指令微调。我们通过多模态对齐和指令微调的两阶段多任务学习，进一步赋予了该语言模型视觉和音频能力。VITA展示了强大的多语言、视觉和音频理解基础能力，这在其在一系列单模态和多模态基准测试中的出色表现中得到了体现。除了基础能力之外，我们在提升自然多模态人机交互体验方面也取得了显著进展。VITA是开源社区探索多模态理解与交互无缝集成的第一步。尽管VITA仍有大量工作要做才能接近闭源模型，但我们希望其作为先行者的角色能为后续研究奠定基石。项目页面：https://vita-home.github.io。|
|**2024-03-20**|[VL-Mamba: Exploring State Space Models for Multimodal Learning](http://arxiv.org/abs/2403.13600)|null|多模态大语言模型（MLLM）引起了广泛关注并具有丰富的应用。然而，其Transformer结构中固有的注意力机制需要二次复杂度，导致昂贵的计算开销。因此，在这项工作中，我们提出了VL-Mamba，一种基于状态空间模型的多模态大语言模型，状态空间模型已被证明在长序列建模方面具有巨大潜力，可实现快速推理和序列长度的线性扩展。具体来说，我们首先用预训练的Mamba语言模型替换了基于Transformer的骨干语言模型，例如LLama或Vicuna。然后，我们经验性地探索了如何有效地将2D视觉选择性扫描机制应用于多模态学习，以及不同视觉编码器和预训练Mamba语言模型变体的组合。在多样化的多模态基准测试上进行的广泛实验，以具有竞争力的性能展示了我们提出的VL-Mamba的有效性，并证明了将状态空间模型应用于多模态学习任务的巨大潜力。|
|**2023-11-30**|[CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation](http://arxiv.org/abs/2311.18775)|null|我们提出了CoDi-2，一个通用且交互式的多模态大语言模型（MLLM），它能够在任意到任意的输入-输出模态范式中，遵循复杂的多模态交错指令，进行上下文学习（ICL），推理、聊天、编辑等。通过在编码和生成时将模态与语言对齐，CoDi-2使大语言模型（LLMs）能够不仅理解复杂的多模态交错指令和上下文示例，而且能在连续特征空间中自回归地生成有基础且连贯的多模态输出。为了训练CoDi-2，我们构建了一个大规模生成数据集，其中包含了跨文本、视觉和音频的上下文多模态指令。CoDi-2展示了广泛的多模态生成零样本能力，例如通过多轮交互式对话实现的上下文学习、推理以及任意到任意模态生成的组合性。CoDi-2在主体驱动图像生成、视觉转换和音频编辑等任务上超越了之前的领域特定模型。CoDi-2标志着在开发一个全面的多模态基础模型方面取得了重大突破，该模型擅长解释上下文中的语言-视觉-音频交错指令并生成多模态输出。|
|**2024-02-05**|[Vision-Language Foundation Models as Effective Robot Imitators](http://arxiv.org/abs/2311.01378)|null|近期视觉语言基础模型的进展表明它们能够理解多模态数据并解决复杂的视觉语言任务，包括机器人操作。我们寻求一种直接的方法，通过在机器人数据上进行简单微调来利用现有的视觉语言模型（VLM）。为此，我们提出了一个简单新颖的视觉语言操作框架，命名为RoboFlamingo，它基于开源VLM OpenFlamingo 构建。与以往工作不同，RoboFlamingo 利用预训练VLM进行单步视觉语言理解，通过显式策略头建模序列历史信息，并且仅在语言条件操作数据集上通过模仿学习进行轻微微调。这种分解为RoboFlamingo 提供了开环控制和在低性能平台部署的灵活性。通过在测试基准上大幅超越最先进的性能，我们表明RoboFlamingo 可以成为一种有效且有竞争力的替代方案，用于将VLM 适应于机器人控制。我们大量的实验结果也揭示了关于不同预训练VLM 在操作任务中行为的几个有趣结论。我们相信RoboFlamingo 有潜力成为一种经济高效且易于使用的机器人操作解决方案，赋予每个人微调自己机器人策略的能力。|
|**2023-10-01**|[Reformulating Vision-Language Foundation Models and Datasets Towards Universal Multimodal Assistants](http://arxiv.org/abs/2310.00653)|null|近期的多模态大语言模型（MLLMs）在感知图像和遵循开放式指令方面展现出令人印象深刻的能力。MLLMs的能力取决于两个关键因素：一是促进视觉模块与大语言模型特征对齐的模型架构；二是用于遵循人类指令的多模态指令微调数据集。(i) 在模型架构方面，大多数现有模型引入了一个外部桥接模块来连接视觉编码器与语言模型，这需要额外的特征对齐预训练。在这项工作中，我们发现紧凑的预训练视觉语言模型能够天然地充当视觉与语言之间的“开箱即用”的桥梁。基于此，我们提出了Muffin框架，该框架直接利用预训练视觉语言模型充当视觉信号的提供者。(ii) 在多模态指令微调数据集方面，现有方法忽略了不同数据集之间的互补关系，简单地混合来自不同任务的数据集。相反，我们提出了UniMM-Chat数据集，该数据集探索了数据集的互补性，以生成110万高质量且多样化的多模态指令。我们合并了来自不同数据集的描述同一图像的信息，并将其转化为更具知识密度的对话数据。实验结果证明了Muffin框架和UniMM-Chat数据集的有效性。Muffin在广泛的视觉语言任务上实现了最先进的性能，显著超越了LLaVA和InstructBLIP等最先进的模型。我们的模型和数据集均可在https://github.com/thunlp/muffin获取。|
|**2023-09-18**|[Multimodal Foundation Models: From Specialists to General-Purpose Assistants](http://arxiv.org/abs/2309.10020)|null|本文全面综述了展示视觉和视觉-语言能力的多模态基础模型的分类和演进，重点关注从专用模型向通用助手的转变。研究领域涵盖五个核心主题，分为两大类。(i) 首先，我们综述了成熟的研究领域：为特定目的预训练的多模态基础模型，包括两个主题——用于视觉理解的视觉骨干网络学习方法和文本到图像生成。(ii) 接着，我们介绍了探索性、开放研究领域的最新进展：旨在扮演通用助手角色的多模态基础模型，包括三个主题——受大型语言模型（LLMs）启发的统一视觉模型、多模态LLMs的端到端训练以及将多模态工具与LLMs链式结合。本文的目标受众是计算机视觉和视觉-语言多模态领域的研究人员、研究生和专业人士，他们渴望学习多模态基础模型的基础知识和最新进展。|
|**2025-01-06**|[VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and Dataset](http://arxiv.org/abs/2304.08345)|null|在这篇论文中，我们提出了一种用于多模态理解和生成的视觉-音频-语言全感知预训练模型（VALOR）。与广泛研究的视觉-语言预训练模型不同，VALOR以端到端的方式联合建模视觉、音频和语言之间的关系。它包含三个独立的编码器用于单一模态表示，以及一个解码器用于多模态条件文本生成。我们设计了两个预训练任务来预训练VALOR模型，包括多模态分组对齐（Multimodal Grouping Alignment, MGA）和多模态分组字幕生成（Multimodal Grouping Captioning, MGC）。MGA将视觉、语言和音频投影到同一个公共空间，同时构建视觉-语言、音频-语言和视听-语言对齐。MGC学习如何在视觉、音频或两者兼有的条件下生成文本标记。为了促进视觉-音频-语言预训练研究，我们构建了一个名为VALOR-1M的大规模高质量三模态数据集，其中包含100万个带有人工标注视听字幕的有声视频。大量实验表明，VALOR能够学习到强大的多模态关联，并能泛化到各种下游任务（例如，检索、字幕生成和问答），支持不同的输入模态（例如，视觉-语言、音频-语言和视听-语言）。VALOR在一系列公共跨模态基准测试中取得了新的最先进性能。代码和数据可在项目页面https://casia-iva-group.github.io/projects/VALOR获取。|

## 大模型PEFT

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-12-19**|[Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection](http://arxiv.org/abs/2512.17630)|null|本文提出了一种信心加权、可信度感知的集成框架，用于基于文本的情绪检测，其灵感来源于孔多塞陪审团定理（CJT）。与传统上依赖同构架构的集成方法不同，我们的方法结合了架构多样化的基于Transformer的小型大语言模型（sLLMs）——BERT、RoBERTa、DistilBERT、DeBERTa和ELECTRA，每个模型都针对情绪分类进行了充分微调。为了保持误差多样性，我们最小化参数收敛，同时利用每个模型独特的偏差。一种双加权投票机制整合了全局可信度（验证F1分数）和局部信心（实例级概率），以动态加权模型贡献。在DAIR-AI数据集上的实验表明，我们的可信度-信心集成方法达到了93.5%的宏观F1分数，超越了最先进的基准，并显著优于大型LLM，包括Falcon、Mistral、Qwen和Phi，即使在经过任务特定的低秩适应（LoRA）之后。总参数量仅为5.95亿，我们的小型LLM集成方法被证明比参数量高达70亿的模型更具参数效率和鲁棒性，这表明精心设计的小型微调模型集成可以在专业自然语言处理（NLP）任务（如情绪检测）中超越大得多的LLM。|
|**2025-12-19**|[AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens](http://arxiv.org/abs/2512.17375)|null|奖励模型和LLM作为评判者系统是RLHF、DPO和RLAIF等现代后训练流水线的核心，它们提供标量反馈和二元决策，指导模型选择和基于强化学习的微调。我们发现这些评判系统存在一个反复出现的漏洞：短序列的低困惑度控制令牌可以通过操纵最后一层的logit间隙，将许多二元评估从正确的“否”判断翻转为不正确的“是”判断。这些控制令牌是策略模型在后训练期间可能生成的模式，因此代表着现实的奖励劫持风险，而非最坏情况的对抗性字符串。我们的方法AdvJudge-Zero利用模型的下一个令牌分布和束搜索探索，从头开始发现多样化的控制令牌序列；我们的分析表明，诱导的隐藏状态扰动集中在一个低秩的“软模式”中，该模式与评判者的拒绝方向反向对齐。实验表明，当大型开源和专业评判模型在数学和推理基准测试中对错误答案进行评分时，这些令牌会导致非常高的假阳性率。最后，我们展示了在小规模控制令牌增强示例集上进行基于LoRA的对抗训练，可以显著减少这些假阳性，同时保持评估质量。|
|**2025-12-19**|[Governance-Aware Hybrid Fine-Tuning for Multilingual Large Language Models](http://arxiv.org/abs/2512.17344)|null|我们提出了一个具备治理意识的混合微调框架，用于大语言模型的多语言低资源适配。该核心算法通过层级混合将梯度对齐的低秩更新与结构化正交变换相结合，并在选定的子层中引入酉约束以稳定深度优化。结合轻量级、无标签的数据治理步骤（包括语言识别、近似重复项去除和质量过滤），该框架旨在严格的计算预算下实现准确性、校准性和跨语言公平性。在XNLI和FLORES数据集上，混合方法相较于强大的PEFT基线实现了持续的提升，同时保持了方向平衡并提高了概率校准，如表II和表III所示。如表IV所示，它对轻量级正字法变体更具弹性；如表V所示，它能从简单的治理步骤中获得叠加收益。训练足迹测量结果表明，该方法开销适中，并具有有利的成本-质量前沿，如表VI和图2所示。综上所述，这些结果表明，当与实际数据治理相结合时，混合和酉PEFT为资源高效的多语言适配提供了一条稳定且易于实现的路径。|
|**2025-12-19**|[Auxiliary Descriptive Knowledge for Few-Shot Adaptation of Vision-Language Model](http://arxiv.org/abs/2512.17313)|null|尽管视觉-语言模型 (VLM) 展现出令人印象深刻的零样本能力，但它们在面对与预训练数据存在分布偏移的下游任务时常常表现不佳。少量样本适应 (FSA-VLM) 已成为关键解决方案，通常采用参数高效微调 (PEFT) 来利用少量数据适应模型。然而，这些 PEFT 方法受限于其对固定、人工设计的提示的依赖，这些提示通常不足以理解类别的语义。尽管一些研究提出利用图像诱导提示为分类提供额外线索，但这在推理时引入了过高的计算开销。因此，我们引入辅助描述知识 (ADK)，这是一种新颖的框架，能够在不损害效率的情况下有效地丰富文本表示。ADK 首先利用大型语言模型为每个类别离线生成一组丰富的描述性提示。这些预计算的特征以两种方式部署：(1) 作为组合知识，即一种提供丰富语义的平均表示，当类别名称对 VLM 模糊或不熟悉时尤其有益；(2) 作为实例特定知识，其中一个轻量级的非参数注意力机制动态选择给定图像最相关的描述。这种方法除了人工设计的提示之外，还提供了两种额外的知识类型，从而促进了跨各种领域的类别区分。此外，ADK 作为一个无参数、即插即用的组件，增强了现有的 PEFT 方法。大量实验表明，ADK 持续提升了多个 PEFT 基线方法的性能，并在各种场景下创造了新的最先进水平。|
|**2025-12-19**|[Vision-Language Model Guided Image Restoration](http://arxiv.org/abs/2512.17292)|null|许多图像修复 (IR) 任务需要像素级保真度和高级语义理解，以恢复具有精细细节的逼真照片。然而，以往的方法通常难以有效利用视觉和语言知识。最近的研究尝试将擅长对齐视觉和文本特征的视觉-语言模型 (VLM) 整合到通用图像修复中。然而，这些方法未能利用语言先验来确保修复过程中的语义一致性。为了解决这个问题，本文提出了视觉-语言模型引导的图像修复 (VLMIR) 框架，该框架利用 CLIP 等 VLM 丰富的视觉-语言先验，通过改进视觉感知和语义理解来提升图像修复性能。我们的方法包括两个阶段：基于 VLM 的特征提取和基于扩散的图像修复。在第一阶段，我们通过 VLM 凝练视觉感知和高级语义先验，从而提取输入图像的互补视觉和语言表示。具体来说，我们使用余弦相似度损失与 LoRA 微调来对齐低质量和高质量图像标题的嵌入，并采用一个退化预测器来分解退化和干净图像内容嵌入。然后，这些互补的视觉和文本嵌入通过交叉注意力机制集成到基于扩散的模型中，以实现增强的修复。大量的实验和消融研究表明，VLMIR 在通用和特定退化的图像修复任务中均取得了卓越性能，强调了 VLM 中集成的视觉和语言知识在提升图像修复能力方面的关键作用。|
|**2025-12-18**|[In-Context Probing for Membership Inference in Fine-Tuned Language Models](http://arxiv.org/abs/2512.16292)|null|成员推断攻击 (MIAs) 对微调的大型语言模型 (LLMs) 构成严重的隐私威胁，尤其是在模型使用敏感数据适应特定领域任务时。尽管先前的黑盒成员推断攻击技术依赖于置信度分数或token似然，但这些信号通常与样本的固有属性（例如内容难度或稀有性）纠缠在一起，导致泛化能力差和信噪比低。在本文中，我们提出了ICP-MIA，一个新颖的成员推断攻击框架，该框架根植于训练动态理论，特别是优化过程中收益递减的现象。我们引入优化差距作为成员身份的一个基本信号：在收敛时，成员样本表现出最小的剩余损失减少潜力，而非成员样本则保留着进一步优化的巨大潜力。为了在黑盒设置中估计这一差距，我们提出了上下文探测 (ICP)，这是一种无需训练的方法，通过策略性构建的输入上下文来模拟微调式行为。我们提出了两种探测策略：基于参考数据（使用语义相似的公共样本）和自扰动（通过掩码或生成）。在三个任务和多个大型语言模型上的实验表明，ICP-MIA显著优于先前的黑盒成员推断攻击，特别是在低误报率下。我们进一步分析了参考数据对齐、模型类型、PEFT配置和训练计划如何影响攻击效果。我们的发现确立了ICP-MIA作为一个实用且有理论基础的框架，用于审计已部署大型语言模型中的隐私风险。|
|**2025-12-19**|[Trustworthy and Controllable Professional Knowledge Utilization in Large Language Models with TEE-GPU Execution](http://arxiv.org/abs/2512.16238)|null|Future improvements in large language model (LLM) services increasingly hinge on access to high-value professional knowledge rather than more generic web data. However, the data providers of this knowledge face a skewed tradeoff between income and risk: they receive little share of downstream value yet retain copyright and privacy liability, making them reluctant to contribute their assets to LLM services. Existing techniques do not offer a trustworthy and controllable way to use professional knowledge, because they keep providers in the dark and combine knowledge parameters with the underlying LLM backbone.   In this paper, we present PKUS, the Professional Knowledge Utilization System, which treats professional knowledge as a first-class, separable artifact. PKUS keeps the backbone model on GPUs and encodes each provider's contribution as a compact adapter that executes only inside an attested Trusted Execution Environment (TEE). A hardware-rooted lifecycle protocol, adapter pruning, multi-provider aggregation, and split-execution scheduling together make this design practical at serving time. On SST-2, MNLI, and SQuAD with GPT-2 Large and Llama-3.2-1B, PKUS preserves model utility, matching the accuracy and F1 of full fine-tuning and plain LoRA, while achieving the lowest per-request latency with 8.1-11.9x speedup over CPU-only TEE inference and naive CPU-GPU co-execution.|
|**2025-12-18**|[Trustworthy and Controllable Professional Knowledge Utilization in Large Language Models with TEE-GPU Execution](http://arxiv.org/abs/2512.16238)|null|大语言模型（LLM）服务的未来改进越来越依赖于访问高价值专业知识，而非更通用的网络数据。然而，这些知识的数据提供者面临着收益与风险之间不对称的权衡：他们在下游价值中获得的份额很少，却仍需承担版权和隐私责任，这使得他们不愿将自己的资产贡献给LLM服务。现有技术未能提供一种可信且可控的方式来使用专业知识，因为它们让提供者蒙在鼓里，并将知识参数与底层LLM骨干模型相结合。在本文中，我们提出了PKUS，即专业知识利用系统，它将专业知识视为一流的、可分离的工件。PKUS将骨干模型保留在GPU上，并将每个提供者的贡献编码为一个紧凑的适配器，该适配器仅在经认证的可信执行环境（TEE）内部执行。基于硬件的生命周期协议、适配器剪枝、多提供者聚合和分段执行调度共同使该设计在服务时具有实用性。在SST-2、MNLI和SQuAD数据集上，使用GPT-2 Large和Llama-3.2-1B模型，PKUS保持了模型效用，匹配了完全微调和普通LoRA的准确率和F1分数，同时实现了最低的单请求延迟，相较于仅使用CPU的TEE推理和朴素的CPU-GPU协同执行，速度提升了8.1-11.9倍。|
|**2025-12-19**|[Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation](http://arxiv.org/abs/2512.16189)|null|在医疗保健领域，任何LLM生成输出都必须可靠且准确，尤其是在涉及决策制定和患者安全的情况下。然而，由于LLM存在生成幻觉输出的风险，其输出在这些关键领域往往不可靠。为解决此问题，我们提出一个独立于任何LLM运行的事实核查模块，以及一个旨在最小化幻觉率的领域特定摘要模型。我们的模型使用低秩适应 (LoRa) 在MIMIC III数据集上进行微调，并与事实核查模块配对，该模块通过自然语言处理 (NLP) 中的离散逻辑，利用数值正确性测试和细粒度逻辑检查来根据电子健康记录 (EHR) 验证事实。我们在完整的MIMIC-III数据集上训练了LLM模型。为了评估事实核查模块，我们抽取了104份摘要，将其提取为3,786个命题，并将其用作事实。事实核查模块达到了0.8904的精确率、0.8234的召回率和0.8556的F1分数。此外，LLM摘要模型在摘要质量方面达到了0.5797的ROUGE-1分数和0.9120的BERTScore。|
|**2025-12-18**|[Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation](http://arxiv.org/abs/2512.16189)|null|在医疗保健领域，任何LLM生成的内容都必须可靠和准确，尤其是在涉及决策和患者安全的情况下。然而，在这些关键领域，由于LLM存在幻觉输出的风险，其生成的内容往往不可靠。为解决这个问题，我们提出了一个独立于任何LLM运行的事实核查模块，以及一个旨在最小化幻觉率的领域专属摘要模型。我们的模型使用低秩适应 (LoRa) 在MIMIC III数据集上进行微调，并与事实核查模块配对；该模块通过自然语言处理 (NLP) 中的离散逻辑，在细粒度级别使用数值测试进行正确性检查和逻辑检查，以根据电子健康记录 (EHR) 验证事实。我们在完整的MIMIC-III数据集上训练了LLM模型。为了评估事实核查模块，我们抽取了104份摘要，将其提取为3,786个命题，并将其用作事实。事实核查模块的精确率达到了0.8904，召回率达到了0.8234，F1分数为0.8556。此外，LLM摘要模型在摘要质量方面达到了0.5797的ROUGE-1分数和0.9120的BERTScore。|
|**2025-12-17**|[How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](http://arxiv.org/abs/2512.15634)|null|大型语言模型正越来越多地通过微调适配到下游任务。全监督微调 (SFT) 和参数高效微调 (PEFT) 方法，例如低秩适应 (LoRA)，是两种主要方法。尽管PEFT方法因其计算效率而被广泛使用，但其配置（例如秩）在下游问答任务和泛化能力方面的影响仍未得到充分探索。在这项工作中，我们跨多个推理和回忆数据集进行了全面评估，通过执行秩扫描来量化SFT和PEFT之间的权衡。我们还比较了PEFT和SFT模型在域内和域外适应中的准确性，突出了不同的泛化行为和任务特异性遗忘。我们证明，LoRA与SFT相比，取得了具有竞争力甚至在某些情况下更优的性能，尤其是在特定秩值下的推理任务上。此外，我们通过谱特征和逐层注意力结构分析了内部表示，为表示漂移和注意力模式的结构变化提供了见解。|
|**2025-12-17**|[Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](http://arxiv.org/abs/2512.15226)|null|This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.|
|**2025-12-16**|[Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](http://arxiv.org/abs/2512.14926)|null|聚焦低资源语言是普及生成式AI的关键一步。在本文中，我们致力于缩小罗马尼亚语的多模态自然语言处理资源鸿沟。我们将广为人知的Flickr30k数据集翻译成罗马尼亚语，并通过利用开源大型语言模型进一步扩展其用于视觉问答。我们通过在罗马尼亚语视觉问答任务上微调开源视觉语言模型，展示了我们数据集的实用性。我们从三个广泛使用的模型家族中选择了视觉语言模型：LLaMA 3.2、LLaVA 1.6和Qwen2。为了进行微调，我们采用了参数高效的LoRA方法。我们的模型在视觉问答方面展现出改进的罗马尼亚语能力，并且在未曾训练过的任务（例如罗马尼亚语图像描述生成）上也表现良好。七十亿参数的Qwen2-VL-RoVQA在两项任务上均取得了最佳分数，相较于其原始版本，BERTScore F1分数分别提高了+6.05%和+2.61%。最后，这些模型与原始形式相比，语法错误显著减少，表明不仅在语言理解方面，而且在罗马尼亚语流利度方面也得到了改进。|
|**2025-12-16**|[Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets](http://arxiv.org/abs/2512.14237)|null|大语言模型（LLM）的微调常常受限于商用GPU上的可用内存。诸如QLoRA等参数高效微调（PEFT）方法减少了可训练参数的数量，但由于全模型中的反向传播，仍然会产生高内存使用量。我们重新审视了Ladder Side Tuning (LST)这种鲜有探索的PEFT技术，它添加了一个轻量级的旁路网络，并表明它在计算扩展斜率上与QLoRA相当，同时将峰值内存削减了50%。在涵盖自然语言理解、数学和LLM批评任务等不同下游基准测试中，LST的平均性能与QLoRA的准确性相当，同时内存效率更高。这种效率使得70亿参数模型的微调可以在单个12 GB消费级GPU上进行，使用2k-token的上下文且无需梯度检查点，而在这些条件下QLoRA会耗尽内存。除了内存效率之外，我们还建立了扩展定律，表明LST的扩展方式与QLoRA相似。我们利用了Ladder的架构灵活性，引入了xLadder，这是一种深度扩展变体，它通过交叉连接增加了有效深度，并在固定参数量下缩短了思维链（CoT）。当内存是瓶颈时，Ladder表现出色；xLadder在此基础上，通过实现更深层次的推理而不增加额外的内存开销。|
|**2025-12-16**|[Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](http://arxiv.org/abs/2512.13996)|null|稀疏专家混合 (MoE) 架构通过仅激活每个输入词元的一部分专家来有效扩展模型容量。然而，标准的 Top-k 路由策略施加了统一的稀疏模式，忽略了词元的不同难度。虽然 Top-p 路由提供了一种灵活的替代方案，但现有实现通常依赖于固定的全局概率阈值，这导致计算成本不受控制且对超参数选择敏感。在本文中，我们提出了 DTop-p MoE，一种稀疏度可控的动态 Top-p 路由机制。为了解决优化不可微分阈值的挑战，我们利用了一个比例积分 (PI) 控制器，它动态调整概率阈值，使运行中的激活专家稀疏度与指定目标对齐。此外，我们引入了一种动态路由归一化机制，该机制调整逐层路由逻辑值，允许不同层学习独特的专家选择模式，同时利用全局概率阈值。在大型语言模型和扩散 Transformer 上的大量实验表明，DTop-p 持续优于 Top-k 和固定阈值 Top-p 基线。我们的分析证实，DTop-p 能够精确控制激活专家的数量，同时自适应地在不同词元和层之间分配资源。此外，DTop-p 在专家粒度、专家容量、模型大小和数据集大小方面展现出强大的扩展性，为大规模 MoE 预训练提供了一个鲁棒的框架。|
|**2025-12-15**|[Large-Language Memorization During the Classification of United States Supreme Court Cases](http://arxiv.org/abs/2512.13654)|null|大语言模型(LLM)已被证明在问答之外的分类任务中能以多种方式响应。LLM的响应有时被称为“幻觉”，因为其输出不符合预期。针对LLM中的记忆策略正在进行详细研究，旨在理解LLM如何响应。我们深入研究了一个基于美国最高法院(SCOTUS)判决的分类任务。SCOTUS语料库是研究LLM记忆准确性的理想分类任务，因为它在句子长度过长、法律术语复杂、结构非标准化和领域特定词汇方面带来了显著挑战。实验采用了最新的LLM微调和检索式方法，例如参数高效微调、自动建模等，在两个传统的基于类别的SCOTUS分类任务上进行，其中一个有15个标注主题，另一个有279个。我们发现，带有记忆的基于提示的模型（例如DeepSeek）在两项任务上比之前的基于BERT的模型更鲁棒，表现比之前非基于提示的模型约好2分。|
|**2025-12-16**|[MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning](http://arxiv.org/abs/2512.13636)|**[link](https://github.com/xiaomi-mlab/MindDrive)**|Current Vision-Language-Action (VLA) paradigms in autonomous driving primarily rely on Imitation Learning (IL), which introduces inherent challenges such as distribution shift and causal confusion. Online Reinforcement Learning offers a promising pathway to address these issues through trial-and-error learning. However, applying online reinforcement learning to VLA models in autonomous driving is hindered by inefficient exploration in continuous action spaces. To overcome this limitation, we propose MindDrive, a VLA framework comprising a large language model (LLM) with two distinct sets of LoRA parameters. The one LLM serves as a Decision Expert for scenario reasoning and driving decision-making, while the other acts as an Action Expert that dynamically maps linguistic decisions into feasible trajectories. By feeding trajectory-level rewards back into the reasoning space, MindDrive enables trial-and-error learning over a finite set of discrete linguistic driving decisions, instead of operating directly in a continuous action space. This approach effectively balances optimal decision-making in complex scenarios, human-like driving behavior, and efficient exploration in online reinforcement learning. Using the lightweight Qwen-0.5B LLM, MindDrive achieves Driving Score (DS) of 78.04 and Success Rate (SR) of 55.09% on the challenging Bench2Drive benchmark. To the best of our knowledge, this is the first work to demonstrate the effectiveness of online reinforcement learning for the VLA model in autonomous driving.|
|**2025-12-12**|[Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning](http://arxiv.org/abs/2512.11485)|null|大语言模型 (LLM) 通过梯度微调（计算量大，存在灾难性遗忘）或上下文学习 (ICL)（鲁棒性差，错误学习能力不足）来适应任务。为此，我们引入了错误笔记学习 (MNL)，这是一个免训练框架，其具有一个持久化的抽象化错误模式知识库。与以往的实例/单轨迹记忆方法不同，MNL 采用批次级错误抽象：它从多次失败中提取可泛化的指导，将洞察存储在动态笔记簿中，并通过留出验证仅保留优于基线的指导（确保单调改进）。我们展示了 MNL 在 GSM8K 上几乎媲美监督微调（93.9% 对 94.3%），并在 GSM8K、Spider、AIME 和 KaggleDBQA 上优于免训练替代方法。在 KaggleDBQA (Qwen3-8B) 上，MNL 达到了 28% 的准确率（相对增益 47%），优于 Memento（15.1%）和 Training-Free GRPO（22.1），证明它是一种用于复杂推理的强大免训练替代方案。|
|**2025-12-12**|[qa-FLoRA: Data-free query-adaptive Fusion of LoRAs for LLMs](http://arxiv.org/abs/2512.11366)|null|大型语言模型在专门任务中的部署通常需要通过低秩适应（LoRA）模块进行领域专用参数高效微调。然而，有效融合这些适配器以处理复杂、多领域的复合查询仍然是一个关键挑战。现有的LoRA融合方法要么使用静态权重，为每个参与的LoRA分配相同的相关性，要么需要针对每种可能的LoRA组合进行数据密集型监督训练以获取各自的最佳融合权重。我们提出了qa-FLoRA，一种新颖的查询自适应、无数据、免训练的LoRA融合方法，它通过测量基础模型和各自适配器之间的分布散度，动态计算层级融合权重。我们的方法消除了对复合训练数据或领域代表性样本的需求，使其易于应用于现有适配器集合。跨九个涵盖数学、编码和医疗领域的多语言复合任务的大量实验表明，qa-FLoRA在LLaMA-2上优于静态融合约5%，在LLaMA-3上优于约6%，在LLaMA-2上优于免训练基线约7%，在LLaMA-3上优于约10%，同时显著缩小了与监督基线之间的差距。此外，我们融合权重的层级分析揭示了可解释的融合模式，证明了我们方法在鲁棒多领域适应方面的有效性。|
|**2025-12-11**|[LDP: Parameter-Efficient Fine-Tuning of Multimodal LLM for Medical Report Generation](http://arxiv.org/abs/2512.10750)|null|结肠镜息肉诊断对结直肠癌的早期检测至关重要，然而，由于高质量多模态医疗数据的稀缺，传统的自动化报告存在不一致性和幻觉问题。为了弥补这一空白，我们提出了LDP，一个利用多模态大语言模型（MLLMs）生成专业息肉诊断报告的新颖框架。具体来说，我们整理了MMEndo，这是一个包含专家标注的结肠镜图像-文本对的多模态内窥镜数据集。我们采用参数高效微调（LoRA）对Qwen2-VL-7B骨干模型进行微调，并通过直接偏好优化（DPO）使其符合临床标准。大量实验表明，我们的LDP在自动化指标和严格的临床专家评估中均优于现有基线（获得了7.2/10的医生评分），并且与完全微调相比，显著降低了833倍的训练计算成本。所提出的解决方案为初级医疗保健提供了一条可扩展、临床可行的路径，此外，在IU-XRay数据集上的额外验证也证实了其鲁棒性。|
|**2025-12-11**|[Multilingual VLM Training: Adapting an English-Trained VLM to French](http://arxiv.org/abs/2512.10336)|null|人工智能近年来取得了巨大进展，特别是在能够理解视觉和文本数据的视觉-语言模型（VLM）的发展方面。然而，这些进展在很大程度上仍局限于英语，降低了非英语使用者的可及性。将这些能力扩展到更广泛的语言至关重要。本文探讨了将英语训练的VLM适应不同语言的挑战。为此，我们将探索和比较不同的方法以评估它们的性能和计算成本。我们考虑了基于翻译的管道、LoRA微调以及一种将视觉适应与语言适应分离的两阶段微调策略。为了评估这些方法，我们结合使用了翻译成目标语言的标准多模态基准以及母语专家的手动评估。结果表明，数据集翻译仍然是多语言VLM性能的主要瓶颈，数据质量限制了训练和评估的有效性。这些发现表明，未来的工作应侧重于母语数据集收集和改进的翻译策略。|
|**2025-12-10**|[Black-Box Behavioral Distillation Breaks Safety Alignment in Medical LLMs](http://arxiv.org/abs/2512.09403)|null|随着医疗大型语言模型 (LLMs) 逐渐融入临床工作流程，人们对齐鲁棒性和安全性的担忧日益加剧。先前关于模型提取的工作侧重于分类模型或记忆泄露，使得安全对齐的生成式医疗大型语言模型的脆弱性尚未得到充分探索。我们提出了一种黑盒蒸馏攻击，仅通过输出层访问即可复制安全对齐医疗 LLMs 的领域特定推理能力。通过向 Meditron-7B 发出 48,000 条指令查询并收集 25,000 对良性指令响应，我们在零对齐监督设置下，通过参数高效的 LoRA 对一个 LLaMA3 8B 替代模型进行微调，无需访问模型权重、安全过滤器或训练数据。仅花费 12 美元，该替代模型在良性输入上实现了强大的保真度，同时对 86% 的对抗性提示生成不安全的补全内容，远超 Meditron-7B (66%) 和未调优的基础模型 (46%)。这揭示了一个显著的功能-伦理鸿沟，即任务效用得以转移，而对齐却崩溃了。为了分析这种崩溃，我们开发了一个动态对抗性评估框架，结合了基于生成查询 (GQ) 的有害提示生成、验证器过滤、分类故障分析以及自适应随机搜索 (RS) 越狱攻击。我们还提出了一个分层防御系统，作为黑盒部署中实时对齐漂移的原型检测器。我们的研究结果表明，仅使用良性数据的黑盒蒸馏揭示了一个实用且未被充分认识的威胁：攻击者可以廉价地复制医疗 LLM 的能力，同时剥离其安全机制，这凸显了对提取感知安全监控的需求。|
|**2025-12-09**|[Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents](http://arxiv.org/abs/2512.08870)|null|LLM智能体广泛部署于复杂交互任务中，然而隐私约束常阻碍其在动态环境中进行集中式优化和协同演化。尽管联邦学习（FL）已被证明在静态数据集上有效，但将其扩展到智能体的开放式自我演化仍有待深入探索。直接应用标准联邦学习面临挑战：异构任务和稀疏的轨迹级奖励引入了严重的梯度冲突，破坏了全局优化过程的稳定性。为弥补这一不足，我们提出了Fed-SE，一个适用于LLM智能体的联邦自演化框架。Fed-SE建立了一个局部演化-全局聚合范式。在局部，智能体在过滤后的高回报轨迹上进行参数高效微调，以实现稳定的梯度更新。在全局，Fed-SE在一个解耦了环境特定动态的低秩子空间内聚合更新，有效减少了客户端之间的负迁移。在五个异构环境中的实验表明，Fed-SE将平均任务成功率比联邦基线提高了约18%，验证了其在隐私受限部署中实现鲁棒跨环境知识迁移的有效性。|
|**2025-12-09**|[MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones](http://arxiv.org/abs/2512.08211)|null|手机是最普遍的终端设备，生成海量由人类创作的数据，并作为终端侧应用的主要平台。随着大语言模型（LLM）的高质量公共数据日益枯竭，设备端微调提供了一个在利用私有用户数据的同时保护隐私的机会。然而，现有方法主要基于仿真或依赖物联网设备和个人电脑，使得商用手机在很大程度上未被探索。一个关键的空白是缺乏一个开源框架，能够在手机上实现实用的大语言模型微调。我们提出了MobileFineTuner，一个统一的开源框架，能够在商用手机上直接实现端到端的大语言模型微调。MobileFineTuner旨在提高效率、可扩展性和可用性，支持全参数微调（Full-FT）和参数高效微调（PEFT）。为解决手机固有的内存和能耗限制，我们引入了系统级优化，包括参数分片、梯度累积和能量感知计算调度。我们通过在真实手机上微调GPT-2、Gemma 3和Qwen 2.5，展示了MobileFineTuner的实用性。广泛的实验和消融研究验证了所提出优化的有效性，并将MobileFineTuner确立为未来设备端大语言模型训练研究的可行基础。|
|**2025-12-09**|[Information-Dense Reasoning for Efficient and Auditable Security Alert Triage](http://arxiv.org/abs/2512.08169)|null|Security Operations Centers face massive, heterogeneous alert streams under minute-level service windows, creating the Alert Triage Latency Paradox: verbose reasoning chains ensure accuracy and compliance but incur prohibitive latency and token costs, while minimal chains sacrifice transparency and auditability. Existing solutions fail: signature systems are brittle, anomaly methods lack actionability, and fully cloud-hosted LLMs raise latency, cost, and privacy concerns. We propose AIDR, a hybrid cloud-edge framework that addresses this trade-off through constrained information-density optimization. The core innovation is gradient-based compression of reasoning chains to retain only decision-critical steps--minimal evidence sufficient to justify predictions while respecting token and latency budgets. We demonstrate that this approach preserves decision-relevant information while minimizing complexity. We construct compact datasets by distilling alerts into 3-5 high-information bullets (68% token reduction), train domain-specialized experts via LoRA, and deploy a cloud-edge architecture: a cloud LLM routes alerts to on-premises experts generating SOAR-ready JSON. Experiments demonstrate AIDR achieves higher accuracy and 40.6% latency reduction versus Chain-of-Thought, with robustness to data corruption and out-of-distribution generalization, enabling auditable and efficient SOC triage with full data residency compliance.|
|**2025-12-08**|[PVeRA: Probabilistic Vector-Based Random Matrix Adaptation](http://arxiv.org/abs/2512.07703)|null|Large foundation models have emerged in the last years and are pushing performance boundaries for a variety of tasks. Training or even finetuning such models demands vast datasets and computational resources, which are often scarce and costly. Adaptation methods provide a computationally efficient solution to address these limitations by allowing such models to be finetuned on small amounts of data and computing power. This is achieved by appending new trainable modules to frozen backbones with only a fraction of the trainable parameters and fitting only these modules on novel tasks. Recently, the VeRA adapter was shown to excel in parameter-efficient adaptations by utilizing a pair of frozen random low-rank matrices shared across all layers. In this paper, we propose PVeRA, a probabilistic version of the VeRA adapter, which modifies the low-rank matrices of VeRA in a probabilistic manner. This modification naturally allows handling inherent ambiguities in the input and allows for different sampling configurations during training and testing. A comprehensive evaluation was performed on the VTAB-1k benchmark and seven adapters, with PVeRA outperforming VeRA and other adapters. Our code for training models with PVeRA and benchmarking all adapters is available https://github.com/leofillioux/pvera.|
|**2025-12-08**|[Bridging Code Graphs and Large Language Models for Better Code Understanding](http://arxiv.org/abs/2512.07666)|**[link](https://github.com/jettbrains/-L-)**|Large Language Models (LLMs) have demonstrated remarkable performance in code intelligence tasks such as code generation, summarization, and translation. However, their reliance on linearized token sequences limits their ability to understand the structural semantics of programs. While prior studies have explored graphaugmented prompting and structure-aware pretraining, they either suffer from prompt length constraints or require task-specific architectural changes that are incompatible with large-scale instructionfollowing LLMs. To address these limitations, this paper proposes CGBridge, a novel plug-and-play method that enhances LLMs with Code Graph information through an external, trainable Bridge module. CGBridge first pre-trains a code graph encoder via selfsupervised learning on a large-scale dataset of 270K code graphs to learn structural code semantics. It then trains an external module to bridge the modality gap among code, graph, and text by aligning their semantics through cross-modal attention mechanisms. Finally, the bridge module generates structure-informed prompts, which are injected into a frozen LLM, and is fine-tuned for downstream code intelligence tasks. Experiments show that CGBridge achieves notable improvements over both the original model and the graphaugmented prompting method. Specifically, it yields a 16.19% and 9.12% relative gain in LLM-as-a-Judge on code summarization, and a 9.84% and 38.87% relative gain in Execution Accuracy on code translation. Moreover, CGBridge achieves over 4x faster inference than LoRA-tuned models, demonstrating both effectiveness and efficiency in structure-aware code understanding.|
|**2025-12-08**|[Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning](http://arxiv.org/abs/2512.07454)|null|人工智能的民主化目前受到为低资源语言训练大型语言模型 (LLM) 所需的巨大计算成本的阻碍。本文介绍了 Persian-Phi，一个38亿参数模型，它挑战了强大的多语言能力需要巨大模型规模或多语言基线的假设。我们展示了微软 Phi-3 Mini——最初是一个单语英语模型——如何通过一种新颖的、资源高效的课程学习管道有效地适应波斯语。我们的方法采用一个独特的“热身”阶段，利用双语叙事（Tiny Stories）在大量训练前对齐嵌入，随后通过参数高效微调 (PEFT) 进行持续预训练和指令微调。尽管其规模紧凑，Persian-Phi 在 HuggingFace 上的开放波斯语 LLM 排行榜上取得了有竞争力的结果。我们的发现提供了一个经过验证的、可扩展的框架，用于以最少的硬件资源将最先进的 LLM 覆盖范围扩展到代表性不足的语言。Persian-Phi 模型可在 https://huggingface.co/amirakhlaghiqqq/PersianPhi 公开获取。|
|**2025-12-08**|[LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples](http://arxiv.org/abs/2512.07375)|null|大语言模型(LLM)拥有从大量训练语料库中获取的庞大知识，但它们通常无法在需要时删除特定信息片段，这使得处理隐私、偏见缓解和知识纠正变得困难。传统的模型遗忘方法需要计算成本高昂的微调或直接权重编辑，这使得它们在实际部署中不切实际。本文介绍了一种基于LoRA的负例遗忘(LUNE)，这是一个轻量级框架，它通过仅更新低秩适配器同时冻结主干网络来执行仅负例遗忘，从而局部化编辑并避免破坏性的全局改变。LUNE利用低秩适应(LoRA)，针对中间表示来抑制（或替换）请求的知识，其计算和内存开销比全量微调或直接权重编辑低一个数量级。在多个事实遗忘任务上进行的大量实验表明，LUNE：(I) 实现了与全量微调和内存编辑方法相当的有效性，并且 (II) 将计算成本降低了大约一个数量级。|
|**2025-12-04**|[Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning](http://arxiv.org/abs/2512.05105)|null|大语言模型（LLM）中的长上下文推理已通过思维链（CoT）推理展现出其认知能力的增强。这类模型的训练通常通过基于可验证奖励的强化学习（RLVR）在数学和编程等基于推理的问题中进行。然而，RLVR受到几个瓶颈的限制，例如，缺乏密集奖励和样本效率不足。因此，它在后训练阶段需要大量的计算资源。为了克服这些限制，在这项工作中，我们提出了一种自蒸馏技术——语义软自举（SSB），其中相同的基本语言模型同时扮演教师和学生的角色，但在训练时接收关于其结果正确性的不同语义上下文。模型首先被提示一个数学问题，并生成多个推理过程。从中筛选出正确响应和最常见的错误响应，然后在上下文中提供给模型，以生成更鲁棒、逐步的解释和经过验证的最终答案。该流程无需任何人工干预，即可从原始问题-答案数据中自动整理出配对的教师-学生训练集。这个生成过程还会产生一个logits序列，学生模型在训练阶段仅凭问题本身就尝试匹配这个序列。在我们的实验中，我们对Qwen2.5-3B-Instruct模型在GSM8K数据集上进行了参数高效微调。随后，我们在MATH500和AIME2024基准测试上测试了其准确率。我们的实验表明，与常用的RLVR算法组相对策略优化（GRPO）相比，准确率分别提升了10.6%和10%。我们的代码可在https://github.com/purbeshmitra/semantic-soft-bootstrapping获取，模型和整理后的数据集可在https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping获取。|
|**2025-12-04**|[David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?](http://arxiv.org/abs/2512.05073)|null|大语言模型（LLM）推理需要大量的计算和能源，使得领域特定任务变得昂贵且不可持续。随着基础模型不断扩展，我们提出疑问：对于硬件设计而言，越大总是越好吗？我们的工作通过在NVIDIA的综合Verilog设计问题（CVDP）基准上评估小型语言模型与精心策划的智能体AI框架相结合来验证这一点。结果表明，智能体工作流——通过任务分解、迭代反馈和纠正——不仅以一小部分成本实现了接近大语言模型的性能，还为智能体创造了学习机会，为复杂设计任务中的高效、自适应解决方案铺平了道路。|
|**2025-12-04**|[Generative Neural Video Compression via Video Diffusion Prior](http://arxiv.org/abs/2512.05016)|null|我们提出了GNVC-VD，这是首个基于DiT的生成式神经视频压缩框架，它建立在先进的视频生成基础模型之上，将时空潜在压缩和序列级生成式细化统一在一个编解码器中。现有感知编解码器主要依赖预训练图像生成先验来恢复高频细节，但其帧级特性缺乏时间建模，不可避免地导致感知闪烁。为解决此问题，GNVC-VD引入了一个统一的流匹配潜在细化模块，该模块利用视频扩散Transformer通过序列级去噪联合增强帧内和帧间潜在信息，确保一致的时空细节。GNVC-VD与视频生成中从纯高斯噪声去噪不同，它从解码后的时空潜在信息初始化细化，并学习一个校正项以使扩散先验适应压缩引起的退化。一个条件适配器进一步将压缩感知提示注入到中间DiT层中，从而在极端比特率限制下有效去除伪影并保持时间连贯性。大量实验表明，GNVC-VD在感知质量方面超越了传统和学习型编解码器，并显著减少了以往生成方法中持续存在的闪烁伪影，即使在低于0.01 bpp的情况下也表现出色，这凸显了将视频原生生成先验集成到神经编解码器中用于下一代感知视频压缩的巨大潜力。|
|**2025-12-04**|[Reflection Removal through Efficient Adaptation of Diffusion Transformers](http://arxiv.org/abs/2512.05000)|null|我们引入了一种扩散变换器（DiT）框架用于单幅图像反射去除，该框架利用了基础扩散模型在图像修复设置中的泛化能力。我们没有依赖任务特定的架构，而是通过以受反射污染的输入为条件并引导其生成清晰的透射层，来重新利用一个预训练的基于DiT的基础模型。我们系统地分析了现有的反射去除数据源在多样性、可扩展性和真实感方面的表现。为了解决适用数据短缺的问题，我们在Blender中构建了一个围绕Principled BSDF的基于物理渲染（PBR）管线，以合成逼真的玻璃材质和反射效果。基础模型的高效LoRA微调，结合所提出的合成数据，在域内和零样本基准测试中均取得了最先进的性能。这些结果表明，预训练的扩散变换器与基于物理的数据合成和高效微调相结合，为反射去除提供了一种可扩展且高保真度的解决方案。项目页面：https://hf.co/spaces/huawei-bayerlab/windowseat-reflection-removal-web|
|**2025-12-04**|[Strategic Self-Improvement for Competitive Agents in AI Labour Markets](http://arxiv.org/abs/2512.04988)|null|随着人工智能（AI）代理被部署到各个经济领域，理解它们的战略行为和市场层面影响变得至关重要。本文提出一个开创性的新框架，首次捕捉了塑造代理劳动力市场的现实经济力量：逆向选择、道德风险和声誉动态。我们的框架包含成功的LLM代理所需的三项核心能力：元认知（对技能的准确自我评估）、竞争意识（模拟竞争对手和市场动态）以及长期战略规划。我们通过一个可控的模拟零工经济来阐明我们的框架，在该经济中，代理式大型语言模型（LLM）竞争工作、发展技能并在竞争压力下调整策略。我们的模拟阐明了被明确提示具备推理能力的LLM代理如何学习战略性自我提升，并表现出对不断变化的市场条件的卓越适应性。在市场层面，我们的模拟重现了在人类劳动力市场中发现的经典宏观经济现象，而受控实验则揭示了潜在的AI驱动经济趋势，例如快速垄断和系统性价格通缩。这项工作为进一步探索AI驱动劳动力市场的经济特性奠定了基础，并提供了一个概念框架来研究在新兴经济中竞争的代理的战略推理能力。|
|**2025-12-04**|[LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging](http://arxiv.org/abs/2512.04939)|**[link](https://github.com/GarlicBa/LiteVGGT-repo)**|3D视觉基础模型，如视觉几何基础Transformer (VGGT)，在几何感知方面取得了巨大进展。然而，对于长序列来说，它耗时且内存密集，限制了其在超出数百张图像的大规模场景中的应用。为解决此问题，我们提出了LiteVGGT，实现了高达10倍的加速和显著的内存减少，从而能够高效处理1000张图像的场景。我们针对3D重建得出了两个关键见解：(1) 来自局部图像区域的tokens具有固有的几何相关性，导致高相似性和计算冗余；(2) 相邻网络层之间的token相似性保持稳定，允许可复用的合并决策。受此启发，我们设计了一种简单而高效的策略，称之为几何感知缓存token合并。我们分析了每个token的几何重要性，优化了锚点token的选择，以更好地保留重建所需的关键信息。我们还缓存并复用跨层的合并索引，在对准确性影响最小的情况下大幅减少了延迟。该策略保留了VGGT的核心性能，并实现了高效微调和FP8量化，以获得进一步的提升。大量实验验证了LiteVGGT的有效性、可扩展性和鲁棒性。项目页面：https://garlicba.github.io/LiteVGGT/|
|**2025-12-04**|[STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions](http://arxiv.org/abs/2512.04871)|null|近期将大型语言模型 (LLM) 应用于时间序列预测的方法，往往未能有效增强原始序列的信息，导致 LLM 的推理能力未被充分利用。现有的提示策略依赖于静态相关性，而非对动态行为的生成式解释，因此缺乏关键的全局和实例特定的上下文。为了解决这个问题，我们提出了 STELLA (语言抽象的语义-时间对齐)，这是一个系统地挖掘和注入结构化补充信息的框架。STELLA 采用一种动态语义抽象机制，将输入序列解耦为趋势、季节性和残差分量。接着，它将这些分量的内在行为特征转化为分层语义锚点：用于全局上下文的语料库级语义先验 (CSP) 和用于实例级模式的细粒度行为提示 (FBP)。STELLA 利用这些锚点作为前缀提示，引导 LLM 建模内在动态。在八个基准数据集上的实验表明，STELLA 在长期和短期预测中优于最先进的方法，并在零样本和少样本设置下展现出卓越的泛化能力。消融研究进一步验证了我们动态生成的语义锚点的有效性。|
|**2025-12-04**|[SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs](http://arxiv.org/abs/2512.04868)|null|基于知识的对话式问答（KBCQA）在指代消解、上下文依赖建模和复杂逻辑推理执行方面面临持续挑战。现有方法，无论是端到端语义解析还是逐步基于代理的推理，通常存在结构不准确性和巨大的计算成本，尤其是在处理大型知识图谱上的复杂查询时。为解决这些局限性，我们引入了SEAL，一个新颖的两阶段语义解析框架，其根植于自我演化代理学习。在第一阶段，一个大语言模型（LLM）提取一个最小S-表达式核心，该核心捕获输入查询的基本语义。然后，该核心通过一个代理校准模块进行精炼，该模块纠正语法不一致性并使实体和关系与底层知识图谱精确对齐。第二阶段采用基于模板的补全，在问题类型预测和占位符实例化的指导下，构建一个完全可执行的S-表达式。这种分解不仅简化了逻辑形式生成，而且显著增强了结构保真度和链接效率。关键地，SEAL整合了一个自我演化机制，该机制将局部和全局记忆与一个反思模块相结合，从而无需显式重新训练即可实现从对话历史和执行反馈中持续适应。在SPICE基准上进行的大量实验表明，SEAL实现了最先进的性能，尤其是在多跳推理、比较和聚合任务中。结果验证了在结构准确性和计算效率方面的显著提升，突显了该框架在鲁棒且可扩展的对话式推理方面的能力。|
|**2025-12-04**|[Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates](http://arxiv.org/abs/2512.04844)|null|扩展指令大语言模型（LLM）的语言多样性对全球可访问性至关重要，但常受阻于对昂贵的专业目标语言标注数据的依赖以及在适应过程中出现的灾难性遗忘。我们在一个现实的低资源约束下解决这一挑战：即仅使用未标注的目标语言数据来适应指令LLM。我们引入了源语言保护更新（Source-Shielded Updates, SSU），这是一种选择性参数更新策略，能够主动保留源语言知识。SSU利用少量源语言数据和一种参数重要性评分方法，识别对维持源语言能力至关重要的参数。然后，它在适应之前应用一种列式冻结策略以保护这些参数。在五种类型学上不同的语言以及7B和13B模型上的实验表明，SSU成功缓解了灾难性遗忘。它将单语源任务上的性能下降平均降低到仅3.4%（7B模型）和2.8%（13B模型），这与完全微调（full fine-tuning）导致的20.3%和22.3%形成了鲜明对比。SSU还在目标语言性能方面达到了与完全微调高度竞争的水平，在7B模型的所有基准测试和13B模型的大多数基准测试中均优于完全微调。|
|**2025-12-04**|[MemLoRA: Distilling Expert Adapters for On-Device Memory Systems](http://arxiv.org/abs/2512.04763)|null|记忆增强型大型语言模型 (LLMs) 通过存储相关记忆并将其作为上下文整合，在长期对话中展现出卓越的一致性。这种基于记忆的个性化在允许用户保持对话和数据私密的设备端设置中也至关重要。然而，记忆增强系统通常依赖于LLMs，而LLMs对于本地设备端部署而言成本过高。尽管小型语言模型 (SLMs) 比LLMs更适合设备端推理，但它们无法达到足够的性能。此外，这些基于LLM的系统缺乏原生视觉能力，限制了它们在多模态场景中的适用性。在本文中，我们介绍了 (i) MemLoRA，这是一种通过为SLMs配备专用记忆适配器来实现本地部署的新颖记忆系统，以及 (ii) 其视觉扩展MemLoRA-V，它将小型视觉-语言模型 (SVLMs) 整合到记忆系统中，从而实现原生视觉理解。遵循知识蒸馏原理，每个适配器都针对特定的记忆操作（知识提取、记忆更新和记忆增强生成）单独训练。借助记忆适配器，小型模型能够实现准确的设备端记忆操作，且无需云端依赖。在纯文本操作中，MemLoRA在LoCoMo基准测试上性能优于10倍大的基线模型（例如Gemma2-27B），并达到了与60倍大的模型（例如GPT-OSS-120B）相当的性能。为了评估视觉理解操作，我们扩展了LoCoMo，加入了需要直接视觉推理的挑战性视觉问答任务。在此方面，我们整合VLM的MemLoRA-V相比基于字幕的方法显示出显著改进（准确率81.3 vs. 23.7），同时在文本任务中保持强劲性能，证明了我们方法在多模态场景中的有效性。|
|**2025-12-02**|[The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models](http://arxiv.org/abs/2512.03026)|null|大语言模型（LLMs）的快速发展和适应性凸显了对道德一致性的需求，即在不同语境下保持伦理连贯推理的能力。现有对齐框架，旨在使模型行为与人类伦理和社会规范对齐的结构化方法，通常依赖静态数据集和事后评估，对伦理推理如何在不同语境或时间尺度上演变提供的洞察有限。本研究提出了道德一致性管道（MoCoP），一个无需数据集的闭环框架，用于持续评估和解释LLMs的道德稳定性。MoCoP在一个自持架构内结合了三个支持层：(i) 词汇完整性分析，(ii) 语义风险估计，以及 (iii) 基于推理的判断建模，该架构无需外部监督即可自主生成、评估和完善伦理场景。我们在GPT-4-Turbo和DeepSeek上的实证结果表明，MoCoP有效捕捉了纵向伦理行为，揭示了伦理维度和毒性维度之间存在强烈的负相关关系（相关系数 rET = -0.81, p 值小于 0.001），以及与响应延迟之间接近零的相关性（相关系数 rEL 大约等于 0）。这些发现表明，道德连贯性和语言安全性倾向于作为模型行为的稳定且可解释的特征出现，而非短期波动。此外，通过将伦理评估重新定义为一种动态的、与模型无关的道德自省形式，MoCoP为可扩展的持续审计提供了一个可复现的基础，并推动了自主AI系统中计算道德的研究。|
|**2025-12-02**|[TokenPowerBench: Benchmarking the Power Consumption of LLM Inference](http://arxiv.org/abs/2512.03024)|null|大语言模型（LLM）服务现在每天响应数十亿次查询，行业报告显示推理而非训练占总功耗的90%以上。然而，现有基准测试侧重于训练/微调或推理性能，很少支持推理功耗测量和分析。我们引入了TokenPowerBench，这是首个专为LLM推理功耗研究设计的轻量级、可扩展的基准测试。该基准测试结合了(i)涵盖模型选择、提示集和推理引擎的声明式配置接口，(ii)无需专用功率计即可捕获GPU、节点和系统级功耗的测量层，以及(iii)将能量归因于每个请求的预填充和解码阶段的相位对齐指标管道。这些元素使得探索LLM推理运行所消耗的功耗变得简单；此外，通过改变批处理大小、上下文长度、并行策略和量化，用户可以快速评估每种设置如何影响每token焦耳数和其他能效指标。我们在四个最广泛使用的模型系列（Llama、Falcon、Qwen和Mistral）上评估了TokenPowerBench。我们的实验涵盖从10亿参数直到前沿规模的Llama3-405B模型。此外，我们将TokenPowerBench作为开源发布，以帮助用户在部署LLM服务时测量功耗、预测运营成本并达到可持续发展目标。|
|**2025-12-02**|[The Evolutionary Ecology of Software: Constraints, Innovation, and the AI Disruption](http://arxiv.org/abs/2512.02953)|null|本章研究软件的演化生态学，重点关注软件与创新之间的共生关系。约束、修补和频率依赖选择之间的相互作用驱动着这些社会技术系统复杂的演化轨迹。我们的方法整合了基于代理的建模和案例研究，借鉴复杂网络分析和演化理论，以探索软件如何在新颖性生成和模仿的竞争力量下演化。通过考察编程语言的演化及其对开发者实践的影响，我们阐明了技术制品如何与社会规范、文化动态和人际互动共同演化并塑造它们。这种生态学视角也为我们分析AI驱动的开发工具在软件演化中新兴作用提供了启发。尽管大语言模型（LLM）提供了前所未有的信息获取能力，但它们的广泛采用引入了新的演化压力，这可能导致文化停滞，如同过去软件生态系统中多样性的下降。理解AI介导的软件生产所引入的演化压力，对于预测更广泛的文化变革、技术适应以及软件创新的未来至关重要。|
|**2025-12-02**|[VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling](http://arxiv.org/abs/2512.02902)|null|视觉-语言-动作 (VLA) 模型在分布内表现出强大的性能，但在新颖的摄像机视角和视觉扰动下性能会急剧下降。我们发现这种脆弱性主要源于空间建模中的错位，而非物理建模。为解决此问题，我们提出了一种一次性适应框架，通过轻量级、可学习的更新来重新校准视觉表征。我们的第一个方法是特征令牌调制 (FTM)，它对视觉令牌应用全局仿射变换，仅用4K参数就将Libero的视角准确率从48.5%提高到87.1%。在此基础上，特征线性适应 (FLA) 为ViT编码器引入低秩更新，以4.7M参数实现了90.8%的成功率——以远低于LoRA的成本达到了LoRA规模的微调效果。综上所述，这些结果揭示了预训练VLA模型中大量未开发的鲁棒性，并证明有针对性、最小化的视觉适应足以恢复视角泛化能力。|
|**2025-12-02**|[MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm](http://arxiv.org/abs/2512.02895)|null|我们提出了MindGPT-4ov，这是一种多模态大语言模型（MLLM），它引入了一种涵盖数据生产、模型训练和高效部署的通用后训练范式。它以低成本在多个基准测试中取得了最先进的性能，有效增强了MLLM的基础能力和泛化能力。本工作聚焦于数据构建、监督微调策略和多模态强化学习方法，提出了三项关键创新：(1) 一种基于信息密度的数据生成方案，结合双维度树形标签系统，能够自动化生成高质量的跨领域数据。(2) 一种协同课程监督微调方法，平衡了领域特定知识的注入与通用能力的保持。(3) 一种混合强化学习范式，在增强推理能力的同时，解决了多样性探索、多模态感知的维持和响应简洁性等多目标优化问题。此外，我们还实施了一系列基础设施优化，例如5D并行训练、算子优化和推理量化，以提高训练和推理效率，同时降低领域适应成本。实验结果表明，MindGPT-4ov模型在MMBench、MMStar、MathVision和MathVista等基准测试中超越了最先进的模型。此外，MindGPT-4ov在垂直领域任务中也展现出卓越的用户体验，实现了从学术研究到工业部署的无缝过渡。MindGPT-4ov提供了一种适用于广泛MLLM的通用后训练范式。基于Qwen3-VL变体的模型权重、数据集和代码将于近期开源，以支持社区对MLLM的开发。|
|**2025-12-02**|[OptPO: Optimal Rollout Allocation for Test-time Policy Optimization](http://arxiv.org/abs/2512.02882)|null|测试时策略优化使大语言模型 (LLMs) 能够通过利用自生成rollout的反馈来适应分布偏移。然而，现有方法依赖固定预算的多数投票来估计奖励，导致大量的计算冗余。我们提出了用于测试时策略优化的最优Rollout分配方法 (OptPO)，这是一个能够自适应地分配推理预算的原则性框架。通过将投票过程表述为贝叶斯序贯概率比检验，OptPO在对共识答案的后验置信度超过指定阈值时动态停止采样。重要的是，它利用保留的rollout进行在线策略更新，无需真实标签即可无缝集成PPO或GRPO等算法。在各种推理基准测试中，与固定采样基线相比，OptPO显著降低了rollout开销，同时保持或提高了准确性。通过将统计最优停止与测试时学习相结合，OptPO为测试时适应提供了一种计算高效的范式。源代码将在论文接受后公开，网址为 https://open-upon-acceptance。|
|**2025-12-02**|[Network Self-Configuration based on Fine-Tuned Small Language Models](http://arxiv.org/abs/2512.02861)|null|随着现代网络规模和复杂性的增长，手动配置变得越来越低效且容易出错。尽管使用大型语言模型（LLM）的意图驱动自配置已展现出巨大潜力，但此类模型计算成本高昂、资源密集，并且由于通常依赖外部云基础设施，常常引发隐私问题。本工作介绍SLM_netconfig，这是一个经过微调的小型语言模型（SLM）框架，它采用基于代理的架构和参数高效适应技术，将以自然语言需求或问题形式表达的配置意图转化为语法和语义均有效的网络配置。该系统在一个通过源自供应商文档的流程生成领域特定数据集上进行训练，确保与实际配置实践高度一致。广泛的评估表明，SLM_netconfig在使用其问答式配置模型时，比LLM-NetCFG取得了更高的语法准确性和目标准确性，同时大幅降低了翻译延迟，并生成了简洁、可解释的配置。这些结果表明，SLM_netconfig中实现的微调小型语言模型能够完全在本地提供高效、准确且保护隐私的自动化配置生成，使其成为现代自主网络配置的实用且可扩展的解决方案。|
|**2025-12-02**|[VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion](http://arxiv.org/abs/2512.02844)|null|自动驾驶系统 (ADS) 的安全部署依赖于全面的测试与评估。然而，在现实世界中，能够有效暴露系统漏洞的安全关键场景极其稀疏。现有场景生成方法在高效构建兼具真实性、关键性和交互性的长尾场景方面面临挑战，尤其缺乏对被测车辆 (VUT) 的实时动态响应能力。为解决这些挑战，本文提出了一种安全关键测试场景生成框架，该框架融合了视觉语言模型 (VLM) 的高级语义理解能力与自适应引导扩散模型的细粒度生成能力。该框架建立了一个三层分层架构，包括用于 VLM 指导的场景生成目标确定的战略层、用于引导函数制定的战术层以及用于引导扩散执行的操作层。我们首先建立了一个学习真实驾驶场景数据分布的高质量基础扩散模型。接下来，我们设计了一种自适应引导扩散方法，该方法能够在闭环仿真中实现对背景车辆 (BV) 的实时、精确控制。随后，VLM 被引入，通过深度场景理解和风险推理自主生成场景生成目标和引导函数，最终引导扩散模型实现 VLM 指导的场景生成。实验结果表明，所提出的方法能够高效生成真实、多样且高度交互的安全关键测试场景。此外，案例研究验证了所提出方法的适应性和 VLM 指导的生成性能。|
|**2025-12-02**|[Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms](http://arxiv.org/abs/2512.02810)|null|建筑自动化中的多机器人任务分配传统上依赖于动态规划和强化学习等优化方法。本研究引入了基于LangGraph的任务分配智能体（LTAA），这是一个由大型语言模型（LLM）驱动的框架，它集成了阶段自适应分配策略、带有分层重试的多阶段验证和动态提示，以实现高效的机器人协调。尽管最近的LLM方法在建筑机器人技术方面显示出潜力，但它们在很大程度上缺乏与现有算法进行严格验证和基准测试。本文首次系统比较了在建筑场景中基于LLM的任务分配与传统方法。该研究通过SMART-LLM复现验证了LLM的可行性，并使用自我纠正智能体架构解决了实施挑战。LTAA利用自然语言推理结合结构化验证机制，通过动态提示实现了显著的计算增益，将token使用量减少了94.6%，分配时间减少了86%。该框架跨阶段调整其策略：早期强调执行可行性，后期分配中强调工作负载平衡。作者使用来自TEACh人机协作数据集的建筑操作，将LTAA与动态规划、Q学习和深度Q网络（DQN）基线进行了评估。在机器人具有很强任务专业性的“Heavy Excels”设置中，LTAA实现了77%的任务完成率，并具有卓越的工作负载平衡，优于所有传统方法。这些发现表明，基于LLM的推理结合结构化验证可以与现有的优化算法相媲美，同时提供额外的优势，例如可解释性、适应性以及无需重新训练即可更新任务逻辑的能力。|
|**2025-12-02**|[FiMMIA: scaling semantic perturbation-based membership inference across modalities](http://arxiv.org/abs/2512.02786)|**[link](https://github.com/ai-forever/data_leakage_detect)**|成员推断攻击（MIAs）旨在确定特定数据点是否包含在目标模型的训练集中。尽管已开发出大量方法用于检测大语言模型（LLMs）中的数据污染，但由于多模态组件适应引入的不稳定性以及跨多个输入可能发生的分布偏移，它们在多模态大语言模型（MLLMs）上的性能表现不佳。在这项工作中，我们研究了多模态成员推断，并解决两个问题：首先，通过识别现有数据集中的分布偏移；其次，通过发布一个扩展的基线管道来检测这些偏移。我们还将基于扰动的成员推断方法泛化到MLLMs，并发布了FiMMIA——一个模块化的多模态成员推断框架。我们的方法训练一个神经网络来分析目标模型在受扰动输入上的行为，从而捕获成员和非成员之间的分布差异。在各种微调多模态模型上的全面评估证明了我们基于扰动的成员推断攻击在多模态领域的有效性。|
|**2025-11-28**|[Visual Generation Tuning](http://arxiv.org/abs/2511.23469)|**[link](https://github.com/ali-vilab/FreeScale)**|大型视觉语言模型（VLM）通过大规模预训练有效地弥合了模态鸿沟，获得了与语言对齐的复杂视觉表示。然而，这些针对多模态理解任务进行优化的表示是否蕴藏着固有的视觉生成潜力，尚未得到充分探索。在本文中，我们提出了VGT，即视觉生成微调，这是一种新颖的范式，旨在激发任何视觉语言模型中的潜在视觉生成能力。通过对预训练良好的VLM进行高效的视觉生成微调，我们显著降低了对齐成本，并加速了连续空间中自回归建模的收敛（20倍加速）。具体而言，我们摒弃了为扩散Transformer设计的纠缠像素级VAE，并通过对齐预训练VLM中的语义编码器与像素解码器的潜在表示来构建VGT-AE。在图像重建任务中，我们在28倍压缩比下实现了26.67 PSNR和0.50 rFID，优于专用VAE；在视觉生成任务中，我们在自回归模型中取得了最先进的结果，在GenEval上达到0.77，在DPG-Bench上达到78.73。此外，我们提出的VGT展示了巨大的可扩展性前景，并且能够灵活地赋予任何针对多模态理解训练的VLM视觉生成能力，这为探索新一代统一多模态基础模型开辟了新途径。模型和代码可在https://github.com/hustvl/VGT获取。|
|**2025-11-28**|[LFM2 Technical Report](http://arxiv.org/abs/2511.23404)|null|我们提出了LFM2，这是一系列流式基础模型，旨在实现高效的设备端部署和强大的任务能力。通过在边缘延迟和内存限制下进行硬件在环架构搜索，我们获得了紧凑的混合骨干网络，该网络结合了门控短卷积和少量分组查询注意力块，与规模相似的模型相比，在CPU上实现了高达2倍的预填充和解码速度提升。LFM2系列涵盖3.5亿至83亿参数，包括稠密模型（3.5亿、7亿、12亿、26亿）和专家混合模型变体（总计83亿，15亿活跃），所有模型都具有32K的上下文长度。LFM2的训练流程包括一个经过退火处理的、解耦的Top-K知识蒸馏目标（避免支持不匹配）、使用难度排序数据的课程学习，以及一个三阶段后训练方案，即有监督微调、长度归一化偏好优化和模型合并。LFM2模型在10-12万亿tokens上预训练，在各种基准测试中取得了优异成绩；例如，LFM2-2.6B在IFEval上达到79.56%，在GSM8K上达到82.41%。我们进一步构建了多模态和检索变体：用于视觉-语言任务的LFM2-VL、用于语音的LFM2-Audio和用于检索的LFM2-ColBERT。LFM2-VL通过令牌高效的视觉处理支持可调的精度-延迟权衡，而LFM2-Audio分离了音频输入和输出路径，以实现与大3倍模型相比具有竞争力的实时语音到语音交互。LFM2-ColBERT为查询和文档提供了低延迟编码器，从而实现了跨多种语言的高性能检索。所有模型均以开放权重形式发布，并提供ExecuTorch、llama.cpp和vLLM的部署包，使LFM2成为需要快速、内存高效推理和强大任务能力的边缘应用的实用基础。|
|**2025-11-28**|[Optimizing Multimodal Language Models through Attention-based Interpretability](http://arxiv.org/abs/2511.23375)|null|现代大型语言模型变得多模态，能够分析文本和图像等各种数据格式。尽管微调对于使这些多模态语言模型（MLMs）适应下游任务是有效的，但全量微调的计算成本很高。参数高效微调（PEFT）方法通过仅训练模型权重的一小部分来解决这个问题。然而，MLMs难以解释，这使得识别哪些组件对于平衡效率和性能的训练最有效变得具有挑战性。我们提出了一种基于注意力的MLMs可解释性方法，通过分析相对于图像token的注意力分数。核心思想是识别专注于图像关键对象的注意力头。我们利用这些信息来选择多模态模型中PEFT的最优模型组件。我们的贡献包括一种识别与图像关键对象相关的注意力头的方法、其在图像字幕PEFT中的应用，以及创建了一个包含图像、关键对象掩码及其文本描述的新数据集。我们对具有2-3亿参数的MLMs进行了实验，以验证该方法的有效性。通过计算头影响（HI）分数，我们量化了注意力头对关键对象的关注程度，表明其在图像理解中的重要性。我们的微调实验表明，与预训练的、随机选择的或最低HI分数层相比，调整具有最高HI分数的层导致指标发生最显著的变化。这表明在这些关键层中微调一小部分（约0.01%）参数可以显著影响图像理解能力。|
|**2025-11-28**|[Chart2Code-MoLA: Efficient Multi-Modal Code Generation via Adaptive Expert Routing](http://arxiv.org/abs/2511.23321)|null|图表到代码生成是自动化数据可视化中的一项关键任务，它将复杂的图表结构转换为可执行程序。尽管近期的多模态大语言模型（MLLM）提升了图表表示能力，但现有方法在实现跨类型泛化、内存效率和模块化设计方面仍然面临挑战。为解决这些挑战，本文提出了C2C-MoLA，一个将专家混合（MoE）与低秩适应（LoRA）相结合的多模态框架。MoE组件采用复杂性感知路由机制，包含领域专用专家和负载均衡的稀疏门控，基于可学习的结构指标（例如元素数量和图表复杂性）动态分配输入。LoRA实现了参数高效更新，适用于资源受限的微调，并通过一种定制的训练策略进一步支持，该策略将路由稳定性与语义准确性对齐。在Chart2Code-160k上的实验表明，与标准微调和仅使用LoRA的基线相比，所提出的模型将生成准确率提高了高达17%，将峰值GPU内存减少了18%，并将收敛速度加快了20%，尤其是在复杂图表上。消融研究验证了最优设计，例如8个专家和秩为8的LoRA，并证实了其在真实世界多模态代码生成中的可扩展性。|
|**2025-11-28**|[Do LLM-judges Align with Human Relevance in Cranfield-style Recommender Evaluation?](http://arxiv.org/abs/2511.23312)|null|评估推荐系统仍然是一个长期存在的挑战，因为基于历史用户交互和训练-测试分割的离线方法，由于曝光偏差、流行度偏差、抽样评估和非随机缺失模式，常常产生不稳定和不一致的结果。相比之下，文本文档检索受益于通过Cranfield风格测试集进行的稳健、标准化评估，这些测试集结合了汇集的相关性判断与受控设置。尽管最近的研究表明将这种方法应用于推荐系统是可行的，但由于需要手动进行相关性判断，构建此类测试集仍然成本高昂，从而限制了可扩展性。本文研究大语言模型（LLMs）是否能作为可靠的自动判断器来解决这些可扩展性挑战。我们首先使用ML-32M-ext Cranfield风格的电影推荐测试集，检查现有评估方法的局限性。然后，我们探讨了LLM判断器与人工提供的相关性标签之间的对齐性以及推荐系统排名的一致性。我们发现，整合更丰富的物品元数据和更长的用户历史可以提高对齐性，并且LLM判断器与基于人工的排名具有高度一致性（Kendall's tau = 0.87）。最后，在播客推荐领域的一个工业案例研究证明了LLM判断器在模型选择方面的实用价值。总而言之，我们的结果表明LLM判断器是一种可行且可扩展的推荐系统评估方法。|
|**2025-11-28**|[Tourism Question Answer System in Indian Language using Domain-Adapted Foundation Models](http://arxiv.org/abs/2511.23235)|null|本文首次全面研究了印地语旅游领域基线抽取式问答（QA）系统的设计，特别关注瓦拉纳西——一个以其虔诚奉献精神（Bhakti-Bhaav）而闻名的文化和精神中心。该工作针对恒河祭祀（Ganga Aarti）、游轮、美食广场、公共厕所、圣池（Kund）、博物馆、一般信息、苦行林（Ashram）、寺庙和旅行这十个以旅游为中心的子领域，解决了印地语中缺乏适用于文化细微应用的特定语言问答资源的问题。在本文中，我们构建了一个包含7,715个与瓦拉纳西旅游相关的印地语问答对的数据集，随后通过Llama零样本提示生成了27,455个问答对进行扩充。我们提出了一个利用基础模型（如BERT和RoBERTa）的框架，并使用监督微调（SFT）和低秩适应（LoRA）进行微调，以优化参数效率和任务性能。我们评估了BERT的多个变体，包括预训练语言模型（例如Hindi-BERT），以衡量它们在低资源领域特定问答任务中的适用性。评估指标——F1、BLEU和ROUGE-L——突出了答案精度和语言流畅性之间的权衡。实验表明，基于LoRA的微调取得了具有竞争力的性能（85.3% F1），同时与SFT相比，可训练参数减少了98%，在效率和准确性之间取得了平衡。跨模型的比较分析显示，使用SFT的RoBERTa在捕捉上下文细微差别方面优于BERT变体，特别是对于文化嵌入的术语（例如，Aarti，Kund）。这项工作为印地语旅游问答系统建立了基础基线，强调了LoRA在低资源环境中的作用，并强调了在旅游领域对文化语境化自然语言处理框架的需求。|
|**2025-11-28**|[Pathryoshka: Compressing Pathology Foundation Models via Multi-Teacher Knowledge Distillation with Nested Embeddings](http://arxiv.org/abs/2511.23204)|null|病理学基础模型（FMs）已显著推动计算病理学的发展。然而，这些性能卓越的模型参数量可轻松超过十亿，并生成高维嵌入，从而在计算资源紧张时限制了其在研究或临床应用中的适用性。本文中，我们引入了Pathryoshka，一个受RADIO蒸馏和Matryoshka表征学习启发的多教师蒸馏框架，旨在减小病理学基础模型大小，同时允许可适应的嵌入维度。我们在一个蒸馏模型上，通过十个具有不同下游任务的公共病理学基准评估了我们的框架。与大得多的教师模型相比，Pathryoshka在性能持平的情况下将模型大小减少了86-92%。它在准确性方面以中位数7.0的幅度超越了尺寸相当的最先进单教师蒸馏模型。通过在不牺牲准确性或表征丰富性的前提下实现高效的本地部署，Pathryoshka使更广泛的研究和临床社区能够普及访问最先进的病理学基础模型。|
|**2025-11-28**|[An LLM-Assisted Multi-Agent Control Framework for Roll-to-Roll Manufacturing Systems](http://arxiv.org/abs/2511.22975)|null|卷对卷制造需要精确的张力与速度控制以确保产品质量，然而，控制器调试和适应仍然是耗时且依赖于专家知识的过程。本文提出了一种大型语言模型（LLM）辅助的多智能体框架，该框架能够自动化R2R系统的控制系统设计和适应，同时保持安全性。该框架通过五个阶段运行：基于运行数据的系统辨识、自动控制器选择和调优、带有安全验证的虚实适应、具有诊断能力的持续监控以及周期性模型精化。在R2R系统上的实验验证表明，在显著模型不确定性下，该框架成功实现了张力调节和速度跟踪，并通过迭代适应达到了性能收敛。该方法减少了手动调优工作量，同时为维护规划提供了透明的诊断信息，为将AI辅助自动化集成到制造控制系统中提供了一条实用的途径。|
|**2025-11-28**|[EnECG: Efficient Ensemble Learning for Electrocardiogram Multi-task Foundation Model](http://arxiv.org/abs/2511.22935)|null|心电图 (ECG) 分析在各种心血管疾病的早期检测、监测和管理中发挥着至关重要的作用。尽管现有模型在心电图解读方面取得了显著成功，但它们未能充分利用各种心脏异常的相互关联特性。相反，开发一个能够为多个心电图任务提取所有相关特征的特定模型仍然是一个重大挑战。大规模基础模型尽管功能强大，但通常未在心电图数据上进行预训练，这使得完全重新训练或微调的计算成本很高。为了应对这些挑战，我们提出了 EnECG（基于专家混合的ECG多任务集成学习），这是一个基于集成的框架，它集成了多个专业化的基础模型，每个模型都在心电图解读的不同方面表现出色。EnECG 不依赖于单一模型或单一任务，而是利用多个专业化模型的优势来处理各种基于心电图的任务。为了减轻完全重新训练或微调的高昂计算成本，我们引入了一种轻量级适应策略：为每个基础模型附加专用的输出层，并仅对这些新添加的参数应用低秩适应 (LoRA)。接着我们采用专家混合 (MoE) 机制来学习集成权重，有效地结合各个模型的互补专业知识。我们的实验结果表明，通过最小化微调的范围，EnECG 可以在保持基础模型强大表示能力的同时，帮助降低计算和内存成本。该框架不仅增强了特征提取和预测性能，而且确保了真实世界临床应用的实际效率。代码可在 https://github.com/yuhaoxu99/EnECG.git 获取。|
|**2025-11-28**|[RAG-Empowered LLM-Driven Dynamic Radio Resource Management in Open 6G RAN](http://arxiv.org/abs/2511.22933)|null|人工智能领域进展对无线通信的影响极其重要，尤其是在资源管理方面。本文提出了一种由检索增强生成（RAG）赋能的大语言模型（ReLLM）驱动的动态无线资源管理框架，适用于受开放无线接入网（O-RAN）启发的6G网络。所提出的方法利用ReLLM框架解释历史和实时网络数据，从而实现网络切片的自适应控制。ReLLM基于两个专用代理，一个负责通过持续监测和评估切片特定性能指标来主动检测服务等级协议（SLA）违规，另一个负责在SLA违规概率超过预定义阈值时动态重新分配物理资源块。这种双代理设计的主要目标是为了最小化不必要的大语言模型推理调用，同时满足切片的SLA要求，从而提高计算和能源效率。所提出的ReLLM框架在基于开源OpenAirInterface仿真器的端到端O-RAN测试床上进行了实现和验证。实验结果表明，大语言模型方法及其降低的令牌消耗特性为低优先级切片保持了接近零的丢包率，同时满足了高优先级切片可接受的延迟性能。ReLLM驱动的设计提高了可靠性和SLA合规性，证实了其在真实世界O-RAN测试床中的实用性及其对未来6G网络的潜在适用性。|
|**2025-11-26**|[Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework](http://arxiv.org/abs/2511.21686)|null|合成数据对于训练大型语言模型变得越来越重要，尤其是在真实数据稀缺、昂贵或涉及隐私敏感性时。许多此类生成任务需要协调的多智能体工作流，其中专门的智能体协作生成质量更高、多样性更强、结构更丰富的数据。然而，现有的多智能体合成框架通常依赖于中心化的协调器，造成可扩展性瓶颈，或者为特定领域硬编码，限制了灵活性。我们提出了 Matrix，一个去中心化框架，它将控制流和数据流都表示为通过分布式队列传递的序列化消息。这种对等式设计消除了中心化的协调器。每个任务通过轻量级智能体独立进行，而计算密集型操作（如大型语言模型推理或容器化环境）则由分布式服务处理。Matrix 基于 Ray 构建，可扩展到数万个并发的智能体工作流，并提供模块化、可配置的设计，能够轻松适应各种数据生成工作流。我们在多种合成场景中评估了 Matrix，例如多智能体协作对话、基于网络的推理数据提取以及客户服务环境中的工具使用轨迹生成。在所有情况下，Matrix 在相同的硬件资源下实现了 2-15 倍更高的数据生成吞吐量，而不损害输出质量。|
|**2025-11-26**|[DSD: A Distributed Speculative Decoding Solution for Edge-Cloud Agile Large Model Serving](http://arxiv.org/abs/2511.21669)|null|大语言模型（LLM）推理在异构边缘-云环境中通常面临高解码延迟和有限的可扩展性。现有推测解码（SD）技术虽能加速令牌生成，但仍局限于单节点执行。我们提出了DSD，一个分布式推测解码框架，通过协调的草稿-目标执行将SD扩展到多设备部署。鉴于之前缺乏模拟这种范式的工作，我们首先介绍了DSD-Sim，一个捕获网络、批处理和调度动态的离散事件模拟器。基于从DSD-Sim获得的洞察，我们进一步设计了一种自适应窗口控制（AWC）策略，该策略动态调整推测窗口大小以优化吞吐量。在多样化工作负载下的实验表明，DSD相较于现有SD基线，实现了高达1.1倍的加速和9.7%的吞吐量提升，从而在边缘和云端实现了敏捷且可扩展的LLM服务。|
|**2025-11-26**|[Aligning LLMs Toward Multi-Turn Conversational Outcomes Using Iterative PPO](http://arxiv.org/abs/2511.21638)|null|优化大语言模型（LLM）以实现多轮对话结果仍然是一个重大挑战，尤其是在AI营销或销售代理通过消息平台促成交易等目标导向型场景中。这种困难源于稀疏的、长周期的奖励以及响应级别规划与令牌级别生成之间的不匹配。在本文中，我们提出将多轮强化学习（RL）问题形式化规约为一系列单轮RLHF风格问题。这通过将学习到的多轮Q函数设定为单轮问题的奖励模型来实现。我们演示并证明了一个关键见解：使用标准的令牌级别PPO解决此单轮RL问题等价于多轮问题中的一个策略改进步骤。这一见解自然引出了迭代PPO，这是一种批处理在线策略迭代算法，它在从记录的对话轨迹中拟合Q函数和改进策略之间交替进行。一个主要的实际优势是，迭代PPO直接利用了稳定、现成的单轮RLHF工具，使其易于实现。我们的方法介于完全在线和完全离线方法之间，在保持在线更新适应性的同时，获得了离线训练的稳定性优势。|
|**2025-11-26**|[Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation](http://arxiv.org/abs/2511.21510)|null|本研究提出了Tool-RoCo，一个基于多机器人协作基准RoCo的新颖基准，用于评估大型语言模型（LLM）在长期多智能体协作中的表现。近期关于基于LLM的多智能体系统的研究依赖于预定义编排，却忽视了智能体自主性。Tool-RoCo将其他智能体视为工具，并引入了协作工具，利用工具使用来评估多智能体协作和自组织能力。工具使用意味着每个智能体（LLM）根据当前状态从候选工具集中选择一个工具，接收反馈，并在后续轮次中调整其选择。为了评估不同自主性水平，我们提出了四种LLM范式：(1) 集中式协作，单个LLM将工具分配给所有智能体；(2) 集中式自组织，中央LLM自主激活智能体，同时保持其他智能体不活跃；(3) 分布式协作，每个智能体拥有自己的LLM并根据本地信息调用工具；(4) 自组织，随机选择的初始智能体可以请求协作，通过工具调用激活其他智能体。Tool-RoCo包含三个多机器人任务：SORT、PACK和CABINET，用于衡量格式和参数准确性以及通过工具使用实现的智能体协调。使用多个LLM的结果表明，协作工具仅占所有工具的7.09%，这表明基于LLM的智能体很少将其他智能体作为助手来调用。此外，激活工具占比96.42%，这表明当前的LLM倾向于保持智能体活跃，而很少为了自适应协调而停用它们。Tool-RoCo提供了一个系统的基准，用于评估LLM在多智能体任务中的自主性和协作能力。代码和演示：https://github.com/ColaZhang22/Tool-Roco|
|**2025-11-26**|[Semantic-Enhanced Feature Matching with Learnable Geometric Verification for Cross-Modal Neuron Registration](http://arxiv.org/abs/2511.21452)|null|精确配准单个神经元的活体双光子和离体荧光显微光学切片断层扫描图像对于神经科学中的结构-功能分析至关重要。由于显著的跨模态表观差异、标注数据稀缺以及严重的组织形变，这项任务极具挑战性。我们提出了一种新颖的深度学习框架来解决这些问题。我们的方法引入了一种语义增强的混合特征描述符，它融合了局部特征的几何精度与视觉基础模型DINOV3的上下文鲁棒性，以弥合模态差异。为了处理复杂的形变，我们用一个可学习的几何一致性置信模块取代了传统的RANSAC，这是一个经过训练用于识别和拒绝物理上不合理的对应关系的新颖分类器。一种数据高效的两阶段训练策略，包括在合成形变数据上进行预训练并在有限的真实数据上进行微调，克服了数据稀缺问题。我们的框架为具有挑战性的生物医学成像场景中的高精度配准提供了一个鲁棒且精确的解决方案，从而能够实现大规模关联研究。|
|**2025-11-26**|[Automated Dynamic AI Inference Scaling on HPC-Infrastructure: Integrating Kubernetes, Slurm and vLLM](http://arxiv.org/abs/2511.21413)|null|鉴于人工智能（AI）推理需求不断增长，尤其是在高等教育领域，利用现有基础设施的新颖解决方案正在涌现。高性能计算（HPC）的应用已成为实施此类解决方案的一种普遍方法。然而，HPC的经典操作模型不太适应同步的、面向用户的动态AI应用工作负载的需求。在本文中，我们提出了一种解决方案，通过在RAMSES超级计算机上集成vLLM、Slurm和Kubernetes来服务大型语言模型（LLMs）。初步基准测试结果表明，所提出的架构能够针对100、500和1000个并发请求高效扩展，在端到端延迟方面仅产生大约500毫秒的开销。|
|**2025-11-26**|[Text-to-SQL as Dual-State Reasoning: Integrating Adaptive Context and Progressive Generation](http://arxiv.org/abs/2511.21402)|**[link](https://github.com/DMIRLAB-Group/DSR-SQL)**|近期分而治之的推理方法，尤其是基于思维链（CoT）的方法，大幅提升了大型语言模型（LLM）的Text-to-SQL能力。然而，当应用于复杂的企业数据库时，这些方法由于上下文容量有限、模式链接不可靠以及数据库语义基础薄弱，难以保持连贯的推理。为了克服这些问题，我们引入了DSR-SQL，这是一个双态推理框架，它将Text-to-SQL建模为自适应上下文状态和渐进式生成状态之间的一种交互。第一个通过精炼大型模式并选择相关结构，构建了一个紧凑、语义忠实的环境；而第二个则将SQL合成形式化为反馈引导的状态转换，使模型能够自我修正并与用户意图对齐。在没有任何后训练或上下文示例的情况下，DSR-SQL取得了有竞争力的性能，在Spider 2.0-Snow上达到了35.28%的执行准确率，并在BIRD开发集上达到了68.32%。我们的实现将在以下地址开源：https://github.com/DMIRLAB-Group/DSR-SQL。|
|**2025-11-26**|[Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions](http://arxiv.org/abs/2511.21380)|null|自动化适配跨数据集的软件工程(SE)研究产物对可扩展性和可复现性至关重要，但在很大程度上仍未被研究。近期在基于大语言模型(LLM)的多智能体系统方面的进展，例如GitHub Copilot的智能体模式，有望通过协调推理、代码生成和工具交互自动化复杂的开发工作流程。本文首次进行了实证研究，探究了最先进的多智能体系统在数据集适配任务中的表现。我们评估了由GPT-4.1和Claude Sonnet 4支持的Copilot在适配源自ROCODE和LogHub2.0等基准代码库的SE研究产物方面的能力。通过一个五阶段评估流程(文件理解、代码编辑、命令生成、验证和最终执行)，我们衡量了成功率，分析了失败模式，并评估了旨在提升智能体性能的提示词干预措施。结果表明，当前系统能够识别关键文件并生成部分适配，但很少能产出功能正确的实现。提示词级别的干预，尤其是提供执行错误消息和参考代码，显著提升了与真实情况的结构相似度(从7.25%到67.14%)，突出了情境化和反馈驱动指导的重要性。我们的发现揭示了当今多智能体LLM系统在数据集适配方面的潜力和局限性，并提出了在未来的SE研究中构建更可靠、自纠正的智能体的具体方向。|
|**2025-11-26**|[Evaluation of Large Language Models for Numeric Anomaly Detection in Power Systems](http://arxiv.org/abs/2511.21371)|null|大语言模型（LLM）因其通用能力而在电网领域受到越来越多的关注。同时，异常检测（AD）对电网韧性至关重要，需要基于多变量遥测数据做出准确且可解释的决策。然而，LLM在处理用于异常检测的大规模数值数据方面的性能在很大程度上尚未得到探索。本文对LLM在电力系统数值异常检测方面的能力进行了全面评估。我们使用GPT-OSS-20B作为代表性模型，并在IEEE 14节点系统上对其进行评估。一个标准化提示框架被应用于零样本、少样本、上下文学习、低秩适应（LoRA）、微调以及LLM与传统方法相结合的混合方法。我们采用基于三西格玛准则的规则感知设计，并报告了检测性能和理由质量。这项研究为进一步探究基于LLM的异常检测的局限性和能力及其与经典检测器在信息物理电网应用中的集成奠定了基础。|
|**2025-11-26**|[Discovery and recovery of crystalline materials with property-conditioned transformers](http://arxiv.org/abs/2511.21299)|**[link](https://github.com/C-Bone-UCL/CrystaLLM-pi)**|生成模型最近在加速新功能材料的设计和发现方面展现出巨大的潜力。条件生成通过允许逆向设计增强了这种能力，即在生成过程中可以请求特定的所需属性。然而，特别是基于Transformer的方法的条件化受到离散分词方案以及在微调过程中灾难性遗忘风险的限制。这项工作引入了CrystaLLM-π（属性注入），这是一个将连续属性表示直接集成到Transformer注意力机制中的条件自回归框架。提出了两种架构：属性-键-值（PKV）前缀注意力和PKV残差注意力。这些方法绕过了低效的序列级分词，并保留了从基于晶体学信息文件（CIFs）的无监督预训练中获得的文本输入形式的基础知识。我们通过系统的鲁棒性研究证实了这些机制的有效性，并评估了该框架在两项不同任务中的多功能性。首先，在结构恢复方面，该模型处理高维、异构的X射线衍射图样，实现了与专业模型相媲美的结构准确性，并展示了在实验结构恢复和多晶型物区分方面的应用。其次，在材料发现方面，该模型在专门的光伏数据集上进行微调，以生成经密度泛函理论（DFT）验证的新型稳定候选材料。它隐式地学会了针对高光伏效率的最佳带隙区域，展示了映射复杂结构-属性关系的能力。CrystaLLM-π 为逆向材料设计提供了一个统一、灵活且计算高效的框架。|
|**2025-11-25**|[Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition](http://arxiv.org/abs/2511.20641)|null|长尾多标签视觉识别提出了重大挑战，因为图像通常包含多个标签，且类别分布高度不平衡，导致模型偏向头部类别，而在尾部类别上表现不佳。最近的研究利用了诸如CLIP等预训练视觉-语言模型，并结合长尾学习技术，以利用丰富的视觉-文本先验来提高性能。然而，现有方法通常直接从不平衡数据集中推导语义类间关系，由于数据稀缺性，这导致尾部类别的关联性不可靠。此外，CLIP的零样本范式是为单标签图像-文本匹配而优化的，使其不适用于多标签任务。为解决这些问题，我们提出了关联适应提示网络（CAPNET），这是一种新颖的端到端框架，它从CLIP的文本编码器中显式建模标签关联。该框架融合了用于标签感知传播的图卷积网络和用于精炼嵌入的可学习软提示。它利用了带有类别感知重加权的分布平衡Focal损失，以优化不平衡条件下的训练。此外，它通过测试时集成提高泛化能力，并使用参数高效微调重新对齐视觉-文本模态，以避免尾部类别过拟合，同时不损害头部类别性能。在VOC-LT、COCO-LT和NUS-WIDE等基准数据集上进行的大量实验和消融研究表明，CAPNET显著优于最新方法，验证了其在真实世界长尾多标签视觉识别中的有效性。|
|**2025-11-25**|[ROOT: Robust Orthogonalized Optimizer for Neural Network Training](http://arxiv.org/abs/2511.20626)|null|大型语言模型 (LLMs) 的优化仍然是一个严峻的挑战，尤其是在模型规模扩大时，会加剧对算法不精确性和训练不稳定性的敏感性。优化器领域的最新进展已经通过动量正交化提高了收敛效率，但存在两个关键的鲁棒性局限：正交化精度上的维度脆弱性以及易受离群值引起的噪声影响。为了解决这些鲁棒性挑战，我们引入了 ROOT，一个鲁棒正交化优化器，它通过双重鲁棒性机制增强了训练稳定性。首先，我们开发了一种维度鲁棒的正交化方案，该方案使用自适应牛顿迭代，并具有针对特定矩阵大小定制的细粒度系数，确保在不同架构配置下都能保持一致的精度。其次，我们通过近端优化引入了一个优化鲁棒框架，该框架能够抑制离群值噪声，同时保留有意义的梯度方向。大量实验表明，与 Muon 和基于 Adam 的优化器相比，ROOT 实现了显著提升的鲁棒性，具有更快的收敛速度和更优的最终性能，尤其是在噪声和非凸场景下。我们的工作建立了一个新范式，用于开发鲁棒且精确的优化器，能够处理现代大规模模型训练的复杂性。代码将在 https://github.com/huawei-noah/noah-research/tree/master/ROOT 提供。|
|**2025-11-25**|[MSTN: Fast and Efficient Multivariate Time Series Model](http://arxiv.org/abs/2511.20577)|null|真实世界时间序列数据高度非平稳，其动态复杂且跨多个时间尺度运行，从快速的短期变化到缓慢的长期趋势均有涉及。大多数现有模型依赖于固定尺度的结构先验，例如基于块的标记化、固定频率变换或冻结的主干架构。这通常会导致时间动态的过度正则化，限制了它们自适应建模完整时间变化范围的能力，并损害了它们在不可预测的、突发的、高幅度事件上的性能。为解决这个问题，我们引入了多尺度时间网络（MSTN），这是一种基于分层多尺度和序列建模原理的新颖深度学习架构。MSTN框架集成了：(i) 一个多尺度卷积编码器，用于构建局部模式的分层特征金字塔；(ii) 一个序列建模组件，用于长程时间依赖性。我们通过BiLSTM和Transformer变体对MSTN进行了实证验证，为未来的架构改进奠定了灵活的基础。以及(iii) 一个门控融合机制，该机制通过挤压-激励（SE）和多头时间注意力（MHTA）进行增强，用于动态、上下文感知的特征集成。这种设计使MSTN能够在统一的框架内自适应地建模从毫秒级到长程依赖性的时间模式。跨时间序列长周期预测、插补、分类和泛化性研究的广泛评估表明，MSTN实现了具有竞争力的最新（SOTA）性能，显示出优于包括EMTSF、LLM4TS、HiMTM、TIME-LLM、MTST、SOFTS、iTransformer、TimesNet和PatchTST在内的现有方法的改进。总的来说，MSTN在32个基准数据集中的24个上建立了新的SOTA性能，展示了其在各种时间任务中的一致表现。|
|**2025-11-25**|[The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models](http://arxiv.org/abs/2511.20507)|null|大型语言模型（LLM）已成为人类语言的候选“模式生物”，为研究诸如失语症等语言障碍的计算基础提供了前所未有的机会。然而，传统的临床评估不适用于LLM，因为它们预设了类人语用压力并探究了并非人工架构所固有的认知过程。我们引入了文本失语症评估量表（TAB），这是一个改编自快速失语症评估量表（QAB）的仅限文本基准，用于评估LLM中类失语症缺陷。TAB包含四个子测试：语篇连贯性、词汇理解、句子理解和复述。本文详细介绍了TAB的设计、子测试和评分标准。为了便于大规模使用，我们验证了一种使用Gemini 2.5 Flash的自动化评估协议，该协议实现了与专家人类评估员相当的可靠性（模型与共识之间的一致性，流行度加权Cohen’s kappa = 0.255；人类与人类之间的一致性，流行度加权Cohen’s kappa = 0.286）。我们发布TAB作为一个具有临床基础且可扩展的框架，用于分析人工智能系统中的语言缺陷。|
|**2025-11-25**|[MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained Transformers](http://arxiv.org/abs/2511.20382)|**[link](https://github.com/phutq341/PhuDepTrai)**|由于维度极高、模态异质性和群体特异性批次效应，多组学数据的表征学习面临挑战。尽管预训练Transformer主干网络在生物序列建模中展现出广泛的泛化能力，但其在多组学整合中的应用仍未得到充分探索。我们提出了MoRE（Multi-Omics Representation Embedding），一个重新利用冻结预训练Transformer将异质性检测数据对齐到共享潜在空间的框架。与纯生成式方法不同，MoRE采用参数高效微调（PEFT）策略，优先考虑跨样本和跨模态对齐而非简单的序列重建。具体而言，MoRE将轻量级、模态特异性适配器和任务自适应融合层连接到冻结的主干网络上。它将掩码建模目标与有监督对比损失和批次不变性对齐损失共同优化，产生保留结构且能泛化到未见过的细胞类型和平台的嵌入。我们将MoRE与scGPT、scVI以及结合scArches的Harmony等已有基线方法进行基准测试，评估了整合保真度、稀有群体检测和模态迁移。我们的结果表明，与完全微调模型相比，MoRE在显著减少可训练参数的同时，实现了有竞争力的批次鲁棒性和生物学保守性。这项工作将MoRE定位为迈向通用组学基础模型的实际一步。|
|**2025-11-25**|[Soft Adaptive Policy Optimization](http://arxiv.org/abs/2511.20347)|null|强化学习（RL）在增强大语言模型（LLMs）的推理能力方面发挥着越来越重要的作用，然而，稳定且高性能的策略优化仍然具有挑战性。词元级重要性比率通常表现出高方差——这种现象在专家混合模型中尤为突出——导致更新不稳定。现有的基于组的策略优化方法，如GSPO和GRPO，通过硬截断来缓解这一问题，但这使得同时保持稳定性和有效学习变得困难。我们提出了软自适应策略优化（SAPO），它将硬截断替换为一种平滑的、温度控制的门，该门能自适应地衰减离策略更新，同时保留有用的学习信号。与GSPO和GRPO相比，SAPO既具有序列一致性又具有词元自适应性。像GSPO一样，SAPO保持了序列级一致性，但其软门控形成了一个连续的信任区域，避免了GSPO中使用的脆弱的硬截断带。当一个序列包含少量高度离策略的词元时，GSPO会抑制该序列的所有梯度，而SAPO则选择性地降低那些“问题”词元的权重，并保留来自接近在策略词元的学习信号，从而提高了样本效率。相对于GRPO，SAPO将硬的词元级截断替换为平滑的、温度控制的缩放，从而实现更具信息量和更稳定的更新。在数学推理基准上的实验结果表明，在可比较的训练预算下，SAPO表现出改进的训练稳定性和更高的Pass@1性能。此外，我们采用SAPO来训练Qwen3-VL模型系列，证明SAPO在不同任务和不同模型尺寸下均能带来持续的性能提升。总的来说，SAPO为LLMs的RL训练提供了一种更可靠、可扩展、有效的优化策略。|
|**2025-11-25**|[NNGPT: Rethinking AutoML with Large Language Models](http://arxiv.org/abs/2511.20333)|null|构建自改进AI系统仍然是AI领域的一个基本挑战。我们提出了NNGPT，一个开源框架，它将大语言模型（LLM）转化为一个自改进的AutoML引擎，用于神经网络开发，主要针对计算机视觉。与先前框架不同，NNGPT通过生成新模型来扩展神经网络数据集，从而实现基于生成、评估和自改进闭环系统的LLM持续微调。它在一个统一的工作流中整合了五个协同的基于LLM的流水线：零样本架构合成、超参数优化（HPO）、代码感知精度/提前停止预测、范围封闭的PyTorch模块的检索增强合成（NN-RAG）以及强化学习。NNGPT以LEMUR数据集作为经过审计的、具有可复现指标的语料库，从单个提示生成并验证网络架构、预处理代码和超参数，端到端执行它们，并从结果中学习。PyTorch适配器使NNGPT框架无关，实现了强大性能：NN-RAG在1,289个目标上达到了73%的可执行性，3样本提示提高了常见数据集上的精度，基于哈希的去重节省了数百次运行。单样本预测与基于搜索的AutoML相匹配，减少了对大量试验的需求。在LEMUR上进行的HPO实现了0.60的均方根误差（RMSE），优于Optuna（0.64），而代码感知预测器则达到了0.14的均方根误差，皮尔逊相关系数r为0.78。该系统已生成超过5K个经过验证的模型，证明NNGPT是一个自主AutoML引擎。论文被接受后，代码、提示和检查点将公开发布，以实现可复现性并促进社区使用。|
|**2025-11-25**|[CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient Adaptation of Cross-Domain Remote Sensing Semantic Segmentation](http://arxiv.org/abs/2511.20302)|null|在遥感 (RS) 领域，参数高效微调 (PEFT) 已成为一种关键方法，用于激活基础模型对下游任务的泛化表示能力。然而，现有的专用PEFT方法在应用于大规模地球观测任务时常常失效，因为它们无法充分处理遥感数据中固有的多方面且不可预测的领域鸿沟 (例如，空间、语义和频率偏移)。为此，我们提出CrossEarth-Gate，具有两项主要贡献。首先，我们建立了一个全面的遥感模块工具箱，包含空间、语义和频率模块，以解决多方面的领域鸿沟。其次，我们开发了一种费雪信息指导的自适应选择机制，在此工具箱上运行。这种选择由费雪信息指导，通过测量每个模块对任务特定梯度流的贡献来量化其重要性。它动态地激活合适的层中最关键的模块，指导梯度流以最大化适应的有效性和效率。全面实验验证了我们方法的有效性和泛化能力，其中CrossEarth-Gate在16个用于遥感语义分割的跨领域基准测试中达到了最先进的性能。该工作的代码将发布。|
|**2025-11-25**|[Improving Language Agents through BREW](http://arxiv.org/abs/2511.20297)|null|基于大型语言模型（LLM）的智能体正越来越多地应用于需要结构化推理、工具使用和环境适应的任务，例如数据操作、多步规划和计算机使用自动化。然而，尽管它们具有多功能性，但当前用于模型权重优化方法（如PPO和GRPO）的训练范式，由于其策略收敛的高计算开销，仍然相对不切实际。此外，由此产生的智能体策略难以解释、适应或增量改进。为解决此问题，我们研究了创建和完善智能体从其环境中经验学习的结构化记忆，以此作为智能体优化的替代途径。我们引入了BREW（引导式经验学习环境知识），这是一个通过知识库（KB）构建和完善来实现下游任务智能体优化的框架。在我们的方法中，我们引入了一种有效的智能体记忆分区方法，以实现更高效的检索和完善。BREW利用任务评估器和行为准则来获取洞察，同时利用状态空间搜索来确保从自然语言中的噪声和非特异性中获得鲁棒性。在真实世界、领域驱动的基准（OSWorld、 $τ^2$ Bench和SpreadsheetBench）上的经验结果表明，BREW实现了任务精度10-20%的提升，API/工具调用减少10-15%，从而缩短了执行时间，同时保持了与基础模型相当的计算效率。与先前将记忆视为静态上下文的工作不同，我们将知识库（KB）确立为智能体优化的模块化、可控基础——这是一个以透明、可解释和可扩展的方式塑造行为的显式杠杆。|
|**2025-11-25**|[REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance](http://arxiv.org/abs/2511.20233)|null|社交媒体上虚假信息的泛滥威胁着公众信任，这要求自动化事实核查系统不仅能提供准确的判断，还能给出可解释的说明。然而，现有基于大型语言模型（LLM）的方法往往严重依赖外部知识来源，这引入了大量的延迟甚至幻觉，从而损害了可靠性、可解释性和响应性，而这些对于实时使用至关重要。为解决这些挑战，我们提出了一种名为“基于推理的潜在解释事实核查”（REason-guided Fact-checking with Latent EXplanations, REFLEX）的范式，这是一种即插即用、自我优化的范式，它利用骨干模型的内部知识来提高判断准确性和解释质量。REFLEX将事实核查重新定义为角色扮演对话，并联合训练判断预测和解释生成。它自适应地提取骨干模型及其微调变体之间的对比激活对，以构建引导向量，从而自然地将真相解耦为风格和实质。这些激活层信号引导推理并抑制噪声解释，实现更忠实、更高效的推理。真实世界数据集上的实验表明，REFLEX优于以往那些只朝单一真相方向引导的方法，并凸显了传统方法在处理事实核查任务中微妙的、人类未知真相时所面临的挑战。值得注意的是，仅用465个自我优化训练样本，REFLEX就达到了最先进的性能。此外，采用解释性目标训练的模型可以有效引导那些没有解释性目标的模型，带来高达7.57%的改进，这强调了内部解释信号在解释和增强事实推理中都发挥着双重作用。|
|**2025-11-21**|[PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM](http://arxiv.org/abs/2511.17467)|null|我们提出了一种新颖的基于人设的语言模型系统框架，其动机是需要能够适应个体用户偏好的个性化AI智能体。在我们的方法中，智能体体现用户的“人设”（例如用户档案或品味），并由大型语言模型（LLM）驱动。为了使智能体能够利用丰富的上下文信息，我们引入了一种知识图谱增强检索增强生成（Graph RAG）机制，该机制构建了一个由LLM派生的相关文档图索引，并总结了相关信息社区。我们的框架通过结合以下两点生成个性化提示：(1) 从知识图谱中提取的用户历史行为和偏好总结，以及 (2) 通过基于图的社区检测识别出的相关全局交互模式。这种动态提示工程方法使智能体能够保持与人设一致的行为，同时受益于集体知识。在LaMP基准测试中，我们的方法将新闻分类F1提高了11.1%，电影标签F1提高了56.1%，并将产品评分MAE比现有方法降低了10.4%。我们的代码可在https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F获取。|
|**2025-11-21**|[ReBaPL: Repulsive Bayesian Prompt Learning](http://arxiv.org/abs/2511.17339)|null|提示学习已成为微调大规模基础模型以适应下游任务的有效技术。然而，传统提示调优方法容易过拟合，并且在分布外泛化方面表现不佳。为解决这些局限性，贝叶斯提示学习被提出，它将提示优化视为一个贝叶斯推理问题以增强鲁棒性。本文介绍了一种新颖的贝叶斯提示学习方法——斥力贝叶斯提示学习（ReBaPL），旨在有效探索提示的复杂且通常多模态的后验景观。我们的方法将周期性步长调度与随机梯度哈密顿蒙特卡洛（SGHMC）算法相结合，实现了探索新模式和利用以细化现有模式的交替阶段。此外，我们引入了一种斥力，该斥力源自基于不同提示产生的表示分布的概率度量（包括最大均值差异和瓦瑟斯坦距离）的势函数。这种表示空间斥力使探索多样化，并防止过早坍缩到单一模式。我们的方法能够更全面地表征提示后验分布，从而带来改进的泛化能力。与先前的贝叶斯提示学习方法相比，我们的方法为任何基于最大似然估计的现有提示学习方法提供了一个模块化即插即用的贝叶斯扩展。我们在多个基准数据集上验证了 ReBaPL 的有效性，结果表明其性能优于最先进的提示学习方法。|
|**2025-11-21**|[Humanlike Multi-user Agent (HUMA): Designing a Deceptively Human AI Facilitator for Group Chats](http://arxiv.org/abs/2511.17315)|null|基于大型语言模型（LLM）的对话代理正变得越来越普遍，然而大多数系统设计用于一对一、轮流对话，而非自然的、异步的群聊。随着AI助手在从虚拟助手到客户服务的数字平台中广泛应用，开发自然且类人的交互模式对于维持用户信任和参与度至关重要。我们提出了一种类人多用户代理（HUMA），它是一种基于LLM的协调者，采用类人的策略和时机参与多方对话。HUMA在先前的多用户聊天机器人工作基础上进行了扩展，采用事件驱动架构来处理消息、回复、反应，并引入了真实的响应时间模拟。HUMA包含路由器、行动代理和反思模块三个组件，它们共同使LLM适应群组对话动态。我们通过一项对照研究评估了HUMA，该研究有97名参与者进行了四人角色扮演聊天，比较了AI和人类社区管理者（CM）。参与者在两种条件下以接近随机的概率将CM分类为人类，表明他们无法可靠地区分HUMA代理和人类。主观体验在不同条件下具有可比性：社区管理者有效性、社交临场感以及参与度/满意度仅有微小差异，且效应量较小。我们的结果表明，在自然群聊环境中，AI协调者可以媲美人类的质量，同时仍难以被识别为非人类。|
|**2025-11-21**|[SpatialGeo:Boosting Spatial Reasoning in Multimodal LLMs via Geometry-Semantics Fusion](http://arxiv.org/abs/2511.17308)|null|多模态大语言模型（MLLMs）因大语言模型（LLMs）强大的推理能力，在图像和语言任务中取得了显著进展。然而，大多数MLLMs在解释和推断三维空间中的空间排列方面，其空间推理能力有限。在这项工作中，我们提出了一种基于几何特征和语义特征分层融合的新型视觉编码器，以生成空间感知视觉嵌入，并提升MLLMs的空间定位能力。具体来说，我们首先揭示了空间模糊性缺点源于大多数现有MLLMs（例如CLIP）中使用的视觉编码器的有损嵌入，该嵌入仅限于实例级语义特征。这促使我们通过分层适配器，利用仅视觉的自监督学习中的几何特征来补充CLIP，从而增强所提出的SpatialGeo中的空间感知能力。该网络利用预训练的LLaVA模型进行高效训练，并通过随机特征丢弃进行优化，以避免仅依赖于CLIP编码器的平凡解。实验结果表明，SpatialGeo提高了空间推理任务的准确性，在SpatialRGPT-Bench上将最先进模型的性能提升至少8.0%，同时在推理过程中内存成本降低约50%。源代码可通过https://ricky-plus.github.io/SpatialGeoPages/获取。|
|**2025-11-21**|[SlsReuse: LLM-Powered Serverless Function Reuse](http://arxiv.org/abs/2511.17262)|null|无服务器计算已迅速兴起成为一种流行的云计算范式。它使开发者能够实现函数级任务（即无服务器函数），而无需管理基础设施。尽管减少了运营开销，但它也带来了挑战，尤其是对新手开发者而言。从头开发函数需要适应异构的、特定于平台的编程风格，这使得开发过程耗时且容易出错。函数重用为解决这些挑战提供了一个有前景的解决方案。然而，无服务器计算领域的研究缺乏专门的函数推荐方法。由于任务描述与异构函数实现之间存在语义鸿沟，传统背景下的现有技术仍然不足。在大规模语料库上预训练的大型语言模型（LLM）的进展，通过将开发者需求与函数语义对齐，为弥合这一鸿沟创造了机会。本文提出了SlsReuse，这是首个由LLM驱动的无服务器函数重用框架。具体而言，SlsReuse首先构建了一个可重用函数库，作为基础知识库。然后，它通过结合小样本提示的有效提示工程，学习异构函数的统一语义增强表示，捕获隐式代码意图、目标平台、编程语言和云服务。最后，给定一个自然语言任务查询，SlsReuse执行意图感知发现，并结合多级剪枝策略和相似性匹配。我们在一个包含110个任务查询的精选数据集上评估了SlsReuse。基于最具代表性的LLM之一ChatGPT-4o，SlsReuse实现了91.20%的Recall@10，超出了最先进的基线24.53个百分点。|
|**2025-11-21**|[E $^3$ -Pruner: Towards Efficient, Economical, and Effective Layer Pruning for Large Language Models](http://arxiv.org/abs/2511.17205)|**[link](https://github.com/phutq341/PhuDepTrai)**|大型语言模型规模的不断增大，层剪枝作为一种硬件友好的模型压缩方法受到了越来越多的关注。然而，现有的层剪枝方法难以同时解决实际部署中的关键挑战，包括性能下降、高训练成本和有限的加速。为了克服这些局限性，我们提出了\name，一个任务有效（task-Effective）、训练经济（training-Economical）且推理高效（inference-Efficient）的层剪枝框架。\namespace引入了两项关键创新：（1）一种使用Gumbel-TopK采样器的可微分掩码优化方法，实现了高效且精确的剪枝掩码搜索；（2）一种熵感知自适应知识蒸馏策略，提升了任务性能。在多样化的模型架构和基准测试上进行的广泛实验表明，我们的方法优于现有最先进的方法。值得注意的是，在Qwen3-32B模型剪枝25%的层后，\namespace在MATH-500数据集上达到了96%的准确率，仅比原始模型（96.8%）下降0.8%，优于现有SOTA（95%），并通过仅消耗0.5B tokens（占训练后数据量的0.5%）实现了1.33倍的推理加速。|
|**2025-11-21**|[The PLLuM Instruction Corpus](http://arxiv.org/abs/2511.17161)|null|本文描述了在PLLuM（波兰大型语言模型）项目中开发的一组基于Transformer的大型语言模型（LLMs）所使用的指令数据集。我们提出了PLLuM中使用的有机指令、转换指令和合成指令的功能分类法，并分享了关于在基础LLMs的语言适应中，使用人工编写的指令数据集与合成指令数据集所产生影响的一些观察。此外，我们发布了PLLuM指令语料库（PLLuMIC）的首个代表性子集，我们相信这有助于指导和规划其他LLMs类似数据集的开发。|
|**2025-11-21**|[A Multi-Stage Optimization Framework for Deploying Learned Image Compression on FPGAs](http://arxiv.org/abs/2511.17135)|null|基于深度学习的图像压缩（LIC）已达到最先进的速率失真（RD）性能，然而将这些模型部署到资源受限的FPGA上仍然是一个重大挑战。本研究提出一个完整的多阶段优化框架，以弥合高性能浮点模型与高效、硬件友好的整数实现之间的差距。首先，我们解决了量化引起的性能下降这一基本问题。我们提出了一种动态范围感知量化（DRAQ）方法，该方法利用统计校准的激活裁剪和新颖的权重正则化方案来抵消极端数据离群值和大动态范围的影响，成功创建了一个高保真8位整数模型。其次，在此坚实基础之上，我们引入了两种专为FPGA定制的硬件感知优化技术。渐进式混合精度搜索算法利用FPGA的灵活性为每个层分配最优的非均匀位宽，在保持性能的同时最小化复杂度。同时，通道剪枝方法适用于LIC中常见的广义除法归一化（GDN）层，通过消除不活跃通道来去除模型冗余。我们的全面实验表明，基础DRAQ方法将基于GDN模型的BD-rate开销从30%降低到6.3%。随后的硬件感知优化进一步将计算复杂度降低了20%以上，同时对RD性能的影响可忽略不计，从而得到一个最终模型，该模型在效率上达到最先进水平，并且在质量上优于现有基于FPGA的LIC实现。|
|**2025-11-21**|[Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation](http://arxiv.org/abs/2511.17129)|null|文本表示在聚类、检索及其他下游应用等任务中扮演着关键角色。随着大语言模型（LLM）的出现，利用其能力实现文本表示的兴趣日益增长。然而，大多数LLM本质上是因果的，并针对下一个词元预测进行了优化，这使得它们在生成整体表示方面表现次优。为解决此问题，最近的研究引入了预训练任务来调整LLM以进行文本表示。然而，这些任务大多依赖于词元级别的预测目标，例如LLM2Vec中使用的掩码下一个词元预测（MNTP）。在这项工作中，我们探索了上下文压缩作为LLM无监督适应预训练任务的未开发潜力。在压缩预训练期间，模型学习生成紧凑的记忆词元，这些词元替代整个上下文用于下游序列预测。实验表明，精心设计的压缩目标可以显著增强基于LLM的文本表示，优于使用词元级别预训练任务训练的模型。通过对比学习进行的进一步改进产生了一个强大的表示模型（LLM2Comp），该模型在广泛的任务上优于当前的基于LLM的文本编码器，同时具有更高的样本效率，需要显著更少的训练数据。|
|**2025-11-21**|[ChainV: Atomic Visual Hints Make Multimodal Reasoning Shorter and Better](http://arxiv.org/abs/2511.17106)|null|多模态推理模型的最新进展在文本和视觉领域展现出令人印象深刻的能力。然而，即使是领先的模型在生成冗长的推理链时也会表现出冗余的自我反思。虽然无训练的CoT压缩方法已在大型语言模型（LLMs）领域出现，但它们依赖静态视觉参考，因此为多模态推理带来的提升有限。因此，我们提出了ChainV，一个将视觉提示动态整合到推理过程中的框架，从而使多模态推理更短更好。具体而言，ChainV首先根据前一步推理进行粗略的视觉补丁选择，然后根据平均注意力强度通过识别最具代表性的原子视觉提示进行细化。此外，ChainV引入了一种基于一致性的评估机制，以评估所选提示的可靠性，指导模型自适应地调整其自我反思水平。最终，所选视觉提示的像素坐标及其可靠性通过伯努利随机过程被纳入思考中。实验表明，我们的方法显著提高了推理的准确性和效率，尤其是在视觉提示对于多步符号推理至关重要的数学密集型基准上。例如，ChainV在MIMO-VL-RL的MathVista上实现了2.3%的改进，同时将推理延迟降低了51.4%，并将输出token长度缩短了24.5%。|
|**2025-11-20**|[Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter](http://arxiv.org/abs/2511.16665)|null|具有强大推理能力的大型语言模型（LLMs）的出现标志着一个重要的里程碑，为复杂问题解决开辟了新领域。然而，训练这些通常使用强化学习（RL）的推理模型时，会遇到关键的效率瓶颈：RL训练期间的响应生成呈现出持续的长尾分布，少数极长的响应主导了执行时间，浪费资源并增加了成本。为解决此问题，我们提出了TLT，一个通过整合自适应推测解码，无损加速推理RL训练的系统。在RL中应用推测解码具有挑战性，原因在于动态工作负载、不断演变的目标模型以及草稿模型训练开销。TLT通过两个协同组件克服了这些障碍：(1) 自适应草稿器，一个轻量级草稿模型，在长尾生成期间利用空闲GPU持续训练，以无额外开销地保持与目标模型的一致性；以及(2) 自适应回滚引擎，它维护一个内存高效的预捕获CUDAGraphs池，并为每个输入批次自适应选择合适的SD策略。评估表明，TLT相较于最先进的系统，实现了超过1.7倍的端到端RL训练加速，保持了模型精度，并生成了一个高质量的草稿模型作为免费的副产品，适用于高效部署。代码已发布在https://github.com/mit-han-lab/fastrl。|
|**2025-11-20**|[Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](http://arxiv.org/abs/2511.16602)|null|开发一个通用且多功能的具身智能系统面临两个主要挑战：关键的具身数据瓶颈，即真实世界数据稀缺且昂贵；以及现有方法算法效率低下，其资源开销巨大。为解决这些局限性，我们引入了刻意练习策略优化（DPPO），这是一种元认知“元循环”训练框架，它动态交替进行监督微调（能力扩展）和强化学习（技能完善）。这使得自动识别弱点和有针对性的资源分配成为可能，专门设计用于最大化从稀疏、有限数据中学习的效率。理论上，DPPO可以被形式化为一个统一的偏好学习框架。经验上，使用DPPO训练一个视觉-语言具身模型（称为Pelican-VL 1.0）比基础模型性能提升了20.3%，并在千亿参数规模上超越了开源模型10.6%。我们正在开源模型和代码，提供了第一个系统性框架，缓解了数据和资源瓶颈，并使社区能够高效地构建多功能具身智能体。|
|**2025-11-20**|[The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](http://arxiv.org/abs/2511.16543)|null|大语言模型（LLM）集成到可解释推荐系统中的端到端架构，通常会导致性能与效率之间的权衡，其中排序和解释的联合优化可能导致次优折衷。为解决此问题，我们提出Prism，一种新颖的解耦框架，它将推荐过程严格分离为专门的排序阶段和解释生成阶段。受知识蒸馏启发，Prism利用强大的教师大语言模型（例如FLAN-T5-XXL）作为预言机，生成高保真解释性知识。然后，紧凑的、经过微调的学生模型（例如BART-Base），即Prism，专门将这些知识合成为个性化解释。这种分解确保每个组件都针对其特定目标进行优化，从而消除了耦合模型中固有的冲突。在基准数据集上进行的大量实验表明，我们拥有1.4亿参数的Prism模型在忠实性和个性化的人工评估中显著优于其拥有110亿参数的教师模型，同时在推理过程中实现了24倍的加速和10倍的内存消耗减少。这些结果验证了解耦结合有针对性的蒸馏，为实现高质量可解释推荐提供了一条高效且有效的途径。|
|**2025-11-20**|[TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](http://arxiv.org/abs/2511.16528)|null|神经信息检索系统在高资源语言中表现出色，但在形态丰富、资源匮乏的语言（如土耳其语）中仍未得到充分探索。目前，稠密双编码器在土耳其语信息检索中占据主导地位，然而晚期交互模型（它们保留词元级表示以进行细粒度匹配）尚未得到系统性评估。我们引入了TurkColBERT，这是首个全面比较土耳其语检索中稠密编码器和晚期交互模型的基准。我们的两阶段适应管道首先在土耳其语NLI/STS任务上微调英语和多语言编码器，然后使用在MS MARCO-TR上训练的PyLate将它们转换为ColBERT风格的检索器。我们在涵盖科学、金融和论证领域的五个土耳其语BEIR数据集上评估了10个模型。结果显示出强大的参数效率：100万参数的colbert-hash-nano-tr比6亿参数的turkish-e5-large稠密编码器小600倍，同时保留了其平均mAP的71%以上。比稠密编码器小3到5倍的晚期交互模型显著优于它们；ColmmBERT-base-TR在领域特定任务上将mAP提升高达13.8%。为了生产就绪性，我们比较了索引算法：MUVERA+Rerank比PLAID快3.33倍，并提供了1.7%的相对mAP增益。这实现了低延迟检索，ColmmBERT-base-TR在MUVERA下实现了0.54毫秒的查询时间。我们发布了所有检查点、配置和评估脚本。局限性包括依赖中等规模数据集（文档数量≤5万）和翻译的基准，这些可能无法完全反映真实世界的土耳其语检索条件；更大规模的MUVERA评估仍然是必要的。|
|**2025-11-20**|[LLM4EO: Large Language Model for Evolutionary Optimization in Flexible Job Shop Scheduling](http://arxiv.org/abs/2511.16485)|null|定制化的静态算子设计使得进化算法（EAs）得到了广泛应用，但其搜索性能在迭代过程中表现出短暂性和易退化性。动态算子旨在解决此问题，但通常依赖预定义的设计和搜索过程中的局部参数控制，缺乏贯穿整个进化过程的自适应优化。为克服这些局限性，本工作利用大型语言模型（LLMs）感知进化动态，并实现算子层面的元进化。所提出的LLMs用于进化优化（LLM4EO）框架包含三个组成部分：基于知识迁移的算子设计、进化感知与分析以及自适应算子进化。首先，通过LLMs迁移经典算子的优势来执行算子的初始化。接着，通过整合适应度性能和进化特征，分析算子的搜索偏好和潜在局限性，并提供相应的改进建议。当种群进化停滞时，通过改进提示策略动态优化算子的基因选择优先级。这种方法实现了搜索过程中种群和算子的协同进化，为提高进化算法的效率和适应性引入了一种新颖的范式。最后，在柔性作业车间调度问题的多个基准数据集上进行的一系列验证表明，LLM4EO加速了种群进化，并优于主流进化编程和传统进化算法。|
|**2025-11-20**|[An Efficient LLM-based Evolutional Recommendation with Locate-Forget-Update Paradigm](http://arxiv.org/abs/2511.16414)|null|如今，大语言模型（LLMs）在序列推荐方面展现出卓越性能，基于大语言模型的推荐系统（LLMRec）在现有电商平台中的应用正日益广泛。尽管性能令人印象深刻，但持续产生的大量新用户-物品交互使得系统难以适应用户偏好随时间演变，尤其对于基于大语言模型的推荐系统而言。这一挑战源于大语言模型中庞大的参数量，这使得传统的演化方法（即重新训练或微调）变得不切实际。具体而言，使用所有交互进行重新训练会导致极高的计算成本。另一方面，仅使用新交互进行微调会导致非活跃用户的偏好遗忘，最终损害整体性能。为了解决这个问题，我们提出了EvoRec，一个为基于大语言模型的推荐系统设计的高效定位-遗忘-更新框架，旨在建模用户偏好演变。EvoRec识别出一小组与偏好变化相关的参数并精确地更新它们，从而节省计算资源，同时保持强大的推荐性能。值得注意的是，修改的参数仅占LoRA适配器参数的30%，且未引入额外参数。在两个真实世界数据集上进行的广泛实验表明，与现有方法相比，EvoRec不仅能高效地演化LLMRec以适应活跃用户的偏好，而且在演化过程中保护了非活跃用户的兴趣不受干扰。|
|**2025-11-20**|[Reasoning Meets Representation: Envisioning Neuro-Symbolic Wireless Foundation Models](http://arxiv.org/abs/2511.16369)|null|无线物理层基础模型（WPFM）的近期进展预示着通用射频（RF）表征的新范式。然而，这些模型继承了深度学习中存在的关键局限性，例如缺乏可解释性、鲁棒性、适应性以及对物理和监管约束的可验证遵守。此外，面向AI原生6G网络的愿景要求一种能够深度嵌入系统并具有可信性的智能水平。在这篇展望论文中，我们认为神经符号范式（将数据驱动的神经网络与基于规则和逻辑的符号推理相结合）对于弥合这一鸿沟至关重要。我们设想了一种新颖的神经符号框架，该框架将通用射频嵌入与符号知识图谱和可微分逻辑层相结合。这种混合方法使模型能够从大数据集中学习，同时对显式领域知识进行推理，从而实现可信、可泛化和高效的无线AI，以满足未来网络的需求。|
|**2025-11-20**|[OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](http://arxiv.org/abs/2511.16334)|**[link](https://github.com/EvolvingLMMs-Lab/OpenMMReasoner)**|大型推理模型的最新进展激发了人们将此类能力扩展到多模态领域的日益增长的兴趣。然而，尽管视觉推理取得了显著进展，但缺乏透明且可复现的数据整理和训练策略仍然是可扩展研究的主要障碍。在这项工作中，我们引入了OpenMMReasoner，这是一个用于多模态推理的完全透明的两阶段方案，涵盖监督微调 (SFT) 和强化学习 (RL)。在SFT阶段，我们构建了一个包含87.4万个样本的冷启动数据集，并经过严格的循序渐进验证，为推理能力奠定了坚实基础。随后的RL阶段利用了一个涵盖多个领域的包含7.4万个样本的数据集，以进一步磨练和稳定这些能力，从而实现更鲁棒高效的学习过程。大量评估表明，我们的训练方案不仅超越了强大的基线，而且强调了数据质量和训练设计在塑造多模态推理性能方面的关键作用。值得注意的是，我们的方法在九个多模态推理基准测试中相较于Qwen2.5-VL-7B-Instruct基线实现了11.6%的提升，为未来的大规模多模态推理研究奠定了坚实的实证基础。我们在https://github.com/EvolvingLMMs-Lab/OpenMMReasoner开源了我们所有的代码、管道和数据。|
|**2025-11-20**|[SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](http://arxiv.org/abs/2511.16324)|**[link](https://github.com/adventurexw/SDA)**|随着大语言模型（LLMs）的快速发展，它们在实际应用中的部署变得越来越广泛。LLMs有望在不同任务、用户偏好和实际场景中提供鲁棒性能。然而，随着需求增长，确保LLMs生成与人类意图对齐的响应仍然是一项基础性挑战。特别是在推理过程中，无需昂贵的再训练或大量监督，有效且高效地对齐模型行为，既是关键要求，也是一项非平凡的技术努力。为解决这一挑战，我们提出了SDA（转向驱动的分布对齐），一个专为开源LLMs设计的免训练、模型无关的对齐框架。SDA基于用户定义的对齐指令动态地重新分配模型输出概率，无需微调即可增强模型行为与人类意图之间的对齐。该方法轻量级、资源高效，并与各种开源LLMs兼容。它可以在推理期间独立运行，也可与基于训练的对齐策略集成。此外，SDA支持个性化偏好对齐，从而实现对模型响应行为的灵活控制。实验结果表明，SDA在具有不同规模和多样化来源的8个开源LLMs上持续提升对齐性能，并在有益性、无害性和诚实性（3H）这三个关键对齐维度上进行了评估。具体而言，SDA在所有测试模型中，有益性平均提升64.4%，诚实性提升30%，无害性提升11.5%，表明其在不同模型和应用场景中的有效性和泛化能力。|
|**2025-11-20**|["To Survive, I Must Defect": Jailbreaking LLMs via the Game-Theory Scenarios](http://arxiv.org/abs/2511.16278)|null|随着大语言模型日益普及，非专业用户可能带来风险，这促使研究人员对越狱攻击进行了广泛深入的研究。然而，大多数现有的黑盒越狱攻击依赖于人工设计的启发式方法或狭窄的搜索空间，这限制了它们的可扩展性。与现有攻击相比，我们提出了博弈论攻击（GTA），一个可扩展的黑盒越狱框架。具体而言，我们将攻击者与安全对齐的大语言模型的交互形式化为一个有限时间范围、可提前终止的序贯随机博弈，并通过量化响应重新参数化了大语言模型的随机输出。基于此，我们引入了一个行为猜想：“模板优先于安全”的翻转：通过博弈论场景重塑大语言模型的有效目标，其原始的安全偏好可能变为最大化模板内的场景收益，从而在特定情境下削弱了安全约束。我们通过囚徒困境的披露变体等经典博弈验证了这一机制，并进一步引入了一个攻击者智能体，该智能体能自适应地升级压力以提高攻击成功率（ASR）。跨多个协议和数据集的实验结果表明，GTA 在 Deepseek-R1 等大语言模型上达到了超过95%的ASR，同时保持了效率。对组件、解码、多语言设置以及智能体核心模型的消融实验证实了其有效性和泛化能力。此外，场景规模扩展研究进一步确立了其可扩展性。GTA 在其他博弈论场景中也获得了高ASR，并且在模型机制不变但背景改变的单次大语言模型生成变体中也取得了可比的ASR。与执行词级别插入的有害词检测智能体相结合，GTA 在提示词防御模型下保持了高ASR，同时降低了检测率。除了基准测试，GTA 还成功越狱了真实世界的大语言模型应用，并报告了对流行的 HuggingFace 大语言模型的纵向安全监测结果。|
|**2025-11-18**|[AdamHD: Decoupled Huber Decay Regularization for Language Model Pre-Training](http://arxiv.org/abs/2511.14721)|null|解耦权重衰减的自适应优化器，如AdamW，已成为预训练大型基于Transformer的生成模型的事实标准。然而，嵌入在权重衰减中的 $\ell_2$惩罚的二次特性以相同的速率将所有参数推向原点，这使得更新易受罕见但极端的梯度方向影响，并且经常过度惩罚条件良好的坐标。我们提出了AdamHuberDecay，一个AdamW的即插即用替代品，它用解耦平滑Huber正则化器替代了$\ell_2$惩罚。由此产生的更新在参数幅度低于阈值$δ$时呈二次衰减，一旦超过$δ$则呈线性衰减（类似$\ell_1$），从而产生(i)有界的正则化梯度，(ii)对逐坐标二阶矩重缩放的不变性，以及(iii)对过大权重施加更强的稀疏性压力。我们推导了闭式形式的解耦Huber衰减步长，并展示了如何以$O(1)$ 的额外开销将其与任何Adam系列优化器集成。对GPT-2和GPT-3预训练进行的大量实验表明，AdamHuberDecay (a)在挂钟时间上收敛速度快10-15%，(b)将验证困惑度降低多达4点，(c)在下游任务中带来2.5-4.7%的性能提升，以及(d)产生明显更稀疏的权重直方图，在幅度剪枝后可节省20-30%的内存，且无需在AdamW使用的默认网格之外调整衰减系数。消融实验证实了其对异常梯度和大批量训练方案的鲁棒性，同时理论分析在噪声更新下限定了预期参数范数。因此，AdamHuberDecay为下一代基础生成式Transformer模型提供了一种简单、有原则的途径，以实现更高效、更具韧性的训练。|
|**2025-11-18**|[Bias in, Bias out: Annotation Bias in Multilingual Large Language Models](http://arxiv.org/abs/2511.14662)|null|自然语言处理数据集中存在的标注偏见仍然是开发多语言大型语言模型（LLMs）的主要挑战，尤其是在文化多样性环境中。源于任务设定、标注者主观性以及文化不匹配的偏见会扭曲模型输出并加剧社会危害。我们提出了一个理解标注偏见的全面框架，区分了指令偏见、标注者偏见以及上下文和文化偏见。我们回顾了检测方法（包括标注者间一致性、模型不一致性和元数据分析），并强调了多语言模型分歧和文化推断等新兴技术。我们进一步概述了主动和被动缓解策略，包括招募多样化的标注者、迭代式指南细化和事后模型调整。我们的贡献包括：（1）标注偏见的类型学；（2）检测指标的综合；（3）一种适用于多语言环境的基于集成的偏见缓解方法；以及（4）标注过程的伦理分析。这些见解旨在共同为LLMs的标注流程提供更公平、更具文化基础的指导。|
|**2025-11-18**|[Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning](http://arxiv.org/abs/2511.14617)|null|强化学习（RL）对于现代大型语言模型（LLMs）的进步至关重要，然而现有的同步强化学习系统面临严重的性能瓶颈。推演阶段主导了端到端迭代时间，由于固有的工作负载不平衡，其存在显著的长尾延迟和低下的资源利用率。我们提出了Seer，一种新颖的在线上下文学习系统，它通过利用共享相同提示的请求之间在输出长度和生成模式上以前被忽视的相似性来解决这些挑战。Seer引入了三项关键技术：用于动态负载均衡的分段推演、上下文感知调度以及自适应分组推测解码。这些机制共同作用，显著减少了推演过程中的长尾延迟并提高了资源效率。在生产级强化学习工作负载上的评估表明，与最先进的同步强化学习系统相比，Seer将端到端推演吞吐量提高了74%至97%，并将长尾延迟降低了75%至93%，从而显著加速了强化学习训练迭代。|
|**2025-11-18**|[Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language](http://arxiv.org/abs/2511.14565)|**[link](https://github.com/MIT-CLEAR-Lab/Masked-IRL)**|机器人可以通过从演示中学习奖励函数来适应用户偏好，但在数据有限的情况下，奖励模型经常过拟合到虚假相关性并泛化失败。这种情况发生是因为演示向机器人展示了如何执行任务，但没有说明对该任务而言什么才是重要的，导致模型关注不相关的状态细节。自然语言可以更直接地指定机器人应该关注什么，并且原则上可以消除与演示一致的许多奖励函数之间的歧义。然而，现有的语言条件奖励学习方法通常将指令视为简单的条件信号，而没有充分利用其解决歧义的潜力。此外，真实的指令本身也常常是模糊的，因此简单的条件作用是不可靠的。我们的关键见解是这两种输入类型携带互补信息：演示展示了如何行动，而语言则指定了什么是重要的。我们提出了掩码逆强化学习（Masked IRL），一个利用大型语言模型（LLM）结合这两种输入类型优势的框架。Masked IRL从语言指令中推断出状态相关性掩码，并强制对不相关的状态分量保持不变性。当指令模糊时，它利用LLM推理在演示的背景下对其进行澄清。在仿真和真实机器人上，Masked IRL比先前的语言条件IRL方法性能提高了高达15%，同时使用的数据量减少了高达4.7倍，证明了其在样本效率、泛化能力和对模糊语言的鲁棒性方面的提升。项目页面：https://MIT-CLEAR-Lab.github.io/Masked-IRL 和 代码：https://github.com/MIT-CLEAR-Lab/Masked-IRL|
|**2025-11-18**|[Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning](http://arxiv.org/abs/2511.14460)|**[link](https://github.com/0russwest0/Agent-R1)**|大型语言模型（LLMs）正越来越多地被探索用于构建能够通过主动环境交互（例如，通过工具使用）来解决复杂问题的智能体。强化学习（RL）被认为是训练此类智能体具有巨大潜力的关键技术；然而，RL在LLM智能体上的有效应用仍处于萌芽阶段，并面临巨大挑战。当前，这一新兴领域缺乏对专门为LLM智能体环境定制的RL方法的深入探索，同时，为此目的设计的灵活且易于扩展的训练框架也十分稀缺。为推动这一领域的发展，本文首先通过系统地扩展马尔可夫决策过程（MDP）框架，以全面定义LLM智能体的关键组成部分，从而重新审视并阐明了LLM智能体的强化学习方法论。其次，我们引入了Agent-R1，这是一个模块化、灵活且用户友好的基于RL的LLM智能体训练框架，旨在轻松适应多样化的任务场景和交互环境。我们在多跳问答（Multihop QA）基准任务上进行了实验，为我们所提出方法和框架的有效性提供了初步验证。|
|**2025-11-18**|[Hyperion: Hierarchical Scheduling for Parallel LLM Acceleration in Multi-tier Networks](http://arxiv.org/abs/2511.14450)|null|大语言模型（LLM）正日益在边缘层、雾层和云层中执行，其中有限的GPU内存、异构计算和可变的层间带宽共同制约了部署，并促使模型分区和请求调度。在这种背景下，实现低端到端延迟不仅取决于模型的部署位置（层间模型分区），还取决于如何跨异构节点调度入站请求（层内任务调度）。这两个问题紧密耦合，因为次优调度器会抵消良好分区带来的优势，反之亦然。在本文中，我们提出了Hyperion，一个分层两阶段框架，它联合优化分区和调度，以最小化多层网络中流水线式LLM推理的端到端延迟，平衡各层级的计算和内存，同时引入可忽略的运行时开销且无需模型再训练。基于分区选择的演变时间尺度慢于请求到达的观察，阶段1通过结合动态规划的二分搜索（BSDP）过程执行离线层间分区，以在层级容量和内存约束下产生平衡的阶段时间；为了适应时变负载，阶段2通过轻量级自适应实时任务调度（ARTS）算法执行在线层内调度，该算法利用队列长度和有效容量的实时估计将每个请求映射到最佳可用节点。在多层推理任务上的实验结果表明，与GPipe和HEFT基线相比，Hyperion使用Phi-3-medium模型时，端到端延迟分别显著降低了高达52.1%和31.2%。此外，Hyperion在长序列生成中展现出卓越的可扩展性，保持比GPipe低44.5%的延迟并实现更高的GPU利用率。|
|**2025-11-18**|[Tell Me: An LLM-powered Mental Well-being Assistant with RAG, Synthetic Dialogue Generation, and Agentic Planning](http://arxiv.org/abs/2511.14445)|null|我们推出了Tell Me，这是一个心理健康系统，它利用大型语言模型的最新进展，为用户和研究人员提供可访问的、上下文感知的支持。该系统集成了三个组件：(i) 一个检索增强生成（RAG）助手，用于个性化、基于知识的对话；(ii) 一个以客户画像为条件的合成客户-治疗师对话生成器，旨在促进治疗语言和数据增强的研究；以及(iii) 一个使用CrewAI实现的心理健康AI团队，负责生成每周自我护理计划和引导式冥想音频。该系统被设计为一个用于情感处理的反思空间，而不是专业治疗的替代品。它阐释了对话助手如何降低支持门槛、补充现有护理并扩大心理健康资源的获取。为解决机密治疗数据短缺的问题，我们引入了以客户画像为条件的合成客户-治疗师对话生成。最后，该规划器展示了一种创新的智能体工作流程，用于动态自适应的个性化自我护理，弥补了静态心理健康工具的局限性。我们描述了其架构，展示了其功能，并报告了在精选的心理健康场景中对RAG助手的评估结果，评估使用了自动化的基于LLM的判断和人类用户研究。这项工作强调了自然语言处理（NLP）研究人员和心理健康专业人员之间进行跨学科合作的机会，以推动促进心理健康的人机交互领域的负责任创新。|
|**2025-11-18**|[ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](http://arxiv.org/abs/2511.14366)|null|大语言模型（LLMs）的快速发展导致许多现有基准测试的性能饱和，质疑其区分前沿模型的能力。同时，现有高难度基准测试通常存在学科范围狭窄、答案形式过于简化以及易受数据污染影响的问题，这与现实世界的科学探究存在保真度差距。为解决这些挑战，我们引入ATLAS（面向通用人工智能的科学逻辑应用测试平台），一个由约800道原创问题组成的大规模、高难度、跨学科评估套件。ATLAS由领域专家（博士及以上级别）开发，涵盖数学、物理、化学、生物、计算机科学、地球科学和材料科学七个核心科学领域。其主要特点包括：（1）高原创性和抗污染性，所有问题均为新创建或大幅改编，以防止测试数据泄露；（2）跨学科关注，旨在评估模型整合知识和跨科学领域推理的能力；（3）高保真度答案，优先考虑涉及多步推理和LaTeX格式表达式的复杂、开放式答案，而非简单的多项选择题；（4）严格的质量控制，采用专家同行评审和对抗性测试的多阶段流程，确保问题的难度、科学价值和正确性。我们还提出一种稳健的评估范式，利用大语言模型（LLM）评判员组对复杂答案进行自动化、细致入微的评估。对领先模型的初步结果证明了ATLAS在区分其高级科学推理能力方面的有效性。我们计划将ATLAS发展成为一个长期、开放、社区驱动的平台，为实现通用人工智能的进展提供一个可靠的“标尺”。|
|**2025-11-18**|[ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation](http://arxiv.org/abs/2511.14259)|null|随着生成模型的快速发展，强大的图像编辑方法现在能够实现多样化且高度逼真的图像篡改，其能力远超传统深度伪造技术，给篡改检测带来了新的挑战。现有的图像篡改检测与定位（IMDL）基准存在内容多样性有限、生成模型覆盖范围窄以及解释性不足的问题，这阻碍了当前篡改检测方法的泛化能力和解释能力。为了解决这些局限性，我们引入了ManipBench，一个专注于AI编辑图像的大规模图像篡改检测与定位基准。ManipBench包含超过45万张篡改图像，由25种最先进的图像编辑模型生成，涵盖12种篡改类别，其中10万张图像进一步标注了边界框、判断线索和文本解释，以支持可解释的检测。基于ManipBench，我们提出了ManipShield，一个基于多模态大语言模型（MLLM）的一体化模型，该模型利用对比LoRA微调和任务专用解码器，以实现统一的图像篡改检测、定位和解释。在ManipBench和多个公共数据集上进行的广泛实验表明，ManipShield实现了最先进的性能，并对未见过的篡改模型表现出强大的泛化能力。ManipBench和ManipShield都将在发表后发布。|
|**2025-11-18**|[Enhancing Generalization of Depth Estimation Foundation Model via Weakly-Supervised Adaptation with Regularization](http://arxiv.org/abs/2511.14238)|null|基础模型的出现，以Depth Anything系列为代表，大幅推动了单目深度估计（MDE）中的零样本泛化能力。然而，鉴于能够获取一些下游任务数据，一个自然而然的问题随之产生：这些模型的性能能否得到进一步提升？为此，我们提出了WeSTAR，一个参数高效的框架，该框架执行弱监督自训练正则化适应，旨在增强MDE基础模型在未见过和多样化领域中的鲁棒性。我们首先采用密集自训练目标作为结构化自监督的主要来源。为了进一步提高鲁棒性，我们引入了语义感知分层归一化，该方法利用实例级分割图来执行更稳定和多尺度的结构归一化。在密集监督之外，我们引入了一种成本高效的弱监督，其形式为成对序数深度标注，以进一步指导适应过程，该弱监督施加了信息丰富的序数约束来减轻局部拓扑错误。最后，我们采用权重正则化损失来锚定LoRA更新，确保训练稳定性并保留模型的泛化知识。在多样化和具有挑战性的场景下，对真实和损坏的分布外数据集进行的大量实验表明，WeSTAR持续提升了泛化能力，并在广泛的基准测试中达到了最先进的性能。|
|**2025-11-14**|[Experience-Guided Adaptation of Inference-Time Reasoning Strategies](http://arxiv.org/abs/2511.11519)|null|使智能体AI系统能够根据训练后交互调整其问题解决方法，仍然是一个基本挑战。虽然已经提出了在推理时更新和维护记忆的系统，但现有设计仅通过修改语言模型或智能体的文本输入来引导系统，这意味着它们无法改变采样参数、移除工具、修改系统提示或在智能体范式和工作流范式之间切换。另一方面，适应性更强的系统需要离线优化，并且一旦部署便保持静态。我们提出了经验引导推理器（EGuR），它根据积累的经验，在推理时动态生成定制策略——包括大语言模型调用、工具、采样参数和控制逻辑在内的完整计算过程。我们通过一个基于大语言模型的元策略——一个输出策略的策略——来实现这一点，从而能够适应所有策略组件（提示、采样参数、工具配置和控制逻辑）。EGuR通过两个组件运行：引导器根据当前问题和过去经验的结构化记忆生成多个候选策略，而整合器则整合执行反馈以改进未来的策略生成。这产生了针对每个问题优化的完整、即用型策略，这些策略可以根据需要进行缓存、检索和执行，而不会浪费资源。在五个具有挑战性的基准测试（AIME 2025、3-SAT 和三个Big Bench Extra Hard任务）中，EGuR相较于最强的基线实现了高达14%的准确率提升，同时将计算成本降低了高达111倍，并且随着系统经验的积累，这两个指标均有所改善。|
|**2025-11-14**|[W2S-AlignTree: Weak-to-Strong Inference-Time Alignment for Large Language Models via Monte Carlo Tree Search](http://arxiv.org/abs/2511.11518)|**[link](https://github.com/alexzdy/W2S-AlignTree)**|大型语言模型（LLM）展现出令人印象深刻的能力，然而，它们的输出常常因弱监督不足和缺乏细粒度控制而与人类偏好不一致。基于人类反馈的强化学习（RLHF）等训练时对齐方法面临专家监督的高昂成本和固有的可扩展性限制，在推理过程中提供有限的动态控制。因此，迫切需要可扩展和适应的对齐机制。为此，我们提出了W2S-AlignTree，这是一个开创性的即插即用推理时对齐框架，首次协同结合了蒙特卡洛树搜索（MCTS）与弱到强泛化范式。W2S-AlignTree将LLM对齐公式化为生成式搜索树中的一个最优启发式搜索问题。通过利用弱模型实时、步级信号作为对齐代理，并引入熵感知探索机制，W2S-AlignTree在不修改强模型参数的情况下，实现了其生成过程中的细粒度指导。该方法在高维生成搜索树中动态平衡了探索与利用。在受控情感生成、摘要和指令遵循任务上的实验表明，W2S-AlignTree始终优于强基线。值得注意的是，W2S-AlignTree将Llama3-8B在摘要任务上的性能从1.89提升到2.19，相对改进了15.9。|
|**2025-11-14**|[OpenUS: A Fully Open-Source Foundation Model for Ultrasound Image Analysis via Self-Adaptive Masked Contrastive Learning](http://arxiv.org/abs/2511.11510)|**[link](https://github.com/XZheng0427/OpenUS)**|超声（US）是应用最广泛的医学成像模态之一，因为它具有成本低、便携、实时反馈和无电离辐射等优点。然而，超声图像判读高度依赖操作者，并且在不同解剖区域、采集协议和设备类型之间差异显著。这些差异，连同斑点噪声、低对比度和有限标准化标注等独特挑战，阻碍了泛化能力强、标签高效的超声AI模型的开发。在本文中，我们提出了OpenUS，这是首个基于大量公开数据构建的可复现、开源超声基础模型。OpenUS采用视觉Mamba主干网络，捕获图像的局部和全局长程依赖关系。为了在预训练期间提取丰富的特征，我们引入了一种新颖的自适应掩码框架，将对比学习与掩码图像建模相结合。该策略将教师模型的注意力图与学生模型的重建损失相结合，自适应地优化临床相关掩码，以提高预训练的有效性。OpenUS还应用动态学习调度，逐步调整预训练过程的难度。为了开发这个基础模型，我们汇编了迄今为止最大的公开超声数据集，包含来自42个公开数据集的超过30.8万张图像，涵盖了不同的解剖区域、医疗机构、成像设备和疾病类型。我们预训练的OpenUS模型可以作为主干网络用于标签高效的微调，从而轻松适应特定的下游任务。代码可在https://github.com/XZheng0427/OpenUS获取。|
|**2025-11-14**|[Rethinking Efficient Mixture-of-Experts for Remote Sensing Modality-Missing Classification](http://arxiv.org/abs/2511.11460)|null|遥感领域的多模态分类常因环境干扰、传感器故障或大气效应导致模态缺失，这严重降低了分类性能。现有的两阶段适应方法计算成本高昂，且假设训练期间模态数据完整，这限制了它们在真实世界不完整数据上的泛化能力。为了克服这些问题，我们提出了一种缺失感知LoRA混合（MaMOL）框架，将模态缺失重新定义为多任务学习问题。MaMOL引入了双路由机制：一个任务导向的动态路由器，自适应地为不同的缺失模式激活专家；以及一个模态特异性共享的静态路由器，用于保持稳定的跨模态知识共享。与以往为每种缺失配置训练独立网络的方法不同，MaMOL通过轻量级专家更新和共享专家复用，实现了参数高效的适应。在多个遥感基准数据集上的实验证明，MaMOL在不同缺失率下展现出卓越的鲁棒性和泛化能力，且计算开销最小。此外，在自然图像数据集上的迁移实验验证了其可扩展性和跨域适用性，突显MaMOL是解决不完整多模态学习问题的通用高效方案。|
|**2025-11-14**|[BOFA: Bridge-Layer Orthogonal Low-Rank Fusion for CLIP-Based Class-Incremental Learning](http://arxiv.org/abs/2511.11421)|null|类别增量学习（CIL）旨在持续学习新类别而不遗忘先前获得的知识。CLIP等视觉-语言模型通过多模态监督提供强大的可迁移表示，使其在CIL中具有前景。然而，将CLIP应用于CIL面临两大挑战：（1）适应下游任务通常需要额外的可学习模块，这增加了模型复杂性并使其易受遗忘影响；（2）虽然多模态表示提供互补优势，但现有方法尚未充分发挥其在有效整合视觉和文本模态方面的潜力。为解决这些问题，我们提出了一种新颖的CIL框架BOFA（桥接层正交融合自适应）。BOFA将所有模型自适应完全限制在CLIP现有的跨模态桥接层中，从而不增加额外参数或推理成本。为防止该层内部的遗忘，它利用正交低秩融合，这是一种将参数更新限制在低秩“安全子空间”的机制，该子空间经过数学构建，使其与过去任务特征正交。这确保了稳定的知识积累而无需数据回放。此外，BOFA采用了一种跨模态混合原型，该原型协同稳定的文本原型与源自我们稳定自适应桥接层的视觉对应物，从而提高了分类性能。在标准基准上的大量实验表明，与现有方法相比，BOFA实现了卓越的准确性和效率。|
|**2025-11-14**|[UFO $^3$: Weaving the Digital Agent Galaxy](http://arxiv.org/abs/2511.11332)|null|大语言模型（LLM）驱动的智能体正在将数字设备从被动工具转变为主动智能协作者。然而，大多数现有框架仍局限于单一操作系统或设备，使得跨设备工作流脆弱且主要依赖手动操作。我们提出了UFO$^3$，一个将异构终端（包括桌面电脑、服务器、移动设备和边缘设备）统一到单一编排框架中的系统。UFO$^3$将每个用户请求建模为一个可变的任务星座（TaskConstellation）：一个由原子子任务（TaskStars）组成的分布式有向无环图（DAG），具有明确的控制和数据依赖关系（TaskStarLines）。任务星座持续演变，随着结果从分布式设备中流入，从而实现异步执行、自适应恢复和动态优化。一个星座编排器（Constellation Orchestrator）安全异步地执行任务，同时应用动态DAG更新，并且智能体交互协议（AIP）提供持久的低延迟通道，用于可靠的任务分派和结果流传输。这些设计消除了设备和平台之间的传统界限，允许智能体无缝协作并增强其集体智能。我们在NebulaBench上评估了UFO$^3$，这是一个包含55个跨设备任务的基准测试，涵盖5台机器和10个类别。UFO$^3$实现了83.3%的子任务完成率、70.9%的任务成功率，平均并行度为1.72，相对于顺序基线，端到端延迟降低了31%。故障注入实验展示了在瞬态和永久性智能体故障下的优雅降级和恢复能力。这些结果表明UFO$^3$ 实现了跨异构设备的准确、高效和有弹性的任务编排，将孤立的智能体统一成一个连贯、自适应的计算结构，且该结构延伸至普适计算的整个领域。|
|**2025-11-14**|[LAET: A Layer-wise Adaptive Ensemble Tuning Framework for Pretrained Language Models](http://arxiv.org/abs/2511.11315)|null|自然语言处理（NLP）已经改变了金融行业，促成了文本分析、风险管理和预测等领域的进步。彭博GPT（BloombergGPT）和FinMA等大型语言模型（LLMs）在情感分析、股票走势预测和信用风险评估等各种金融NLP任务中设立了新的基准。此外，双语金融LLM FinMA-ES在使用FLARE和FLARE-ES基准测试时也展现出强大的性能。然而，这些模型的高计算需求限制了许多组织的使用。为了解决这个问题，我们提出逐层自适应集成微调（LAET），这是一种新颖的策略，通过分析隐藏状态表示，选择性地微调预训练LLM中最有效的层，同时冻结不那么关键的层。LAET显著降低了计算开销，同时提升了任务特定性能。我们的方法在金融NLP任务中展现出强大的结果，甚至在使用较小LLM（约30亿参数）的情况下，也优于现有基准和像GPT-4这样的最先进LLM。这项工作通过为金融应用提供高效且可扩展的模型，弥合了尖端金融NLP研究与实际部署之间的差距。|
|**2025-11-14**|[Align $^3$GR: Unified Multi-Level Alignment for LLM-based Generative Recommendation](http://arxiv.org/abs/2511.11255)|null|大语言模型（LLMs）在利用结构化世界知识和多步推理能力方面展现出显著优势。然而，由于语义和行为失配，在将LLMs转化为真实世界的推荐系统时存在根本性挑战。为弥合这一差距，我们提出了Align$^3$GR，一个统一了标记级、行为建模级和偏好级对齐的新颖框架。我们的方法引入了：融合用户-物品语义和协同信号的双重标记化；结合双向语义对齐的增强行为建模；以及结合自我博弈（SP-DPO）和真实世界反馈（RF-DPO）的渐进式DPO策略，用于动态偏好适应。实验表明，Align$^3$ GR在公共数据集上的Recall@10和NDCG@10方面分别超越了最先进的基线17.8%和20.2%，并在线上A/B测试以及工业级大规模推荐平台上的全面部署中取得了显著提升。|
|**2025-11-14**|[Analysing Personal Attacks in U.S. Presidential Debates](http://arxiv.org/abs/2511.11108)|null|人身攻击已成为美国总统辩论的一个显著特征，并在选举期间对塑造公众认知发挥重要作用。检测此类攻击可以提高政治话语的透明度，并为记者、分析师和公众提供见解。深度学习和基于Transformer的模型，特别是BERT和大型语言模型（LLM）的进展，为有害语言的自动化检测创造了新机遇。受这些进展启发，我们提出了一个分析美国总统辩论中人身攻击的框架。我们的工作包括对2016、2020和2024年选举周期辩论记录进行人工标注，随后进行统计分析和基于语言模型的分析。我们探讨了微调的Transformer模型以及通用LLM在检测正式政治演讲中人身攻击方面的潜力。本研究展示了现代语言模型的任务特定适应如何有助于更深入地理解政治传播。|
|**2025-11-14**|[AccKV: Towards Efficient Audio-Video LLMs Inference via Adaptive-Focusing and Cross-Calibration KV Cache Optimization](http://arxiv.org/abs/2511.11106)|null|音视频大语言模型（AV-LLMs）的最新进展增强了它们在音视频问答和多模态对话系统等任务中的能力。视频和音频引入了扩展的时间维度，导致与静态图像嵌入相比，键值（KV）缓存更大。一种朴素的优化策略是根据任务选择性地关注和保留音频或视频的KV缓存。然而，在实验中我们观察到，AV-LLMs在高层中对各种模态的注意力并非严格依赖于任务。在较高层中，AV-LLMs的注意力更多地转向视频模态。此外，我们还发现直接整合音频的时间KV和视频的时空KV可能导致信息混淆和AV-LLMs的显著性能下降。如果不加区分地处理音频和视频，还可能导致某种模态的过度压缩或保留，从而破坏模态间的对齐。为了解决这些挑战，我们提出了AccKV，一个专为高效AV-LLMs推理设计的自适应聚焦与交叉校准KV缓存优化框架。我们的方法基于层自适应聚焦技术，根据不同层的特性选择性地聚焦关键模态，并通过注意力重新分配增强对重击标记的识别。此外，我们提出了一种交叉校准技术，该技术首先整合音频和视频模态内低效的KV缓存，然后将低优先级模态与高优先级模态对齐，以选择性地驱逐低优先级模态的KV缓存。实验结果表明，AccKV在保持准确性的同时，能显著提高AV-LLMs的计算效率。|
|**2025-11-07**|[OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data](http://arxiv.org/abs/2511.05028)|null|联邦微调 (FFT) 使基础模型适应分散式数据，但由于局部漂移（即客户端级别的更新分歧，导致全局模型出现系统性偏差和放大方差），在异构客户端分布下仍然脆弱。现有的聚合和个性化方法主要是在事后纠正漂移，这在极端非独立同分布 (non-IID) 条件下被证明是脆弱的。我们引入了 OvA-LP，据我们所知，它是一个极简框架，是第一个明确设计用于在基于 PEFT 的 FFT 范式内从源头抑制漂移的方法。OvA-LP 结合了对冻结编码器进行线性探测、一对多 (one-vs-all) 头和一个简单的两阶段过程，从而保留了预训练特征的几何结构并解耦 logits，以阻止放大漂移的机制。在具有 100 个客户端的 CIFAR-100 上，平均在 shard-1、shard-2 和伯努利-狄利克雷 (Bernoulli-Dirichlet) 分区上，OvA-LP 保留了其 95.9% 的 IID 准确率，而最先进的 FFT 基线在相同条件下仅保留了 10.1% (PFPT) 和 34.5% (FFT-MoE)。OvA-LP 还在对称和非对称标签噪声下保持了韧性。此外，预计算编码器特征使得每轮成本几乎与编码器大小无关。综合来看，这些结果表明 OvA-LP 为在异构性下实现鲁棒的 FFT 提供了一个原则性且高效的基础。|
|**2025-11-06**|[Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](http://arxiv.org/abs/2511.04875)|null|近期研究揭示，大型语言模型 (LLMs) 可以表现出行为自我意识：即无需明确监督，准确描述或预测自身习得行为的能力。这种能力引发了安全担忧，例如，它可能使模型在评估过程中更好地隐藏其真实能力。我们试图刻画这种自我意识浮现的最小条件，以及其显现的机制过程。通过在指令微调的LLMs上使用低秩适配器 (LoRA) 进行受控微调实验，我们发现：(1) 自我意识可以使用单个秩为1的LoRA适配器可靠地诱导；(2) 习得的自我意识行为可以在很大程度上通过激活空间中的一个单一操纵向量来捕获，恢复了几乎所有微调的行为效果；(3) 自我意识并非普遍存在，而是领域局部的，在不同任务中具有独立的表示。综上所述，这些发现表明行为自我意识表现为一种领域特定的线性特征，可以被轻易诱导和调节。|
|**2025-11-03**|[Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models](http://arxiv.org/abs/2511.02869)|null|编程语言可以通过利用语言模型来执行软件工程任务，从而相互受益。对代码语言模型（Code-LMs）进行全量微调和参数高效微调（PEFT）已被探索用于多语言知识迁移。AdapterFusion是一种PEFT架构，旨在通过利用来自多种编程语言的信息来提升任务性能，但主要侧重于目标编程语言。在我们之前的工作中，我们提出了一种名为AdvFusion的新型基于PEFT的方法，该方法在适应目标任务之前能有效学习其他编程语言。尽管之前的实验表明AdvFusion优于AdapterFusion和LoRA，但它仅应用于预训练的Code-LMs，并且仅限于两个任务：代码摘要和方法名预测。在本研究中，我们扩展了我们的工作，并在代码大语言模型（Code-LLMs）上研究了AdvFusion，考虑了三个新任务：代码生成、代码翻译和提交消息生成。我们观察到不同的Code-LLMs/任务表现出不同的特性。在代码生成任务中，AdvFusion优于AdapterFusion，但不如其他PEFT方法（LoRA、Compacter和TaskAdapter）。在提交消息生成任务中，AdapterFusion表现优于AdvFusion，并且与代码生成任务相反，我们发现其他PEFT方法并未表现出更好的性能。在代码翻译任务中，AdvFusion的整体表现差于AdapterFusion，并且随着模型尺寸的增加，性能差距略微扩大。然而，与代码生成任务一致的是，其他PEFT方法表现出了更好的性能。|
|**2025-11-05**|[TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models](http://arxiv.org/abs/2511.02802)|**[link](https://github.com/Lexsi-Labs/TabTune)**|表格基础模型代表了结构化数据学习中一种日益增长的范式，将大规模预训练的优势扩展到表格领域。然而，由于异构的预处理流程、分散的API、不一致的微调过程，以及缺乏针对校准和公平性等部署导向型指标的标准化评估，它们的采用仍然有限。我们提出了TabTune，这是一个统一的库，通过单一接口标准化了表格基础模型的完整工作流。TabTune提供对七个最先进模型的一致访问，支持多种适应策略，包括零样本推理、元学习、有监督微调（SFT）和参数高效微调（PEFT）。该框架自动化了模型感知的预处理，在内部管理架构异构性，并集成了用于性能、校准和公平性的评估模块。TabTune旨在实现可扩展性和可复现性，从而能够对表格基础模型的适应策略进行一致的基准测试。|
|**2025-11-04**|[TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models](http://arxiv.org/abs/2511.02802)|null|表格基础模型代表了结构化数据学习中一个新兴范式，将大规模预训练的优势扩展到表格领域。然而，由于异构的预处理流程、分散的API、不一致的微调过程以及缺乏对校准和公平性等面向部署指标的标准化评估，其应用仍受限制。我们提出了TabTune，这是一个统一库，通过单一接口标准化了表格基础模型的完整工作流程。TabTune提供对七种最先进模型的一致访问，支持多种适配策略，包括零样本推理、元学习、有监督微调（SFT）和参数高效微调（PEFT）。该框架自动化了模型感知的预处理，内部管理架构异构性，并集成了用于性能、校准和公平性的评估模块。TabTune旨在实现可扩展性和可复现性，支持对表格基础模型适配策略的一致基准测试。该库是开源的，可在https://github.com/Lexsi-Labs/TabTune 获取。|
|**2025-11-03**|[DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning](http://arxiv.org/abs/2511.01610)|null|视觉基础模型 (VFMs) 通过自监督方法推动了表示学习的进展。然而，现有训练流程通常不灵活、领域特定或计算成本高昂，这限制了它们在不同领域和资源配置下的可用性。DINO-MX 是一个模块化、可扩展的训练框架，它在一个统一的配置驱动系统中结合了 DINO、DINOv2 和 DINOv3 的核心原理。它支持多种基于 Transformer 的架构，并与 Hugging Face 生态系统完全兼容。该框架包括低秩适应 (LoRA)、层冻结和知识蒸馏等多种训练策略，并支持通过分布式数据并行 (DDP) 和完全分片数据并行 (FSDP) 进行分布式训练。DINO-MX 旨在处理自然和专用数据类型，包括单通道和多通道图像。在多样化数据集上的实验结果表明，DINO-MX 实现了有竞争力的性能，同时显著降低了计算成本。此外，它提供了可解释性工具和一种标签引导的数据增强方法，该方法无需额外的检测或分割头即可改善基于注意力的定位。DINO-MX 为在各种研究和实际应用中开发、适应和基准测试自监督视觉模型提供了一个可复现且可扩展的基础。|
|**2025-11-03**|[HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA](http://arxiv.org/abs/2511.01463)|null|指令微调数据的扩展使得基础语言模型能够表现出改进的指令遵循能力和在多样化下游任务上的卓越性能。语义丰富的3D人体运动正逐步与这些基础模型整合，以增强多模态理解和跨模态生成能力。然而，人体运动与文本之间的模态鸿沟在此整合过程中引发了关于灾难性遗忘的未解决担忧。此外，开发能够保持在异构下游任务中泛化能力的自回归兼容姿态表示，仍然是一个关键的技术障碍。为解决这些问题，我们提出了人体运动-视觉-语言模型 (HMVLM)，这是一个基于专家混合低秩自适应 (MoE LoRA) 策略的统一框架。该框架利用门控网络根据输入提示动态分配LoRA专家权重，从而实现多任务的同步微调。为了缓解指令微调过程中的灾难性遗忘，我们引入了一种新颖的零专家，该专家保留了用于通用语言任务的预训练参数。在姿态表示方面，我们通过将人体划分为不同的关节组来实现身体部位特异性分词，从而增强了表示的空间分辨率。实验表明，我们的方法有效缓解了指令微调过程中的知识遗忘，并在多样化的人体运动下游任务中取得了显著性能。|
|**2025-11-02**|[VesSAM: Efficient Multi-Prompting for Segmenting Complex Vessel](http://arxiv.org/abs/2511.00981)|null|精准血管分割对于疾病诊断和手术规划等临床应用至关重要，但由于血管结构纤细、分支多且纹理对比度低，其分割仍然充满挑战。尽管Segment Anything Model (SAM) 等基础模型在通用分割方面展现出潜力，但它们在血管结构上的表现次优。在这项工作中，我们提出了VesSAM，一个强大而高效的框架，专为2D血管分割定制。VesSAM整合了(1)一个卷积适配器，用于增强局部纹理特征；(2)一个多提示编码器，通过分层交叉注意力融合包括骨架、分叉点和血管段中点在内的解剖学提示；以及(3)一个轻量级掩膜解码器，用于减少锯齿状伪影。我们还引入了一个自动化流程来生成结构化的多提示标注，并构建了一个多样化的基准数据集，该数据集涵盖了5种成像模式下的8个数据集。实验结果表明，VesSAM持续优于最先进的基于PEFT的SAM变体，在Dice和IoU指标上分别提升了10%以上和13%以上，并且与完全微调方法相比，以显著更少的参数量取得了具有竞争力的性能。VesSAM在域外(OoD)设置中也表现出良好的泛化能力，在平均OoD Dice和IoU方面均优于所有基线方法。|
|**2025-11-02**|[The Biased Oracle: Assessing LLMs' Understandability and Empathy in Medical Diagnoses](http://arxiv.org/abs/2511.00924)|null|大型语言模型（LLM）通过为患者生成解释和指导，在诊断沟通中展现出支持临床医生的潜力。然而，它们生成既易于理解又富有同情心的输出的能力仍不确定。我们在医疗诊断场景中评估了两个领先的LLM，使用可读性指标作为代理来评估其可理解性，并通过与人工评估相比的“LLM即评委”评分来评估其同情心。结果表明，LLM会根据社会人口学变量和患者状况调整解释。然而，它们也生成过于复杂的内容，并表现出有偏见的感情同情心，导致可及性和支持的不均衡。这些模式强调了进行系统性校准的必要性，以确保公平的患者沟通。代码和数据已发布：https://github.com/Jeffateth/Biased_Oracle|
|**2025-11-01**|[MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts](http://arxiv.org/abs/2511.00421)|null|大语言模型（LLM）在医疗应用中显示出日益增长的潜力，但它们在临床文本中检测和纠正错误的能力——这是安全部署的先决条件——仍未得到充分评估，尤其是在英语之外的语言中。我们引入了MedRECT，这是一个跨语言（日语/英语）基准，它将医疗错误处理定义为三个子任务：错误检测、错误定位（句子提取）和错误纠正。MedRECT采用可扩展的自动化流程构建，数据来源于日本医师执照考试（JMLE）以及一个精心策划的英语对应数据集，从而生成了MedRECT-ja（663篇文本）和MedRECT-en（458篇文本），两者具有相似的错误/无错误平衡。我们评估了9个当前主流的LLM，它们涵盖了专有模型、开源模型和推理模型系列。主要发现包括：(i) 推理模型显著优于标准架构，在错误检测方面相对改进高达13.5%，在句子提取方面达到51.0%；(ii) 跨语言评估显示，从英语到日语存在5-10%的性能差距，而推理模型的差距较小；(iii) 针对性的LoRA微调在错误纠正性能方面产生了不对称的改进（日语：+0.078，英语：+0.168），同时保持了推理能力；(iv) 我们的微调模型在结构化医疗错误纠正任务上超越了人类专家的表现。据我们所知，MedRECT是首个全面的跨语言医疗错误纠正基准，为开发更安全的跨语言医疗LLM提供了一个可复现的框架和资源。|
|**2025-11-01**|[Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs](http://arxiv.org/abs/2511.00382)|**[link](https://github.com/mina-taraghi/PEFT_Safety_Fairness)**|组织正日益采纳和调整托管在如HuggingFace等公共仓库中的大语言模型（LLMs）。尽管这些调整通常能提升模型在特定下游任务上的性能，但最新证据表明，它们也可能损害模型的安全性或公平性。鉴于不同的微调技术可能对这些关键维度产生不同的影响，本研究对它们的权衡进行了系统评估。四种广泛使用的参数高效微调方法，LoRA、IA3、Prompt-Tuning和P-Tuning，被应用于四种指令微调模型家族（Meta-Llama-3-8B、Qwen2.5-7B、Mistral-7B和Gemma-7B）。总共235个微调变体在十一个安全风险类别和九个人口统计学公平性维度上进行了评估。结果表明，基于适配器的方法（LoRA、IA3）倾向于提高安全得分，并且对公平性的影响最小，保留了更高的准确性和更低的偏差得分。相比之下，基于提示的方法（Prompt-Tuning和P-Tuning）通常会降低安全性并导致更大的公平性退化，伴随着准确性下降和偏差增加。对齐性变化受基础模型类型强烈调节：LLaMA保持稳定，Qwen获得适度提升，Gemma经历了最陡峭的安全下降，而Mistral（发布时未包含内部审核层）则表现出最大的方差。安全性的提升不一定转化为公平性的提升，并且没有单一配置能够同时优化所有公平性指标，这表明这些目标之间存在固有的权衡。这些发现为安全关键型部署提供了实用指导：从一个对齐良好的基础模型开始，优先选择基于适配器的PEFT，并对安全性和公平性进行类别特定的审计。|
|**2025-11-04**|[A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios](http://arxiv.org/abs/2511.00130)|null|大语言模型（LLM）的卓越能力通常需要针对特定应用进行定制，这要求整合新知识或获取新技能。尽管完全微调是一种强大的适应方法，但其计算成本高昂，并可能导致泛化推理能力下降，这种现象被称为灾难性遗忘。存在一系列替代技术，每种技术都有其自身的权衡。上下文学习（ICL）速度快但受限于上下文长度，而低秩适应（LoRA）等参数高效微调（PEFT）方法通过最小化参数改变提供了一种折衷方案。然而，灾难性遗忘的挑战依然存在，这引发了关于特定任务最佳适应策略的疑问。本文对数据稀缺场景下的监督微调（SFT）、LoRA和ICL进行了比较分析。我们发现LoRA提供了最有效的平衡，成功地灌输了新技能，同时对基础模型的通用知识影响最小。相比之下，SFT虽然擅长技能获取，但极易受到灾难性遗忘的影响。ICL在整合事实知识方面有效，但在处理复杂技能时表现不佳。我们的研究结果为选择LLM适应策略提供了一个实用框架。我们强调了技能获取和知识整合之间的关键区别，并阐明了任务特定性能与通用能力保留之间的权衡。|
|**2025-10-31**|[Cognitive Alignment in Personality Reasoning: Leveraging Prototype Theory for MBTI Inference](http://arxiv.org/abs/2511.00115)|null|文本个性识别通常被视为硬标签分类，这模糊了人类个性判断的渐进的、原型式的本质。我们提出了ProtoMBTI，这是一个认知对齐的MBTI推断框架，它在一个基于LLM的流程中将原型理论操作化。首先，我们通过LLM引导的多维度增强（语义、语言学、情感）构建了一个平衡的、质量受控的语料库。接下来，我们LoRA微调了一个轻量级（参数量小于等于2B）编码器，以学习判别性嵌入并标准化一组个性原型。在推断时，我们为查询帖子检索top-k原型，并执行一个检索-重用-修正-保留循环：模型通过提示式投票聚合原型证据，在出现不一致时进行修正，并在正确预测后保留样本以持续丰富原型库。在Kaggle和Pandora基准测试中，ProtoMBTI在MBTI的四个二元对和完整的16种类型任务上均优于基线，并展现出强大的跨数据集泛化能力。我们的结果表明，将推断过程与心理原型推理对齐，对于基于文本的个性建模在准确性、可解释性和迁移方面带来了提升。|
|**2025-11-03**|[Image Hashing via Cross-View Code Alignment in the Age of Foundation Models](http://arxiv.org/abs/2510.27584)|**[link](https://github.com/ilyassmoummad/CroVCA)**|高效大规模检索需要紧凑且具有区分性的表示。基础模型提供了强大的视觉和多模态嵌入，但在这些高维空间中进行最近邻搜索的计算开销很大。哈希通过使用二进制码实现快速汉明距离搜索，提供了一种高效的替代方案，然而现有方法通常依赖于复杂的流程、多项目标函数、专门针对单一学习范式的设计以及漫长的训练时间。我们引入了CroVCA（跨视图代码对齐），这是一个简单统一的原则，用于学习在语义对齐视图间保持一致的二进制码。单一的二元交叉熵损失用于强制对齐，而编码率最大化则作为抗崩溃正则化器，以促进平衡且多样化的代码。为此，我们设计了HashCoder，一个轻量级MLP哈希网络，其最终批归一化层用于确保代码平衡。HashCoder可以用作冻结嵌入上的探测头，或通过LoRA微调高效地适应编码器。在各种基准测试中，CroVCA仅用5个训练周期就取得了最先进的结果。在16位设置下，它表现尤为出色——例如，在单个GPU上，COCO数据集上的无监督哈希在2分钟内完成，ImageNet100数据集上的有监督哈希在大约3分钟内完成。这些结果凸显了CroVCA的效率、适应性和广泛适用性。|
|**2025-10-31**|[Image Hashing via Cross-View Code Alignment in the Age of Foundation Models](http://arxiv.org/abs/2510.27584)|**[link](https://github.com/ilyassmoummad/CroVCA)**|高效的大规模检索需要紧凑且具有区分性的表征。基础模型提供了强大的视觉和多模态嵌入，但在这些高维空间中进行最近邻搜索的计算成本很高。哈希通过使用二进制编码实现快速汉明距离搜索，提供了一种高效的替代方案，然而，现有方法常常依赖于复杂的流水线、多项目标函数、专门针对单一学习范式的设计以及漫长的训练时间。我们引入了CroVCA（跨视图代码对齐），这是一个简单统一的原则，用于学习在语义对齐的视图之间保持一致的二进制编码。单一的二元交叉熵损失强制执行对齐，同时编码率最大化作为一种抗坍塌正则化器，以促进平衡和多样化的编码。为了实现这一点，我们设计了HashCoder，这是一个轻量级的MLP哈希网络，带有一个最终批归一化层以强制平衡编码。HashCoder可以用作冻结嵌入上的探测头，也可以通过LoRA微调高效地适应编码器。在各项基准测试中，CroVCA仅用5个训练周期就取得了最先进的结果。在16位时，它表现尤为出色——例如，在单个GPU上，COCO上的无监督哈希在2分钟内完成，ImageNet100上的有监督哈希在大约3分钟内完成。这些结果突出了CroVCA的效率、适应性和广泛适用性。|
|**2025-10-30**|[LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits](http://arxiv.org/abs/2510.26690)|null|低秩适配（LoRA）已成为大语言模型（LLMs）参数高效微调的一种流行技术。在许多实际场景中，会同时加载多个适配器，以实现LLM定制，提供个性化用户体验或支持多种多样的任务。尽管每个适配器单独来看都是轻量级的，但它们在规模化应用时的总成本会变得巨大。为解决此问题，我们提出了LoRAQuant，一种专为LoRA量身定制的混合精度后训练量化方法。具体而言，LoRAQuant通过奇异值分解（SVD）重新参数化每个适配器，将最重要的信息集中到特定的行和列中。这使得可以将重要组件量化为更高精度，而将其余部分量化为超低位宽。我们使用LLaMA 2-7B、LLaMA 2-13B和Mistral 7B模型，在数学推理、编码和摘要任务上进行了全面实验。结果表明，我们的LoRAQuant使用的位数显著低于其他量化方法，但取得了可比甚至更高的性能。|
|**2025-10-30**|[Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models](http://arxiv.org/abs/2510.26683)|null|大语言模型（LLM）通过利用大规模预训练和精心整理的微调数据，在多个领域展现出卓越的能力。然而，在医疗保健等数据敏感领域，高质量领域特定训练语料库的缺乏阻碍了LLM适应专门应用。与此同时，领域专家已将领域智慧提炼成本体规则，这些规则形式化了概念间的关系，并确保了知识管理存储库的完整性。我们将LLM视为人类知识的隐式存储库，并提出了Evontree，这是一个新颖的框架，它利用一小部分高质量本体规则，系统地提取、验证和增强LLM内部的领域知识，而无需大量外部数据集。具体来说，Evontree从原始模型中提取领域本体，使用两个核心本体规则检测不一致性，并通过自蒸馏微调强化提炼的知识。在Llama3-8B-Instruct和Med42-v2模型上进行的医疗问答基准实验表明，我们的方法持续优于未经修改的模型和领先的监督基线，准确率最高提升了3.7%。这些结果证实了我们方法在LLM低资源域适应方面的有效性、效率和鲁棒性。|
|**2025-10-30**|[WeaveRec: An LLM-Based Cross-Domain Sequential Recommendation Framework with Model Merging](http://arxiv.org/abs/2510.26546)|null|跨域序列推荐（CDSR）旨在通过从多个领域迁移知识来改进用户偏好建模。尽管CDSR已取得进展，但大多数现有方法依赖于重叠用户或物品来建立跨域关联，而这一要求在现实世界场景中很少成立。大语言模型（LLM）和模型合并技术的出现似乎通过在没有显式重叠的情况下统一多领域数据来克服这一局限性。然而，我们的实证研究表明，简单地在组合领域上训练一个大语言模型——或者仅仅合并几个领域特定的大语言模型——相对于仅在目标领域上训练的模型，其性能通常会下降。为了解决这些挑战，我们首先通过实验调查了基于大语言模型的跨域推荐和模型合并中次优性能产生的原因。基于这些见解，我们引入了WeaveRec，它以交织的方式使用源领域和目标领域数据交叉训练多个LoRA模块，并通过模型合并将它们融合。WeaveRec可以扩展到多源领域场景，并且显著地不会在延迟或内存方面引入额外的推理时间成本。此外，我们提供了理论保证，证明WeaveRec可以降低目标领域中期望误差的上限。在单源、多源和跨平台跨域推荐场景中的大量实验验证了WeaveRec有效减轻了性能下降，并在现实世界推荐任务中持续优于基线方法。|
|**2025-10-30**|[ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems](http://arxiv.org/abs/2510.26475)|null|通过强化学习（RL）适应大语言模型（LLM）通常会受到生成阶段的瓶颈，该阶段可能消耗超过75%的训练时间。推测解码（SD）加速了服务系统中的自回归生成，但其在强化学习训练下的行为仍未得到充分探索。我们识别出阻碍将SD简单集成到RL系统中的三个关键不足：在大批量下加速效果减弱、在持续的actor更新下草稿模型的陈旧性，以及草稿模型导致的策略退化。为解决这些不足，我们提出了ReSpec，一个通过三个互补机制将SD适配到RL的系统：动态调整SD配置、通过知识蒸馏演进草稿模型，以及根据轨迹奖励加权更新。在Qwen模型（3B--14B）上，ReSpec实现了高达4.5倍的加速，同时保持了奖励收敛和训练稳定性，为高效的基于强化学习的LLM适应提供了一个实用的解决方案。|
|**2025-10-28**|[zFLoRA: Zero-Latency Fused Low-Rank Adapters](http://arxiv.org/abs/2510.25784)|null|大语言模型 (LLMs) 越来越多地部署带有任务专用适配器，以满足多种下游应用的需求。在这种情况下，这些看似微不足道的适配器参数数量（通常不到基础模型的1%）所带来的额外计算开销，却在推理时显得不成比例地显著（最高可达基础模型的2.5倍）。在本文中，我们提出了一种新的零延迟融合低秩适配器 (zFLoRA)，它在基础模型之上引入了零或可忽略的延迟开销。在1B、3B和7B规模的LLMs上的实验结果表明，zFLoRA 优于流行的监督微调基准，包括低秩适配器 (LoRA) 和全量微调 (FFT)。实验在三个不同类别（即常识推理、数学推理和摘要对话）共18个不同任务上进行。在NPU (Samsung Galaxy S25+) 和 GPU (NVIDIA H100) 平台上进行的延迟测量表明，所提出的 zFLoRA 适配器引入了零到可忽略的延迟开销。|
|**2025-10-29**|[Continual Low-Rank Adapters for LLM-based Generative Recommender Systems](http://arxiv.org/abs/2510.25093)|null|大语言模型（LLMs）在推荐领域表现出强大的性能，但随着用户、物品和用户偏好随时间演变，它们在持续学习中面临挑战。现有的基于LoRA的持续学习方法主要侧重于保持在先前任务上的性能，但这忽略了推荐的独特本质：目标并非预测过去的偏好，并且当当前兴趣发生显著变化时，过时的偏好甚至可能损害性能。为解决此问题，我们提出了PESO (Proximally rEgularized Single evolving lOra)，这是一种用于推荐领域LoRA的持续适应方法。PESO引入了一个近端正则化器，它将当前适配器锚定在其最近的冻结状态，使模型能够灵活地平衡适应性和保持性，并更好地捕捉最近的用户行为。理论上，我们表明这种近端设计在LoRA子空间中提供了数据感知、方向性的指导。经验上，PESO始终优于现有的基于LoRA的持续学习方法。|
|**2025-10-28**|[Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation](http://arxiv.org/abs/2510.24619)|null|随着 Llama 和 Mistral 等新型大语言模型 (LLMs) 的发布，由于其多语言预训练和强大的泛化能力，零样本跨语言迁移变得越来越可行。然而，将这些仅解码器架构的LLMs适应于跨语言的新任务仍然具有挑战性。尽管低秩适应 (LoRA) 等参数高效微调 (PeFT) 技术被广泛使用，但基于前缀的技术，如软提示调优、前缀调优和 Llama Adapter，却较少被探索，尤其是在仅解码器模型中的零样本迁移方面。我们对三种基于前缀的方法进行了全面研究，以实现从英语到 35 种以上高资源和低资源语言的零样本跨语言迁移。我们的分析进一步探讨了跨语言家族和文字系统的迁移，以及将模型规模从 1B 扩展到 24B 的影响。使用 Llama 3.1 8B，前缀方法在 Belebele 基准测试上比 LoRA 基线表现高出高达 6%。使用 Mistral v0.3 7B 也观察到类似的改进。尽管采用前缀调优仅使用了 1.23M 个可学习参数，我们仍在不同的基准测试中取得了持续的改进。这些发现突出了基于前缀的技术作为 LoRA 的一种有效且可扩展的替代方案的潜力，尤其是在低资源多语言环境中。|
|**2025-10-28**|[LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis](http://arxiv.org/abs/2510.24561)|null|随着大型语言模型的广泛采用，LoRA已成为参数高效微调（PEFT）的主导方法，其初始化方法受到了越来越多的关注。然而，现有方法存在显著局限性：许多方法未整合目标域数据，而基于梯度的方法仅通过依赖一步梯度分解在浅层利用数据，这仍然不尽人意，原因在于作为其基础的一步微调模型经验性能较弱，并且这些方法要么缺乏严格的理论基础，要么严重依赖于限制性的各向同性假设。在本文中，我们基于渐近分析，为数据感知型LoRA初始化建立了一个理论框架。从一个最小化微调模型与目标模型之间参数差异期望的通用优化目标出发，我们推导出了一个包含两个组成部分的优化问题：一个偏差项，它与微调模型和目标模型之间的参数距离相关，并使用费雪梯度公式近似以保留各向异性；以及一个方差项，它通过费雪信息解释了抽样随机性引入的不确定性。通过解决这个问题，我们获得了LoRA的最优初始化策略。基于这一理论框架，我们开发了一种高效算法LoRA-DA，它从一小部分目标域样本中估计优化问题中的各项，并获得最优的LoRA初始化。在多个基准测试中的实验结果表明，LoRA-DA相较于现有初始化方法持续提高了最终准确性。进一步的研究表明，LoRA-DA具有更快、更稳定的收敛、在不同秩下的鲁棒性，并且仅有很小的初始化开销。源代码将在发表后发布。|
|**2025-10-28**|[FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic](http://arxiv.org/abs/2510.24061)|**[link](https://github.com/iamkanghyunchoi/falqon)**|低比特浮点 (FP) 格式，如FP8，凭借现代GPU和NPU的原生硬件支持，在模型训练中提供了显著的加速和内存节省。然而，我们分析发现，FP8量化主要为大维度矩阵乘法提供加速，而当应用于低秩适应 (LoRA) 时，其固有的量化开销会降低加速效果，因为LoRA使用小维度矩阵来高效微调大语言模型 (LLM)。为了解决这一限制，我们提出了FALQON，一个新颖的框架，它通过在微调过程中将LoRA适配器直接合并到FP8量化的主干网络中，消除了来自独立LoRA计算路径的量化开销。此外，我们重新设计了合并适配器的前向和后向计算，以显著减少量化开销，并引入了一种行级代理更新机制，有效地将实质性更新整合到量化的主干网络中。实验评估表明，FALQON在相似的精度水平下，相较于现有量化LoRA方法，训练速度提升了约3倍，为高效的大规模模型微调提供了实用解决方案。此外，FALQON的端到端FP8工作流消除了对训练后量化的需求，促进了高效部署。代码可在https://github.com/iamkanghyunchoi/falqon获取。|
|**2025-10-27**|[ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning](http://arxiv.org/abs/2510.23818)|null|随着大型语言模型（LLMs）规模的不断扩大，计算开销已成为任务特异性微调的一个主要瓶颈。尽管低秩适应（LoRA）通过将权重更新限制在低维子空间中，有效地减少了这一开销，但这种限制可能会阻碍有效性并减缓收敛。本文通过从连续的低秩增量中逐步累积高秩权重更新来解决这些局限性。具体而言，我们确定了每次更新的最优低秩矩阵，以最小化损失函数并紧密逼近全量微调。为了实现高效且无需重新启动的无缝优化，这种最优选择是通过适当缩放原始低秩矩阵的列来形成的。严格的性能保证表明，最优缩放可以通过解析方式找到。使用规模达120亿参数的流行LLMs进行的广泛数值测试表明，在自然语言理解、常识推理和数学问题解决等多样化任务上，相较于最先进的LoRA变体，本文方法展现了持续的性能提升和快速收敛。|
|**2025-10-27**|[Block-Diagonal LoRA for Eliminating Communication Overhead in Tensor Parallel LoRA Serving](http://arxiv.org/abs/2510.23346)|null|当同时为单个基础LLM提供多个不同的LoRA适配器服务时，适配器不能简单地与基础模型的权重合并，因为适配器切换会产生开销，并且使用不同适配器的请求无法进行批处理。相反，LoRA计算必须与基础LLM计算分离，并且在多设备设置中，LoRA适配器可以按照与基础模型的张量并行执行良好对齐的方式进行分片，正如S-LoRA中提出的。然而，S-LoRA分片策略会遇到一些通信开销，这在理论上可能很小，但在实践中可能很大。在本文中，我们提出将某些LoRA因子约束为块对角矩阵，这允许一种替代的LoRA适配器分片方式，不需要为LoRA计算进行任何额外的通信。我们在广泛的实验中证明，我们的块对角LoRA方法与标准LoRA具有相似的参数效率（即，在相似的参数数量下，它实现了相似的下游性能），并且相较于S-LoRA，它带来了显著的端到端加速。例如，当在八个A100 GPU上提供服务时，我们观察到Llama-3.1-70B的端到端加速高达1.79倍（1.23倍），对应适配器参数数量为0.87倍（1.74倍）；Llama-3.1-8B的端到端加速高达1.63倍（1.3倍），对应适配器参数数量为0.86倍（1.73倍）。|
|**2025-10-27**|[DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification](http://arxiv.org/abs/2510.23203)|null|精确的顶点级人与周围物体接触预测是用于机器人技术、AR/VR和行为模拟的高保真人物交互模型的先决条件。DECO是第一个用于此任务的野外估计器，但它仅限于二元接触图，并且在处理软表面、遮挡、儿童和足部假阳性接触时表现不佳。我们解决了这些问题并引入了DecoDINO，这是一个基于DECO框架的三分支网络。它使用了两个DINOv2 ViT-g/14编码器、类别平衡损失加权以减少偏差，以及补丁级交叉注意力以改进局部推理。顶点特征最终通过一个带有softmax的轻量级MLP，以分配语义接触标签。我们还测试了一个视觉语言模型（VLM）来集成文本特征，但更简单的架构表现更好并被采用。在DAMON基准测试中，DecoDINO (i) 将二元接触F1分数提高了7%，(ii) 将测地误差减半，并且 (iii) 用物体级语义标签增强了预测。消融研究表明，LoRA微调和双编码器是这些改进的关键。DecoDINO在DAMON挑战赛的两项任务中均超越了挑战基线。我们的代码可在https://github.com/DavidePasero/deco/tree/main获取。|
|**2025-10-27**|[Beyond Higher Rank: Token-wise Input-Output Projections for Efficient Low-Rank Adaptation](http://arxiv.org/abs/2510.23123)|**[link](https://github.com/Leopold1423/toplora-neurips25)**|低秩适应 (LoRA) 是一种在大语言模型 (LLMs) 中广泛使用的参数高效微调 (PEFT) 方法。LoRA本质上描述了将输入空间投影到低维输出空间的过程，其维度由LoRA秩决定。在标准LoRA中，所有输入词元共享相同的权重并经历相同的输入-输出投影。由于词元之间固有的语义差异，这限制了LoRA捕获词元特异性信息的能力。为了解决这一局限性，我们提出了词元级投影低秩适应 (TopLoRA)，它根据输入词元动态调整LoRA权重，从而以端到端的方式学习词元级的输入-输出投影。形式上，TopLoRA的权重可以表示为 $B\Sigma_X A$，其中 $A$ 和 $B$ 是低秩矩阵（如标准LoRA中所示），而 $\Sigma_X$ 是由每个输入词元 $X$ 生成的对角矩阵。值得注意的是，TopLoRA并未增加LoRA权重的秩，而是通过学习词元级的LoRA权重（即词元级的输入-输出投影）实现了更细粒度的适应。在多个模型和数据集上的大量实验表明，TopLoRA持续优于LoRA及其变体。代码可在 https://github.com/Leopold1423/toplora-neurips25 获取。|
|**2025-10-27**|[Adapting Speech Foundation Models with Large Language Models for Unified Speech Recognition](http://arxiv.org/abs/2510.22961)|null|统一语音识别旨在在单个模型框架内执行听觉、视觉和视听语音识别。尽管语音基础模型 (SFM) 在听觉任务中已展示出卓越性能，但它们在多模态场景中的适应性仍未得到充分探索。本文提出了UASR-LLM，这是一个新颖的框架，通过利用大语言模型 (LLM) 作为文本解码器，将冻结的SFM适应于统一的VSR、ASR和AVSR任务。我们的方法通过视觉注入模块将视觉表示引入到多个SFM层中，从而实现多模态输入处理和统一的隐藏表示。增强的SFM通过前馈适配器与仅解码器LLM连接，其中拼接的表示和指令提示指导语音转录。我们实施了两阶段训练策略：视觉注入预训练，随后是语音识别微调。SFM参数在整个训练过程中保持冻结，仅视觉注入模块在初始阶段进行优化，随后使用LoRA参数对LLM进行微调。实验结果表明，在干净和嘈杂条件下，该方法在VSR、ASR和AVSR任务中均优于最先进的基线。消融研究证实了该方法在各种SFM和LLM上的泛化能力，验证了所提出的训练策略。|
|**2025-10-26**|[LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction](http://arxiv.org/abs/2510.22829)|null|本文探讨了在MediaEval 2025研讨会竞赛的“记忆性：预测电影和商业记忆性”任务中，作为“子任务2：商业/广告记忆性”的一部分，商业（品牌）记忆性的预测问题。我们提出了一个以Gemma-3 LLM为骨干的多模态融合系统，该系统通过多模态投影整合了预计算的视觉（ViT）和文本（E5）特征。该模型采用低秩适应（LoRA）进行适配。一个经过精心调优的梯度提升树集成模型作为基线。一个关键贡献在于，我们使用了基于专家推导的记忆性方面的LLM生成的推理提示来指导融合模型。结果表明，与基线相比，基于LLM的系统在最终测试集上表现出更高的鲁棒性和泛化性能。本文的代码库可在https://github.com/dsgt-arc/mediaeval-2025-memorability找到。|
|**2025-10-26**|[Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study](http://arxiv.org/abs/2510.22747)|null|尽管大语言模型（LLM）已被广泛采用，但其最强能力仍主要局限于少数拥有丰富训练数据的高资源语言。最近，持续预训练（CPT）已成为将这些模型微调至低资源区域方言的一种手段。本文研究了在严格的数据和计算预算下，CPT在方言学习中的应用。我们利用低秩适应（LoRA）和计算高效的持续预训练，使用一个非常小的数据集将三个LLM适应到魁北克法语方言，并在COLE套件上对其进行了基准测试。我们的实验表明，在更新不到1%的模型参数的情况下，少数方言基准上取得了改进，而标准语言基准上的性能下降最小。结果分析表明，收益高度依赖于语料库构成。这些发现表明，结合参数高效微调（PEFT）的CPT可以通过提供成本效益高且可持续的语言资源创建，缩小方言差距，从而将高质量LLM的访问扩展到少数语言社区。我们在HuggingFace上发布了首批魁北克法语LLM。|
|**2025-10-22**|[SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment](http://arxiv.org/abs/2510.19979)|null|随着大语言模型（LLMs）在移动和边缘平台上的部署日益增多，保护它们免受模型提取攻击已成为一个紧迫的问题。然而，在不牺牲GPU等不受信任的AI加速器所带来的性能优势的前提下保护模型隐私，提出了一个具有挑战性的权衡。在本文中，我们首次研究了LLMs上的高性能执行，并提出了SecureInfer，这是一个混合框架，它利用异构可信执行环境（TEEs）-GPU架构来隔离隐私关键组件，同时将计算密集型操作卸载到不受信任的加速器。基于一种外包方案，SecureInfer采用了一种信息论和威胁感知的划分策略：安全敏感组件，包括非线性层、注意力头投影、前馈网络（FNN）变换和LoRA适配器，在SGX安全飞地内执行，而其他线性操作（矩阵乘法）在加密后在GPU上执行，并在安全飞地内安全恢复。我们使用LLaMA-2模型实现了SecureInfer的原型，并从性能和安全指标两方面对其进行了评估。我们的结果表明，SecureInfer提供了强大的安全保障且具有合理的性能，为安全的设备端模型推理提供了一个实用的解决方案。|
|**2025-10-22**|[GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters](http://arxiv.org/abs/2510.19778)|null|稀疏微调技术通过仅调整模型参数的稀疏子集，使大型语言模型（LLMs）适应下游任务。然而，稀疏适应的有效性取决于优化选择待微调的模型参数。在这项工作中，我们引入了一种名为GaLLoP的新型稀疏微调技术：基于梯度的低幅度参数稀疏学习，该技术仅微调那些在下游任务上具有最大梯度幅值且预训练幅值最小的模型参数，直观上优先考虑那些高度任务相关但对预训练知识的破坏最小的参数。我们以LLaMA3 8B和Gemma 2B作为基础模型的实验表明，GaLLoP始终能够提高或匹配通过使用其他领先的参数高效微调技术（包括LoRA、DoRA和SAFT）获得的分布内以及分布外性能。我们的分析表明，GaLLoP缓解了灾难性遗忘和任务数据的记忆，因为重要的预训练参数保持不变，并相对于其他微调技术稳定了性能，在大多数随机种子下均能稳健泛化。|
|**2025-10-23**|[Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning](http://arxiv.org/abs/2510.19733)|**[link](https://github.com/machinelearningnuremberg/Zhyper)**|大语言模型（LLM）条件化指的是指示LLM生成符合特定文化规范和价值观、特定政治立场信念或任何期望的文本指定语义条件的内容。不幸的是，由于预训练和对齐数据集的归纳偏置，提示工程无法确保LLM按照期望的条件化行为。先前的工作专注于通过直接条件化LoRA权重来微调LLM；然而，此类方法引入了大量参数。作为补救措施，我们提出了Zhyper，这是一种参数高效的分解超网络框架，它能从文本描述中生成上下文感知的LoRA适配器。在多个基准测试上的实验表明，Zhyper实现了具有竞争力的性能，且参数量比最先进的基线减少高达26倍。此外，我们将Zhyper扩展到文化对齐，展示了对域外设置的泛化能力有所提高，并能更好地捕获细粒度的上下文价值。|
|**2025-10-22**|[CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](http://arxiv.org/abs/2510.19670)|null|我们提出了CoSense-LLM，一个边缘优先框架，它将连续的多模态传感器流（例如Wi-Fi CSI、IMU、音频、RFID和轻量级视觉）转化为紧凑、可验证的语义令牌，并在明确的延迟、能耗、带宽和隐私约束下与大语言模型协同工作。CoSense-LLM包含四个部分：(i) SenseFusion，一个轻量级编码器，将传感器嵌入与语言对齐，并将其压缩成短的离散代码序列；(ii) Edge-RAG，一个本地混合检索层，根据特定站点的策略和笔记生成内容；(iii) PromptRouter，一个成本和不确定性感知的策略，用于选择仅边缘生成、边缘加检索或紧凑的云升级；(iv) Secure Execution，一个可审计的编辑路径，强制执行数据最小化，确保原始波形永不离开设备。该系统与现代服务优化协同工作，包括分页或流式KV缓存、FlashAttention风格的内核、推测解码和量化LoRA适配器，并支持设备端个性化和在非IID漂移下的联邦更新。在家庭、办公室和诊所的部署中，CoSense-LLM提供了有依据的解释，同时满足了严格的服务水平目标：它在边缘主导路径上保持亚秒级 (p95) 端到端延迟，通过优先选择基于本地检索的响应来降低层间令牌和带宽成本，并通过仅传输离散代码和编辑过的元数据来保护隐私。消融实验表明，Edge-RAG提高了事实一致性并减少了矛盾，校准的不确定性实现了选择性回避和受控升级，KV加解码加速器降低了每次决策的能耗。这些结果支持一种边缘优先设计，即在易受干扰环境中部署大型模型时，将语义、隐私和可预测延迟视为同等重要的目标。|
|**2025-10-21**|[SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish](http://arxiv.org/abs/2510.18725)|**[link](https://github.com/JoshMcGiff/SemiAdapt-SemiLoRA)**|微调被广泛用于为神经机器翻译（NMT）等特定任务定制大语言模型。然而，在微调拥有数十亿参数的大型多语言模型时，利用迁移学习在计算上成本高昂，这为从事爱尔兰语翻译等低资源领域的研究人员设置了准入门槛。参数高效微调（PEFT）通过仅训练原始模型一小部分参数来弥合这一差距，其中低秩适应（LoRA）方法引入了小型可训练的适配器层。我们引入SemiAdapt和SemiLoRA作为半监督推理高效方法，它们能增强领域适应性并提高NMT的整体性能。我们证明SemiAdapt可以优于全领域微调，最值得注意的是，SemiLoRA可以将PEFT方法的性能提升到与全模型微调相当甚至超越的水平。我们进一步评估了按领域-数据集进行的微调，并证明我们基于嵌入的推理方法在更大和更嘈杂的语料库上表现尤为出色。本工作中开发的所有爱尔兰语翻译模型均作为开放资源发布。这些方法旨在使高质量的领域适应和微调对从事低资源语言研究的研究人员更易于获取。|
|**2025-10-21**|[Bayesian Low-Rank Factorization for Robust Model Adaptation](http://arxiv.org/abs/2510.18723)|null|大型语音基础模型在许多领域取得了强大的性能，但它们通常需要进行适应以应对本地需求，例如语码转换（即说话者在同一话语中混合语言）。直接微调这些模型有过度拟合目标域并覆盖基础模型广泛能力的风险。为了解决这一挑战，我们探索了用于语音基础模型的贝叶斯因子化适配器，该适配器将先验置于接近零的位置，以实现更稀疏的适应矩阵，从而在适应特定领域的同时保留通用性能。我们将我们的方法应用于 Whisper 模型，并在不同的多语言语码转换场景中进行评估。我们的结果表明，仅有最小的适应损失，同时显著减少了基础模型的灾难性遗忘。与LoRA相比，我们的方法实现了54%的向后增益，而在新领域上仅下降4%。这些发现突出了贝叶斯适应在微调语音基础模型方面不牺牲泛化能力的有效性。|
|**2025-10-20**|[ParaVul: A Parallel Large Language Model and Retrieval-Augmented Framework for Smart Contract Vulnerability Detection](http://arxiv.org/abs/2510.17919)|null|智能合约在自动化区块链服务中发挥着重要作用。然而，智能合约中的漏洞对区块链安全构成严重威胁。目前，传统的检测方法主要依赖静态分析和形式化验证，这可能导致高误报率和较差的可扩展性。大型语言模型（LLMs）最近在智能合约漏洞检测方面取得了显著进展。然而，它们仍面临推理成本高和计算开销大等挑战。在本文中，我们提出了ParaVul，一个并行的LLM和检索增强框架，旨在提高智能合约漏洞检测的可靠性和准确性。具体而言，我们首先开发了用于LLM微调的稀疏低秩适应（SLoRA）。SLoRA通过将稀疏矩阵引入量化后的基于LoRA的LLM中来引入稀疏化，从而减少计算开销和资源需求，同时增强其理解漏洞相关问题的能力。然后，我们构建了一个漏洞合约数据集，并开发了一个混合检索增强生成（RAG）系统，该系统将密集检索与最佳匹配25（BM25）相结合，以辅助验证LLM生成的结果。此外，我们提出了一种元学习模型，用于融合RAG系统和LLM的输出，从而生成最终的检测结果。完成漏洞检测后，我们设计了思维链提示，以指导LLM生成全面的漏洞检测报告。仿真结果表明ParaVul的优越性，特别是在F1分数方面，单标签检测达到0.9398，多标签检测达到0.9330。|
|**2025-10-19**|[Activation Manifold Projection: Liberating Task-Specific Behaviors from LLM Architectures](http://arxiv.org/abs/2510.17902)|null|大语言模型（LLM）架构的激增带来了一个根本性挑战：通过低秩适应（LoRA）等微调方法学习到的有价值的、任务特定的行为，实际上被困在其源模型的架构中，本文称之为架构锁定。现有的迁移方法试图通过对齐模型的静态权重空间来弥合这一差距，这是一种脆弱且间接的方法，依赖于参数几何形状之间微弱的相关性。本文介绍了一种根本不同且更直接的范式：筒式激活空间迁移（CAST），这是一个新颖的框架，通过学习在两种不同LLM架构的激活流形（即模型内部神经元激活所形成的几何结构）之间建立直接的非线性映射，从而解放LoRA编码的行为。CAST将预训练的LoRA视为一个冻结的“行为核”。它学习一组轻量级的双向投影头，将目标模型的激活流转换到源模型的潜在空间中，应用冻结的核，并将结果投射回来。这个过程在通用文本语料库上进行训练，无需任何任务特定数据，有效地将所学技能与源架构解耦。我们证明了CAST能够实现任何标准LoRA适配器的真正“零样本”转换。我们的实验，包括Llama-2和Mistral等异构模型家族之间的迁移，表明CAST转换的适配器达到了在目标模型上完全重新训练的LoRA性能的85-95%，在量化上优于当前的权重空间迁移技术，并在模型互操作性方面建立了新的最先进水平。|
|**2025-10-19**|[L-MoE: End-to-End Training of a Lightweight Mixture of Low-Rank Adaptation Experts](http://arxiv.org/abs/2510.17898)|null|专家混合（MoE）架构通过为每个输入激活权重的稀疏子集，在推理过程中保持恒定的计算成本，从而实现大语言模型（LLMs）扩展到数万亿参数。同时，低秩适应（LoRA）已成为一种主流技术，用于在专门任务上对LLMs进行参数高效微调。在这项工作中，我们将这两种范式统一为一个新颖的、端到端可训练的框架，命名为L-MoE：一个轻量级LoRA专家混合。L-MoE将MoE专家重新定义为一组任务专用、低秩适配器，而非密集的前馈网络。一个与专家共同训练的轻量级门控网络，通过计算每个输入词元参数的加权平均值，学习动态组合这些LoRA适配器。这种组合是完全可微分的，允许来自标准自回归语言建模目标的梯度流回整个架构，同时优化专家适配器和路由策略。这种方法创建了一个高度参数高效的MoE模型，它在设计上是模块化的，允许动态技能组合，并且可以端到端训练。我们提出了L-MoE的形式化数学框架，详细阐述了可微分路由机制和联合优化目标，从而为构建更高效、可扩展和专业化的语言模型提供了一条新途径。|
|**2025-10-20**|[Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs](http://arxiv.org/abs/2510.17651)|null|我们研究了用于暴力检测的节俭联邦学习方法，通过比较两种互补策略：(i) 视觉-语言模型 (VLM) 的零样本和联邦微调，以及 (ii) 紧凑型3D卷积神经网络 (CNN3D) 的个性化训练。我们以LLaVA-7B和65.8M参数的CNN3D为代表性案例，在实际的非独立同分布 (non-IID) 设置下评估了准确性、校准性和能耗。两种方法都超过90%的准确性。CNN3D在ROC AUC和对数损失方面略优于采用低秩适应 (LoRA) 微调的VLM，同时能耗更低。VLM在上下文推理和多模态推理方面仍然具有优势。我们量化了训练和推理过程中的能耗和二氧化碳排放，并分析了部署的可持续性权衡。据我们所知，这是首次对经LoRA微调的视觉-语言模型和个性化CNN进行联邦暴力检测的比较研究，重点关注能效和环境指标。这些发现支持了一种混合模型：轻量级CNN用于常规分类，VLM则根据复杂或描述性场景选择性激活。所得框架为视频监控中负责任、资源感知的人工智能提供了一个可复现的基线，并可扩展到实时、多模态和生命周期感知的系统。|
|**2025-10-19**|[Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection](http://arxiv.org/abs/2510.16985)|null|孟加拉语社交媒体平台上的仇恨言论急剧增加，对女性和青少年造成了不成比例的影响。尽管BD-SHS等数据集为结构化评估提供了基础，但大多数现有方法要么依赖于计算成本高昂的全模型微调，要么依赖于专有API。本文首次展示了参数高效微调（PEFT）在孟加拉语仇恨言论检测中的应用，使用了LoRA和QLoRA技术。三个经过指令微调的大型语言模型——Gemma-3-4B、Llama-3.2-3B和Mistral-7B——在包含50,281条标注评论的BD-SHS数据集上进行了微调。每个模型通过训练不到其1%的参数进行了适应，从而可以在单个消费级GPU上进行实验。结果表明，Llama-3.2-3B取得了最高的F1分数，达到92.23%，其次是Mistral-7B（88.94%）和Gemma-3-4B（80.25%）。这些发现确立了PEFT作为一种实用且可复现的策略，适用于孟加拉语及相关低资源语言。|
|**2025-10-19**|[EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation](http://arxiv.org/abs/2510.16776)|null|基于X射线图像的医学报告生成（MRG）是人工智能领域的一个关键方向，可以显著减轻临床医生的诊断负担并缩短患者等待时间。现有MRG模型主要依赖大型语言模型（LLM）来改进报告生成，对预训练视觉基础模型或先进微调技术的探索有限。主流框架要么避免微调，要么采用LoRA等简单方法，经常忽视增强交叉注意力机制的潜力。此外，尽管基于Transformer的模型在视觉-语言任务中占据主导地位，非Transformer架构，例如Mamba网络，在医学报告生成方面仍未得到充分探索，为未来的研究提供了一个有前景的方向。在本文中，我们提出了EMRRG，一个新颖的X射线报告生成框架，它利用参数高效方法对预训练Mamba网络进行微调。具体而言，X射线图像被分割成图像块，并进行标记化，随后由基于SSM的视觉骨干网络进行处理以提取特征，其中Partial LoRA产生了最佳性能。一个带有混合解码器的LLM生成医学报告，实现了端到端训练，并在基准数据集上取得了优异结果。在三个广泛使用的基准数据集上进行的广泛实验充分验证了我们提出的X射线MRG策略的有效性。本文的源代码将发布在https://github.com/Event-AHU/Medical_Image_Analysis。|
|**2025-10-19**|[All You Need is One: Capsule Prompt Tuning with a Single Vector](http://arxiv.org/abs/2510.16670)|null|基于提示的学习已成为一种参数高效微调（PEFT）方法，通过任务感知指导来调节生成，从而促进大语言模型（LLM）适应下游任务。尽管取得了成功，但当前的基于提示的学习方法严重依赖费力的网格搜索来寻找最佳提示长度，并且通常需要大量的提示，引入了额外的计算负担。更糟糕的是，我们的初步发现表明，任务感知提示设计本质上受限于其缺乏实例感知信息，导致与输入序列的微妙注意力交互。相比之下，简单地将实例感知信息作为指导的一部分，可以在无需额外微调的情况下提升提示微调模型的性能。此外，我们发现了一个有趣的现象，即“注意力锚点”，将实例感知标记整合到序列的最早位置，能够成功地保持对关键结构信息的强注意力，并与所有输入标记表现出更活跃的注意力交互。鉴于我们的观察，我们引入了胶囊提示微调（CaPT），这是一种高效且有效的解决方案，将现成的、信息丰富的实例语义利用到基于提示的学习中。我们的方法以几乎无参数的方式（即一个单一的胶囊提示）创新性地整合了实例感知和任务感知信息。实验结果表明，我们的方法在各种语言任务中（例如，在T5-Large上平均准确率为84.03%）表现出卓越的性能，作为“注意力锚点”，同时享有高参数效率（例如，在Llama3.2-1B上仅占模型参数的0.003%）。|
|**2025-10-18**|[ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights](http://arxiv.org/abs/2510.16466)|null|随着客户反馈在战略增长中日益占据核心地位，从非结构化评论中提取可操作见解的能力变得至关重要。尽管传统的人工智能驱动系统擅长预测用户偏好，但将客户评论转化为规范性、面向业务的建议的研究却少之又少。本文介绍了ReviewSense，一个新颖的规范性决策支持框架，它利用先进的大型语言模型（LLMs）将客户评论转化为有针对性的、可操作的业务建议。通过识别客户情绪中的关键趋势、反复出现的问题和具体担忧，ReviewSense超越了基于偏好的系统，为企业提供了更深入的洞察，以维持增长和增强客户忠诚度。本工作的创新之处在于将聚类、LLM适应和专家驱动的评估整合到一个统一的、面向业务的流程中。初步的手动评估表明，模型的建议与业务目标高度一致，突显了其推动数据驱动决策的潜力。该框架为人工智能驱动的情感分析提供了新的视角，展示了其在优化业务策略和最大化客户反馈影响方面的价值。|
|**2025-10-16**|[Attention Is All You Need for KV Cache in Diffusion LLMs](http://arxiv.org/abs/2510.14973)|null|本工作研究如何自适应地重新计算扩散大语言模型(DLM)的键值(KV)缓存，以最大化预测准确性同时最小化解码延迟。先前方法的解码器在每个去噪步骤和层对所有token重新计算QKV，尽管KV状态在大多数步骤中变化不大，尤其是在浅层，这导致了大量的冗余。我们有三个发现：(1) 远距离的MASK token主要充当长度偏差，并且可以在活跃预测窗口之外按块进行缓存；(2) KV动态随深度增加，表明从更深层开始的选择性刷新是足够的；(3) 最受关注的token表现出最小的KV漂移，为其他token的缓存变化提供了保守的下界。基于这些发现，我们提出了Elastic-Cache，这是一种无需训练、与架构无关的策略，它协同决定何时刷新（通过对最受关注token的注意力感知漂移测试）以及何处刷新（通过一个深度感知调度，从选定层开始重新计算，同时重用浅层缓存和窗口外MASK缓存）。与固定周期方案不同，Elastic-Cache为扩散大语言模型执行自适应的、层感知的缓存更新，减少了冗余计算，并在生成质量损失可忽略不计的情况下加速了解码。在LLaDA-Instruct、LLaDA-1.5和LLaDA-V上进行的数学推理和代码生成任务实验展示了一致的加速效果：在GSM8K（256个token）上达到8.7倍，在更长序列上达到45.1倍，在HumanEval上达到4.8倍，同时始终保持比基线更高的准确性。我们的方法实现了显著更高的吞吐量（在GSM8K上达到6.8倍），优于现有的基于置信度的方法，同时保持生成质量，从而实现扩散大语言模型的实际部署。|
|**2025-10-16**|[AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations](http://arxiv.org/abs/2510.14937)|null|精神健康障碍仍然是全球导致残疾的主要原因之一，然而，由于主观评估、临床资源有限以及污名化和低认知度，抑郁症、焦虑症和创伤后应激障碍（PTSD）等疾病经常被漏诊或误诊。在初级保健环境中，研究表明，提供者在超过60%的病例中误诊抑郁症或焦虑症，这凸显了对可扩展、可及且上下文感知的诊断工具的迫切需求，以支持早期发现和干预。在本研究中，我们使用一个包含553个真实世界半结构化访谈的独特数据集，评估了机器学习模型用于心理健康筛查的有效性，每个访谈都与重度抑郁发作（MDE）、焦虑症和PTSD的真实诊断配对。我们对多种模型类别进行了基准测试，包括使用GPT-4.1 Mini和MetaLLaMA进行零样本提示，以及使用低秩适应（LoRA）微调的RoBERTa模型。我们的模型在所有诊断类别中均达到了超过80%的准确率，尤其在PTSD上表现出色（准确率高达89%，召回率高达98%）。我们还发现，使用更短、聚焦的上下文片段可以提高召回率，这表明聚焦的叙事线索能增强检测灵敏度。LoRA微调被证明既高效又有效，较低秩配置（例如秩8和秩16）在各项评估指标上均保持了有竞争力的性能。我们的结果表明，基于大型语言模型（LLM）的模型可以比传统的自我报告筛查工具提供显著改进，为低门槛、人工智能驱动的早期诊断提供了一条途径。这项工作为将机器学习整合到真实世界的临床工作流程中奠定了基础，尤其是在资源匮乏或污名化严重、及时获得心理健康护理最为受限的环境中。|
|**2025-10-15**|[Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs](http://arxiv.org/abs/2510.13586)|null|大型语言模型（LLMs）的兴起为在游戏环境中创建动态非玩家角色（NPCs）开辟了新机遇，使其既能执行功能性任务，又能生成与角色设定一致的对话。在本文中，我们（Tu_Character_lab）报告了我们参与2025年常识性角色导向对话挑战赛（CPDC）第二轮的情况，该挑战赛在任务导向对话、上下文感知对话及其集成这三个赛道上评估智能体。我们的方法结合了两种互补策略：(i) 在API赛道中采用轻量级提示技术，包括一种“去过度角色扮演”提示方法，以抑制过度的角色扮演并提高任务保真度；(ii) 在GPU赛道中采用微调大型模型，利用Qwen3-14B并结合有监督微调（SFT）和低秩适应（LoRA）。我们最好的提交结果在任务1中排名第二，在任务3（API赛道）中排名第二，在任务3（GPU赛道）中排名第四。|
|**2025-10-15**|[Sparse Subnetwork Enhancement for Underrepresented Languages in Large Language Models](http://arxiv.org/abs/2510.13580)|null|大语言模型在跨语言方面表现出不均衡的性能，高资源语言和低资源语言之间存在显著差距。我们提出一个框架，通过对语言特异性子网络进行有针对性的微调，在保持大语言模型通用性能的同时，增强其在代表性不足语言中的单语言能力。我们的方法使用语言激活概率熵识别语言特异性神经元，并仅在目标语言数据上微调与这些神经元（一个专用子网络）相关的权重。在Llama-3.1-8B和Mistral-Nemo-12B上涵盖12种中低资源语言的实验表明，我们的方法始终优于全量微调、仅FFN微调、LoRA适应和随机子集微调基线，同时高效地仅更新模型参数的1%。除了性能提升，我们还观察到更优的训练动态、跨语言表征对齐以及系统性的权重更新变化。为了促进未来的研究，我们发布了超过100种语言的语言特异性神经元识别结果以及我们的适应管道，为将最先进的模型适应到代表性不足的语言中提供了一条经济高效的途径。|
|**2025-10-15**|[K-Merge: Online Continual Merging of Adapters for On-device Large Language Models](http://arxiv.org/abs/2510.13537)|null|大语言模型（LLMs）的设备端部署常利用低秩适配器（LoRAs）在紧张的资源约束下支持多样化的下游任务。为解决移动设备存储容量有限的问题，近期研究探索了模型合并技术，以将多个LoRA融合为一个。然而在实践中，LoRA通常是增量式交付的，即随着用户请求对新任务（例如，新型问题类型或语言）的支持而提供。这种情况引入了一个新挑战：设备端在线持续合并，其目标是在整合新的LoRA的同时，保持对先前已支持任务的性能。在本文中，我们提出了一种免数据且计算高效的策略，用于在新的LoRA可用时选择和合并LoRA，假设设备只能存储有限数量的适配器。在真实世界任务上的大量实验证明，与替代策略相比，我们的方法在遵守设备端设置的存储预算和计算限制的同时，展现出优越性。|
|**2025-10-15**|[Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems](http://arxiv.org/abs/2510.13351)|null|大语言模型 (LLM) 在企业和任务关键型领域日益增多的部署，强调了对确保安全性、可靠性和合规性的强大护栏系统的迫切需求。现有解决方案常常难以应对实时监督、多模态数据处理和可解释性——这些局限性阻碍了它们在受监管环境中的采用。现有护栏大多独立运行，仅关注文本，这使得它们不足以应对多模态、生产规模的环境。我们推出了 Protect，这是一种原生多模态护栏模型，旨在无缝运行于文本、图像和音频输入，并专为企业级部署设计。Protect 集成了经过微调的、类别特定的适配器，这些适配器通过低秩适应 (LoRA) 在一个广泛的多模态数据集上进行训练，涵盖了四个安全维度：有害性、性别歧视、数据隐私和提示注入。我们的教师辅助标注管道利用推理和解释追踪，跨模态生成高保真、上下文感知的标签。实验结果表明，Protect 在所有安全维度上均展现出最先进的性能，超越了现有的开源和专有模型，例如 WildGuard、LlamaGuard-4 和 GPT-4.1。Protect 为可信赖、可审计且可用于生产环境的安全系统奠定了坚实基础，这些系统能够在文本、图像和音频模态中运行。|
|**2025-10-15**|[What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging](http://arxiv.org/abs/2510.13232)|null|最先进的视觉-语言模型(VLM)在理解否定方面存在一个关键性缺陷，通常被称为肯定偏见。这种局限性在描述性目标检测(DOD)任务中尤为严重。为解决此问题，我们提出了两项主要贡献：(1)一种新的数据集构建流程和(2)一种新颖、轻量级的适应方法。首先，我们引入了CoVAND，一个通过系统化的思维链(CoT)和基于VQA的流程构建的数据集，以生成高质量、实例级接地的否定数据。其次，我们提出了NegToMe，一个新颖的文本词元合并模块，它直接解决了肯定偏见的架构性原因。NegToMe从根本上解决了词元化过程中否定线索的结构性丢失问题，将它们与属性分组，形成连贯的语义短语。它在输入层面保持了正确的极性，从而实现了鲁棒的否定理解，即使在数据有限的情况下也是如此。例如，为了防止模型将零散的词元“not”和“girl”简单地视为“girl”，NegToMe将它们绑定成一个单一的词元，其含义与单独的“girl”正确区分开来。该模块与一种参数高效且具有策略性的LoRA微调方法相结合。我们的方法显著提升了在具有挑战性的否定基准上的性能，降低了假阳性率，在OVDEval上将NMS-AP提高了高达+10.8个百分点，并展示了对最先进VLM的泛化能力。这项工作标志着在解决现实世界检测应用的否定理解方面迈出了关键一步。|
|**2025-10-14**|[OPLoRA: Orthogonal Projection LoRA Prevents Catastrophic Forgetting during Parameter-Efficient Fine-Tuning](http://arxiv.org/abs/2510.13003)|null|低秩适配（LoRA）能够高效微调大语言模型，但当学习到的更新干扰编码重要预训练知识的主导奇异方向时，它会遭受灾难性遗忘。我们提出正交投影LoRA（OPLoRA），这是一种有理论基础的方法，通过双边正交投影来阻止这种干扰。通过SVD分解冻结权重，OPLoRA利用投影 $P_L = I - U_k U_k^\top$和$P_R = I - V_k V_k^\top$将LoRA更新约束在完全位于前$k$个奇异子空间的正交补空间内。我们证明了这种构造精确地保留了前$k$个奇异三元组，为知识保留提供了数学保证。为了量化子空间干扰，我们引入了$\rho_k$ 作为衡量更新与主导方向对齐程度的度量。在常识推理、数学和代码生成方面进行的大量实验表明，OPLoRA显著减少了遗忘，同时在LLaMA-2 7B和Qwen2.5 7B上保持了有竞争力的特定任务性能，确立了正交投影作为参数高效微调中知识保留的有效机制。|
|**2025-10-14**|[The Curious Case of Curiosity across Human Cultures and LLMs](http://arxiv.org/abs/2510.12943)|**[link](https://github.com/MichiganNLP/CUEST)**|大型语言模型（LLMs）的最新进展拓展了它们在人机交互中的作用，然而，好奇心——探究的核心驱动力——在这些系统中仍未得到充分探索，尤其是在跨文化背景下。在这项工作中，我们利用雅虎问答（Yahoo! Answers）——一个涵盖广泛主题的真实世界多国数据集——调查好奇心的文化差异。我们引入了CUEST（跨社会好奇心评估），这是一个通过语言（风格）、主题偏好（内容）分析并将洞察力建立在社会科学构建之上，以衡量好奇心方面人机对齐的评估框架。跨越开源和闭源模型，我们发现LLMs趋于弱化跨文化多样性，更紧密地与西方国家好奇心的表达方式对齐。随后，我们探索了微调策略以在LLMs中诱导好奇心，将人机对齐差距缩小了高达50%。最后，我们展示了好奇心对于LLM在跨文化中的适应性的实际价值，表明其对未来自然语言处理（NLP）研究的重要性。|
|**2025-10-14**|[Personalized Federated Fine-Tuning of Vision Foundation Models for Healthcare](http://arxiv.org/abs/2510.12741)|null|基础模型为人工智能在医疗保健领域的应用开辟了新的可能性。然而，即使在健康数据上进行了预训练，它们仍然需要进行微调以适应特定的下游任务。此外，尽管基础模型减少了达到良好性能所需的训练数据量，但获取足够的数据仍然是一个挑战。这部分是由于为了保护患者隐私而限制了来自不同来源的数据共享和聚合。一个可能的解决方案是通过联邦学习跨多个参与客户端（即医院、诊所等）微调基础模型。在这项工作中，我们提出了一种新的个性化联邦微调方法，该方法学习正交的LoRA适配器以解耦通用知识和客户端特定知识，使每个客户端都能充分利用自身数据和他人数据。我们的初步结果在真实世界的联邦医学影像任务上表明，我们的方法与当前的联邦微调方法相比具有竞争力。|
|**2025-10-14**|[The Role of Parametric Injection-A Systematic Study of Parametric Retrieval-Augmented Generation](http://arxiv.org/abs/2510.12668)|null|检索增强生成（RAG）通过检索外部文档来增强大型语言模型（LLM）。作为一种新兴的RAG形式，参数化检索增强生成（PRAG）将文档编码为模型参数（即LoRA模块），并在推理过程中将这些表示注入模型，从而使LLM与文档能够在参数层面进行交互。与直接将文档放入输入上下文相比，PRAG更高效，并有可能提供更深层次的模型与文档交互。尽管PRAG受到越来越多的关注，但参数注入的底层机制仍知之甚少。在这项工作中，我们对PRAG进行了系统性研究，以阐明参数注入的作用，结果表明参数化文档仅捕获文档的部分语义信息，并且单独依赖它们与文本层面的交互相比，性能较差。然而，这些参数化表示编码了高级文档信息，可以增强模型对输入上下文中文档的理解。当参数化文档与文本文档结合使用时，模型可以更有效地利用相关信息，并对噪声输入更具鲁棒性，从而实现优于单独使用任一来源的性能。我们建议联合使用参数化文档和文本文档，并提倡增加参数化表示的信息含量以推进PRAG。|
|**2025-10-14**|[DeePAQ: A Perceptual Audio Quality Metric Based On Foundational Models and Weakly Supervised Learning](http://arxiv.org/abs/2510.12326)|null|本文提出了一种基于深度学习的感知音频质量度量（DeePAQ），用于评估通用音频质量。我们的方法利用度量学习与音乐基础模型MERT相结合，并在代理标签的指导下，构建了一个能够捕获通用音频中失真强度的嵌入空间。据我们所知，DeePAQ是通用音频质量领域中首次利用弱监督标签和度量学习，通过低秩适应（LoRA）微调音乐基础模型的方法，这是其他最先进方法尚未探索的方向。我们通过涵盖音频编码和源分离的听力测试，将所提出的模型与最先进的客观音频质量度量进行了基准测试。结果表明，我们的方法在检测编码伪影方面超越了现有度量标准，并且对源分离等未见过的失真泛化良好，突出了其鲁棒性和多功能性。|
|**2025-10-14**|[HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization](http://arxiv.org/abs/2510.12266)|null|低秩适应（LoRA）因其模块化设计和在HuggingFace等平台上的广泛可用性，已成为将大型语言模型（LLM）适应新领域的广泛使用技术。这种可用性促使人们努力重用现有LoRA以实现域泛化。然而，现有方法通常依赖于显式任务标签或额外训练，这对于部署来说是不切实际的。此外，它们通常激活固定数量的整个LoRA模块，导致参数冗余或不足，从而降低性能。在本文中，我们提出了\texttt{HiLoRA}，一个免训练框架，它在LoRA池上执行自适应分层路由。借鉴LoRA的结构特性，我们定义了秩一分量（ROCs），其中每个秩参数被视为一个独立单元。对于给定的输入序列，\texttt{HiLoRA}首先自适应地选择一个LoRA子集，并根据序列级别的高斯似然确定其ROCs分配。在词元级别，它通过仅激活最具信息量的ROCs来进一步细化路由。我们进一步提供了理论保证，表明\texttt{HiLoRA}以高概率选择最相关的LoRA。广泛的实验表明，\texttt{HiLoRA}在域泛化方面取得了显著改进，相较于最先进的基线，准确率提高了高达55%，同时保持了可比的推理吞吐量。|
|**2025-10-14**|[Evolution of meta's llama models and parameter-efficient fine-tuning of large language models: a survey](http://arxiv.org/abs/2510.12178)|null|本综述调查了Meta AI的LLaMA（大型语言模型Meta AI）系列的快速演进——从LLaMA 1到LLaMA 4，以及为这些模型开发的专门的参数高效微调（PEFT）方法。我们首先描述了LLaMA系列基础模型（从7B-65B到288B参数），它们的架构（包括原生多模态和专家混合变体），以及关键的性能特征。随后，我们描述并讨论了PEFT的概念，该方法通过仅更新一小部分参数来适应大型预训练模型，并回顾了五种已应用于LLaMA的PEFT方法：LoRA（低秩适应）、LLaMA-Adapter V1和V2、LLaMA-Excitor以及QLoRA（量化LoRA）。我们讨论了每种方法的机制、参数节省以及在LLaMA上的应用示例（例如，指令微调、多模态任务）。我们对模型和适配器架构、参数数量以及基准测试结果进行了结构化讨论和分析（包括微调的LLaMA模型超越更大基线模型的例子）。最后，我们考察了LLaMA模型和PEFT成功应用的实际案例（例如，法律和医疗领域），并讨论了持续挑战和未来研究方向（例如，扩展到更大的上下文和提高鲁棒性）。本综述论文为对LLaMA模型和高效微调策略感兴趣的机器学习研究人员和从业者提供了一站式资源。|
|**2025-10-14**|[Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback](http://arxiv.org/abs/2510.12089)|null|扩散模型近期进展显著改进了音频驱动的人体视频生成，在质量和可控性上均超越了传统方法。然而，现有方法在唇形同步精度、长视频生成的时间连贯性以及多角色动画方面仍面临挑战。在这项工作中，我们提出了一种基于扩散Transformer (DiT) 的框架，用于生成任意长度的逼真说话视频，并引入了一种免训练的多角色音频驱动动画方法。首先，我们采用了一种基于LoRA的训练策略，并结合了位置偏移推理方法，这使得在保留基础模型能力的同时，能够高效地生成长视频。此外，我们结合了部分参数更新与奖励反馈，以同时增强唇形同步和自然身体动作。最后，我们提出了一种免训练方法，即掩码分类器自由引导 (Mask-CFG)，用于多角色动画，该方法不需要专门的数据集或模型修改，并支持三个或更多角色的音频驱动动画。实验结果表明，我们的方法优于现有最先进的方法，以一种简单、高效且经济的方式实现了高质量、时间连贯的多角色音频驱动视频生成。|
|**2025-10-14**|[FedLoDrop: Federated LoRA with Dropout for Generalized LLM Fine-tuning](http://arxiv.org/abs/2510.12078)|null|大语言模型（LLMs）的微调（FT）对于使通用模型适应特定任务、以最少资源提高准确性和相关性至关重要。为进一步增强泛化能力同时降低训练成本，本文提出了一种新颖的框架——联邦LoRA与Dropout (FedLoDrop)，它将dropout应用于联邦LoRA中可训练矩阵的行和列。本文推导了在稀疏性正则化下的泛化误差界和收敛性分析，阐明了欠拟合和过拟合之间的基本权衡。误差界揭示，更高的dropout率增加了模型稀疏性，从而降低了点式假设稳定性（PHS）的上限。尽管这减少了经验误差和泛化误差之间的差距，但它也导致了更高的经验误差，而经验误差与差距共同决定了整体泛化误差。另一方面，尽管dropout降低了通信成本，但由于有限的网络资源，在网络边缘部署FedLoDrop仍然面临挑战。为解决这个问题，本文提出了一个优化问题，通过联合优化dropout率和资源分配，以最小化泛化误差的上限，同时受限于延迟和每设备能耗约束。为了解决这个问题，本文提出了一种基于分支定界（B&B）的方法以获得其全局最优解。此外，为了降低基于B&B方法的高计算复杂度，本文提出了一种基于惩罚连续凸逼近（P-SCA）的算法，以有效获得其高质量次优解。最后，数值结果证明了所提出方法在缓解过拟合和提高泛化能力方面的有效性。|
|**2025-10-14**|[Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models](http://arxiv.org/abs/2510.12044)|null|现有的大型语言模型 (LLMs) 对齐技术，例如直接偏好优化 (DPO)，通常将模型视为一个单一整体，对所有层施加统一的优化压力。这种方法忽略了 Transformer 架构内部的功能专业化，在该架构中，不同层已知处理从语法到抽象推理的不同任务。在本文中，我们通过引入分层对齐来挑战这种一刀切的范式，这是一种将有针对性的 DPO 应用于模型层中不同功能块的新颖方法：局部（语法）、中间（逻辑）和全局（事实性）。通过对 Llama-3.1-8B 和 Qwen1.5-7B 等最先进模型进行一系列使用 LoRA 进行外科式微调的对照实验，我们由一个强大的“LLM作为评判者”评估的结果，证明了显著且可预测的改进。具体来说，对齐局部层（局部对齐）增强了语法流畅性。更重要的是，对齐全局层（全局对齐）不仅如假设般提高了事实一致性，而且被证明是增强逻辑连贯性最有效的策略，优于所有基线。关键的是，所有分层策略都成功避免了在标准 DPO 中观察到的“对齐税”，即流畅性上的提升是以逻辑推理能力下降为代价的。这些发现为模型对齐建立了一条更资源高效、可控且可解释的路径，强调了从单一整体优化转向结构感知的外科式微调在构建更先进、更可靠的 LLMs 方面的巨大潜力。|
|**2025-10-13**|[QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning for LLMs](http://arxiv.org/abs/2510.11696)|null|我们提出了QeRL，一个针对大型语言模型（LLMs）的量化增强强化学习框架。尽管强化学习对于LLMs的推理能力至关重要，但它资源密集，需要大量的GPU内存和漫长的rollout（轨迹生成）持续时间。QeRL通过结合NVFP4量化与低秩适应（LoRA）来解决这些问题，加速了强化学习的rollout阶段，同时降低了内存开销。除了效率之外，我们的发现表明，量化噪声增加了策略熵，增强了探索能力，并使得在强化学习过程中能够发现更好的策略。为了进一步优化探索，QeRL引入了一种自适应量化噪声（AQN）机制，该机制在训练期间动态调整噪声。实验表明QeRL在rollout阶段提供了超过1.5倍的加速。此外，这是第一个能够在单个H100 80GB GPU上实现32B LLM的强化学习训练的框架，同时为强化学习训练带来了整体加速。它还比16位LoRA和QLoRA实现了更快的奖励增长和更高的最终准确率，同时在7B模型上，在GSM8K（90.8%）和MATH 500（77.4%）等数学基准测试中，其性能与全参数微调相当。这些结果确立了QeRL作为一个高效且有效的LLMs强化学习训练框架。|
|**2025-10-13**|[MeTA-LoRA: Data-Efficient Multi-Task Fine-Tuning for Large Language Models](http://arxiv.org/abs/2510.11598)|null|低秩适应 (LoRA) 已成为将大语言模型 (LLMs) 适应到下游任务中最广泛使用的参数高效微调 (PEFT) 方法之一。尽管在单任务设置中非常高效，但在复杂的多任务学习场景中，LoRA 难以有效利用任务间知识，通常需要大量特定任务数据才能达到最佳性能。为解决这一局限性，我们引入了 MeTA-LoRA，这是一个两阶段优化框架，可显著提高多任务适应中的数据效率。在第一阶段，仅使用每个相关数据集的少量样本来学习特定任务的 LoRA 适配器，从而在无需大规模监督的情况下实现快速适应。在第二阶段，通过聚合来自多个任务的梯度来更新共享 LoRA 适配器，以促进跨任务的知识迁移，并通过利用共同模式进一步减少数据使用。在多任务学习和多语言学习场景中，我们的方法达到或超越了传统全数据 LoRA 微调方法的性能，同时显著减少了特定任务数据的使用量。|
|**2025-10-11**|[Q-Adapter: Visual Query Adapter for Extracting Textually-related Features in Video Captioning](http://arxiv.org/abs/2510.10022)|null|视频字幕生成领域的最新进展得益于大规模预训练模型，这些模型遵循标准的“预训练后微调”范式，即对完整模型进行微调以执行下游任务。尽管有效，但随着模型规模的增大，这种方法在计算上变得难以承受。参数高效微调 (PEFT) 方法提供了一个有前景的替代方案，但主要侧重于多模态大语言模型 (MLLMs) 的语言组件。尽管最近取得了进展，但 PEFT 在多模态任务中仍未得到充分探索，并且在微调模型时缺乏对视觉信息的充分理解。为了弥补这一差距，我们提出了 Query-Adapter (Q-Adapter)，这是一个轻量级视觉适配器模块，旨在通过实现视频字幕生成任务的高效微调来增强 MLLMs。Q-Adapter 将可学习的查询 token 和门控层引入视觉编码器，从而无需依赖外部文本监督即可有效提取稀疏的、与字幕相关的特征。我们在两个知名视频字幕数据集 MSR-VTT 和 MSVD 上评估了 Q-Adapter，在采用 PEFT 方法的模型中，它在 BLEU@4、METEOR、ROUGE-L 和 CIDEr 指标上均达到了最先进的性能。与采用完整微调方法相比，Q-Adapter 也实现了具有竞争力的性能，同时仅需要 1.4% 的参数。我们进一步分析了关键超参数和设计选择对微调有效性的影响，为基于适配器的学习的优化策略提供了见解。这些结果强调了 Q-Adapter 在平衡字幕质量和参数效率方面的巨大潜力，展示了其在视频-语言建模方面的可扩展性。|
|**2025-10-10**|[Vision Language Models: A Survey of 26K Papers](http://arxiv.org/abs/2510.09586)|null|我们对2023-2025年CVPR、ICLR和NeurIPS的26,104篇录用论文的研究趋势进行了透明、可复现的测量。论文标题和摘要经过规范化、短语保护处理，并与手工构建的词典进行匹配，以分配多达35个主题标签，并挖掘关于任务、架构、训练方案、目标、数据集以及共同提及模态的细粒度线索。分析量化了三个宏观转变：(1) 多模态视觉-语言-大型语言模型（LLM）工作急剧增长，这越来越将经典感知重构为指令遵循和多步推理；(2) 生成方法稳步扩展，其中扩散模型研究围绕可控性、蒸馏和速度进行整合；(3) 3D和视频研究活动保持活跃，合成技术从NeRFs转向高斯泼溅，并且越来越强调以人-和智能体为中心的理解。在视觉-语言模型（VLM）内部，提示/适配器/LoRA等参数高效适应技术和轻量级视觉-语言桥梁占据主导地位；训练实践从头构建编码器转向指令微调和微调强大的骨干网络；对比目标相对于交叉熵/排序和蒸馏有所退却。跨会议比较显示，CVPR在3D领域有更强的影响力，ICLR拥有最高的VLM份额，而效率或鲁棒性等可靠性主题则扩散到各个领域。我们发布了该词典和方法，以方便审计和扩展。局限性包括词典召回率和仅限于摘要的范围，但纵向信号在不同会议和年份之间保持一致。|
|**2025-10-10**|[Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives](http://arxiv.org/abs/2510.09434)|null|自由文本事故叙述记录在真实世界事故数据库中，已被证明在改善交通安全方面发挥着重要作用。然而，大规模分析仍难以实施，因为没有已记录的工具可以批量处理由经验各异、细致程度不同的作者撰写的非结构化、非标准化文本内容。近年来，基于Transformer的预训练语言模型（PLM），如基于Transformer的双向编码器表示（BERT）和大语言模型（LLM），在各种自然语言处理任务中展现出强大的能力。这些模型可以从事故叙述中提取显性事实，但其在推理密集型任务（例如，可能涉及近100个类别的事故类型识别）上的性能会下降。此外，通过外部API依赖闭源LLM会引发敏感事故数据的隐私问题。另外，这些黑盒工具由于领域知识有限，往往表现不佳。受这些挑战的启发，我们研究了紧凑型开源PLM是否能支持从事故叙述中进行推理密集型提取。我们针对两个具有挑战性的目标：1）识别事故的碰撞方式，以及2）从真实世界事故叙述中识别事故事件中每辆涉事车辆的事故类型。为弥合领域差距，我们应用微调技术，通过低秩适应（LoRA）和BERT向LLM注入任务特定知识。在权威的真实世界数据集事故调查抽样系统（CISS）上进行的实验表明，我们微调后的紧凑模型优于强大的闭源LLM，例如GPT-4o，同时仅需极少的训练资源。进一步分析表明，微调后的PLM可以捕获更丰富的叙述细节，甚至纠正数据集中一些错误标注。|
|**2025-10-10**|[Understanding the Effects of Domain Finetuning on LLMs](http://arxiv.org/abs/2510.09359)|null|针对特定领域微调的大语言模型（LLMs）表现出强大的性能；然而，这种微调如何重塑其参数空间的潜在机制尚未被充分理解。先前的工作主要关注自回归或通用指令模型，使得领域专用LLMs的研究不足。我们首次对大型医学语言模型中的领域特定微调进行了系统性研究。我们的分析表明，微调仅修改了表征子空间的一小部分，基本上保留了预训练模型的表征。为了解释子空间中的这些变化，我们提出了调优向量，这是一种受任务向量启发的全新框架，它明确捕获了由微调引起的参数方向性偏移。我们证明这些向量对于增强指令遵循能力和生成质量至关重要。此外，结合来自不同领域的调优向量能够提高泛化能力。对方向性对齐进行更仔细的检查后，我们发现这些向量主要将新的方向性信息写入模型的MLP层，同时放大注意力头中已有的方向。我们的发现为LLM适应性提供了新见解，并提供了一个通用、可解释的框架，用于分析大语言模型中的专业化。|
|**2025-10-10**|[Auto-scaling Continuous Memory for GUI Agent](http://arxiv.org/abs/2510.09038)|**[link](https://github.com/WenyiWU0111/CoMEM-Agent)**|我们研究如何赋予GUI智能体可扩展记忆，以帮助其在不熟悉的界面和长周期任务中进行泛化。此前的GUI智能体将过去的轨迹压缩成文本标记，这会显著增加上下文长度并遗漏决定性的视觉线索（例如，精确的控件大小和位置）。我们提出一种连续记忆，它使用VLM本身作为编码器，将每个GUI轨迹编码成固定长度的连续嵌入序列；这些嵌入直接插入到主干网络的输入层，大幅降低了上下文成本，同时保留了细粒度的视觉信息。随着记忆大小和检索深度的增加，性能单调提升，这与文本记忆在长提示下性能下降的情况不同。为了以低成本扩展记忆，我们引入了一个自动扩展数据飞轮，它(i)通过搜索发现新环境，(ii)使用开源VLM合成任务，(iii)使用智能体推出轨迹，以及(iv)使用同一VLM验证成功。利用这个管道，我们以大约4000美元的成本收集了超过10万条轨迹，并仅使用1500个样本对记忆编码器（Q-Former上的LoRA，1.2%参数）进行微调。在真实世界的GUI基准测试中，我们的记忆增强智能体在长周期和分布偏移下持续提高成功率。值得注意的是，Qwen-2.5-VL-7B加上连续记忆达到了与最先进的闭源模型（例如GPT-4o、Claude-4）相当的性能。|
|**2025-10-09**|[TinyGraphEstimator: Adapting Lightweight Language Models for Graph Structure Inference](http://arxiv.org/abs/2510.08808)|null|图为表示复杂的关联系统提供了通用框架，推断其结构属性是图分析和推理中的核心挑战。尽管大语言模型最近在执行符号和数值推理方面展示出了新兴能力，但在此背景下，小型、资源高效模型的潜力仍未得到充分探索。本文研究紧凑型Transformer语言模型是否能直接从文本图表示中推断图论参数。为了实现系统评估，我们引入了TinyGraphEstimator数据集——一个从多种随机图模型生成并用详细的结构元数据进行标注的平衡连通图集合。我们评估了几个小型开源模型在预测关键图参数（例如密度、聚类系数和色数）方面的能力。此外，我们使用低秩适应（LoRA）技术应用了轻量级微调，在所有评估指标上取得了持续改进。结果表明，小型语言模型对图结构数据具有非平凡的推理能力，并且可以通过高效的参数调整有效地适应结构推断任务。|
|**2025-10-09**|[FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts](http://arxiv.org/abs/2510.08396)|**[link](https://github.com/gfyddha/FlyLoRA)**|低秩适应（LoRA）是一种广泛用于基础模型的参数高效微调方法，但它存在参数干扰问题，导致次优性能。尽管基于专家混合（MoE）的LoRA变体在缓解单任务指令微调中的任务内相关性方面显示出前景，但它们引入了额外的路由参数，并且在出现任务间干扰的多任务模型合并中仍然无效。受苍蝇嗅觉回路的启发，我们提出了FlyLoRA，这是一种隐式基于MoE的LoRA变体，它引入了：（1）上投影矩阵中的秩级专家激活，以及（2）一个统一了专家路由和下投影的隐式路由器，其中一个冻结的稀疏随机投影矩阵取代了传统的密集可训练版本。这种设计通过消除对显式路由器的需求，解决了任务内去相关和计算效率之间的权衡，同时由于随机矩阵的正交性，固有地缓解了任务间干扰。跨通用知识理解、科学问答、数学推理和代码生成这四个领域的大量实验证明，FlyLoRA相对于现有方法具有一致的性能提升。除了经验性收益之外，FlyLoRA还强调了生物结构如何启发人工智能技术的创新。代码可在https://github.com/gfyddha/FlyLoRA获取。|
|**2025-10-09**|[Mitigating Subject Dependency in EEG Decoding with Subject-Specific Low-Rank Adapters](http://arxiv.org/abs/2510.08059)|**[link](https://github.com/timonkl/SubjectConditionedLayer)**|受试者特异性分布偏移是脑电图解码基础模型开发的一个重要障碍。为解决此问题，我们提出了受试者条件层（Subject-Conditioned Layer），这是一种自适应层，旨在作为任何神经网络架构中标准线性层或卷积层的即插即用替代品。我们的层通过将其权重分解为一个共享的、受试者不变的组件以及一个轻量级、低秩的、每个受试者独有的校正项，从而捕获受试者特异性变异性。这种将通用知识与个性化适应明确分离的方法，使现有模型能够对受试者偏移具有鲁棒性。经验上，配备我们层的模型优于仅使用共享权重的模型（受试者无关模型）以及单独训练的受试者特异性模型的平均性能。因此，受试者条件层为构建有效的跨受试者脑电图基础模型提供了一条实用且可扩展的路径。|
|**2025-10-09**|[HySim-LLM: Embedding-Weighted Fine-Tuning Bounds and Manifold Denoising for Domain-Adapted LLMs](http://arxiv.org/abs/2510.07796)|null|从科学文献中提取和标准化药代动力学（PK）信息仍然是计算药理学中的重大挑战，这限制了数据驱动模型在药物开发中的可靠性。大语言模型（LLMs）在文本理解和推理方面取得了显著进展，但其对结构化生物医学数据（如PK表格）的适应性仍受到异质性、噪声和领域漂移的限制。为解决这些局限性，我们提出了HySim-LLM，一个统一的数学和计算框架，它整合了嵌入加权微调和流形感知去噪，以增强LLMs的鲁棒性和可解释性。我们建立了两个理论结果：（1）一个相似度加权泛化界，量化了嵌入散度下的适应性能，以及（2）一个基于流形的去噪保证，限制了来自噪声或偏离流形的样本的损失贡献。这些定理为在结构化生物医学环境中微调LLMs提供了原则性基础。该框架为生物医学和数据密集型科学领域中可靠且可解释的LLM适应提供了一条具有数学基础的途径。|
|**2025-10-09**|[Banking Done Right: Redefining Retail Banking with Language-Centric AI](http://arxiv.org/abs/2510.07645)|null|本文介绍了Ryt AI，一个LLM原生智能体框架，它为Ryt银行提供支持，使客户能够通过自然语言对话执行核心金融交易。这代表了全球首个获得监管机构批准的部署，其中对话式AI作为主要的银行界面，与之前仅限于咨询或支持角色的助手形成对比。Ryt AI完全自主开发，由内部开发的闭源LLM ILMU驱动，并用一个由四个LLM驱动的智能体（Guardrails、Intent、Payment和FAQ）编排的单一对话取代了僵硬的多屏幕工作流程。每个智能体都为ILMU附加一个任务特定的LoRA适配器，ILMU部署在银行基础设施内，以确保行为一致且开销最小。确定性护栏、人工干预确认以及无状态审计架构为安全和合规性提供了深度防御。最终实现了“银行事务，妥善办理”这一目标：证明了经监管机构批准的自然语言界面能够在严格治理下可靠地支持核心金融操作。|
|**2025-10-09**|[Role-Conditioned Refusals: Evaluating Access Control Reasoning in Large Language Models](http://arxiv.org/abs/2510.07642)|null|访问控制是安全计算的基石，然而大型语言模型通过生成不受限制的响应，常常模糊了角色边界。我们研究了角色条件式拒绝，重点关注LLM在被授权时回答、未被授权时拒绝，从而遵守访问控制策略的能力。为了评估这种行为，我们创建了一个新颖的数据集，该数据集扩展了Spider和BIRD文本到SQL数据集，这两个数据集都已通过表级和列级的真实PostgreSQL基于角色的策略进行了修改。我们比较了三种设计：(i) 零样本或少样本提示，(ii) 一个根据策略检查SQL的两步生成器-验证器流水线，以及 (iii) 直接学习权限感知的LoRA微调模型。在多个模型家族中，显式验证（两步框架）提高了拒绝的精确度并降低了错误允许。同时，微调在安全性和实用性（即，在考虑执行准确性时）之间实现了更强的平衡。更长、更复杂的策略持续降低了所有系统的可靠性。我们发布了RBAC增强型数据集和代码。|
|**2025-10-08**|[Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts](http://arxiv.org/abs/2510.07239)|null|自动化红队测试已成为部署前审计大型语言模型（LLMs）的一种可扩展方法，然而现有方法缺乏在推理时有效适应模型特有漏洞的机制。我们引入了Red-Bandit，这是一个红队测试框架，它能在线适应，以识别并利用在不同攻击风格（例如，操纵、俚语）下的模型故障模式。Red-Bandit后训练了一组参数高效的LoRA专家模型，每个专家模型专门针对一种特定攻击风格，并利用强化学习，通过基于规则的安全模型奖励不安全提示的生成。在推理时，一个多臂老虎机策略根据目标模型的响应安全性，动态地从这些攻击风格专家模型中进行选择，从而平衡探索与利用。Red-Bandit在AdvBench上，在充分探索（ASR@10）的条件下取得了最先进的结果，同时生成了更具可读性（更低困惑度）的提示。此外，Red-Bandit的多臂老虎机策略通过指示哪些攻击风格最有效地引发不安全行为，可作为揭示模型特有漏洞的诊断工具。|
|**2025-10-08**|[Making Machines Sound Sarcastic: LLM-Enhanced and Retrieval-Guided Sarcastic Speech Synthesis](http://arxiv.org/abs/2510.07096)|null|讽刺是一种微妙的非字面语言形式，由于其依赖细致入微的语义、上下文和韵律线索，对语音合成构成了重大挑战。现有语音合成研究主要关注广泛的情感类别，而讽刺在很大程度上仍未被充分探索。在本文中，我们提出了一种大语言模型（LLM）增强的检索增强框架，用于讽刺感知语音合成。我们的方法结合了 (1) 来自经过LoRA微调的LLaMA 3的语义嵌入，它们捕捉了讽刺的语用不一致性和语篇级线索，以及 (2) 通过检索增强生成（RAG）模块检索到的韵律范例，它们提供了讽刺表达的富有表现力的参考模式。整合到VITS骨干网络中，这种双重条件化使得生成更自然、上下文更适宜的讽刺性语音成为可能。实验表明，我们的方法在客观指标和主观评估两方面均优于基线，在语音自然度、讽刺表现力以及下游讽刺检测方面都取得了改进。|
|**2025-10-08**|[Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report](http://arxiv.org/abs/2510.07092)|null|世界模型是人工智能和机器人学中一个强大的范式，它使智能体能够通过预测视觉观测或紧凑的潜在状态来推理未来。1X世界模型挑战赛引入了一个针对真实世界人形机器人交互的开源基准，包含两个互补的赛道：采样赛道专注于预测未来图像帧，压缩赛道专注于预测未来离散潜在编码。对于采样赛道，我们调整了视频生成基础模型Wan-2.2 TI2V-5B以进行视频状态条件下的未来帧预测。我们采用AdaLN-Zero使用机器人状态对视频生成进行条件化，并使用LoRA对模型进行进一步后训练。对于压缩赛道，我们从头开始训练了一个时空Transformer模型。我们的模型在采样任务中达到23.0 dB的PSNR，在压缩任务中达到6.6386的Top-500 CE，在两项挑战中均获得第一名。|
|**2025-10-07**|[MASA: Rethinking the Representational Bottleneck in LoRA with Multi-A Shared Adaptation](http://arxiv.org/abs/2510.06005)|**[link](https://github.com/Mwie1024/MASA)**|低秩适应 (LoRA) 已成为大语言模型参数高效微调 (PEFT) 中的一种主导方法，它通过一个下投影 $A$ 和一个上投影 $B$ 来增强Transformer层。然而，LoRA 对单个下投影矩阵 ($A$) 的依赖造成了表示瓶颈，因为这个单一的特征提取器本质上不足以捕获复杂任务所需的多种信号。这促使我们进行架构转变，专注于丰富特征适应以提高下游任务适应能力。我们提出了 MASA (多-$A$ 共享适应)，这是一种实现多-$A$ 单-$B$ 结构的架构，其中多-$A$ 专家集成在层间非对称共享以确保参数效率。在 MASA 中，这些专门化专家捕获多样化特征，然后由一个单一的、层特定的 $B$ 矩阵进行整合。我们方法的有效性和多功能性通过涵盖多领域泛化、单领域专业化和多任务推理的一系列综合实验得到了验证。例如，在 MMLU 基准测试中，MASA 实现了 59.62% 的平均准确率，以可比的 0.52% 可学习参数，优于标准 LoRA 1.08 个百分点（相对提升 1.84%）。|
|**2025-10-06**|[Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning](http://arxiv.org/abs/2510.05003)|null|大语言模型（LLMs），如GPT-4和LLaMA，已展现出卓越的推理能力，但微调需要大量的计算资源。本文提出一种资源高效的微调方法，针对LLaMA-3.2-3B，以增强医疗链式推理能力，同时在受限的GPU和内存环境下运行。采用参数高效微调技术，如LoRA和QLoRA，我们在基础模型上进行适配，基于公开可用的医疗推理数据集。该模型实现了改进的推理连贯性和事实准确性，同时内存使用量相较于标准的全量微调减少高达60%。实验评估表明，轻量级适配在医疗问答任务中能够保持强大的推理能力。这项工作突出了在低资源研究环境中部署LLM的实用策略，并为医疗AI系统平衡效率和领域专业化提供了见解。|
|**2025-10-06**|[TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA](http://arxiv.org/abs/2510.04682)|null|大语言模型（LLMs）广泛应用于实际场景，但对其进行微调会带来显著的计算和存储成本。参数高效微调（PEFT）方法如LoRA缓解了这些成本，但其适应性参数依赖于基础模型，无法跨不同骨干网络迁移。解决此问题的一种方法是通过知识蒸馏，但其有效性本质上取决于训练数据。最近的研究工作，例如TransLoRA，通过生成合成数据来避免此问题，但这增加了复杂性，因为它需要训练一个额外的判别器模型。在本文中，我们提出了TiTok，一个通过令牌级知识迁移实现有效LoRA移植的新框架。具体而言，TiTok通过有LoRA和无LoRA的源模型之间的对比余量来捕获与任务相关的信息。这种余量突出了信息丰富的令牌，并实现了合成数据的选择性过滤，所有这些都无需额外的模型或开销。通过在多个迁移设置下的三个基准数据集上的实验，我们的实验表明，所提出的方法始终有效，与整体基线相比，平均性能提升了4~8%。|
|**2025-10-06**|[Topic-Specific Classifiers are Better Relevance Judges than Prompted LLMs](http://arxiv.org/abs/2510.04633)|null|未判文档问题是指，在信息检索中，汇集测试集在评估新的检索系统时存在不完整的相关性判断，这是测试集复用性的一个关键障碍。尽管处理该问题的实际标准是将未判文档视为不相关，但许多替代方案已被提出，包括使用大型语言模型（LLM）作为相关性判官（LLM-as-a-judge）。然而，这被批评为循环论证，因为同一个LLM可以同时用作判官和排序器。我们提出转而训练主题特定的相关性分类器：通过对针对单个主题文档池的单个评估员的判断进行独立的LoRA权重适应来微调monoT5，我们使其与该评估员对该主题的相关性概念保持一致。通过我们分类器的相关性判断获得的系统排名与真实系统排名实现了斯皮尔曼 $\rho$ 相关性大于0.95。每个主题只需128个初始人工判断就足以提高模型的比较性，相比于将未判文档视为不相关，同时比现有LLM-as-a-judge方法更可靠。因此，主题特定的相关性分类器是一种轻量级且直接的方法来解决未判文档问题，同时保持人工判断作为检索评估的黄金标准。代码、模型和数据已公开提供。|
|**2025-10-06**|[FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning](http://arxiv.org/abs/2510.04601)|null|当前在公开可用的网络数据上训练大型语言模型（LLM）的范式正变得不可持续，专业领域内的高质量数据源已接近枯竭。联邦学习（FL）作为去中心化网络上下一代人工智能的实用解决方案应运而生，通过利用分布在全球客户端的私有数据，实现隐私保护的协作式微调。尽管低秩适应（LoRA）是高效微调的标准方法，但其在联邦设置中的应用面临一个关键挑战：在网络异构条件下，通信开销仍然是一个显著的瓶颈。LoRA参数中的结构冗余不仅带来了沉重的通信负担，而且在聚合客户端更新时引入了冲突。为了解决这个问题，我们提出了FedSRD，一个稀疏化-重构-分解框架，旨在实现通信高效的联邦学习。我们首先引入了一种基于重要性的稀疏化方法，它保持LoRA更新的结构完整性，以减少上传的参数数量。服务器随后在全秩空间中重构并聚合这些更新，以减轻冲突。最后，它将全局更新分解为稀疏低秩格式用于广播，确保一个对称高效的循环。我们还提出了一种高效变体FedSRD-e，以减少计算开销。在10个基准上的实验结果表明，我们的框架显著降低了高达90%的通信成本，同时甚至提高了异构客户端数据上的模型性能。|
|**2025-10-07**|[DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise Injection and Auxiliary Networks](http://arxiv.org/abs/2510.04331)|null|参数高效微调 (PEFT) 方法已成为适应大规模模型的标准范式。在这些技术中，权重分解低秩适应 (DoRA) 通过将预训练权重显式分解为幅度和方向分量，已被证明可以改进原始低秩适应 (LoRA) 方法的学习能力和训练稳定性。在这项工作中，我们提出了 DoRAN，它是 DoRA 的一个新变体，旨在进一步稳定训练并提高 DoRA 的样本效率。我们的方法包括两个关键阶段：(i) 将噪声注入 DoRA 权重分解的分母中，这作为一种自适应正则化器以减轻不稳定性；(ii) 用动态生成低秩矩阵的辅助网络替换静态低秩矩阵，从而实现跨层的参数耦合，并在理论和实践中都产生了更好的样本效率。在视觉和语言基准上的全面实验表明，DoRAN 始终优于 LoRA、DoRA 和其他 PEFT 基线。这些结果强调了通过基于噪声的正则化实现稳定性与基于网络的参数生成相结合的有效性，为基础模型的鲁棒和高效微调提供了一个有前景的方向。|
|**2025-10-05**|[GROK: From Quantitative Biomarkers to Qualitative Diagnosis via a Grounded MLLM with Knowledge-Guided Instruction](http://arxiv.org/abs/2510.04281)|**[link](https://github.com/NatsuGao7/GROK-A-Retinal-MLLMs)**|多模态大语言模型 (MLLMs) 在整合多种数据模态方面具有潜力，但目前诸如LLaVA-Med等医学适配模型往往未能充分利用彩色眼底摄影 (CFP) 和光学相干断层扫描 (OCT) 之间的协同作用，且对定量生物标志物的可解释性有限。我们引入了GROK，一种接地多模态大语言模型，它能够联合处理CFP、OCT和文本数据，以提供临床医生级别的眼部和全身性疾病诊断。GROK包含三个核心模块：知识引导指令生成、CLIP风格的OCT生物标志物对齐和监督指令微调，它们共同建立了一个从定量到定性的诊断思维链，在生成详细病灶注释时，这与真实的临床推理过程相吻合。为了评估我们的方法，我们引入了接地眼科理解基准，该基准涵盖六种疾病类别和三项任务：宏观诊断分类、报告生成质量以及对所生成思维链的细粒度临床评估。实验结果表明，仅通过对7B参数的Qwen2主干模型进行LoRA（低秩适应）微调，GROK在报告质量和细粒度临床指标上均优于可比较的7B和32B基线模型，甚至超越了OpenAI o3。代码和数据已在GROK代码库中公开。|
|**2025-10-04**|[Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs](http://arxiv.org/abs/2510.03847)|null|小型语言模型（SLM；10亿至120亿参数，有时高达200亿）对于以模式和API约束下的准确性而非开放式生成为目标的智能体工作负载来说是足够且通常更优的。我们综合了开源和专有SLM（Phi-4-Mini、Qwen-2.5-7B、Gemma-2-9B、Llama-3.2-1B/3B、Ministral-3B/8B、Apple on-device 3B、DeepSeek-R1-Distill）的近期证据，并将其与现代评估方法（BFCL v3/v4、StableToolBench）以及搭配引导式解码库（XGrammar、Outlines）的服务栈（vLLM、SGLang、TensorRT-LLM）联系起来。我们形式化了采用不确定性感知路由和验证器级联的SLM优先、LLM回退系统，并提出了反映实际生产目标的工程指标：每成功任务成本（CPS）、模式有效性率、可执行调用率、p50/p95延迟以及每请求能耗。引导式解码、严格的JSON Schema输出和验证器优先的工具执行大大缩小了与大型模型的能力差距，并经常使SLM在工具使用、函数调用和RAG方面匹敌或超越LLM，同时以10到100倍更低的token成本实现显著更好的延迟和能耗。我们为优先使用SLM的智能体栈提供了设计模式：模式优先提示、类型安全的函数注册表、结合验证器汇总的置信度评分以及通过LoRA/QLoRA进行的轻量级适应。我们也划定了回退仍然有价值的局限性（开放域推理和某些长期规划）。其结果是一个实用的蓝图，用于构建默认使用SLM并同时通过有针对性的LLM辅助保留余量的快速、廉价且可靠的智能体。关键词：小型语言模型，智能体，函数调用，结构化输出，JSON Schema，引导式解码，LoRA/QLoRA，路由，能效，边缘推理|
|**2025-10-04**|[Optimizing Fine-Tuning through Advanced Initialization Strategies for Low-Rank Adaptation](http://arxiv.org/abs/2510.03731)|null|参数高效微调方法的快速发展显著提高了适应大型语言模型的效率。其中，LoRA因其在有效性和参数效率之间取得了良好的平衡而广受欢迎。然而，LoRA依赖于初始化两个乘积为零的低秩矩阵，这限制了其有效激活和利用原始模型权重的能力，为实现最佳性能造成了潜在瓶颈。为解决这一限制，我们提出了IniLoRA，一种新颖的初始化策略，它将低秩矩阵初始化为与原始模型权重紧密近似。实验结果表明，IniLoRA在一系列模型和任务上均优于LoRA。此外，我们还引入了两种变体IniLoRA- $\alpha$和IniLoRA-$\beta$ ，它们都利用了不同的初始化方法来进一步提升性能。|
|**2025-10-04**|[Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs](http://arxiv.org/abs/2510.03680)|null|扩散大语言模型（dLLMs）已成为自回归模型的一个有前景的替代方案，提供灵活的生成顺序并在复杂推理任务上表现出强大的性能。然而，指令微调的dLLMs表现出我们称之为\texttt{<eos>}溢出的关键漏洞：随着分配的序列长度增加，响应反而会缩短，崩溃为提前终止或退化为一连串的\texttt{<eos>}标记。尽管在实践中已被注意到，但此问题尚未得到系统分析。我们将其根本原因追溯到\texttt{<eos>}作为终止和填充的双重角色，这使得概率质量集中在较靠后位置的\texttt{<eos>}上，并向后传播以触发提前终止。为了解决这个问题，我们引入了Rainbow Padding，这是一种简单的补救措施，它用循环重复的不同填充标记替换重复的\texttt{<eos>}占位符，从而分散概率质量并打破\texttt{<eos>}的主导地位。实验表明，Rainbow Padding显著提高了长度鲁棒性和输出质量，仅需七个填充标记就足以防止提前终止。此外，该方法可以有效地集成到现有的指令微调模型中：在少量数据上进行一个epoch的LoRA微调即可带来显著改进，使该解决方案具有高度实用性。代码已公开发布于https://github.com/quasar529/rainbow-padding。|
|**2025-10-03**|[HyperAdaLoRA: Accelerating LoRA Rank Allocation During Training via Hypernetworks without Sacrificing Performance](http://arxiv.org/abs/2510.02630)|null|参数高效微调（PEFT），特别是低秩适应（LoRA），已成为一种有前景的方法，可在减少计算和内存开销的同时微调大型语言模型（LLMs）。然而，LoRA为每个增量矩阵假设一个统一的秩r，并未考虑权重矩阵在不同模块和层之间的不同重要性。AdaLoRA利用奇异值分解（SVD）来参数化更新，并采用奇异值剪枝来引入动态秩分配，从而增强了适应性。然而，在训练过程中，它经常遇到收敛速度慢和计算开销高的问题。为解决此问题，我们提出了HyperAdaLoRA，这是一种新颖的框架，通过利用超网络来加速AdaLoRA的收敛。HyperAdaLoRA没有直接优化奇异值分解的组成部分（P, Λ, Q），而是采用基于注意力机制的超网络来动态生成这些参数。通过剪枝生成奇异值的超网络的输出，实现了动态秩分配。在各种数据集和模型上进行的综合实验表明，我们的方法在不牺牲性能的情况下实现了更快的收敛。此外，对其他基于LoRA的方法进行的进一步扩展实验验证了我们方法的广泛适用性。|
|**2025-10-01**|[AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization](http://arxiv.org/abs/2510.02393)|**[link](https://github.com/TsingZ0/AP2O)**|大型语言模型的代码生成能力显著提升了编程任务的效率。然而，大型语言模型生成的代码仍然存在编译错误和运行时错误。现有的离线偏好优化方法主要侧重于利用偏好数据中的通过/失败信号来提升大型语言模型的编码能力，却忽略了失败代码中深层次的错误类型。为此，我们提出了编码的自适应渐进式偏好优化（AP2O-Coder）方法，该方法能够自适应、系统性地指导大型语言模型减少代码生成中的代码错误。具体来说，我们从失败代码中构建了一个错误记录本，并逐步优化大型语言模型以逐个类型地纠正错误。此外，我们在整个训练过程中自适应地重放错误类型，以适应大型语言模型不断变化的弱点。通过对参数规模从0.5B到34B不等的代码专用和通用大型语言模型（Llama、Qwen和DeepSeek系列）进行广泛实验，我们的AP2O-Coder在pass@k指标上将代码生成性能提升高达3%，同时使用了更少的偏好数据。代码：https://github.com/TsingZ0/AP2O|
|**2025-10-02**|[LLM-Based Multi-Task Bangla Hate Speech Detection: Type, Severity, and Target](http://arxiv.org/abs/2510.01995)|null|在线社交媒体平台是日常交流和信息获取的核心。尽管这些平台具有积极作用，但它们也为仇恨言论、冒犯性语言和针对个人、组织及社区的欺凌内容的传播提供了温床。此类内容损害了在线安全性、参与度和公平性。因此，需要可靠的检测系统，尤其对于审核工具有限的资源匮乏语言。在孟加拉语中，先前工作贡献了资源和模型，但大多数是单任务的（例如，二元仇恨/冒犯分类），对多方面信号（类型、严重程度、目标）的覆盖有限。我们通过引入首个多任务孟加拉语仇恨言论数据集BanglaMultiHate来解决这些空白，这是迄今为止最大的手动标注语料库之一。基于此资源，我们进行了一项全面、受控的比较，涵盖了经典基线模型、单语预训练模型以及在零样本提示和LoRA微调条件下的LLM。我们的实验评估了LLM在低资源环境中的适应性，并揭示了一个一致的趋势：尽管经过LoRA微调的LLM与BanglaBERT具有竞争力，但具有文化和语言基础的预训练对于稳健的性能仍然至关重要。我们的数据集和研究结果共同为在低资源环境中开发文化上一致的审核工具建立了一个更强的基准。为了可复现性，我们将发布数据集和所有相关脚本。|
|**2025-10-02**|[AMAS: Adaptively Determining Communication Topology for LLM-based Multi-Agent System](http://arxiv.org/abs/2510.01617)|null|尽管大语言模型（LLMs）彻底改变了自然语言处理能力，但它们作为自主多智能体系统（MAS）在工业问题解决中的实际应用仍面临持续障碍。传统的MAS架构根本上受限于僵化、人工设计的图拓扑结构，这些结构缺乏上下文响应能力，导致在各种学术和商业工作负载中的效率降低。为了克服这些限制，我们引入了AMAS，这是一个范式转变的框架，通过一种新颖的动态图设计器重新定义了基于LLM的MAS。该组件通过轻量级LLM自适应自主识别任务特定的最优图配置，消除了对单一、普遍适用的结构模板的依赖。相反，AMAS利用单个输入的内在特性，通过任务优化的智能体路径智能地引导查询轨迹。在问答、数学推导和代码生成基准测试中的严格验证证实，AMAS系统地超越了在不同LLM架构上的最先进的单智能体和多智能体方法。我们的研究表明，上下文敏感的结构适应性构成了高性能LLM MAS部署的基本要求。|
|**2025-10-03**|[Fine-tuning LLMs with variational Bayesian last layer for high-dimensional Bayesian optimization](http://arxiv.org/abs/2510.01471)|null|众多应用涉及求解具有高昂评估成本的黑盒优化问题，包括药物发现、材料设计以及超参数调优。为了以样本高效的方式找到此类黑盒优化问题的全局最优解，贝叶斯优化（BO）是一个理论上优雅的框架，它依赖于一个概率代理模型，以便迭代地选择具有良好平衡的探索-利用权衡的查询点。高斯过程（GP）作为代理建模的事实标准选择，在处理低维连续变量的传统BO方面取得了令人信服的性能。然而，GP在处理具有不规则变量（例如，分类、序数等）的高维对应物时表现不足。为了缓解这个问题，研究人员探索了基于神经网络的代理模型。受LLM强大能力的启发，我们采用LLM作为代理模型来建模从高维输入变量到目标函数的映射。为了适应当前问题，我们利用低秩适应（LoRA）通过变分贝叶斯最后一层（VBLL）框架来微调LLM参数以及线性回归头部的后验。所得到的LoRA-VBLL与现有替代方案相比不仅计算开销小，而且支持递归更新。为了自动化LoRA秩以及其他超参数的关键选择，我们设计了一个LoRA-VBLL代理模型的加权集成（ENS），该集成通过递归贝叶斯进一步支持每个模型的权重和单个LoRA-VBLL参数的持续更新。广泛的实验结果证明了所提出的（ENS-）LoRA-VBLL方法在各种高维基准测试和真实世界的分子优化任务上都取得了令人信服的性能。|
|**2025-10-01**|[Fine-tuning LLMs with variational Bayesian last layer for high-dimensional Bayesian optimzation](http://arxiv.org/abs/2510.01471)|null|大量应用涉及解决具有高评估成本的黑盒优化问题，包括药物发现、材料设计以及超参数调优。为了以样本效率寻找这类黑盒优化问题的全局最优解，贝叶斯优化 (BO) 是一种理论上优雅的框架，它依赖于概率代理模型，以迭代方式选择具有良好平衡探索-利用权衡的查询点。高斯过程 (GP) 作为代理建模的事实选择，在处理低维连续变量的传统BO方面取得了令人瞩目的性能。然而，GP在应对具有不规则变量（例如分类变量、序数变量等）的高维对应问题时表现不佳。为了缓解这一问题，基于神经网络的代理模型已被探索。受大型语言模型 (LLMs) 强大能力的启发，我们采用LLM作为代理模型来建模从高维输入变量到目标函数的映射。为了适应当前问题，我们利用低秩适应 (LoRA) 通过变分贝叶斯最后一层 (VBLL) 框架，微调LLM参数并结合线性回归头部的后验。所得的LoRA-VBLL与现有替代方案相比，不仅计算开销小，而且支持递归更新。为了自动化LoRA秩以及其他超参数的关键选择，我们设计了一种LoRA-VBLL代理模型的加权集成 (ENS)，它通过递归贝叶斯进一步适应了每个模型的权重以及单独LoRA-VBLL参数的持续更新。大量实验结果表明，所提出的 (ENS-)LoRA-VBLL方法在各种高维基准测试和真实世界的分子优化任务中展现出令人瞩目的性能。|
|**2025-10-01**|[Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving](http://arxiv.org/abs/2510.01126)|null|大型视觉-语言模型（VLM）越来越多地用于自动驾驶汽车（AV）堆栈中，但幻觉限制了它们在安全关键型管道中的可靠性。我们提出了一种采用Shapley信用分配、上下文感知且考虑一致性的Dawid-Skene方法，这是一种用于主视角行车记录仪视频多标签理解的博弈论融合方法。它从标注历史数据中学习每个模型、每个标签、上下文条件下的可靠性，并在推理时，将每个模型的报告转换为一种由一致性保障的对数似然比，该比值结合了上下文先验和通过基于Shapley的团队信用更新的公共声誉状态。结果是经过校准、可设阈值的后验概率，它们（i）放大可靠模型之间的一致性，（ii）保留单个模型独有的正确信号，以及（iii）适应漂移。为了使通用VLM专业化，我们通过一个自动管道整理了1000个真实世界的行车记录仪视频片段，并带有结构化标注（场景描述、驾驶操作建议、理由），该管道融合了HDD真值、车辆运动学和YOLOv11 + BoT-SORT跟踪，并在三步思维链提示的指导下进行；然后使用LoRA对三个异构VLM进行微调。我们使用汉明距离、微观-宏观F1和每个视频的平均延迟进行评估。经验上，与最佳单一模型相比，所提出的方法在汉明距离上实现了23%的减少，在宏观F1上提高了55%，在微观F1上提高了47%，这支持了VLM融合作为AV管道中一个经过校准、可解释且鲁棒的决策支持组件。|
|**2025-10-01**|[Family Matters: Language Transfer and Merging for Adapting Small LLMs to Faroese](http://arxiv.org/abs/2510.00810)|null|我们研究了如何将小型高效的大语言模型适应到法罗语这种低资源北日耳曼语。我们从英语模型开始，在相关斯堪的纳维亚语种上继续进行预训练，无论是单独进行还是通过合并结合进行，然后在法罗语上进行微调。我们比较了全量微调与使用LoRA的参数高效微调，评估了它们对语言准确性和文本理解能力的影响。由于缺乏现有的法罗语评估数据，我们从改编和新收集的数据集中构建了两个新的最小对基准，并辅以法罗语语言学家的专家人工评估。我们的结果表明，从相关语言进行迁移至关重要，尽管最佳源语言取决于任务：冰岛语能提高语言准确性，而丹麦语则能增强理解能力。类似地，全量微调和LoRA之间的选择也取决于任务：LoRA提升了语言可接受性并略微提高了基础模型的人工评估分数，而全量微调则产生了更强的理解性能，并在下游微调过程中更好地保留了模型能力。|
|**2025-10-01**|[Facilitating Cognitive Accessibility with LLMs: A Multi-Task Approach to Easy-to-Read Text Generation](http://arxiv.org/abs/2510.00662)|null|简化复杂文本对于确保公平获取信息至关重要，特别是对于认知障碍人士。易读文本（ETR）倡议提供了一个框架，使内容对神经多样性人群可访问，但此类文本的手动创建仍然耗时且资源密集。在这项工作中，我们研究了大型语言模型（LLMs）自动化生成易读文本（ETR）内容的潜力。为了解决对齐语料库稀缺以及易读文本（ETR）约束的特殊性问题，我们提出了一种多任务学习（MTL）方法，该方法在文本摘要、文本简化和易读文本（ETR）生成上联合训练模型。我们探索了两种不同的策略：用于上下文学习的多任务检索增强生成（RAG），以及用于参数高效微调的MTL-LoRA。我们基于新的高质量数据集ETR-fr，使用Mistral-7B和LLaMA-3-8B进行的实验表明，在所有配置下，多任务设置相对于单任务基线具有优势。此外，结果显示，基于RAG的策略能够在域外设置中实现泛化，而MTL-LoRA在域内配置中优于所有学习策略。|
|**2025-10-01**|[Flow of Knowledge: Federated Fine-Tuning of LLMs in Healthcare under Non-IID Conditions](http://arxiv.org/abs/2510.00543)|null|大型语言模型（LLM）在医疗健康领域展现出巨大潜力，但其应用受到数据隐私限制和跨机构协作挑战的阻碍。敏感医疗数据无法集中化，而跨机构的非独立同分布（non-IID）特性进一步加剧了收敛性和公平性的复杂性。为解决这些问题，我们提出了一种基于低秩适应（LoRA）的联邦微调方法，实现了跨机构的隐私保护知识流。该方法迭代地结合局部LoRA适应与全局参数聚合，实现了高效的知识共享而不暴露原始数据。在这种分布式网络中，区块链身份方案用于识别独立的LLM。我们在异构且高度非独立同分布的医疗文本数据集上评估了这种方法，实验表明，联邦LoRA不仅增强了跨客户端泛化能力，而且提高了最弱客户端的性能，实现了稳定的收敛和更公平的结果。这些发现强调了联邦LoRA微调作为一种实用有效的范式，用于在医疗健康领域适应LLM，为多中心医疗AI协作提供了新途径。|
|**2025-09-30**|[Efficient Layer-wise LLM Fine-tuning for Revision Intention Prediction](http://arxiv.org/abs/2510.00268)|null|大语言模型（LLMs）在各种文本生成任务中取得了非凡的成功；然而，它们在简单但重要的文本分类方面的潜力仍未得到充分探索，因为LLM预训练倾向于强调生成而非分类。尽管通过指令微调的LLMs可以将分类任务转化为生成任务，但它们常常难以对细微文本进行分类。一个这样的例子是文本修订，它涉及文本对之间细微的编辑。虽然仅仅对LLM进行修订分类的微调似乎可行，但这需要大量的修订标注，而这些标注在社区中极其昂贵且稀缺。为了解决这个问题，我们引入了一个即插即用的层级参数高效微调（PEFT）框架，即IR-Tuning，它微调LLM中一部分重要的层，这些层是根据它们的梯度范数分布动态选择的，同时冻结冗余层的参数。大量实验表明，IR-Tuning在各种文本修订任务上超越了几个层级PEFT基线，同时实现了快速收敛、低GPU内存消耗以及在小型修订语料库上的有效性。|
|**2025-09-30**|[DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems](http://arxiv.org/abs/2510.00229)|null|将大语言模型（LLM）部署为智能体编排器彻底改变了任务自动化，但对隐私保护、经济高效解决方案的需求要求具备设备端推理能力。然而，在工具调用场景中，本地LLM相比前沿模型表现持续不佳，在从大型工具集中选择工具以及为复杂参数结构准确生成参数方面都面临困难。我们提出了一种方法，将工具调用任务分解为两个不同的子任务：工具选择和参数生成。我们提出了“解耦微调”，这是一种新颖的后训练方法，它采用LoRA微调，通过为每个子任务使用单独的损失掩码，为工具选择和针对特定工具的参数生成创建专用的LoRA适配器。此外，我们提出了DualTune，这是一个推理框架，它利用通过解耦微调创建的LoRA适配器，借助终端用户设备上的本地模型执行高效的智能体编排。DualTune将工具调用生成步骤分解为工具选择和参数生成，并动态加载相应的LoRA适配器来生成工具调用。此外，DualTune还实现了分层编排，以限制工具选择所需的工具数量。我们在MCP-Bench基准上的实验表明，使用解耦微调训练的Qwen-2.5-7B模型将基础模型的工具调用准确率提高了46%，并且在所有情况下都优于其他规模相似的本地推理、非推理和微调模型，在大多数情况下也优于大2倍的模型。|
|**2025-09-30**|[LoRAFusion: Efficient LoRA Fine-Tuning for LLMs](http://arxiv.org/abs/2510.00206)|**[link](https://github.com/CentML/lorafusion)**|低秩适配（LoRA）已成为大语言模型（LLMs）领先的参数高效微调（PEFT）方法，因为它在显著减少GPU内存使用的同时，仍能在下游任务中保持有竞争力的微调模型质量。尽管有这些优势，我们发现了现有LoRA微调系统中的两个主要低效之处。首先，由于对大型激活张量的冗余内存访问，它们引入了大量的运行时开销。其次，它们错失了在同一组GPU上并行微调多个共享相同基模型的独立LoRA适配器的机会，这导致性能提升的丧失，例如减少流水线气泡、更好的通信重叠和改进的GPU负载均衡。为了解决这些问题，我们引入了LoRAFusion，一个针对LLMs的高效LoRA微调系统。在内核层面，我们提出了一种图分割方法，该方法融合了内存密集型操作。这种设计消除了不必要的内存访问，并保持了计算密集型GEMM的性能，而无需承担重新计算或同步的开销。在调度层面，LoRAFusion引入了一种自适应批处理算法用于多任务微调。它首先将LoRA适配器分成组，以有意错开跨任务的批处理执行，然后解决每组内的装箱问题，以生成平衡的、依赖感知的微批次。相比Megatron-LM，LoRAFusion实现了高达1.96倍（平均1.47倍）的端到端加速，相比最先进的多LoRA微调系统mLoRA，性能提升高达1.46倍（平均1.29倍）。我们融合的内核实现了高达1.39倍（平均1.27倍）的内核性能提升，并且可以直接作为现有LoRA系统中的即插即用替代方案。我们已在https://github.com/CentML/lorafusion开源了LoRAFusion。|
|**2025-09-30**|[Commmunication-Efficient and Accurate Approach for Aggregation in Federated Low-Rank Adaptation](http://arxiv.org/abs/2509.26399)|null|随着基础模型的迅速兴起以及在分布式环境中进行微调的需求日益增长，联邦低秩适应（FedLoRA）最近获得了广泛关注。尽管潜力巨大，但当前的FedLoRA方法由于不精确更新而面临显著挑战。现有方法试图缓解这个问题，但它们往往引入了局部-全局泛化鸿沟并产生巨大的通信开销，限制了它们的可扩展性和有效性。为了解决这些局限性，我们提出了联邦低秩聚合与近似精确估计（FLoRA-NA）。FLoRA-NA利用服务器上的局部LoRA矩阵来估计聚合矩阵 $\hat{A}$和$\hat{B}$，然后将其分发给客户端进行局部更新。这种替代的聚合矩阵在不增加超出传统FedLoRA通信成本的情况下，最小化了理想更新$\nabla \Bar{W} = \sum^{U}_{u=1}B_u A_u$与实际更新$\nabla \hat{W} = \hat{B}\hat{A}$ 之间的差异。通过这样做，FLoRA-NA实现了通信效率，并弥合了局部个性化与全局泛化之间的鸿沟，解决了先前个性化FedLoRA方法的一个关键局限性。我们使用各种基础模型，在自然语言理解、数学推理和代码求解能力等多样化任务上进行了广泛评估。实验结果一致表明，FLoRA-NA在保持低通信开销的同时，实现了最先进的全局性能。|
|**2025-09-30**|[Adapting SAM with Dynamic Similarity Graphs for Few-Shot Parameter-Efficient Small Dense Object Detection: A Case Study of Chickpea Pods in Field Conditions](http://arxiv.org/abs/2509.25805)|null|基础模型在农业计算机视觉任务中的参数高效微调（PEFT）由于训练数据有限和复杂的田间条件而仍然具有挑战性。本研究引入了一种基于动态相似性的图适应（DSGA）模块，以在极端数据限制下适应Segment Anything Model（SAM），从而在复杂农业环境中对小型密集物体进行精确的前景和实例分割。通过构建动态相似图，结合可学习的多项式衰减初始化权重排序机制和自适应局部特征聚合，DSGA仅用4.00M可训练参数（占原始SAM的4.26%）建立了鲁棒的空间和动态相似性表示。将这种基于图的特征适应与低秩适应（LoRA）相结合，创建了一个互补的优化框架，该框架有效地捕获了图像嵌入中的局部和全局依赖关系，同时保持了模型的稳定性和参数效率。在具有挑战性的鹰嘴豆荚数据集上的实验结果表明，DSGA与LoRA在2、4、8和10次样本设置下评估的多个指标上均取得了卓越性能，并且随着样本数量的增加，性能增益逐步提高。定量指标显示，与基线SAM微调相比，结构度量（Structure-measure）提高了17.31%，自适应F度量（adaptive F-measure）提高了62.36%。通过Grad-CAM和t-SNE进行的全面消融研究和可视化分析验证了该框架在特征判别方面的有效性。所提出的适应方法展示了自动化农业监测应用的实际价值，在具有挑战性的田间条件下，对于包含10到120个豆荚的图像，实现了准确的豆荚计数，调整后的R平方为0.8987。|
|**2025-09-30**|[HNote: Extending YNote with Hexadecimal Encoding for Fine-Tuning LLMs in Music Modeling](http://arxiv.org/abs/2509.25694)|null|大语言模型（LLMs）的最新进展为符号音乐生成创造了新的机遇。然而，MIDI、ABC和MusicXML等现有格式要么过于复杂，要么结构不一致，限制了它们在基于token的学习架构中的适用性。为解决这些挑战，我们提出了HNote，一种从YNote扩展而来的新型基于十六进制的记谱系统，它在一个固定的32单位小节框架内编码音高和时长。这种设计确保了对齐，减少了歧义，并与LLM架构直接兼容。我们将12,300首源自传统民乐曲目的江南风格歌曲从YNote转换为HNote，并利用参数高效的LoRA对LLaMA-3.1(8B)进行了微调。实验结果表明，HNote实现了82.5%的句法正确率，且BLEU和ROUGE评估显示出强大的符号和结构相似性，从而生成了风格连贯的乐曲。本研究将HNote确立为一种将LLMs与文化音乐建模相结合的有效框架。|
|**2025-09-30**|[LD-MoLE: Learnable Dynamic Routing for Mixture of LoRA Experts](http://arxiv.org/abs/2509.25684)|null|近期研究表明，将参数高效微调 (PEFT) 与专家混合 (MoE) 结合，是使大型语言模型 (LLMs) 适应下游任务的一种有效策略。然而，大多数现有方法依赖于传统的 TopK 路由，这需要仔细的超参数调优，并为每个 token 分配固定数量的专家。在这项工作中，我们提出了 LD-MoLE，这是一种用于 LoRA 专家混合的可学习动态路由机制，它能够实现自适应、与 token 相关和层级的专家分配。我们的方法用可微分的路由函数和闭式解取代了不可微分的 TopK 选择。此外，我们的设计允许模型自适应地确定不同层中每个 token 需要激活的专家数量。此外，我们引入了一个分析性稀疏性控制目标，用于规范激活专家的数量。在 Qwen3-1.7B 和 Llama-3.2-3B 模型上进行的广泛实验表明，与最先进的基线相比，LD-MoLE 在各种基准测试中取得了最高的平均分数。我们的方法不仅实现了卓越的性能，而且还展示了学习与 token 相关和层级专家分配的能力。|
|**2025-09-29**|[Rethinking Parameter Sharing for LLM Fine-Tuning with Multiple LoRAs](http://arxiv.org/abs/2509.25414)|**[link](https://github.com/OptMN-Lab/ALoRA)**|大语言模型常使用低秩适应（LoRA）等参数高效技术进行适配，其公式表示为 $y = W_0x + BAx$，其中 $W_0$ 是预训练参数，$x$ 是适配层的输入。尽管多适配器扩展通常采用多个LoRA，但先前研究表明，在训练过程中，内部 $A$ 矩阵高度相似，因此适合共享。我们重新审视这一现象，发现这种相似性主要归因于相同的初始化而非共享知识，而 $B$ 在知识编码和迁移中扮演更关键的角色。受这些洞察的启发，我们提出ALoRA，这是一种在多任务微调中具有多个 $A$ 矩阵和单个共享 $B$ 的非对称多LoRA设计，以及Fed-ALoRA，它通过一种新颖的矩阵分解策略在同构和异构设置下的联邦微调中跨客户端共享 $B$ ，以适应客户端间异构的秩。在常识推理、数学推理、多任务自然语言处理数据集和联邦自然语言处理数据集上的实验表明，我们的方法相对于现有LoRA方法实现了任务间更平衡的性能，并取得了相当或更优的平均准确率。代码可在 https://github.com/OptMN-Lab/ALoRA 获取。|
|**2025-09-29**|[MMRQA: Signal-Enhanced Multimodal Large Language Models for MRI Quality Assessment](http://arxiv.org/abs/2509.24888)|null|磁共振成像（MRI）质量评估对临床决策至关重要，但由于数据稀缺性和协议变异性，其仍面临挑战。传统方法存在根本性权衡：MRIQC等基于信号的方法提供定量指标但缺乏语义理解，而深度学习方法虽实现高准确性但牺牲了可解释性。为解决这些局限性，我们引入了多模态MRI质量评估（MMRQA）框架，开创性地将多模态大语言模型（MLLMs）与采集感知信号处理相结合。MMRQA结合了三项关键创新：通过MRQy增强模拟伪影实现鲁棒指标提取；使用Qwen将指标结构化转换为问答对；以及通过LLaVA-OneVision的低秩适应（LoRA）实现参数高效融合。在MR-ART、FastMRI和MyConnectome基准上进行评估，MMRQA通过全面的消融研究验证，实现了最先进的性能和强大的零样本泛化能力。通过连接定量分析与语义推理，我们的框架生成了临床可解释的输出，从而增强了动态医疗环境中的质量控制。|
|**2025-09-29**|[Vision Function Layer in Multimodal LLMs](http://arxiv.org/abs/2509.24791)|null|本研究发现，视觉相关功能解码在多模态大语言模型（MLLMs）的不同解码器层中分布。通常，每个功能，例如计数、定位或OCR识别，会集中在两到三个层中，我们将其定义为视觉功能层（VFL）。此外，不同VFL的深度及其顺序在不同的MLLMs中呈现出一致的模式，这与人类行为高度一致（例如，识别先发生，然后是计数，最后是定位）。这些发现来源于视觉令牌交换（Visual Token Swapping），我们新颖的分析框架修改目标KV缓存条目，以精确阐明解码过程中层特有的功能。此外，这些见解在为实际下游应用定制MLLMs方面提供了巨大的实用价值。例如，当LoRA训练被选择性地应用于功能与训练数据对齐的VFL时，VFL-LoRA不仅优于全LoRA，而且还能防止域外功能遗忘。此外，通过分析当特定VFL被消融时训练数据上的性能差异，VFL-select能根据功能自动对数据进行分类，从而实现高效的数据选择，以直接增强相应能力。因此，VFL-select在数据选择方面超越了人类专家，并以仅20%的原始数据集实现了全数据性能的98%。本研究深化了对MLLM视觉处理的理解，促进了创建更高效、可解释和鲁棒的模型。|
|**2025-09-29**|[Stable Forgetting: Bounded Parameter-Efficient Unlearning in LLMs](http://arxiv.org/abs/2509.24166)|null|大语言模型(LLM)中的机器遗忘对隐私和安全至关重要；然而，现有方法仍不稳定且不可靠。一种广泛使用的策略，即梯度差分法，对保留数据执行梯度下降，同时对遗忘数据（即应移除其影响的数据）执行梯度上升。然而，当与交叉熵损失结合时，这种过程会导致权重和梯度的无界增长，从而导致训练不稳定并损害遗忘和保留性能。我们提出了一个理论框架来解释这种失效，明确展示了遗忘集上的梯度上升如何破坏LLM前馈多层感知机(MLP)层的优化稳定性。受此启发，我们提出了有界参数高效遗忘，这是一种参数高效的方法，通过对MLP适配器应用有界函数来稳定基于LoRA的微调。这一简单的修改控制了梯度上升过程中的权重动态，使梯度差分法能够可靠收敛。在TOFU、TDEC和MUSE基准测试中，以及跨越从1.25亿到80亿参数的不同架构和规模，我们的方法在遗忘方面取得了显著改进，同时保持了保留性能，为LLM中的机器遗忘建立了一个新颖的、有理论基础且实际可扩展的框架。|
|**2025-09-28**|[PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM](http://arxiv.org/abs/2509.24085)|null|我们提出了PEARL（通过设备端大语言模型实现同伴增强的自适应无线电），一个用于设备到设备（D2D）通信中协作式跨层优化的框架。基于我们之前在单设备端大语言模型方面的工作，PEARL通过利用发布者和订阅者状态来指导Wi-Fi Aware（WA）参数选择，从而扩展了这一范式。一个上下文感知奖励，它根据应用容忍度归一化延迟并根据设备电池状态调整能量，为基于KL的微调提供了更丰富的监督。我们研究了两种轻量级变体：PEARL（头部+低秩适应（LoRA））实现了最佳的整体性能，而PEARL-Lite（仅头部）在几乎相同的目标分数下实现了低于20毫秒的推理。在基于真实测量的合成场景中，PEARL相对于启发式和紧凑模型基线提高了目标分数，并在协作式低电量情况下将能耗降低了高达16%。这些结果表明，同伴感知上下文、奖励对齐训练和基于头部的效率使大语言模型在常开的设备端跨层控制中变得实用。|
|**2025-09-28**|[ByteSized32Refactored: Towards an Extensible Interactive Text Games Corpus for LLM World Modeling and Evaluation](http://arxiv.org/abs/2509.23979)|null|模拟交互式世界模型仍然是大语言模型（LLMs）中的一个核心挑战。在这项工作中，我们引入了ByteSized32Refactored，它是对原始ByteSized32语料库进行重构、模块化和可扩展的实现，旨在探索文本游戏生成任务。我们进一步优化了每个文本游戏的代码结构，并创建了GameBasic.py基础库，该库通过将7个基类（如GameObject等）抽象为可重用模块，集中了所有32个游戏的通用逻辑，从而与原始的Bytesized32相比，将Python代码总行数从2万行减少到1万行。我们重构的实现实现了可扩展性——凭借我们集中化的设计，ByteSized32Refactored可以通过重用共享逻辑和功能，更高效地扩展以包含新场景和新规格的文本游戏。使用GPT-4o进行的广泛实验显示出混合的性能——使用Bytesized32Refactored，为未见过场景生成的文本游戏在四个评估维度中的两个上显示出质量改进，而在另外两个上有所下降，这表明重构代码的层次结构给LLMs带来了新的挑战。总的来说，我们强调我们以基础库和模块化优化为中心的可扩展代码结构，不仅促进了LLM对环境规范的适应，而且建立了一个支持未来扩展的可扩展环境。|
|**2025-09-26**|[AxLLM: accelerator architecture for large language models with computation reuse capability](http://arxiv.org/abs/2509.22512)|null|大语言模型需要巨大的计算能力和内存资源，这对高效部署带来了巨大的挑战。尽管量化已被广泛探索以减小模型尺寸和计算量，但本文论证了一个额外的好处：量化增加了参数局部性，为计算复用创造了机会。基于这一洞察，我们提出了AxLLM，一种专为量化模型设计的硬件加速器架构。AxLLM引入了一种新颖的冗余消除技术，该技术缓存并复用重复权重值的乘法结果，大幅减少了冗余操作。该架构具有双重乘法与复用流水线，无需修改参数、重新训练或离线预处理，即可有效支持基础模型和LoRA微调模型。实验结果表明，AxLLM的计算量减少高达90%，能耗降低28%，相较于基线执行实现了1.7倍的加速。这些结果突出了AxLLM是用于在专用硬件上加速大语言模型的一种可扩展且高效的解决方案。|
|**2025-09-26**|[Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting](http://arxiv.org/abs/2509.22195)|null|在机器人远程操作数据上微调视觉-语言模型（VLM）以创建视觉-语言-动作（VLA）模型是训练通用策略的一种有前景的范式，但它存在一个根本性权衡：学习生成动作常常削弱VLM的基础推理和多模态理解能力，阻碍其泛化到新颖场景、遵循指令和语义理解。我们认为这种灾难性遗忘是由于VLM的互联网规模预训练语料库与机器人微调数据之间存在分布不匹配造成的。受此观察启发，我们引入了VLM2VLA：一种VLA训练范式，它首先在数据层面通过用自然语言表示低级动作来解决这种不匹配。这种对齐使得训练VLA仅使用低秩适应（LoRA）成为可能，从而最大限度地减少对VLM骨干的修改并避免灾难性遗忘。结果是，VLM可以在机器人远程操作数据上进行微调，而无需根本性地改变底层架构，也无需在互联网规模的VLM数据集上进行昂贵的协同训练。通过广泛的视觉问答（VQA）研究和800多次真实世界机器人实验，我们证明VLM2VLA保留了VLM的核心能力，从而实现对需要开放世界语义推理和多语言指令遵循的新颖任务的零样本泛化。|
|**2025-09-26**|[Task-Adaptive Parameter-Efficient Fine-Tuning for Weather Foundation Models](http://arxiv.org/abs/2509.22020)|null|机器学习的最新进展为天气基础模型 (WFMs) 赋予了在各种下游任务中强大的泛化能力，但其规模扩大带来的计算需求不断增长，日益阻碍了实际部署。当前的参数高效微调 (PEFT) 方法专为视觉或语言任务设计，未能解决天气下游任务的独特挑战，例如变量异构性、分辨率多样性和时空覆盖变化，导致应用于 WFMs 时性能次优。为了弥合这一差距，我们提出了 WeatherPEFT，这是一种新颖的适用于 WFMs 的 PEFT 框架，结合了两种协同创新。首先，在前向传播过程中，任务自适应动态提示 (TADP) 通过内部和外部模式提取，将编码器内部的嵌入权重动态注入到预训练主干网络的输入标记中，从而实现针对特定下游任务的上下文感知特征重校准。此外，在反向传播过程中，随机费雪引导自适应选择 (SFAS) 不仅利用费雪信息来识别和更新最关键的任务参数，从而保留不变的预训练知识，而且引入了随机性以稳定选择过程。我们在三个下游任务上展示了 WeatherPEFT 的有效性和效率，在这些任务中，现有 PEFT 方法与完全微调 (Full-Tuning) 相比存在显著差距，而 WeatherPEFT 使用更少的训练参数实现了与完全微调相当的性能。本工作的代码将发布。|
|**2025-09-26**|[Enhancing Low-Rank Adaptation with Structured Nonlinear Transformations](http://arxiv.org/abs/2509.21870)|null|低秩适配 (LoRA) 是一种广泛应用于大语言模型的参数高效微调方法。然而，其线性本质限制了表达能力。我们提出了 LoRAN，它是 LoRA 的一种非线性扩展，将轻量级变换应用于低秩更新。我们进一步引入了 Sinter，它是一种基于正弦的激活函数，可在不增加参数数量的情况下增加结构化扰动。在文本摘要和分类任务中的实验表明，LoRAN 始终优于 QLoRA。消融研究揭示 Sinter 优于 Sigmoid、ReLU 和 Tanh 等标准激活函数，强调了激活函数设计在低秩微调中的重要性。|
|**2025-09-25**|[MORPH: Shape-agnostic PDE Foundation Models](http://arxiv.org/abs/2509.21670)|null|我们引入了MORPH，一个形状无关的、自回归的偏微分方程（PDEs）基础模型。MORPH建立在卷积视觉Transformer骨干网络之上，能够无缝处理具有不同数据维度（1D-3D）、不同分辨率、以及具有混合标量和矢量分量的多个场的异构时空数据集。该架构结合了（i）分量级卷积，它联合处理标量和矢量通道以捕获局部相互作用；（ii）场间交叉注意力，它在不同物理场之间建模并选择性地传播信息；（iii）轴向注意力，它沿单独的空间和时间轴分解完整的时空自注意力，从而在保持表达能力的同时减少计算负担。我们在一系列多样化的异构PDE数据集上预训练了多个模型变体，并评估了其在各种下游预测任务上的迁移能力。通过全模型微调和参数高效的低秩适配器（LoRA），MORPH在零样本和全样本泛化方面均优于从头开始训练的模型。在广泛的评估中，MORPH达到或超越了强大的基线模型和最新的最先进模型。总的来说，这些能力为从科学观测的异构和多模态性质中学习提供了一个灵活而强大的骨干网络，为可扩展且数据高效的科学机器学习开辟了一条道路。|
|**2025-09-25**|[Explaining Fine Tuned LLMs via Counterfactuals A Knowledge Graph Driven Framework](http://arxiv.org/abs/2509.21241)|null|低秩适应（LoRA）的广泛采用使得大型语言模型（LLMs）能够以显著的效率获取领域特定知识。然而，理解这种微调机制如何改变模型的结构化推理和语义行为仍然是一个开放性挑战。本工作引入了一个新颖的框架，通过基于知识图谱的反事实来解释微调后的LLMs。具体而言，我们构建了BioToolKG，这是一个生物信息学工具领域的特定异构知识图谱，并设计了一个基于反事实的微调LLMs解释器（CFFTLLMExplainer），该解释器学习图节点和边上的软掩码，以生成最小的结构扰动，从而引起最大的语义分歧。我们的方法联合优化了结构稀疏性和语义分歧，同时施加了保持可解释性的约束，例如熵正则化和边平滑性。我们将此框架应用于一个基于LLaMA的微调LLM，并揭示反事实掩码暴露了模型的结构依赖性，并与LoRA引起的参数偏移对齐。这项工作为微调LLMs的内部机制提供了新见解，并强调反事实图是可解释人工智能的潜在工具。|
|**2025-09-25**|[SiNGER: A Clearer Voice Distills Vision Transformers Further](http://arxiv.org/abs/2509.20986)|null|视觉Transformer被广泛用作视觉基础模型的主干网络，但已知它们会产生降低表示质量的高范数伪影。当知识蒸馏将这些特征传递给学生模型时，高范数伪影主导了目标函数，导致学生模型过度拟合伪影并低估了信息丰富的信号，从而削弱了从更大模型中获得的收益。先前工作曾尝试去除伪影，但在伪影抑制和保留教师模型的信息信号之间遇到了一个固有的权衡。为了解决这个问题，我们引入了奇异零空间引导的能量重分配 (SiNGER)，这是一种新颖的蒸馏框架，能够在抑制伪影的同时保留信息信号。其核心思想是原则性的教师特征精炼：在精炼过程中，我们利用零空间引导的扰动，在抑制伪影的同时保留信息。随后，精炼后的教师特征被蒸馏到学生模型。我们使用基于LoRA的适配器高效实现了这一扰动，仅需要最小的结构修改。大量实验表明，SiNGER持续改进了学生模型，在多个下游任务中取得了最先进的性能，并产生了更清晰、更可解释的表示。|
|**2025-09-25**|[MemLens: Uncovering Memorization in LLMs with Activation Trajectories](http://arxiv.org/abs/2509.20909)|null|大语言模型（LLMs）通常在AIME和Math500等具有挑战性的基准上进行评估，这些基准容易受到数据污染并存在模型记忆的风险。现有的检测方法主要依赖于表面词汇重叠和困惑度，泛化能力较差，在遇到隐式污染数据时会显著退化。在本文中，我们提出了MemLens（一种用于记忆检测的激活透镜），通过分析生成过程中数字标记的概率轨迹来检测模型记忆。我们的方法揭示，污染样本表现出“捷径”行为，在模型的早期层中以高置信度锁定答案，而干净样本则在模型的整个深度中显示出更渐进的证据积累。我们观察到，污染样本和干净样本表现出明显且良好分离的推理轨迹。为了进一步验证这一点，我们通过LoRA微调将精心设计的样本注入模型，并观察到与自然污染数据中相同的轨迹模式。这些结果提供了强有力的证据，表明MemLens捕获了真正的记忆信号而非虚假关联。|
|**2025-09-25**|[DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation](http://arxiv.org/abs/2509.20792)|null|视觉-语言模型（VLMs）是自动驾驶、医疗诊断和内容审核等关键应用的基础。虽然像LoRA这样的参数高效微调（PEFT）方法使其能够高效适应专业任务，但这些模型仍然容易受到可能危及安全关键决策的对抗性攻击。CLIP作为众多下游VLM的骨干模型，是一个高价值目标，其脆弱性可能在多模态AI生态系统中产生连锁反应。我们提出了动态对抗课程DAC-LoRA，这是一个将对抗训练整合到PEFT中的新颖框架。我们方法的核心原理，即逐步增强攻击难度的智能课程，具有通用性，并可潜在地应用于任何迭代攻击方法。在第一阶平稳条件（FOSC）和受TRADES启发的损失函数的指导下，DAC-LoRA在对抗鲁棒性方面取得了显著提升，而没有显著损害干净准确性。我们的工作提出了一种有效、轻量且广泛适用的方法，旨在证明DAC-LoRA框架可以轻松集成到标准PEFT流程中以显著增强鲁棒性。|
|**2025-09-25**|[SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](http://arxiv.org/abs/2509.20758)|null|有监督微调（SFT）在领域特定数据集上是使大语言模型（LLMs）适应专门任务的常用方法，但通常认为这会损害其通用能力。在这项工作中，我们重新审视了这种权衡，并提出了经验和理论见解。首先，我们表明SFT并非总是有害：使用较小的学习率可以大幅缓解通用性能下降，同时保持可比的目标领域性能。随后，我们提供了一项理论分析，解释了这些现象，并进一步推动了一种新方法——词元自适应损失重加权（TALR）。在此基础上，鉴于仅靠较小的学习率并不能完全消除所有情况下的通用性能下降，我们评估了一系列减少通用能力损失的策略，包括L2正则化、LoRA、模型平均、FLOW以及我们提出的TALR。实验结果表明，虽然没有哪种方法能完全消除这种权衡，但TALR在平衡领域特定收益和通用能力方面始终优于这些基线方法。最后，我们将研究结果提炼成将大语言模型适应到新领域的实用指南：(i) 使用较小的学习率以实现有利的权衡；(ii) 当需要更强的平衡时，采用TALR作为一种有效策略。|
|**2025-09-24**|[TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios](http://arxiv.org/abs/2509.19834)|null|中医领域特定大型语言模型在研究环境中面临适应性受限、评估数据集不足和计算资源有限等局限。本研究介绍了天汇（TianHui），一个通过上下文数据整合和领域知识融合构建的专门中医大型语言模型。我们构建了一个大规模中医语料库（包含0.97GB无监督数据和611,312个问答对），并采用了结合QLoRA、DeepSpeed Stage 2和Flash Attention 2的两阶段训练策略。在12个基准测试中的评估显示，天汇在六个数据集（APQ、TCMCD、HFR、HCCA、DHPE、TLAW）的所有指标上均位列前三，并在另外六个数据集（TCMEE、APR、GCPMI、TCMKQA、TCMRC、ADTG）中取得了领先结果。最佳配置被确定为LoRA秩=128，alpha=256，迭代周期=4，dropout=0.2，最大长度=2048。天汇实现了中医知识的系统化保存和可扩展应用。所有资源均已开源。|
|**2025-09-23**|[Analysis on distribution and clustering of weight](http://arxiv.org/abs/2509.19122)|**[link](https://github.com/sayantann11/all-classification-templetes-for-ML)**|大语言模型架构和参数特性的研究仍然是当前的热点。本文关注权重的特性，并以此分析模型之间的相关性和差异。提出了标准差向量和聚类向量两种向量来描述模型的特征。在第一种情况下，假设权重服从正态分布。将投影矩阵的标准差值进行归一化，形成标准差向量，用以表示模型的分布特性。在第二种情况下，从每个权重投影矩阵中提取奇异值，并通过K-Means算法进行分组。将同类型矩阵的分组数据组合成聚类向量，用以表示模型权重的相关特性。研究表明，这两种向量能有效区分不同模型，并清楚地显示同一系列模型之间的相似性。此外，在使用不同数据集和模型进行LoRA微调后发现，标准差向量表示的权重分布直接受数据集影响，但聚类向量表示的不同权重之间的相关性不受影响，并与预训练模型保持高度一致。|
|**2025-09-23**|[Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](http://arxiv.org/abs/2509.18942)|**[link](https://github.com/zzm-black/DEAL-Continuous-Low-Rank-Fine-Tuning)**|大语言模型（LLM）的最新进展强调了微调（FT）技术在使LLM适应特定任务中的关键作用，尤其是在从头开始重新训练在计算上不可行时。微调使LLM能够利用任务或领域特定数据，从而生成能更有效满足目标应用需求的模型。然而，传统的微调方法通常面临灾难性遗忘和次优数据效率的问题，这限制了它们的实际应用性。为解决这些挑战，本文提出DEAL，一个将低秩适应（LoRA）与连续微调策略相结合的新颖框架。通过引入知识保留和自适应参数更新模块，该框架缓解了现有微调方法的局限性，同时在隐私保护设置中保持了效率。在15个不同数据集上的实验表明，DEAL持续优于基线方法，在任务准确性和资源效率方面取得了显著提升。这些发现表明我们的方法通过提高任务性能同时提升资源效率，从而推动LLM中持续适应的潜力。|
|**2025-09-23**|[Memory in Large Language Models: Mechanisms, Evaluation and Evolution](http://arxiv.org/abs/2509.18868)|null|在统一操作定义下，我们将大语言模型（LLM）记忆定义为在预训练、微调或推理期间写入的持久状态，该状态随后可被寻址并稳定地影响输出。我们提出了一种四部分分类法（参数式、上下文式、外部式、程序式/情景式）和一个记忆四元组（位置、持久性、写入/访问路径、可控性）。我们通过“写入 -> 读取 -> 抑制/更新”链条将机制、评估和治理联系起来。为避免在异构设置中出现扭曲的比较，我们采用了一种三设置协议（仅参数式、离线检索、在线检索），该协议将能力与相同数据和时间线上的信息可用性解耦。在此基础上，我们构建了一个分层评估体系：参数式（闭卷回忆、编辑差异、记忆/隐私）、上下文式（位置曲线和序列中部下降）、外部式（答案正确性与片段归因/忠实度）以及程序式/情景式（跨会话一致性和时间线重放，E MARS+）。该框架集成了时间治理和泄露审计（新鲜度命中、过时答案、拒绝响应片段），并通过评估者间一致性以及带有多重比较校正的配对测试来报告不确定性。针对更新和遗忘，我们提出了DMM Gov：协调DAPT/TAPT、PEFT、模型编辑（ROME、MEND、MEMIT、SERAC）和RAG，以形成一个可审计的循环，涵盖准入阈值、部署、监控、回滚和变更审计，并明确了及时性、冲突处理和长期一致性的规范。最后，我们提出了四个可测试命题：最小可识别性；最小评估卡；具有可验证遗忘的因果约束编辑；以及小窗口重放检索何时优于超长上下文阅读。这为研究和部署提供了一个可复现、可比较、可治理的坐标系。|
|**2025-09-23**|[HyperAdapt: Simple High-Rank Adaptation](http://arxiv.org/abs/2509.18629)|null|基础模型在各种任务中表现出色，但将它们适应到专用应用通常需要微调，这种方法是内存和计算密集型的。参数高效微调（PEFT）方法通过仅更新一小部分权重来缓解这一问题。在本文中，我们引入了HyperAdapt，这是一种参数高效微调方法，与LoRA等最先进方法相比，它显著减少了可训练参数的数量。具体而言，HyperAdapt通过对预训练权重矩阵应用行向和列向缩放（通过对角矩阵）来适应模型，从而产生高秩更新，而对于一个 $n \times m$矩阵，仅需要$n+m$ 个可训练参数。理论上，我们建立了HyperAdapt更新的秩的上限，经验上，我们证实它在模型层中始终能产生高秩变换。在GLUE、算术推理和常识推理基准上，使用高达140亿参数的模型进行的实验表明，HyperAdapt的性能与完全微调和最先进的PEFT方法相当或接近，同时使用的可训练参数数量少了几个数量级。|
|**2025-09-22**|[SEQR: Secure and Efficient QR-based LoRA Routing](http://arxiv.org/abs/2509.18093)|null|低秩适配（LoRA）已成为大语言模型参数高效微调的标准技术，使得为特定任务或领域创建大型LoRA库成为可能。然而，对于给定输入如何有效选择正确的LoRA适配器仍然是一个挑战，尤其是在安全环境中，路由器的监督训练可能引发隐私问题。受先前方法的启发，我们将无监督LoRA路由的目标形式化为激活范数最大化，并为此提供了一个理论分析框架。我们证明了激活范数的鉴别能力，并引入了SEQR，这是一种旨在最大化效率同时提供严格路由保证的无监督LoRA路由算法。SEQR可证明地以显著更高的效率识别范数最大化适配器，使其成为动态LoRA组合的高度可扩展和有效的解决方案。我们通过实验验证了我们的结果，这些实验证明了多任务性能和效率的提升。|
|**2025-09-22**|[MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM](http://arxiv.org/abs/2509.17489)|null|大语言模型 (LLMs) 已将代码生成从单函数任务推进到编程竞赛问题，但现有的多智能体解决方案要么依赖于昂贵的大规模 (超过300亿参数) 模型，要么在缩小到小型开源模型时性能崩溃。我们提出了 MapCoder-Lite，它仅使用秩为32、特定于角色的LoRA适配器 (额外参数少于3%)，将一个70亿参数模型升级为四个角色专业化智能体：检索器、规划器、编码器和调试器。三种轻量级技术使其成为可能：(i) 从强大LLM中进行的轨迹蒸馏解决了检索和调试中的格式脆弱性问题；(ii) 监督者引导的纠正增强了规划和编码智能体；(iii) 智能体级别的LoRA微调实现了内存高效的专业化。在xCodeEval、APPS和CodeContests上的综合评估表明，MapCoder-Lite 将xCodeEval准确率提高了一倍以上 (从13.2%提升至28.3%)，消除了所有格式错误，并将与一个320亿参数基线的差距缩小到六个百分点之内，同时将GPU内存和令牌生成时间减少了四倍。这些结果表明，仔细的智能体级别微调在小型语言模型上释放了高质量的多智能体编码能力。|
|**2025-09-23**|[QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models](http://arxiv.org/abs/2509.17428)|null|大语言模型（LLMs）高效部署的需求推动了对量化（可降低推理成本）和参数高效微调（PEFT，可减少训练开销）的关注。这促使了量化感知型PEFT的开发，以生成准确而高效的量化模型。在这种背景下，在微调之前减少量化误差对于实现高模型精度至关重要。然而，现有依赖低秩适应的方法存在表示能力有限的问题。近期基于傅里叶相关变换（FT）的适配器比低秩适配器提供了更强的表示能力，但将其直接集成到量化模型中往往会导致误差减少效果不佳并增加计算开销。为了克服这些局限性，我们提出了QWHA，该方法通过采用Walsh-Hadamard变换（WHT）作为变换核，并结合一种新颖的适配器初始化方案（该方案包含自适应参数选择和值细化），将基于FT的适配器集成到量化模型中。我们证明了QWHA能有效缓解量化误差，同时便于微调，并且其设计大幅降低了计算成本。实验结果表明，QWHA在低比特量化精度方面持续优于基线方法，并相对于现有基于FT的适配器实现了显著的训练加速。代码已在https://github.com/vantaa89/qwha提供。|
|**2025-09-22**|[EpiCache: Episodic KV Cache Management for Long Conversational Question Answering](http://arxiv.org/abs/2509.17396)|null|大语言模型（LLMs）的近期进展扩展了上下文长度，使助手能够维持长对话历史，以生成连贯、个性化的回复。然而，这种能力依赖于键值（KV）缓存，其内存随对话长度线性增长，并在严格的资源限制下迅速占据主导地位。减少这种开销的一个活跃研究方向是KV缓存压缩，它旨在限制缓存大小同时保持准确性。然而，现有方法面临两个主要限制：(i) 在全上下文预填充后驱逐条目会导致无限制的峰值内存，以及 (ii) 依赖于查询的驱逐将缓存范围缩小到单个查询，导致多轮对话中准确性下降。我们引入了EpiCache，这是一个在固定内存预算下用于长对话问答（LongConvQA）的无需训练的KV缓存管理框架。EpiCache通过块级预填充限制缓存增长，并通过情景式KV压缩保留主题相关的上下文，该压缩将对话历史聚类成连贯的情景并应用情景特定的KV缓存驱逐。我们进一步设计了一种自适应的逐层预算分配策略，该策略衡量每个层对驱逐的敏感性，并相应地在各层之间分配内存预算。在三个LongConvQA基准测试中，EpiCache将准确性比近期基线提高了高达40%，在4-6倍压缩下保持接近完整的KV准确性，并将延迟和内存分别降低了高达2.4倍和3.5倍，从而在严格的资源限制下实现了高效的多轮交互。|
|**2025-09-21**|[Parameter-efficient fine-tuning (PEFT) of Vision Foundation Models for Atypical Mitotic Figure Classification](http://arxiv.org/abs/2509.16935)|null|非典型有丝分裂像（AMFs）是罕见的异常细胞分裂，与肿瘤侵袭性和不良预后相关。由于微妙的形态学线索、类别不平衡以及病理学家之间观察者间差异，它们的检测仍然是一个重大挑战。MIDOG 2025挑战赛引入了一个专门用于非典型有丝分裂分类的赛道，从而能够系统地评估深度学习方法。在本研究中，我们探索了使用大型视觉基础模型（包括Virchow、Virchow2和UNI），并结合低秩适应（LoRA）进行参数高效微调。我们通过不同LoRA秩以及随机和基于组的数据划分进行了大量实验，以分析在不同条件下的鲁棒性。我们的最佳方法是结合LoRA秩为8的Virchow模型和三折交叉验证集成，在初步测试集上实现了88.37%的平衡准确率，在挑战赛排行榜上并列第9位。这些结果突显了基础模型结合高效适应策略在非典型有丝分裂分类方面的潜力，同时也强调了在特异性和域泛化方面进行改进的必要性。|
|**2025-09-19**|[BEFT: Bias-Efficient Fine-Tuning of Language Models](http://arxiv.org/abs/2509.15974)|null|对所有偏置项进行微调在各种参数高效微调（PEFT）技术中脱颖而出，这归因于其开箱即用性和具有竞争力的性能，尤其是在低数据量场景下。仅微调偏置项有潜力实现前所未有的参数效率。然而，微调不同偏置项（即查询、键或值投影中的偏置项）与下游性能之间的联系仍不明确。现有方法，例如基于偏置变化幅度或经验费雪信息的方法，为选择特定的偏置项以实现有效微调提供的指导有限。在本文中，我们提出了一种选择要微调的偏置项的方法，构成了我们偏置高效微调（BEFT）的基础。我们广泛评估了我们的偏置高效方法，并将其与其他偏置选择方法进行了对比，涵盖了从1.1亿到67亿参数的、跨越仅编码器和仅解码器架构的各种大型语言模型（LLMs）。我们的结果表明，在包括分类、多项选择和生成任务在内的多种下游任务上，我们的偏置高效方法具有有效性和优越性。|
|**2025-09-19**|[Distribution-Aligned Decoding for Efficient LLM Task Adaptation](http://arxiv.org/abs/2509.15888)|null|即使使用参数高效微调（PEFT），将亿参数语言模型适配到下游任务仍然成本高昂。我们将任务适配重新定义为输出分布对齐：目标是在解码过程中直接将输出分布引导至任务分布，而不是通过权重更新间接实现。基于这种观点，我们引入了引导向量解码（SVD），这是一种轻量级、兼容PEFT且具有理论基础的方法。我们首先进行一个简短的热启动微调，并从热启动模型和预训练模型输出分布之间的库尔巴克-莱布勒（KL）散度梯度中提取一个任务感知的引导向量。随后，该引导向量被用于引导解码过程，以将模型的输出分布引导至任务分布。我们理论上证明了SVD与全量微调的梯度步长一阶等价，并推导出了引导向量强度的全局最优解。在三个任务和九个基准测试中，SVD与四种标准PEFT方法结合，将多项选择准确率提高了多达5个百分点，将开放式真实性提高了2个百分点，并在常识数据集上取得了类似的提升（1-2个百分点），且除了PEFT适配器之外不增加任何可训练参数。因此，SVD为大语言模型提供了一条轻量级、有理论基础的途径，以实现更强的任务适配。|
|**2025-09-19**|[Mamba-2 audio captioning: design space exploration and analysis](http://arxiv.org/abs/2509.15680)|null|我们提出了一种基于Mamba-2大语言模型骨干的音频字幕生成模型，Mamba-2是一种最先进（SOTA）的状态空间模型（SSM）。我们系统地探索了设计空间，包括LLM尺寸、LoRA秩和连接器设计，这些设计利用了Mamba-2在序列长度方面的线性时间复杂度。在各项基准测试中，与在相同数据集上训练的更大语言模型相比，我们的模型在使用了更少参数的情况下，仍实现了强大的字幕生成性能。我们首次深入分析了LLM参数数量、音频编码器微调策略、音频特征多样性以及不同的特征降维或扩展技术如何影响性能。|
|**2025-09-19**|[UNIV: Unified Foundation Model for Infrared and Visible Modalities](http://arxiv.org/abs/2509.15642)|null|联合可见光和红外感知的需求正在快速增长，尤其是在各种天气条件下实现鲁棒性能方面。尽管针对可见光和红外数据的预训练模型在各自领域表现出色，但在多模态场景中（例如配备这两种传感器的自动驾驶汽车）往往表现不佳。为解决这一挑战，我们提出了一种受生物学启发的红外与可见光模态统一基础模型 (UNIV)，该模型具有两项关键创新。首先，我们引入了逐块跨模态对比学习 (PCCL)，这是一种注意力引导的蒸馏框架，它模仿视网膜水平细胞的侧向抑制作用，能够在与任何基于Transformer的架构兼容的同时，实现有效的跨模态特征对齐。其次，我们的双知识保留机制模拟视网膜双极细胞的信号路由——结合LoRA适配器（增加2%的参数）和同步蒸馏以防止灾难性遗忘，从而复制视网膜的明视（锥体细胞驱动）和暗视（杆体细胞驱动）功能。为支持跨模态学习，我们引入了MVIP数据集，这是迄今为止最全面的可见光-红外基准。它包含98,992对精确对齐的图像，涵盖各种场景。大量实验表明，UNIV在红外任务上表现优越（语义分割中mIoU提升1.7，目标检测中mAP提升0.7），同时在可见光RGB任务上保持了99%以上的基线性能。我们的代码可在 https://github.com/fangyuanmao/UNIV 获取。|
|**2025-09-18**|[Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding](http://arxiv.org/abs/2509.15476)|null|讽刺检测在自然语言理解中仍然是一个挑战，因为讽刺意图通常依赖于文本、语音和视觉等微妙的跨模态线索。尽管先前的工作主要集中在文本或视觉-文本讽刺上，但全面的音频-视觉-文本讽刺理解仍未得到充分探索。在本文中，我们系统地评估了大语言模型 (LLMs) 和多模态大语言模型在零样本、少样本和LoRA微调设置下，对英语 (MUStARD++) 和中文 (MCSD 1.0) 讽刺检测的性能。除了直接分类，我们还探索将模型用作特征编码器，并通过协同门控融合模块整合它们的表示。实验结果表明，基于音频的模型实现了最强的单模态性能，而文本-音频和音频-视觉组合则优于单模态和三模态模型。此外，Qwen-Omni等多模态大语言模型展现出有竞争力的零样本和微调性能。我们的研究结果强调了多模态大语言模型在跨语言、音频-视觉-文本讽刺理解方面的潜力。|
|**2025-09-18**|[Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation](http://arxiv.org/abs/2509.15225)|null|我们提出VocAlign，一种专门为开放词汇语义分割中的视觉语言模型（VLMs）设计的无源域适应新框架。我们的方法采用学生-教师范式，并辅以词汇对齐策略，通过引入额外的类别概念来改进伪标签生成。为确保效率，我们使用低秩适应（LoRA）来微调模型，在保留其原始能力的同时最大限度地减少计算开销。此外，我们为学生模型提出了一种Top-K类别选择机制，该机制显著减少了内存需求，同时进一步提高了适应性能。我们的方法在CityScapes数据集上实现了mIoU显著的6.11点提升，并在零样本分割基准测试中表现出卓越性能，为开放词汇设置下的无源适应设定了新标准。|
|**2025-09-18**|[Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning](http://arxiv.org/abs/2509.15087)|null|大型语言模型（LLMs）在各种任务中展现出令人印象深刻的能力，但为领域特定应用微调LLMs通常需要大量可能分布在多个组织中的领域特定数据。联邦学习（FL）提供了一种隐私保护解决方案，但在应用于LLMs时面临计算约束的挑战。低秩适应（LoRA）作为一种参数高效的微调方法应运而生，但单个LoRA模块在处理不同领域的异构数据时往往表现不佳。本文解决了联邦LoRA微调中的两个关键挑战：1. 确定异构客户端之间LoRA专家的最佳数量和分配，以及2. 使客户端能够根据其特定数据特征选择性地利用这些专家。我们提出了FedLEASE（联邦自适应LoRA专家分配与选择），这是一种新颖的框架，它根据表示相似性自适应地聚类客户端，以分配和训练领域特定的LoRA专家。它还引入了一种自适应的top- $M$ 专家混合机制，允许每个客户端选择所利用专家的最佳数量。我们在各种基准数据集上进行的大量实验表明，FedLEASE在异构客户端设置中显著优于现有的联邦微调方法，同时保持了通信效率。|
|**2025-09-18**|[Explicit vs. Implicit Biographies: Evaluating and Adapting LLM Information Extraction on Wikidata-Derived Texts](http://arxiv.org/abs/2509.14943)|null|文本隐含性一直是自然语言处理 (NLP) 中的一个难题，传统方法依赖于显式陈述来识别实体及其关系。例如，从句子“Zuhdi attends church every Sunday”中，Zuhdi 与基督教之间的关系对人类读者来说是显而易见的，但当需要自动推断时，这便提出了挑战。大语言模型 (LLMs) 已被证明在文本理解和信息抽取 (IE) 等NLP下游任务中表现出色。本研究考察了文本隐含性如何影响预训练LLM（包括 LLaMA 2.3、DeepSeekV1 和 Phi1.5）在IE任务中的表现。我们生成了两个包含1万条隐含和显式传记信息表达的合成数据集，以衡量其对LLM性能的影响，并分析对隐含数据进行微调是否能提高其在隐含推理任务中的泛化能力。本研究展示了一项关于LLM在IE中内部推理过程的实验，特别是在处理隐含和显式上下文方面。结果表明，使用LoRA（低秩适应）对LLM模型进行微调可以提高其从隐含文本中抽取信息的性能，从而有助于提升模型的解释性和可靠性。|
|**2025-09-18**|[LLM4MG: Adapting Large Language Model for Multipath Generation via Synesthesia of Machines](http://arxiv.org/abs/2509.14711)|null|基于机器联觉 (SoM)，大语言模型 (LLM) 首次被用于多径生成 (LLM4MG)。考虑到典型的第六代 (6G) 车-基础设施 (V2I) 场景，本文构建了一个新的多模态感知-通信数据集，命名为 SynthSoM-V2I，其中包括信道多径信息、毫米波 (mmWave) 雷达感知数据、RGB-D 图像以及光探测与测距 (LiDAR) 点云。基于 SynthSoM-V2I 数据集，所提出的 LLM4MG 利用大语言模型 Meta AI (LLaMA) 3.2 通过多模态感知数据进行多径生成。所提出的 LLM4MG 通过特征提取和融合网络，将多模态特征空间与 LLaMA 语义空间对齐。为进一步实现从预训练 LLaMA 到通过多模态感知数据进行多径生成的通用知识迁移，本文采用了低秩适应 (LoRA) 参数高效微调和传播感知提示工程。仿真结果表明，所提出的 LLM4MG 在视距 (LoS)/非视距 (NLoS) 分类方面优于传统的基于深度学习的方法，准确率达到 92.76%；在多径功率/时延生成精度方面，归一化均方误差 (NMSE) 分别为 0.099/0.032；并且在跨车辆交通密度 (VTD)、跨频段和跨场景泛化方面也表现出色。通过真实世界泛化验证了所提出的 LLM4MG 的实用性。通过信道容量比较，也证明了高精度多径生成对于系统设计的必要性。|
|**2025-09-18**|[Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors](http://arxiv.org/abs/2509.14543)|**[link](https://github.com/jaaack-wang/llms-implicit-writing-styles-imitation)**|随着大型语言模型（LLM）日益融入个人写作工具，一个关键问题浮现：LLM能否仅凭少量示例忠实模仿个体的写作风格？个人风格通常是微妙且隐性的，这使得通过提示（prompt）难以明确指定，但对于用户对齐的生成至关重要。本工作对最先进LLM模仿个人写作风格的能力进行了全面评估，通过少量用户原创样本进行上下文学习（in-context learning）。我们引入了一套互补的指标——包括作者归属、作者验证、风格匹配和AI检测——以稳健地评估风格模仿能力。我们的评估涵盖每个模型超过40000次生成，跨越新闻、电子邮件、论坛和博客等领域，包含了来自400多位真实作者的写作样本。结果表明，尽管LLM可以在新闻和电子邮件等结构化格式中近似用户风格，但它们在博客和论坛中处理细致入微、非正式的写作时表现不佳。对各种提示策略（例如演示数量）的进一步分析揭示了有效个性化中的关键局限。我们的发现突出了个性化LLM适应方面的一个根本性差距，以及对改进技术以支持隐式、风格一致生成的需求。为了促进未来研究和可复现性，我们开源了数据和代码。|
|**2025-09-18**|[CLAIP-Emo: Parameter-Efficient Adaptation of Language-supervised models for In-the-Wild Audiovisual Emotion Recognition](http://arxiv.org/abs/2509.14527)|null|真实场景下的视听情感识别（AVER）仍受姿态变化、遮挡和背景噪声的阻碍。现有方法主要依赖于大规模领域特定预训练，这成本高昂且通常与真实世界的情感数据不匹配。为解决此问题，我们提出了CLAIP-Emo，一个模块化框架，它将真实场景下的AVER重新定义为语言监督基础模型（CLIP/CLAP）的参数高效适应。具体而言，它（i）通过冻结CLIP/CLAP骨干网络并通过LoRA进行情感导向适应（更新总参数的\ensuremath{\le}4.0%）来保留语言监督先验知识，（ii）非对称地分配时间建模，采用轻量级Transformer处理视觉动态，同时对音频韵律应用均值池化，以及（iii）应用一个简单的融合头进行预测。在DFEW和MAFW数据集上，CLAIP-Emo (ViT-L/14) 仅用8M训练参数就达到了80.14%和61.18%的加权平均召回率，创造了新的最先进水平。我们的发现表明，语言监督基础模型的参数高效适应为真实场景下的AVER提供了一种可扩展的替代方案，以替代领域特定预训练。代码和模型将在此处提供：\href{https://github.com/MSA-LMC/CLAIP-Emo}{https://github.com/MSA-LMC/CLAIP-Emo}。|
|**2025-09-17**|[Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection](http://arxiv.org/abs/2509.13934)|null|部署无人机 (UAV) 从空间分布设备进行可靠且节能的数据收集，在支持多样化的物联网 (IoT) 应用方面具有巨大潜力。然而，无人机有限的续航能力和通信范围使得智能轨迹规划成为必要。尽管强化学习 (RL) 已被广泛探索用于无人机轨迹优化，但其交互性在真实世界环境中带来了高成本和高风险。离线 RL 缓解了这些问题，但仍易受不稳定训练影响，并高度依赖专家质量数据集。为解决这些挑战，我们提出了一个无人机轨迹规划与资源分配联合问题，以最大化数据收集的能源效率。资源分配子问题首先被转化为等价的线性规划公式，并以多项式时间复杂度得到最优解。随后，我们提出了一个大型语言模型 (LLM) 赋能的批评者正则化决策 Transformer (DT) 框架，称之为 LLM-CRDT，以学习有效的无人机控制策略。在 LLM-CRDT 中，我们整合了批评者网络来正则化 DT 模型训练，从而将 DT 的序列建模能力与基于批评者的价值指导相结合，以实现从次优数据集中学习有效策略。此外，为缓解 Transformer 模型对数据的高需求特性，我们采用预训练 LLM 作为 DT 模型的 Transformer 主干，并采纳参数高效微调策略 LoRA，从而在小规模数据集和低计算开销下实现对无人机控制任务的快速适应。大量仿真表明，LLM-CRDT 优于基准在线和离线 RL 方法，与当前最先进的 DT 方法相比，能源效率提高高达 36.7%。|
|**2025-09-17**|[Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection](http://arxiv.org/abs/2509.13878)|null|Wav2Vec2等基础模型在语音任务（包括音频深度伪造检测）中的表征学习方面表现出色。然而，在对一组固定的真实和伪造音频片段进行微调后，它们通常无法泛化到训练中未出现的新颖深度伪造方法。为解决此问题，我们提出了一种LoRA专家混合方法，该方法将多个低秩适配器（LoRA）集成到模型的注意力层中。一种路由机制选择性地激活专门的专家，从而增强了对不断演变的深度伪造攻击的适应性。实验结果表明，我们的方法在域内和域外场景中均优于标准微调，相对于基线模型降低了等错误率。值得注意的是，我们最佳的MoE-LoRA模型将平均域外EER从8.55%降低到6.08%，证明了其在实现可泛化的音频深度伪造检测方面的有效性。|
|**2025-09-18**|[Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](http://arxiv.org/abs/2509.13775)|null|本文探讨了我们对阿拉伯方言识别 (ADI) 中不同数据高效和参数高效方法的探索。具体来说，我们研究了各种软提示策略，包括 prefix-tuning、prompt-tuning、P-tuning 和 P-tuning V2，以及 LoRA 重参数化。对于数据高效策略，我们分析了结合零样本和少样本推理的硬提示，以分析大型语言模型 (LLMs) 的方言识别能力。对于参数高效的 PEFT 方法，我们使用阿拉伯语专用的编码器模型在几个主要数据集上进行了实验。我们还在开源的仅解码器模型、一个通用多语言模型 (Phi-3.5) 和一个阿拉伯语专用模型 (SILMA) 上分析了 n-shot 推理。我们观察到，LLMs 在少样本或零样本设置中通常难以区分方言细微差别。软提示编码器变体表现更好，而基于 LoRA 的微调模型表现最佳，甚至超越了完全微调。|
|**2025-09-17**|[Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](http://arxiv.org/abs/2509.13624)|null|大语言模型正越来越多地部署到各种应用中。这通常包括大语言模型在训练期间未曾遇到的任务。这意味着枚举并获取所有任务的高质量训练数据是不可行的。因此，我们通常需要依赖于使用具有不同特征的数据集的迁移学习，并预测分布外请求。受此实际需求的启发，我们提出了一个分析框架，通过构建迁移学习矩阵和降维来剖析这些跨任务交互。我们训练并分析了10个模型，以识别潜在能力（例如，推理、情感分类、自然语言理解、算术）并发现迁移学习的副作用。我们的发现揭示，性能提升往往难以用基于表层数据集相似性或源数据质量的解释来阐明。相反，源数据集的隐藏统计因素，例如类别分布和生成长度倾向性，以及特定的语言特征，实际上更具影响力。这项工作为理解迁移学习的复杂动态提供了见解，为更可预测和更有效的大语言模型适应铺平了道路。|
|**2025-04-19**|[PEFT A2Z: Parameter-Efficient Fine-Tuning Survey for Large Language and Vision Models](http://arxiv.org/abs/2504.14117)|null|大型模型，如大语言模型（LLM）和视觉语言模型（VLM），已经彻底改变了人工智能，推动了自然语言处理、计算机视觉和多模态学习等领域的应用。然而，对这些模型进行全量微调仍然成本高昂，需要大量的计算资源、内存和任务特定数据。参数高效微调（PEFT）作为一种有前景的解决方案应运而生，它允许通过仅更新一小部分参数来使大型模型适应下游任务。本综述全面概述了PEFT技术，重点介绍了它们的动机、设计原则和有效性。我们首先分析了传统微调带来的资源和可访问性挑战，并强调了过拟合、灾难性遗忘和参数低效性等关键问题。随后，我们引入了PEFT方法的结构化分类——分为附加型、选择型、重参数化型、混合型和统一框架——并系统地比较了它们的机制和权衡。除了分类之外，我们还探讨了PEFT在不同领域（包括语言、视觉和生成建模）的影响，展示了这些技术如何在较低的资源成本下提供强大的性能。我们还讨论了可扩展性、可解释性和鲁棒性方面重要的开放挑战，并提出了联邦学习、域适应和理论基础等未来发展方向。我们的目标是提供对PEFT及其在实现大型模型实际、高效和可持续使用方面日益增长的作用的统一理解。|
|**2025-06-09**|[Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought](http://arxiv.org/abs/2504.05599)|null|我们引入了Skywork R1V，这是一种多模态推理模型，它通过一种高效的多模态迁移方法，将R1系列大语言模型（LLM）扩展到视觉模态。Skywork R1V利用轻量级视觉投影器，实现了无缝的多模态适应，而无需重新训练基础语言模型或视觉编码器。为了增强视觉-文本对齐，我们提出了一种混合优化策略，该策略结合了迭代监督微调（SFT）和群组相对策略优化（GRPO），显著提高了跨模态集成效率。此外，我们引入了一种自适应长度思维链蒸馏方法，用于推理数据生成。这种方法动态优化推理链长度，从而提高推理效率并防止过度推理。经验评估表明，Skywork R1V仅用380亿参数就提供了具有竞争力的性能，在MMMU基准测试中获得69.0分，在MathVista上获得67.5分。同时，它保持了强大的文本推理性能，在AIME上获得了72.0分，在MATH500上获得了94.0分的出色表现证明了这一点。Skywork R1V模型权重已公开发布，以促进开放性和可复现性。|
|**2025-04-08**|[ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion](http://arxiv.org/abs/2503.24354)|null|参数生成已成为神经网络开发的一种新范式，通过直接合成高质量模型权重，为传统神经网络训练提供了一种替代方案。在针对演进的（即持续更新的）大型语言模型 (LLM) 的低秩适应 (LoRA) 背景下，这种方法有望实现高效适应，而无需昂贵的再训练。然而，现有方法在同时实现可扩展性和可控性方面面临关键局限性。在本文中，我们引入了 $\texttt{ORAL}$，这是一种新颖的条件循环扩散框架，旨在解决这些挑战。$\texttt{ORAL}$ 融合了一种新颖的条件机制，该机制整合了模型架构和文本任务规范，使得能够生成特定任务的LoRA参数，这些参数可以无缝迁移到演进的基础模型上。我们的方法成功扩展到具有数十亿参数的LLM，并保持了可控性。通过对七个语言任务、四个视觉任务和三个多模态任务进行广泛实验，并使用五个预训练LLM，我们证明 $\texttt{ORAL}$ 生成的高质量LoRA参数实现了与传统训练对应物可比或更优的性能。|
|**2025-02-22**|[A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models](http://arxiv.org/abs/2502.17516)|null|基础模型的兴起改变了机器学习研究，促使人们努力揭示其内部工作机制并开发更高效、更可靠的应用以实现更好的控制。尽管在解释大型语言模型（LLM）方面取得了显著进展，但多模态基础模型（MMFM）——例如对比视觉-语言模型、生成式视觉-语言模型和文本到图像模型——带来了超越单模态框架的独特解释性挑战。尽管已有初步研究，LLM和MMFM的解释性之间仍存在巨大差距。本综述探讨了两个关键方面：(1) 将LLM解释性方法应用于多模态模型，以及(2) 理解单模态语言模型和跨模态系统之间的机制差异。通过系统回顾当前的MMFM分析技术，我们提出了一个结构化的解释性方法分类，比较了单模态和多模态架构之间的见解，并强调了关键的研究空白。|
|**2024-08-13**|[CROME: Cross-Modal Adapters for Efficient Multimodal LLM](http://arxiv.org/abs/2408.06610)|null|多模态大型语言模型（MLLM）展现出卓越的图文理解能力，但其广泛应用面临经济高效的训练和适应性挑战。现有方法通常需要昂贵的语言模型再训练和有限的适应性。此外，当前对零样本性能提升的关注为任务特定微调提供的指导不足。我们提出了CROME，一种高效的视觉-语言指令微调框架。它具有一种新颖的门控跨模态适配器，该适配器在输入到冻结的LLM之前有效地结合了视觉和文本表示。这种轻量级适配器仅用少量参数进行训练，能够实现高效的跨模态理解。值得注意的是，CROME在标准视觉问答和指令遵循基准上展现出卓越的零样本性能。此外，它实现了参数效率极高的微调，可与任务特定专家最先进方法相媲美。CROME展示了预LLM对齐在构建可扩展、适应性强且参数高效的多模态模型方面的潜力。|
|**2024-07-08**|[Can LLMs' Tuning Methods Work in Medical Multimodal Domain?](http://arxiv.org/abs/2403.06407)|**[link](https://github.com/TIMMY-CHAN/MILE)**|尽管大语言模型（LLMs）在世界知识理解方面表现出色，但将其应用于特定子领域需要精确的调整。由于模型规模庞大，传统的全局微调方法计算成本高昂，并可能影响模型的泛化能力。为应对这一挑战，一系列创新的参数高效微调（PEFT）方法应运而生，并在大语言模型（LLMs）和大型视觉语言模型（LVLMs）中均取得了显著成功。在医疗领域，微调医学视觉语言预训练（VLP）模型对于使其适应特定任务至关重要。那么，大模型的微调方法能否迁移到医疗领域，以提高迁移学习效率呢？在本文中，我们深入探讨了LLMs的微调方法，并进行了广泛的实验，旨在从训练数据层面和模型结构层面探究大模型的微调方法对医疗领域现有多模态模型的影响。我们展示了大模型微调方法对医疗VLM的不同影响，并开发了最有效的医疗VLP模型微调方法。我们希望这项研究能指导医疗领域研究人员优化VLM的训练成本，促进VLM在医疗保健领域的更广泛应用。代码和数据集已发布在https://github.com/TIMMY-CHAN/MILE。|
|**2023-10-24**|[Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models](http://arxiv.org/abs/2305.15023)|null|近来，人们对扩展大语言模型（LLM）的多模态能力（例如视觉-语言（VL）学习）的兴趣日益增长，这被认为是实现通用人工智能的下一个里程碑。然而，现有解决方案的成本极其昂贵，它们不仅需要优化过多的参数，而且在进行VL指令微调之前还需要进行另一轮大规模预训练。本文提出了一种新颖且经济的解决方案，用于LLM的有效VL适应，名为模态混合适应（MMA）。MMA没有使用大型神经网络来连接图像编码器和LLM，而是采用了轻量级模块（即适配器）来弥合LLM与VL任务之间的鸿沟，这也使得图像模型和语言模型的联合优化成为可能。同时，MMA还配备了一个路由算法，帮助LLM在单模态和多模态指令之间实现自动切换，而不损害其自然语言理解能力。为了验证MMA，我们将其应用于一个名为LLaMA的近期LLM，并将由此形成的大型视觉-语言指令模型命名为LaVIN。为了验证MMA和LaVIN，我们在多模态科学问答和多模态对话这两种设置下进行了广泛的实验。实验结果不仅证明了LaVIN相比现有多模态LLM的竞争性能和卓越训练效率，而且还证实了其作为通用聊天机器人的巨大潜力。更重要的是，LaVIN的实际开销极其低廉，例如，仅需1.4小时的训练时间和3.8M可训练参数，这极大地证实了MMA的有效性。我们的项目已发布于https://luogen1996.github.io/lavin。|
|**2024-04-04**|[ArtGPT-4: Towards Artistic-understanding Large Vision-Language Models with Enhanced Adapter](http://arxiv.org/abs/2305.07490)|null|大语言模型（LLMs）的成功启发了多模态学习这一新兴研究领域。然而，将LLMs用于多模态学习面临的一个巨大挑战是预训练LLMs的规模，它们通常拥有数十亿参数。为了应对这一挑战，MiniGPT-4和LLaVA等模型被开发出来，以利用更少参数微调预训练模型。尽管它们表现出有前景的性能，但这些模型在理解艺术图像方面仍存在局限性。为了促进更好的艺术理解，本文提出ArtGPT-4，这是一种开创性的大型视觉-语言模型，专门旨在解决现有模型在艺术理解方面的局限性。ArtGPT-4的关键创新在于其针对艺术图像理解这一复杂挑战的设计，使其区别于其他忽略细节而关注更广泛主题的模型。具体来说，它通过将一些专门的适配器层集成到LLM中来工作，使模型能够更高效、更有效地解析和解释复杂视觉标记，而非像现有方法那样微调整个LLM。ArtGPT-4在效率方面展示了其卓越性能：利用Tesla A100设备，其训练可以在短短2小时内完成，数据集包含约0.52M图像-文本对。此外，ArtGPT-4还在ArtEmis和ArtEmis-v2.0数据集以及本文建立的基准上取得了最先进的性能，在6分制下仅比专业艺术家的描述落后微不足道的0.15分。ArtGPT-4的卓越性能表明它能够以艺术理解呈现图像，并传达它们所激发的情感，媲美人类的解读。代码和预训练模型可在\url{https://github.com/DLYuanGod/ArtGPT-4}获取。|
|**2023-05-21**|[UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling](http://arxiv.org/abs/2302.06605)|null|大规模视觉-语言预训练模型已显示出对各种下游任务的良好迁移能力。随着这些基础模型规模和下游任务数量的增长，由于高昂的计算和存储成本，标准的S全量微调范式变得不可持续。本文提出了UniAdapter，它统一了单模态和多模态适配器，以在预训练的视觉-语言模型上实现参数高效的跨模态适应。具体来说，适配器被分配到不同的模态及其交互中，通过部分权重共享减少了可调参数的总数。这种统一的知识共享设计能够实现强大的跨模态表示，使各种下游任务受益，仅需要预训练模型1.0%-2.0%的可调参数。在6个跨模态下游基准（包括视频-文本检索、图像-文本检索、VideoQA和VQA）上进行的广泛实验表明，在大多数情况下，UniAdapter不仅优于最先进的方法，甚至击败了全量微调策略。特别地，在MSRVTT检索任务上，UniAdapter以2.2%的模型参数实现了49.7%的recall@1，领先最新的竞争对手2.0%。代码和模型可在https://github.com/RERV/UniAdapter获取。|

## 大模型强化学习

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-12-19**|[AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning](http://arxiv.org/abs/2512.17853)|null|Generalist robot learning remains constrained by data: large-scale, diverse, and high-quality interaction data are expensive to collect in the real world. While simulation has become a promising way for scaling up data collection, the related tasks, including simulation task design, task-aware scene generation, expert demonstration synthesis, and sim-to-real transfer, still demand substantial human effort. We present AnyTask, an automated framework that pairs massively parallel GPU simulation with foundation models to design diverse manipulation tasks and synthesize robot data. We introduce three AnyTask agents for generating expert demonstrations aiming to solve as many tasks as possible: 1) ViPR, a novel task and motion planning agent with VLM-in-the-loop Parallel Refinement; 2) ViPR-Eureka, a reinforcement learning agent with generated dense rewards and LLM-guided contact sampling; 3) ViPR-RL, a hybrid planning and learning approach that jointly produces high-quality demonstrations with only sparse rewards. We train behavior cloning policies on generated data, validate them in simulation, and deploy them directly on real robot hardware. The policies generalize to novel object poses, achieving 44% average success across a suite of real-world pick-and-place, drawer opening, contact-rich pushing, and long-horizon manipulation tasks. Our project website is at https://anytask.rai-inst.com .|
|**2025-12-19**|[Trust-Region Adaptive Policy Optimization](http://arxiv.org/abs/2512.17636)|**[link](https://github.com/Su-my/TRAPO)**|Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\textbf{T}rust-\textbf{R}egion \textbf{A}daptive \textbf{P}olicy \textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.|
|**2025-12-19**|[Xiaomi MiMo-VL-Miloco Technical Report](http://arxiv.org/abs/2512.17436)|null|We open-source \textbf{MiMo-VL-Miloco-7B} and its quantized variant \textbf{MiMo-VL-Miloco-7B-GGUF}, a pair of home-centric vision-language models that achieve strong performance on both home-scenario understanding and general multimodal reasoning. Built on the MiMo-VL-7B backbone, MiMo-VL-Miloco-7B is specialized for smart-home environments, attaining leading F1 scores on gesture recognition and common home-scenario understanding, while also delivering consistent gains across video benchmarks such as Video-MME, Video-MMMU, and Charades-STA, as well as language understanding benchmarks including MMMU-Pro and MMLU-Pro. In our experiments, MiMo-VL-Miloco-7B outperforms strong closed-source and open-source baselines on home-scenario understanding and several multimodal reasoning benchmarks. To balance specialization and generality, we design a two-stage training pipeline that combines supervised fine-tuning with reinforcement learning based on Group Relative Policy Optimization, leveraging efficient multi-domain data. We further incorporate chain-of-thought supervision and token-budget-aware reasoning, enabling the model to learn knowledge in a data-efficient manner while also performing reasoning efficiently. Our analysis shows that targeted home-scenario training not only enhances activity and gesture understanding, but also improves text-only reasoning with only modest trade-offs on document-centric tasks. Model checkpoints, quantized GGUF weights, and our home-scenario evaluation toolkit are publicly available at \href{https://github.com/XiaoMi/xiaomi-mimo-vl-miloco}{https://github.com/XiaoMi/xiaomi-mimo-vl-miloco} to support research and deployment in real-world smart-home applications.|
|**2025-12-19**|[AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens](http://arxiv.org/abs/2512.17375)|null|Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.|
|**2025-12-19**|[Neuro-Symbolic Control with Large Language Models for Language-Guided Spatial Tasks](http://arxiv.org/abs/2512.17321)|null|尽管大语言模型（LLM）最近已成为具身系统中语言条件控制的有效工具，但其固有的不稳定性、收敛速度慢和幻觉动作仍持续限制它们在连续控制中的直接应用。本文提出了一种模块化神经符号控制框架，该框架明确区分了低级运动执行和高级语义推理。轻量级神经增量控制器在连续空间中执行有界增量动作，而局部部署的LLM则解释符号任务。我们在平面操作设置中评估了所提出的方法，其中对象之间的空间关系通过语言指定。在广泛的实验中，我们使用大量任务和Mistral、Phi、LLaMA-3.2等本地语言模型，比较了仅LLM控制、仅神经控制以及所提出的LLM+DL框架。与仅LLM基线相比，结果表明神经符号集成持续提高了成功率和效率，平均步数减少超过70%，加速比高达8.83倍，同时对语言模型质量保持鲁棒性。通过将LLM控制到符号输出，并将未解释的执行分配给在人工几何数据上训练的神经控制器，所提出的框架在无需强化学习或昂贵试运行的情况下，增强了可解释性、稳定性和泛化能力。这些输出凭经验表明，神经符号分解提供了一种可扩展且有原则的方法来将语言理解与持续控制集成，这种方法促进了可靠且有效的语言引导具身系统的创建。|
|**2025-12-19**|[Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation](http://arxiv.org/abs/2512.17308)|null|Strategic decision-making in Pokémon battles presents a unique testbed for evaluating large language models. Pokémon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language Models (LLMs) can serve as competent battle agents, capable of both making tactically sound decisions and generating novel, balanced game content. We developed a turn-based Pokémon battle system where LLMs select moves based on battle state rather than pre-programmed logic. The framework captures essential Pokémon mechanics: type effectiveness multipliers, stat-based damage calculations, and multi-Pokémon team management. Through systematic evaluation across multiple model architectures we measured win rates, decision latency, type-alignment accuracy, and token efficiency. These results suggest LLMs can function as dynamic game opponents without domain-specific training, offering a practical alternative to reinforcement learning for turn-based strategic games. The dual capability of tactical reasoning and content creation, positions LLMs as both players and designers, with implications for procedural generation and adaptive difficulty systems in interactive entertainment.|
|**2025-12-19**|[Understanding Generalization in Role-Playing Models via Information Theory](http://arxiv.org/abs/2512.17270)|null|Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.|
|**2025-12-19**|[Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience](http://arxiv.org/abs/2512.17260)|null|Large language models have recently made significant progress to generate rigorous mathematical proofs. In contrast, utilizing LLMs for theorem proving in formal languages (such as Lean) remains challenging and computationally expensive, particularly when addressing problems at the undergraduate level and beyond. In this work, we present \textbf{Seed-Prover 1.5}, a formal theorem-proving model trained via large-scale agentic reinforcement learning, alongside an efficient test-time scaling (TTS) workflow. Through extensive interactions with Lean and other tools, the model continuously accumulates experience during the RL process, substantially enhancing the capability and efficiency of formal theorem proving. Furthermore, leveraging recent advancements in natural language proving, our TTS workflow efficiently bridges the gap between natural and formal languages. Compared to state-of-the-art methods, Seed-Prover 1.5 achieves superior performance with a smaller compute budget. It solves \textbf{88\% of PutnamBench} (undergraduate-level), \textbf{80\% of Fate-H} (graduate-level), and \textbf{33\% of Fate-X} (PhD-level) problems. Notably, using our system, we solved \textbf{11 out of 12 problems} from Putnam 2025 within 9 hours. Our findings suggest that scaling learning from experience, driven by high-quality formal feedback, holds immense potential for the future of formal mathematical reasoning.|
|**2025-12-19**|[Learning When to Look: A Disentangled Curriculum for Strategic Perception in Multimodal Reasoning](http://arxiv.org/abs/2512.17227)|null|Multimodal Large Language Models (MLLMs) demonstrate significant potential but remain brittle in complex, long-chain visual reasoning tasks. A critical failure mode is "visual forgetting", where models progressively lose visual grounding as reasoning extends, a phenomenon aptly described as "think longer, see less". We posit this failure stems from current training paradigms prematurely entangling two distinct cognitive skills: (1) abstract logical reasoning "how-to-think") and (2) strategic visual perception ("when-to-look"). This creates a foundational cold-start deficiency -- weakening abstract reasoning -- and a strategic perception deficit, as models lack a policy for when to perceive. In this paper, we propose a novel curriculum-based framework to disentangle these skills. First, we introduce a disentangled Supervised Fine-Tuning (SFT) curriculum that builds a robust abstract reasoning backbone on text-only data before anchoring it to vision with a novel Perception-Grounded Chain-of-Thought (PG-CoT) paradigm. Second, we resolve the strategic perception deficit by formulating timing as a reinforcement learning problem. We design a Pivotal Perception Reward that teaches the model when to look by coupling perceptual actions to linguistic markers of cognitive uncertainty (e.g., "wait", "verify"), thereby learning an autonomous grounding policy. Our contributions include the formalization of these two deficiencies and the development of a principled, two-stage framework to address them, transforming the model from a heuristic-driven observer to a strategic, grounded reasoner. \textbf{Code}: \url{https://github.com/gaozilve-max/learning-when-to-look}.|
|**2025-12-19**|[CheXPO-v2: Preference Optimization for Chest X-ray VLMs with Knowledge Graph Consistency](http://arxiv.org/abs/2512.17213)|null|Medical Vision-Language Models (VLMs) are prone to hallucinations, compromising clinical reliability. While reinforcement learning methods like Group Relative Policy Optimization (GRPO) offer a low-cost alignment solution, their reliance on sparse, outcome-based rewards inadvertently encourages models to "overthink" -- generating verbose, convoluted, and unverifiable Chain-of-Thought reasoning to justify answers. This focus on outcomes obscures factual errors and poses significant safety risks. To address this, we propose CheXPO-v2, a novel alignment framework that shifts from outcome to process supervision. Our core innovation is a Knowledge Graph Consistency Reward mechanism driven by Entity-Relation Matching. By explicitly parsing reasoning steps into structured "Disease, Relation, Anatomy" triplets, we provide fine-grained supervision that penalizes incoherent logic and hallucinations at the atomic level. Integrating this with a hard-example mining strategy, our approach significantly outperforms GRPO and state-of-the-art models on benchmarks like MIMIC-CXR-VQA. Crucially, CheXPO-v2 achieves new state-of-the-art accuracy using only 5k samples, demonstrating exceptional data efficiency while producing clinically sound and verifiable reasoning. The project source code is publicly available at: https://github.com/ecoxial2007/CheX-Phi4MM.|
|**2025-12-18**|[Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification](http://arxiv.org/abs/2512.16921)|null|传统的评估多模态大语言模型（MLLM）的方法缺乏可解释性，并且往往不足以完全揭示不同模型之间显著的能力差距。为此，我们引入了AuditDM，一个自动化框架，它通过审计MLLM的分歧来主动发现并纠正其失效模式。AuditDM通过强化学习微调一个MLLM作为审计器，以生成挑战性问题和反事实图像，从而最大化目标模型之间的分歧。训练完成后，审计器会发现多样化、可解释的示例，这些示例揭示了模型的弱点，并可作为免标注数据用于纠正。当应用于Gemma-3和PaliGemma-2等最先进模型时，AuditDM发现了超过20种不同的失效类型。基于这些发现进行微调，持续改进了所有模型在16个基准测试上的表现，并使一个3B模型超越了其28B的对应模型。我们的结果表明，随着数据扩展达到边际收益递减，针对性的模型审计提供了一种有效的模型诊断和改进途径。|
|**2025-12-18**|[AdaTooler-V: Adaptive Tool-Use for Images and Videos](http://arxiv.org/abs/2512.16918)|null|Recent advances have shown that multimodal large language models (MLLMs) benefit from multimodal interleaved chain-of-thought (CoT) with vision tool interactions. However, existing open-source models often exhibit blind tool-use reasoning patterns, invoking vision tools even when they are unnecessary, which significantly increases inference overhead and degrades model performance. To this end, we propose AdaTooler-V, an MLLM that performs adaptive tool-use by determining whether a visual problem truly requires tools. First, we introduce AT-GRPO, a reinforcement learning algorithm that adaptively adjusts reward scales based on the Tool Benefit Score of each sample, encouraging the model to invoke tools only when they provide genuine improvements. Moreover, we construct two datasets to support training: AdaTooler-V-CoT-100k for SFT cold start and AdaTooler-V-300k for RL with verifiable rewards across single-image, multi-image, and video data. Experiments across twelve benchmarks demonstrate the strong reasoning capability of AdaTooler-V, outperforming existing methods in diverse visual reasoning tasks. Notably, AdaTooler-V-7B achieves an accuracy of 89.8\% on the high-resolution benchmark V*, surpassing the commercial proprietary model GPT-4o and Gemini 1.5 Pro. All code, models, and data are released.|
|**2025-12-18**|[Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning](http://arxiv.org/abs/2512.16917)|null|Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper, we introduce Generative Adversarial Reasoner, an on-policy joint training framework designed to enhance reasoning by co-evolving an LLM reasoner and an LLM-based discriminator through adversarial reinforcement learning. A compute-efficient review schedule partitions each reasoning chain into logically complete slices of comparable length, and the discriminator evaluates each slice's soundness with concise, structured justifications. Learning couples complementary signals: the LLM reasoner is rewarded for logically consistent steps that yield correct answers, while the discriminator earns rewards for correctly detecting errors or distinguishing traces in the reasoning process. This produces dense, well-calibrated, on-policy step-level rewards that supplement sparse exact-match signals, improving credit assignment, increasing sample efficiency, and enhancing overall reasoning quality of LLMs. Across various mathematical benchmarks, the method delivers consistent gains over strong baselines with standard RL post-training. Specifically, on AIME24, we improve DeepSeek-R1-Distill-Qwen-7B from 54.0 to 61.3 (+7.3) and DeepSeek-R1-Distill-Llama-8B from 43.7 to 53.7 (+10.0). The modular discriminator also enables flexible reward shaping for objectives such as teacher distillation, preference alignment, and mathematical proof-based reasoning.|
|**2025-12-18**|[Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward](http://arxiv.org/abs/2512.16912)|null|This paper examines the exploration-exploitation trade-off in reinforcement learning with verifiable rewards (RLVR), a framework for improving the reasoning of Large Language Models (LLMs). Recent studies suggest that RLVR can elicit strong mathematical reasoning in LLMs through two seemingly paradoxical mechanisms: spurious rewards, which suppress exploitation by rewarding outcomes unrelated to the ground truth, and entropy minimization, which suppresses exploration by pushing the model toward more confident and deterministic outputs, highlighting a puzzling dynamic: both discouraging exploitation and discouraging exploration improve reasoning performance, yet the underlying principles that reconcile these effects remain poorly understood. We focus on two fundamental questions: (i) how policy entropy relates to performance, and (ii) whether spurious rewards yield gains, potentially through the interplay of clipping bias and model contamination. Our results show that clipping bias under spurious rewards reduces policy entropy, leading to more confident and deterministic outputs, while entropy minimization alone is insufficient for improvement. We further propose a reward-misalignment model explaining why spurious rewards can enhance performance beyond contaminated settings. Our findings clarify the mechanisms behind spurious-reward benefits and provide principles for more effective RLVR training.|
|**2025-12-18**|[MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning](http://arxiv.org/abs/2512.16909)|null|Mobile manipulators in households must both navigate and manipulate. This requires a compact, semantically rich scene representation that captures where objects are, how they function, and which parts are actionable. Scene graphs are a natural choice, yet prior work often separates spatial and functional relations, treats scenes as static snapshots without object states or temporal updates, and overlooks information most relevant for accomplishing the current task. To address these limitations, we introduce MomaGraph, a unified scene representation for embodied agents that integrates spatial-functional relationships and part-level interactive elements. However, advancing such a representation requires both suitable data and rigorous evaluation, which have been largely missing. We thus contribute MomaGraph-Scenes, the first large-scale dataset of richly annotated, task-driven scene graphs in household environments, along with MomaGraph-Bench, a systematic evaluation suite spanning six reasoning capabilities from high-level planning to fine-grained scene understanding. Built upon this foundation, we further develop MomaGraph-R1, a 7B vision-language model trained with reinforcement learning on MomaGraph-Scenes. MomaGraph-R1 predicts task-oriented scene graphs and serves as a zero-shot task planner under a Graph-then-Plan framework. Extensive experiments demonstrate that our model achieves state-of-the-art results among open-source models, reaching 71.6% accuracy on the benchmark (+11.4% over the best baseline), while generalizing across public benchmarks and transferring effectively to real-robot experiments.|
|**2025-12-18**|[VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization](http://arxiv.org/abs/2512.16906)|null|Instruction-based video editing aims to modify an input video according to a natural-language instruction while preserving content fidelity and temporal coherence. However, existing diffusion-based approaches are often trained on paired data of simple editing operations, which fundamentally limits their ability to generalize to diverse and complex, real-world instructions. To address this generalization gap, we propose VIVA, a scalable framework for instruction-based video editing that leverages VLM-guided encoding and reward optimization. First, we introduce a VLM-based instructor that encodes the textual instruction, the first frame of the source video, and an optional reference image into visually-grounded instruction representations, providing fine-grained spatial and semantic context for the diffusion transformer backbone. Second, we propose a post-training stage, Edit-GRPO, which adapts Group Relative Policy Optimization to the domain of video editing, directly optimizing the model for instruction-faithful, content-preserving, and aesthetically pleasing edits using relative rewards. Furthermore, we propose a data construction pipeline designed to synthetically generate diverse, high-fidelity paired video-instruction data of basic editing operations. Extensive experiments show that VIVA achieves superior instruction following, generalization, and editing quality over state-of-the-art methods. Website: https://viva-paper.github.io|
|**2025-12-18**|[AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning](http://arxiv.org/abs/2512.16883)|null|Equipping large language models (LLMs) with search engines via reinforcement learning (RL) has emerged as an effective approach for building search agents. However, overreliance on search introduces unnecessary cost and risks exposure to noisy or malicious content, while relying solely on parametric knowledge risks hallucination. The central challenge is to develop agents that adaptively balance parametric knowledge with external search, invoking search only when necessary. Prior work mitigates search overuse by shaping rewards around the number of tool calls. However, these penalties require substantial reward engineering, provide ambiguous credit assignment, and can be exploited by agents that superficially reduce calls. Moreover, evaluating performance solely through call counts conflates necessary and unnecessary search, obscuring the measurement of true adaptive behavior. To address these limitations, we first quantify the self-knowledge awareness of existing search agents via an F1-based decision metric, revealing that methods such as Search-R1 often overlook readily available parametric knowledge. Motivated by these findings, we propose AdaSearch, a simple two-stage, outcome-driven RL framework that disentangles problem solving from the decision of whether to invoke search, and makes this decision process explicit and interpretable. This transparency is crucial for high-stakes domains such as finance and medical question answering, yet is largely neglected by prior approaches. Experiments across multiple model families and sizes demonstrate that AdaSearch substantially improves knowledge-boundary awareness, reduces unnecessary search calls, preserves strong task performance, and offers more transparent, interpretable decision behaviors.|
|**2025-12-18**|[Meta-RL Induces Exploration in Language Agents](http://arxiv.org/abs/2512.16848)|null|Reinforcement learning (RL) has enabled the training of large language model (LLM) agents to interact with the environment and to solve multi-turn long-horizon tasks. However, the RL-trained agents often struggle in tasks that require active exploration and fail to efficiently adapt from trial-and-error experiences. In this paper, we present LaMer, a general Meta-RL framework that enables LLM agents to actively explore and learn from the environment feedback at test time. LaMer consists of two key components: (i) a cross-episode training framework to encourage exploration and long-term rewards optimization; and (ii) in-context policy adaptation via reflection, allowing the agent to adapt their policy from task feedback signal without gradient update. Experiments across diverse environments show that LaMer significantly improves performance over RL baselines, with 11%, 14%, and 19% performance gains on Sokoban, MineSweeper and Webshop, respectively. Moreover, LaMer also demonstrates better generalization to more challenging or previously unseen tasks compared to the RL-trained agents. Overall, our results demonstrate that Meta-RL provides a principled approach to induce exploration in language agents, enabling more robust adaptation to novel environments through learned exploration strategies.|
|**2025-12-18**|[JustRL: Scaling a 1.5B LLM with a Simple RL Recipe](http://arxiv.org/abs/2512.16649)|null|Recent advances in reinforcement learning for large language models have converged on increasing complexity: multi-stage training pipelines, dynamic hyperparameter schedules, and curriculum learning strategies. This raises a fundamental question: \textbf{Is this complexity necessary?} We present \textbf{JustRL}, a minimal approach using single-stage training with fixed hyperparameters that achieves state-of-the-art performance on two 1.5B reasoning models (54.9\% and 64.3\% average accuracy across nine mathematical benchmarks) while using 2 $\times$ less compute than sophisticated approaches. The same hyperparameters transfer across both models without tuning, and training exhibits smooth, monotonic improvement over 4,000+ steps without the collapses or plateaus that typically motivate interventions. Critically, ablations reveal that adding ``standard tricks'' like explicit length penalties and robust verifiers may degrade performance by collapsing exploration. These results suggest that the field may be adding complexity to solve problems that disappear with a stable, scaled-up baseline. We release our models and code to establish a simple, validated baseline for the community.|
|**2025-12-18**|[Stackelberg Learning from Human Feedback: Preference Optimization as a Sequential Game](http://arxiv.org/abs/2512.16626)|null|We introduce Stackelberg Learning from Human Feedback (SLHF), a new framework for preference optimization. SLHF frames the alignment problem as a sequential-move game between two policies: a Leader, which commits to an action, and a Follower, which responds conditionally on the Leader's action. This approach decomposes preference optimization into a refinement problem for the Follower and an optimization problem against an adversary for the Leader. Unlike Reinforcement Learning from Human Feedback (RLHF), which assigns scalar rewards to actions, or Nash Learning from Human Feedback (NLHF), which seeks a simultaneous-move equilibrium, SLHF leverages the asymmetry of sequential play to capture richer preference structures. The sequential design of SLHF naturally enables inference-time refinement, as the Follower learns to improve the Leader's actions, and these refinements can be leveraged through iterative sampling. We compare the solution concepts of SLHF, RLHF, and NLHF, and lay out key advantages in consistency, data sensitivity, and robustness to intransitive preferences. Experiments on large language models demonstrate that SLHF achieves strong alignment across diverse preference datasets, scales from 0.5B to 8B parameters, and yields inference-time refinements that transfer across model families without further fine-tuning.|
|**2025-12-12**|[SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support](http://arxiv.org/abs/2512.11755)|null|Online product reviews contain rich but noisy signals that overwhelm users and hinder effective decision-making. Existing LLM-based summarizers remain generic and fail to account for individual preferences, limiting their practical utility. We propose SUMFORU, a steerable review summarization framework that aligns outputs with explicit user personas to support personalized purchase decisions. Our approach integrates a high-quality data pipeline built from the Amazon 2023 Review Dataset with a two-stage alignment procedure: (1) persona-aware Supervised Fine-Tuning (SFT) via asymmetric knowledge distillation, and (2) Reinforcement Learning with AI Feedback (RLAIF) using a preference estimator to capture fine-grained, persona-relevant signals. We evaluate the model across rule-based, LLM-based, and human-centered metrics, demonstrating consistent improvements in consistency, grounding, and preference alignment. Our framework achieves the highest performance across all evaluation settings and generalizes effectively to unseen product categories. Our results highlight the promise of steerable pluralistic alignment for building next-generation personalized decision-support systems.|
|**2025-12-12**|[DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry](http://arxiv.org/abs/2512.11558)|null|Reliable interpretation of multimodal data in dentistry is essential for automated oral healthcare, yet current multimodal large language models (MLLMs) struggle to capture fine-grained dental visual details and lack sufficient reasoning ability for precise diagnosis. To address these limitations, we present DentalGPT, a specialized dental MLLM developed through high-quality domain knowledge injection and reinforcement learning. Specifically, the largest annotated multimodal dataset for dentistry to date was constructed by aggregating over 120k dental images paired with detailed descriptions that highlight diagnostically relevant visual features, making it the multimodal dataset with the most extensive collection of dental images to date. Training on this dataset significantly enhances the MLLM's visual understanding of dental conditions, while the subsequent reinforcement learning stage further strengthens its capability for multimodal complex reasoning. Comprehensive evaluations on intraoral and panoramic benchmarks, along with dental subsets of medical VQA benchmarks, show that DentalGPT achieves superior performance in disease classification and dental VQA tasks, outperforming many state-of-the-art MLLMs despite having only 7B parameters. These results demonstrate that high-quality dental data combined with staged adaptation provides an effective pathway for building capable and domain-specialized dental MLLMs.|
|**2025-12-12**|[Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning](http://arxiv.org/abs/2512.11485)|null|Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base of abstracted error patterns. Unlike prior instance/single-trajectory memory methods, MNL uses batch-wise error abstraction: it extracts generalizable guidance from multiple failures, stores insights in a dynamic notebook, and retains only baseline-outperforming guidance via hold-out validation (ensuring monotonic improvement). We show MNL nearly matches Supervised Fine-Tuning (93.9% vs 94.3% on GSM8K) and outperforms training-free alternatives on GSM8K, Spider, AIME, and KaggleDBQA. On KaggleDBQA (Qwen3-8B), MNL hits 28% accuracy (47% relative gain), outperforming Memento (15.1%) and Training-Free GRPO (22.1) - proving it's a strong training-free alternative for complex reasoning.|
|**2025-12-12**|[Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance](http://arxiv.org/abs/2512.11421)|null|Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.   The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.|
|**2025-12-12**|[Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization](http://arxiv.org/abs/2512.11391)|null|As Large Language Models (LLMs) are increasingly deployed in real-world applications, it is important to ensure their behaviors align with human values, societal norms, and ethical principles. However, safety alignment under Reinforcement Learning (RL) often suffers from forgetting learned general abilities, which is also known as the alignment tax. To address this issue, we introduce Null-Space constrained Policy Optimization (NSPO), a novel RL framework for LLM safety alignment while preserving their core abilities. The safety policy gradients are geometrically projected into the null space of general tasks, thereby mitigating the safety alignment tax. In addition, we theoretically prove that NSPO preserves the model's original core capabilities, while still guaranteeing a descent direction for effective safety alignment. Extensive experiments demonstrate that NSPO outperforms existing methods by a large margin, achieving state-of-the-art safety performance without sacrificing accuracy on general tasks, including math, code, and instruction-following tasks. Notably, NSPO is data-efficient and only requires 40% of public human-annotated safety data from PKU-SafeRLHF to achieve promising safety performance, without a large amount of mixed general tasks data in existing alignment methods.|
|**2025-12-12**|[When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents](http://arxiv.org/abs/2512.11277)|null|监督微调（SFT）已成为提高大语言模型（LLMs）在下游任务中性能的最有效方法之一。然而，当底层数据分布发生变化时，即使新数据并未完全超出训练域，SFT 的泛化能力也可能面临困难。最近专注于推理的模型，例如 o1 和 R1，相比其非推理模型展现出持续的提升，凸显了推理对于提高泛化能力和可靠性的重要性。然而，为 SFT 收集高质量的推理轨迹仍然具有挑战性——标注成本高昂、主观性强且难以扩展。为解决这一局限，我们利用强化学习（RL）使模型能够直接从任务结果中学习推理策略。我们提出了一个流程，其中 LLMs 生成推理步骤，以指导工具的调用（例如函数调用）和对话代理的最终答案生成。我们的方法采用组相对策略优化（GRPO），其奖励围绕工具准确性和答案正确性设计，使模型能够迭代地完善其推理和行动。实验结果表明，我们的方法提高了推理质量和工具调用的精度，相比 SFT 模型（未经过显式思考训练）实现了 1.5% 的相对提升，并相比原始 Qwen3-1.7B 模型的基线提升了 40%。这些发现展示了通过 RL 统一推理和行动学习，以构建更强大、更具泛化能力的对话代理的广阔前景。|
|**2025-12-12**|[A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation](http://arxiv.org/abs/2512.11270)|null|Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.|
|**2025-12-11**|[OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification](http://arxiv.org/abs/2512.10756)|null|Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.|
|**2025-12-11**|[Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving](http://arxiv.org/abs/2512.10739)|null|Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \textbf{O}utcome-based \textbf{P}rocess \textbf{V}erifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \textsc{\thisbench}, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\% to 73.3\% on AIME2025 as the compute budget scales.|
|**2025-12-11**|[Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning](http://arxiv.org/abs/2512.10691)|null|Recent advances in vision-language models (VLMs) have improved Chest X-ray (CXR) interpretation in multiple aspects. However, many medical VLMs rely solely on supervised fine-tuning (SFT), which optimizes next-token prediction without evaluating answer quality. In contrast, reinforcement learning (RL) can incorporate task-specific feedback, and its combination with explicit intermediate reasoning ("thinking") has demonstrated substantial gains on verifiable math and coding tasks. To investigate the effects of RL and thinking in a CXR VLM, we perform large-scale SFT on CXR data to build an updated RadVLM based on Qwen3-VL, followed by a cold-start SFT stage that equips the model with basic thinking ability. We then apply Group Relative Policy Optimization (GRPO) with clinically grounded, task-specific rewards for report generation and visual grounding, and run matched RL experiments on both domain-specific and general-domain Qwen3-VL variants, with and without thinking. Across these settings, we find that while strong SFT remains crucial for high base performance, RL provides additional gains on both tasks, whereas explicit thinking does not appear to further improve results. Under a unified evaluation pipeline, the RL-optimized RadVLM models outperform their baseline counterparts and reach state-of-the-art performance on both report generation and grounding, highlighting clinically aligned RL as a powerful complement to SFT for medical VLMs.|
|**2025-12-11**|[AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence](http://arxiv.org/abs/2512.10624)|null|Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.|
|**2025-12-11**|[Multi-Objective Reward and Preference Optimization: Theory and Algorithms](http://arxiv.org/abs/2512.10601)|null|This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.|
|**2025-12-11**|[Grounding Everything in Tokens for Multimodal Large Language Models](http://arxiv.org/abs/2512.10554)|null|Multimodal large language models (MLLMs) have made significant advancements in vision understanding and reasoning. However, the autoregressive Transformer architecture used by MLLMs requries tokenization on input images, which limits their ability to accurately ground objects within the 2D image space. This raises an important question: how can sequential language tokens be improved to better ground objects in 2D spatial space for MLLMs? To address this, we present a spatial representation method for grounding objects, namely GETok, that integrates a specialized vocabulary of learnable tokens into MLLMs. GETok first uses grid tokens to partition the image plane into structured spatial anchors, and then exploits offset tokens to enable precise and iterative refinement of localization predictions. By embedding spatial relationships directly into tokens, GETok significantly advances MLLMs in native 2D space reasoning without modifying the autoregressive architecture. Extensive experiments demonstrate that GETok achieves superior performance over the state-of-the-art methods across various referring tasks in both supervised fine-tuning and reinforcement learning settings.|
|**2025-12-11**|[Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning](http://arxiv.org/abs/2512.10534)|null|Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.|
|**2025-12-11**|[Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention](http://arxiv.org/abs/2512.10414)|null|Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL- based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing stud- ies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ig- nore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the di- versity of responses. In this paper, we propose Selective- adversarial Entropy Intervention, namely SaEI, which en- hances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the en- tropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formu- lates the entropy of sampled responses as an adversarial ob- jective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger an- swer space during RL sampling. Then, we propose token- selective entropy computation (TsEC) to maximize the ef- fectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.|
|**2025-12-11**|[GPG: Generalized Policy Gradient Theorem for Transformer-based Policies](http://arxiv.org/abs/2512.10365)|null|We present the Generalized Policy Gradient (GPG) Theorem, specifically designed for Transformer-based policies. Notably, we demonstrate that both standard Policy Gradient Theorem and GRPO emerge as special cases within our GPG framework. Furthermore, we explore its practical applications in training Large Language Models (LLMs), offering new insights into efficient policy optimization.|
|**2025-12-10**|[FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning](http://arxiv.org/abs/2512.09872)|null|Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.|
|**2025-12-04**|[ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning](http://arxiv.org/abs/2512.05111)|**[link](https://github.com/InternLM/ARM-Thinker)**|奖励模型对于使视觉-语言系统与人类偏好对齐至关重要，然而现有方法存在幻觉、视觉定位能力薄弱以及无法使用工具进行验证等问题，限制了它们在复杂多模态推理任务上的可靠性。我们提出了ARM-Thinker，一个智能体式多模态奖励模型，它能够自主调用外部工具（例如，图像裁剪、文档页面检索），将判断建立在可验证的证据之上，从而取代了静态、非交互式的奖励评分。这使得模型能够验证细粒度视觉细节、交叉引用多页证据并验证推理主张，这些能力是现有奖励模型所不具备的。我们使用多阶段强化学习来训练ARM-Thinker，联合优化工具调用决策和判断准确性。为了评估智能体式奖励模型，我们引入了ARMBench-VL，该基准包含三个子基准，分别评估细粒度视觉定位（图像级工具）、多页文档理解（检索工具）和指令遵循（文本级验证）。ARM-Thinker在奖励模型基准上平均提升了16.2%，在工具使用任务上提升了9.6%，并在多模态数学和逻辑推理基准上优于基线模型。我们的结果表明，智能体能力显著增强了奖励模型的准确性和可解释性。|
|**2025-12-04**|[STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models](http://arxiv.org/abs/2512.05107)|null|在大型语言模型和基于强化学习的微调的推动下，视觉-语言-动作 (VLA) 模型最近的进展在机器人操作方面取得了显著成就。现有方法通常将长时程动作视为语言序列，并应用轨迹级优化方法，例如轨迹偏好优化 (TPO) 或近端策略优化 (PPO)，这导致了粗粒度信用分配和不稳定的训练。然而，与语言不同的是，语言在灵活的句子顺序下仍能保持统一语义，而动作轨迹则通过具有不同学习难度的因果链式阶段逐步进行。这激发了渐进式阶段优化。因此，我们提出了阶段感知强化 (STARE)，这是一个将长时程动作轨迹分解为语义有意义的阶段，并提供密集、可解释且阶段对齐的强化信号的模块。将STARE整合到TPO和PPO中，我们分别得到了用于离线阶段偏好的阶段感知TPO (STA-TPO) 和用于在线阶段内交互的阶段感知PPO (STA-PPO)。在以有监督微调作为初始化的基础上，我们进一步提出了模仿 -> 偏好 -> 交互 (IPI)，这是一个用于提高VLA模型动作准确性的串行微调流程。在SimplerEnv和ManiSkill3上的实验表明取得了显著提升，在SimplerEnv上实现了98.0%的最先进成功率，在ManiSkill3任务上实现了96.4%的最先进成功率。|
|**2025-12-04**|[Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning](http://arxiv.org/abs/2512.05105)|null|大语言模型（LLM）中的长上下文推理已通过思维链（CoT）推理展现出对其认知能力的增强。此类模型的训练通常通过在数学和编程等基于推理的问题中使用基于可验证奖励的强化学习（RLVR）来完成。然而，RLVR受限于几个瓶颈，例如缺乏密集奖励和样本效率不足。因此，它在后训练阶段需要大量的计算资源。为了克服这些限制，在这项工作中，我们提出了语义软自举（SSB），这是一种自蒸馏技术，其中相同的基本语言模型同时扮演教师和学生的角色，但在训练时接收关于其结果正确性的不同语义上下文。模型首先被提示一个数学问题，并生成多个推演。从中筛选出正确响应和最常见的错误响应，然后在上下文中提供给模型，以生成一个更鲁棒、逐步的解释以及一个经过验证的最终答案。该流程无需任何人工干预，即可从原始问题-答案数据中自动筛选出配对的教师-学生训练集。这种生成过程还会产生一个logits序列，这是学生模型在训练阶段仅凭问题本身尝试匹配的目标。在我们的实验中，我们对GSM8K数据集上的Qwen2.5-3B-Instruct模型进行了参数高效微调。然后，我们测试了其在MATH500和AIME2024基准上的准确率。我们的实验表明，与常用的RLVR算法群体相对策略优化（GRPO）相比，准确率分别提高了10.6%和10%。我们的代码可在https://github.com/purbeshmitra/semantic-soft-bootstrapping获取，模型和筛选数据集可在https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping获取。|
|**2025-12-04**|[SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards](http://arxiv.org/abs/2512.05098)|null|近年来，针对人工智能生成图像（AIGI）的图像质量评估（IQA）发展迅速；然而，现有方法主要针对人像和艺术图像，缺乏对室内场景的系统评估。我们引入了空间美学（Spatial Aesthetics），这是一种从布局、协调性、光照和失真四个维度评估室内图像美学质量的范式。我们构建了SA-BENCH，这是首个空间美学基准，包含18,000张图像和50,000条精确标注。利用SA-BENCH，我们系统地评估了当前的IQA方法，并通过多模态大语言模型（MLLM）微调和多维度融合方法开发了SA-IQA，作为一个评估空间美学的综合奖励框架。我们将SA-IQA应用于两个下游任务：(1) 作为奖励信号与GRPO强化学习结合，以优化AIGC生成流程，以及 (2) 进行N选一（Best-of-N）选择，以筛选高质量图像并提高生成质量。实验表明，SA-IQA在SA-BENCH上显著优于现有方法，为空间美学评估树立了新标准。代码和数据集将开源，以推动该领域的研究和应用。|
|**2025-12-04**|[EtCon: Edit-then-Consolidate for Reliable Knowledge Editing](http://arxiv.org/abs/2512.04753)|null|知识编辑旨在无需进行完全重训练的情况下更新大语言模型（LLMs）中的特定事实。此前的研究致力于调整LLMs的知识层，被证明对选择性编辑有效。然而，在受控的、教师引导式评估中的表现与在终身学习场景中的真实世界有效性之间存在显著差距，这极大地限制了它们的实际应用性。本工作的实证分析揭示了与这一差距相关的两个反复出现的问题：（1）大多数传统方法导致编辑后的模型过度拟合新事实，从而损害预训练能力；（2）缺乏关键的知识整合阶段，导致新事实在自回归生成下未能充分整合到LLMs的推理时行为中，从而导致参数知识与实际生成行为之间不匹配。为此，我们提出了“编辑-整合”（Edit-then-Consolidate）这一新颖的知识编辑范式，旨在弥合理论知识编辑方法与其实际世界适用性之间的差距。具体而言，（1）我们的框架通过目标近端监督微调（TPSFT）来缓解过拟合，该方法通过信赖域目标局部化编辑以限制策略漂移；（2）接着，一个使用组相对策略优化（GRPO）的整合阶段通过在全面的奖励信号下优化轨迹级行为，使编辑后的知识与基于CoT的推理策略对齐。大量实验表明，在真实世界评估中，我们的框架持续改进了编辑可靠性和泛化能力，同时更好地保留了局部性和预训练能力。|
|**2025-12-04**|[RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting](http://arxiv.org/abs/2512.04752)|null|人类反馈强化学习 (RLHF) 是一种用于大型语言模型 (LLMs) 的重要微调技术，包含生成、推理和训练三个阶段。生成阶段生成样本，这些样本随后用于推断可学习经验以进行训练。我们观察到生成阶段是整个执行过程的瓶颈，并将其视为优化的关键点。具体来说，我们首次尝试将推测解码集成到RLHF生成阶段，并提出了RLHFSpec，这是一个通过自适应推测解码和样本重新分配来加速生成执行的RLHF系统。为了充分发挥推测解码所提供的性能潜力，特别是处理生成阶段的动态工作负载，RLHFSpec提出了一种工作负载感知的草稿策略选择机制，该机制通过联合考虑验证成本和接受的token数量来选择接近最优的策略。此外，RLHFSpec还提出样本重新分配以充分利用GPU资源，并通过高效的样本迁移机制对其进行优化。实验结果表明，与最先进的工作相比，RLHFSpec能够在生成阶段实现更高的吞吐量。此外，由于有效缓解了生成瓶颈，RLHFSpec在整个RLHF执行中也表现出显著的性能加速。|
|**2025-12-04**|[TRINITY: An Evolved LLM Coordinator](http://arxiv.org/abs/2512.04695)|null|结合多样化的基础模型很有前景，但权重合并受限于架构不匹配和封闭的API。Trinity通过一个轻量级协调器解决了这个问题，该协调器协调大型语言模型（LLM）之间的协作。该协调器由一个紧凑型语言模型（约6亿参数）和一个轻量级头部（约1万参数）组成，通过进化策略进行优化，以实现高效和自适应的委托。Trinity通过多轮处理查询，在每一轮中，协调器将三种角色之一（思考者、工作者或验证者）分配给选定的LLM，有效地将复杂技能的学习从协调器本身卸载。实验表明，Trinity在编码、数学、推理和领域知识任务中始终优于单个模型和现有方法，并对分布外任务具有强大的泛化能力。在标准基准测试中，Trinity取得了最先进的结果，包括在LiveCodeBench上达到86.2%的得分。理论和实证分析确定了这一性能背后的两个主要因素：(1) 协调器的隐藏状态表示提供了丰富的输入上下文信息，以及 (2) 在高维度和严格预算约束下，可分离的协方差矩阵自适应进化策略通过利用潜在的块-epsilon可分离性，相比强化学习、模仿学习和随机搜索具有优势。|
|**2025-12-04**|[COOPER: A Unified Model for Cooperative Perception and Reasoning in Spatial Intelligence](http://arxiv.org/abs/2512.04563)|**[link](https://github.com/zhangzef/COOPER)**|视觉空间推理对于使多模态大语言模型（MLLM）理解物体属性和空间关系至关重要，但当前模型在3D感知推理方面仍然面临挑战。现有方法通常通过使用深度和分割等辅助模态增强RGB输入来提升感知能力，或者通过在空间VQA数据集上训练并应用强化学习来增强推理能力，因此将这两个方面孤立处理。在这项工作中，我们研究了统一的MLLM是否能够发展出一种内在能力，以增强空间感知，并通过自适应的交错推理实现更强的空间智能。我们提出了COOPER，一个统一的MLLM，它利用深度和分割作为辅助模态，并分两个阶段进行训练，以获得辅助模态生成和自适应交错推理能力。COOPER在保持通用性能的同时，实现了空间推理平均6.91%的提升。此外，即使是仅为辅助模态生成而训练的变体，也在距离和尺寸估计上取得了7.92%的提升，这表明学习生成辅助模态有助于内化空间知识并增强空间理解。|
|**2025-12-04**|[GTM: Simulating the World of Tools for AI Agents](http://arxiv.org/abs/2512.04535)|null|外部工具的集成对于赋予大型语言模型（LLM）智能体真实世界的能力至关重要。然而，通过与各种工具进行直接、持续的交互来训练这些智能体通常成本过高、速度缓慢，并会带来额外的开发和维护开销。为了应对这一挑战，我们引入了通用工具模型（GTM），这是一个拥有15亿参数的模型，它学习充当一个通用工具模拟器。GTM仅通过提示级配置即可访问工具功能及输入参数，并生成忠实模拟真实工具执行的输出，提供了一种快速且经济高效的解决方案，消除了开发开销。为了构建GTM，我们提出了上下文感知响应生成（CARG）流水线，该流水线合成了涵盖物理、医学、机器人和金融等300多个领域、20,000多种工具的综合训练数据。通过该流水线，GTM不仅学会生成语法正确的输出，还能生成逻辑连贯且上下文适当的响应。实验表明，GTM能生成高质量的输出，并具有强大的一致性和可靠性。此外，当GTM用于智能体训练的真实强化学习场景时，与真实工具相比，它展现出显著更快的模拟速度，同时保持了可比的输出质量，并具有卓越的泛化能力和领域适应性。我们的研究结果确立了GTM作为开发未来AI智能体的基础组件，从而能够高效且可扩展地训练工具增强型系统。|
|**2025-12-04**|[Towards 6G Native-AI Edge Networks: A Semantic-Aware and Agentic Intelligence Paradigm](http://arxiv.org/abs/2512.04405)|null|迈向第六代无线系统（6G）的演进将智能定位为一种原生网络能力，从根本上改变了无线接入网络（RAN）的设计。在这一愿景中，语义原生通信（SemCom）和智能体智能有望发挥核心作用。语义原生通信（SemCom）摆脱了比特级保真度，转而强调面向任务的意义交换，从而实现紧凑的语义通信，并引入了语义保真度和任务成功率等新的性能指标。智能体智能赋予分布式RAN实体目标驱动的自主性、推理、规划和多智能体协作能力，并日益得到基础模型和知识图谱的支持。在这项工作中，我们首先介绍了语义原生通信和智能体网络的概念基础，并讨论了为什么现有的AI驱动的O-RAN解决方案仍然主要以比特为中心且任务孤立。随后，我们提出了一个统一的分类法，沿三个维度组织了近期研究：i) 语义抽象级别（符号/特征/意图/知识），ii) 智能体自主性和协调粒度（单智能体、多智能体和分层智能体），以及iii) RAN控制在物理层/MAC层、近实时RIC和非实时RIC之间的部署。基于此分类法，我们系统地介绍了关键使能技术，包括面向任务的语义编解码器、多智能体强化学习、基础模型辅助的RAN智能体，以及用于跨层感知的基于知识图谱的推理。本文分析了沉浸式XR、车载V2X和工业数字孪生等典型的6G用例，以说明语义-智能体融合在实践中的应用。最后，我们指出了语义表示标准化、可扩展可信的智能体协调、O-RAN互操作性和节能AI部署等方面的开放挑战，并概述了实现可操作的语义-智能体AI-RAN的研究方向。|
|**2025-12-02**|[OneThinker: All-in-one Reasoning Model for Image and Video](http://arxiv.org/abs/2512.03043)|**[link](https://github.com/isLinXu/OneThinker)**|强化学习（RL）最近在激发多模态大语言模型（MLLM）的视觉推理能力方面取得了显著成功。然而，现有方法通常为不同任务训练独立的模型，并将图像和视频推理视为不相交的领域。这导致了多模态推理通才模型的可扩展性有限，从而限制了实际应用的多功能性并阻碍了任务和模态间的潜在知识共享。为此，我们提出了OneThinker，一个一体化的推理模型，它统一了图像和视频在各种基本视觉任务上的理解，包括问答、图像描述、空间和时间定位、跟踪以及分割。为实现这一目标，我们构建了OneThinker-600k训练语料库，涵盖所有这些任务，并利用商业模型进行CoT（思维链）标注，从而产生了用于SFT（监督微调）冷启动的OneThinker-SFT-340k。此外，我们提出了EMA-GRPO，通过跟踪任务奖励标准差的指数移动平均值来实现平衡优化，以处理多任务强化学习中的奖励异质性。在各种视觉基准上进行的大量实验表明，OneThinker在10个基本视觉理解任务的31个基准测试中表现出色。此外，它在某些任务之间展示了有效的知识迁移和初步的零样本泛化能力，标志着向统一多模态推理通才模型迈出了一步。所有代码、模型和数据均已发布。|
|**2025-12-02**|[LORE: A Large Generative Model for Search Relevance](http://arxiv.org/abs/2512.03025)|null|我们提出LORE，一个用于基于大型生成模型（LGM）的电商搜索相关性的系统性框架。经过三年多的部署和迭代，LORE在线上好评率（GoodRate）指标上实现了累计27%的提升。本报告分享了在其整个开发生命周期中获得的宝贵经验，涵盖数据、特征、训练、评估和部署。尽管现有工作应用思维链（CoT）来提升相关性，但它们常常达到性能瓶颈。我们认为这源于将相关性视为一个单一任务，缺乏原则性的解构。我们的关键见解是，相关性包含着不同的能力：知识与推理、多模态匹配和规则遵循。我们认为，定性驱动的分解对于突破当前性能瓶颈至关重要。LORE为大语言模型（LLM）相关性生命周期提供了一个完整的蓝图。主要贡献包括：(1) 一个两阶段训练范式，结合通过SFT进行的渐进式思维链合成与通过RL进行的人类偏好对齐。(2) 一个综合性基准RAIR，旨在评估这些核心能力。(3) 一个查询频率分层部署策略，能够有效地将离线LLM能力迁移到在线系统。LORE既是一个实用解决方案，也为其他垂直领域提供了方法论参考。|
|**2025-12-02**|[MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm](http://arxiv.org/abs/2512.02895)|null|我们提出MindGPT-4ov，这是一种引入了涵盖数据生产、模型训练和高效部署的通用后训练范式的多模态大语言模型（MLLM）。它以低成本在多个基准测试中实现了最先进的性能，有效提升了MLLM的基础能力和泛化能力。本工作聚焦于数据构建、有监督微调策略和多模态强化学习方法，提出了三项关键创新：(1) 一种基于信息密度的数据生成方案，结合双维度树状标签系统，实现了高质量跨领域数据的自动化生成。(2) 一种协同课程有监督微调方法，平衡了领域特定知识的注入与通用能力的保持。(3) 一种混合强化学习范式，在提升推理能力的同时，解决了多样性探索、多模态感知维持和响应简洁性等多目标优化问题。此外，我们实施了一系列基础设施优化，例如5D并行训练、算子优化和推理量化，以提高训练和推理效率，同时降低领域适应成本。实验结果表明，MindGPT-4ov模型在MMBench、MMStar、MathVision和MathVista等基准测试中超越了最先进的模型。此外，MindGPT-4ov还在垂直领域任务中展示了卓越的用户体验，实现了从学术研究到工业部署的无缝过渡。MindGPT-4ov提供了一种适用于广泛MLLM的通用后训练范式。基于Qwen3-VL变体的模型权重、数据集和代码将近期开源，以支持社区开发MLLM。|
|**2025-12-02**|[OptPO: Optimal Rollout Allocation for Test-time Policy Optimization](http://arxiv.org/abs/2512.02882)|null|测试时策略优化使大型语言模型 (LLM) 能够通过利用自生成轨迹的反馈来适应分布偏移。然而，现有方法依赖固定预算的多数投票来估计奖励，导致大量的计算冗余。我们提出了测试时策略优化的最优轨迹分配 (OptPO)，一个原则性框架，能够自适应地分配推理预算。通过将投票过程形式化为贝叶斯序贯概率比检验，OptPO 在共识答案的后验置信度超过指定阈值时动态停止采样。至关重要的是，它利用保留的轨迹进行在线策略更新，无缝集成到 PPO 或 GRPO 等算法中，而无需真实标签。在各种推理基准上，与固定采样基线相比，OptPO 显著减少了轨迹开销，同时保持或提高了准确性。通过将统计最优停止与测试时学习相结合，OptPO 为测试时适应提供了一种计算高效的范式。源代码将在接收后公开，地址为 https://open-upon-acceptance。|
|**2025-12-02**|[ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning](http://arxiv.org/abs/2512.02835)|null|以推理为中心的视频目标分割本质上是一项复杂的任务：查询通常涉及动态、因果关系和时间交互，而非静态外观。然而，现有解决方案通常将这些因素归结为使用潜在嵌入的简化推理，使得推理链不透明且本质上难以处理。因此，我们采用显式分解的视角，并引入ReVSeg，它在预训练视觉语言模型（VLM）的原生接口中将推理作为顺序决策执行。ReVSeg没有将所有推理折叠成一步预测，而是执行三个显式操作——语义解释、时间证据选择和空间定位——从而与预训练能力对齐。我们进一步采用强化学习来优化多步推理链，使模型能够根据结果驱动信号自我完善其决策质量。实验结果表明，ReVSeg在标准视频目标分割基准上取得了最先进的性能，并产生了可解释的推理轨迹。项目页面可在https://clementine24.github.io/ReVSeg/访问。|
|**2025-12-02**|[Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach](http://arxiv.org/abs/2512.02834)|**[link](https://github.com/breez3young/TACO)**|通过流匹配或扩散目标训练的视觉-语言-动作 (VLA) 模型，擅长从大规模多模态数据集（例如人类遥操作、脚本策略）中学习复杂行为。然而，由于VLA在预训练阶段整合了多样化的数据模式，且微调数据集通常包含以运动学次优或不理想方式收集的演示数据，导致存在与下游任务成功动作模式无关的冗余动作模式。具体来说，在对预训练VLA进行监督微调之后，我们观察到各种采样噪声之间存在关键的推理时脆弱性。在本文中，我们将这种不稳定性归因于VLA策略与下游任务数据集中稳定成功模式所诱导的策略之间的分布漂移。因此，我们提出了TACO，这是一个测试时缩放 (TTS) 框架，它应用轻量级的伪计数估计器作为动作块的高保真验证器。集成TACO的VLA模型可以从所有采样的动作块中执行具有最大伪计数的动作，从而防止分布漂移，同时由于该约束仅在推理期间应用，因此保留了VLA的泛化能力。我们的方法类似于离线强化学习 (RL) 中的经典反探索原则，并且由于是无梯度的，与RL更新相比带来了显著的计算优势，特别是对于由于去噪过程而难以执行RL更新的基于流或扩散的VLA。在四个仿真基准 (RoboTwin2.0, Robotwin, LIBERO, SimplerEnv) 和一个双臂平台上进行的大量实验表明，我们的方法显著提高了下游任务适应中的推理稳定性和成功率。|
|**2025-12-02**|[Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms](http://arxiv.org/abs/2512.02810)|null|建筑自动化中的多机器人任务分配传统上依赖于动态规划和强化学习等优化方法。本研究引入了基于LangGraph的任务分配代理（LTAA），这是一个由大型语言模型（LLM）驱动的框架，它集成了阶段自适应分配策略、带分层重试的多阶段验证以及动态提示，以实现高效的机器人协调。尽管最近的LLM方法在建筑机器人领域显示出潜力，但它们在很大程度上缺乏与已有的算法进行严格验证和基准测试。本文首次系统地比较了建筑场景中基于LLM的任务分配与传统方法。该研究通过SMART-LLM复现验证了LLM的可行性，并利用自修正代理架构解决了实施挑战。LTAA利用自然语言推理结合结构化验证机制，通过动态提示实现了显著的计算增益，将token使用量减少了94.6%，分配时间减少了86%。该框架在不同阶段调整其策略：在早期强调执行可行性，在后续分配中强调工作负载平衡。作者利用TEACh人机协作数据集中的建筑操作，将LTAA与动态规划、Q学习和深度Q网络（DQN）基线进行了评估。在机器人具有很强任务专业化能力的“重度擅长”（Heavy Excels）设置中，LTAA实现了77%的任务完成率，且工作负载平衡性更优，超越了所有传统方法。这些发现表明，结合结构化验证的基于LLM的推理可以与已有的优化算法相媲美，同时提供额外的优势，例如可解释性、适应性以及无需重新训练即可更新任务逻辑的能力。|
|**2025-12-02**|[SR-GRPO: Stable Rank as an Intrinsic Geometric Reward for Large Language Model Alignment](http://arxiv.org/abs/2512.02807)|null|将大语言模型（LLM）与人类偏好对齐通常依赖于外部监督，但这面临着严峻的局限性：人工标注稀缺且主观，奖励模型容易受到奖励欺骗的影响，而自我评估方法则存在提示敏感性和偏差。在这项工作中，我们提出稳定秩，这是一种从模型表示中提取的内在的、无标注的质量信号。稳定秩通过计算总方差与主导方向方差之比来衡量隐藏状态的有效维度，从而通过信息在表示维度中的分布方式来捕捉质量。经验表明，稳定秩在RewardBench上达到了84.04%的准确率，并通过N选1采样相较于贪婪解码，平均将任务准确率提高了11.3个百分点。利用这一见解，我们引入了稳定秩群组相对策略优化（SR-GRPO），它使用稳定秩作为强化学习的奖励信号。在没有外部监督的情况下，SR-GRPO将Qwen2.5-1.5B-Instruct在STEM任务上的性能提高了10%，在数学推理任务上提高了19%，优于学习到的奖励模型和自我评估基线。我们的研究结果表明，质量信号可以从内部模型几何中提取，为无需外部监督的可扩展对齐提供了一条途径。|
|**2025-12-02**|[RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning](http://arxiv.org/abs/2512.02729)|null|我们引入了Robowheel，这是一种数据引擎，能将人手与物体交互 (HOI) 视频转换为可用于跨形态机器人学习的训练监督信号。通过单目RGB或RGB-D输入，我们执行高精度HOI重建，并通过一个强化学习 (RL) 优化器来强制实现物理合理性，该优化器在接触和穿透约束下精炼手与物体的相对姿态。然后，我们将重建的、富含接触信息的轨迹重定向到跨形态机器人，包括带有简单末端执行器的机器人手臂、灵巧手和人形机器人，从而产生可执行的动作和轨迹。为了扩大覆盖范围，我们在Isaac Sim上构建了一个模拟增强框架，该框架具有多样化的领域随机化（形态、轨迹、物体检索、背景纹理、手部动作镜像），这在保持空间关系和物理合理性的同时，丰富了轨迹和观测的分布。整个数据管线形成了一个从视频、重建、重定向到增强数据采集的端到端管线。我们在主流视觉语言动作 (VLA) 和模仿学习架构上验证了这些数据，结果表明我们管线生成的轨迹与遥操作产生的轨迹一样稳定，并能带来相当的持续性能提升。据我们所知，这首次提供了定量证据，表明HOI模态可以作为机器人学习的有效监督信号。与遥操作相比，Robowheel是轻量级的，单个单目RGB(D)相机足以提取通用的、与形态无关的运动表示，这种表示可以在不同形态之间灵活重定向。我们进一步整合了一个大规模多模态数据集，结合了多相机捕捉、单目视频和公开HOI语料库，用于训练和评估具身模型。|
|**2025-12-02**|[Beyond N-grams: A Hierarchical Reward Learning Framework for Clinically-Aware Medical Report Generation](http://arxiv.org/abs/2512.02710)|null|自动医学报告生成可以大幅减轻医生工作量，但在实际部署中往往不可靠。当前方法能写出语法流畅的句子，但可能存在事实错误，引入严重的医疗错误，即临床幻觉，这使其在诊断中不可信。为弥合这一差距，我们引入了HiMed-RL，一个分层医学奖励学习框架，旨在明确优先考虑临床质量。HiMed-RL超越了简单的文本匹配，通过将奖励学习分解为三个协同级别：它首先在词元级别确保语言流畅性，接着在概念级别通过将关键医学术语与专家知识对齐来强制实施事实基础，最后在语义级别使用专门的LLM验证器评估高级诊断一致性。这种分层奖励通过一种受人类启发动态奖励调整策略实现，该策略首先教模型学习基本事实，然后才进展到更复杂的诊断推理。实验上，HiMed-3B在域内和域外基准测试中均取得了最先进的性能，尤其是在后者上，比次优基线提高了12.1%。我们的工作提供了一个鲁棒的范式，用于生成不仅提高流畅性而且提高临床细粒度质量的报告。|
|**2025-11-28**|[Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models](http://arxiv.org/abs/2511.23478)|**[link](https://github.com/mbzuai-oryx/Video-R2)**|对动态视觉内容进行推理仍然是多模态大语言模型面临的核心挑战。近期的思维模型为可解释性生成显式推理轨迹；然而，它们的推理虽然看起来令人信服，但往往在逻辑上不一致或视觉证据基础薄弱。我们通过两个诊断性指标识别并形式化了这些问题：思维-答案一致性 (TAC)，它衡量推理与答案之间的一致性；以及视频注意力分数 (VAS)，它捕捉推理对视觉线索与文本线索的依赖程度。对11个视频推理基准的分析表明，当前模型严重依赖语言先验知识而非视觉内容。为解决此问题，我们提出了一种强化学习方法，该方法可提高时间精度和推理一致性。我们的方法将时间戳感知监督微调与由新型时间对齐奖励 (TAR) 指导的群体相对策略优化 (GRPO) 相结合。这一双步骤后训练阶段鼓励实现时间对齐且因果连贯的视频推理。得到的模型Video R2在多个基准测试中持续实现了更高的TAC、VAS和准确性，这表明时间对齐和推理连贯性的改进能够带来更准确、更可信的视频理解。我们的代码、数据集和模型将开源。|
|**2025-11-28**|[Video-CoM: Interactive Video Reasoning via Chain of Manipulations](http://arxiv.org/abs/2511.23477)|**[link](https://github.com/mbzuai-oryx/Video-CoM)**|近期的多模态大语言模型 (MLLMs) 提升了视频理解能力，但大多数模型仍然“思考视频”，即一旦视频被编码，推理就完全在文本中展开，将视觉输入视为静态上下文。这种被动范式造成了语义瓶颈：模型无法重看、重新聚焦或验证证据，从而导致在需要细粒度时空理解的任务上视觉推理能力肤浅。在这项工作中，我们提出了交互式视频推理，这是一种新范式，它将视频转化为一个主动的认知工作空间，使模型能够“与视频共同思考”。我们的模型Video CoM通过一系列操作 (Chain of Manipulations, CoM) 进行推理，执行迭代的视觉动作来收集和完善证据。为支持这种行为，我们构建了Video CoM Instruct，这是一个包含1.8万个指令的指令微调数据集，专为多步操作推理而策划。除了监督学习，我们还通过强化学习，采用推理感知的组相对策略优化 (Group Relative Policy Optimization, GRPO) 来进一步优化操作策略。与以往仅依赖稀疏答案奖励的工作不同，我们的方法引入了步级推理奖励，引导模型进行有依据且一致的推理。Video CoM 在九个视频推理基准测试中取得了优异结果，将平均性能比近期最先进模型提升了3.6%，同时仅使用了2.5万个SFT和3千个GRPO视频样本进行训练，显著少于同类大型模型。消融研究表明，推理感知奖励提高了准确性和可解释性。代码：https://github.com/mbzuai-oryx/Video-CoM|
|**2025-11-28**|[ThetaEvolve: Test-time Learning on Open Problems](http://arxiv.org/abs/2511.23473)|**[link](https://github.com/ypwang61/ThetaEvolve)**|大型语言模型（LLM）的最新进展使数学发现取得了突破，例如AlphaEvolve，一个通过演化程序来改进开放问题界限的闭源系统。然而，它依赖于前沿LLM的集成来达到新的界限，并且是一个纯推理系统，模型无法内化其演化策略。我们引入了ThetaEvolve，一个开源框架，它简化并扩展了AlphaEvolve，以在测试时高效地扩展上下文学习和强化学习（RL），使模型能够从其改进开放优化问题的经验中持续学习。ThetaEvolve具有单个LLM、用于增强探索的大型程序数据库、用于提高吞吐量的批处理采样、用于阻止停滞输出的惰性惩罚以及用于稳定训练信号的可选奖励整形等特点。ThetaEvolve是第一个能够使小型开源模型（如DeepSeek-R1-0528-Qwen3-8B）在AlphaEvolve中提到的开放问题（圆堆积和第一自相关不等式）上取得新的已知最佳界限的演化框架。此外，在两个模型和四个开放任务中，我们发现，在测试时结合RL的ThetaEvolve始终优于仅推理的基线，并且模型确实学习了演化能力，因为经过RL训练的检查点在训练过的目标任务和其他未见任务上都表现出更快的进展和更好的最终性能。我们已公开我们的代码：https://github.com/ypwang61/ThetaEvolve|
|**2025-11-28**|[Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent](http://arxiv.org/abs/2511.23436)|null|我们介绍了 SuperIntelliAgent，一个智能体学习框架，它将一个可训练的小型扩散模型（学习器）与一个冻结的大型语言模型（验证器）相结合，以实现智能通过持续的自监督交互而不断增长。与传统的监督微调不同，SuperIntelliAgent 无需标注即可自主学习：学习器生成候选输出，验证器通过逐步推理评估这些输出，它们的交互产生用于直接偏好优化（DPO）的选中/拒绝对。这将每个输入转换为一个伪训练信号，用于持续改进。该框架集成了双尺度记忆：短期语境记忆，用于在细化循环中保留推理痕迹；以及长期记忆，通过轻量级即时微调来巩固习得的知识。一个回放缓冲区保留显示可验证进度的样本，并将它们作为辅助监督进行回放，从而在形成自适应课程的同时强化最近的学习。SuperIntelliAgent 是与基础设施无关的，并且可以插入到现有的智能体框架中，同时将普通的推理循环转化为一个终身优化过程。我们认为，将可训练的学习器与具备推理能力的验证器配对，构成了不断增长的智能的最小可靠单元，因为配对反馈和部分历史回放能产生更丰富的学习课程和更强的偏好对齐。仅用少量自动生成的 DPO 对，学习器在所有基准测试中均有所改进，这表明该机制为持续智能积累和实际部署提供了一个有前景的方向。|
|**2025-11-28**|[OBLR-PO: A Theoretical Framework for Stable Reinforcement Learning](http://arxiv.org/abs/2511.23310)|null|现有的基于强化学习（RL）的大语言模型后训练方法发展迅速，但其设计主要依靠启发式方法而非系统的理论原则。这一空白限制了我们对梯度估计器性质以及相关优化算法的理解，从而制约了提高训练稳定性和整体性能的机会。在这项工作中，我们提出了一个统一的理论框架，在温和假设下描述了常用策略梯度估计器的统计特性。我们的分析确立了无偏性，推导了精确的方差表达式，并得到了一个优化损失上界，使得能够对学习动力学进行有原则的推理。基于这些结果，我们证明了收敛性保证，并推导了一个由梯度的信噪比（SNR）控制的自适应学习率调度。我们进一步表明，方差最优基线是一个梯度加权估计器，为方差减少提供了一个新原则，并自然地增强了现有方法之外的稳定性。这些见解促使我们提出了优化基线和学习率策略优化（OBLR-PO），该算法以理论为基础，联合调整学习率和基线。在Qwen3-4B-Base和Qwen3-8B-Base上的实验证明了相对于现有策略优化方法的持续改进，验证了我们的理论贡献在大规模后训练中带来了实际改进。|
|**2025-11-28**|[Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning](http://arxiv.org/abs/2511.23262)|null|近期的视觉-语言模型（VLMs）展现出强大的感知推理能力，然而，它们在测试时遇到新任务时常常难以高效适应。相比之下，人类利用带有记忆的元认知模型，当面对新挑战时，通过元认知控制实现持续的策略优化。为了弥合这一差距，我们提出了元认知测试时推理（MCTR），一个赋予模型在测试时通过元认知自我更新来学习、适应和改进能力的框架。受人类元认知双重结构的启发，MCTR包含元级别和对象级别的视觉-语言模型推理模块，每个模块都配备了专用的记忆系统，用于分层自适应推理。具体来说，MCTR包括 (1) 一个元推理模块，该模块通过发现和存储从测试时观察中以自然语言描述形式的任务相关规则、环境模式以及行动-结果关系，增量地构建结构化记忆；以及 (2) 一个行动推理模块，该模块通过动态检索和整合记忆中的知识，通过上下文感知和策略推理来确定最优行动。行动推理模块通过我们提出的元认知测试时强化学习持续更新其策略，并随着知识记忆的演变而进行适应。我们在45个雅达利游戏（33个已见，12个未见）上评估了MCTR。MCTR展现出强大的测试时适应能力，与基线相比，在未见游戏上取得了9/12的top-1结果。通过消融实验、学习动态和案例研究进行的分析揭示了两个组件的互补贡献，并表明元推理正朝着类人适应策略演进。|
|**2025-11-28**|[Obstruction reasoning for robotic grasping](http://arxiv.org/abs/2511.23186)|null|在杂乱环境中成功的机器人抓取，不仅需要模型能够视觉定位目标物体，还需要推理必须预先清除的障碍物。尽管当前的视觉-语言具身推理模型展现出涌现的空间理解能力，但在障碍物推理和可达性规划方面仍然存在局限。为了弥补这一差距，我们提出了UNOGrasp，一个基于学习的视觉-语言模型，能够执行视觉定位的障碍物推理，以推断清除路径障碍并抓取目标物体所需的行动序列。我们设计了一种新颖的多步推理过程，该过程基于源自目标物体的障碍物路径。我们通过障碍物感知的视觉线索来支撑每个推理步骤，以激励模型的推理能力。UNOGrasp通过可验证的推理奖励结合了监督学习和强化学习微调。此外，我们构建了UNOBench，一个基于MetaGraspNetV2的大规模数据集，用于训练和基准测试，该数据集包含超过10万条经人工标注的障碍物路径，其中包含障碍物比例、接触点和自然语言指令。大量实验和真实机器人评估表明，UNOGrasp在合成环境和真实世界环境中均显著提高了障碍物推理和抓取成功率，优于通用和专有替代方案。项目网站：https://tev-fbk.github.io/UnoGrasp/。|
|**2025-11-28**|[REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection](http://arxiv.org/abs/2511.23158)|null|生成模型的快速发展使得视觉上逼真的AI生成图像越来越难以与真实图像区分，这对社会信任和信息完整性构成了严重威胁。因此，迫切需要高效且真正可解释的图像取证方法。近期检测范式已转向可解释取证。然而，最先进的方法主要依赖事后合理化或视觉判别，缺乏可验证的证据链。这种对表层模式匹配的依赖限制了因果解释的生成，并且通常导致泛化能力差。为了弥补这一关键差距，我们引入了REVEAL-Bench，这是第一个用于AI生成图像检测的增强推理多模态基准，它明确围绕源自多个轻量级专家模型的证据链构建，并记录了逐步推理轨迹和证据性论证。基于此数据集，我们提出了REVEAL（增强推理的取证证据分析），这是一种有效且可解释的取证框架，将检测与一种新颖的专家驱动强化学习相结合。我们的奖励机制经过专门设计，旨在联合优化检测准确性、解释保真度和基于明确取证证据的逻辑连贯性，使REVEAL能够在生成检测结果的同时，产生细粒度、可解释和可验证的推理链。大量实验结果表明，REVEAL显著提升了检测准确性、解释保真度和鲁棒的跨模型泛化能力，为可解释图像取证树立了新的技术标杆。|
|**2025-11-28**|[Evolutionary Discovery of Heuristic Policies for Traffic Signal Control](http://arxiv.org/abs/2511.23122)|null|交通信号控制（TSC）涉及一个具有挑战性的权衡：经典启发式算法效率高但过于简化，而深度强化学习（DRL）性能高但泛化能力差且策略不透明。在线大型语言模型（LLMs）提供通用推理能力，但延迟高且缺乏针对特定环境的优化。为了解决这些问题，我们提出了交通时序策略演化（\method{}），它使用LLM作为演化引擎来推导专门的启发式策略。该框架引入了两个关键模块：（1）结构化状态抽象（SSA），将高维交通数据转换为用于推理的时序逻辑事实；（2）信用分配反馈（CAF），将有缺陷的微观决策追溯到不良的宏观结果，以进行有针对性的批评。\method{}完全在提示级别操作，无需训练，产生针对特定交通环境优化的轻量级、鲁棒的策略，其性能优于启发式算法和在线LLM执行器。|
|**2025-11-28**|[From Illusion to Intention: Visual Rationale Learning for Vision-Language Reasoning](http://arxiv.org/abs/2511.23031)|null|视觉语言推理的最新进展强调了图像思考的重要性，其中模型主动将其推理建立在视觉证据之上。然而，现有框架将视觉操作视为可选工具，尽管能提升指标，却使得推理缺乏依据，并且裁剪操作无效。这一差距导致了图像思考的错觉：模型似乎在视觉上有所依据，但却依赖于与上下文无关的操作，这些操作既不能提升感知，也不能引导推理得出正确答案。我们通过将视觉操作重新定义为核心推理原语而非可选工具来解决此问题，我们将其称为视觉合理化，即文本思维链的视觉类比。基于这一洞察，我们提出了视觉合理化学习（ViRL），这是一种将训练建立在视觉合理化本身之上的端到端范式。ViRL集成了（1）带有真值合理化的过程监督，（2）通过步骤级奖励塑形实现目标对齐，以及（3）细粒度信用分配，以区分正确、冗余和错误的操作。通过确保每个操作都对推理链做出有意义的贡献，ViRL使模型能够“基于正确的视觉原因得出正确答案”。纯粹通过端到端强化学习进行训练，ViRL在涵盖感知、幻觉和推理的基准测试中取得了最先进的结果。这项工作将视觉合理化确立为一种与任务无关、以过程为基础的范式，用于构建透明、可验证和值得信赖的视觉语言模型。|
|**2025-11-26**|[ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration](http://arxiv.org/abs/2511.21689)|null|大语言模型是强大的通用型模型，然而解决人类终极考试（HLE）等深度复杂问题在概念上仍具挑战性，且计算成本高昂。我们展示了管理其他模型和各种工具的小型编排器，既能提升智能上限，又能提高解决困难智能体任务的效率。我们引入了ToolOrchestra，这是一种训练协调智能工具的小型编排器的方法。ToolOrchestra明确使用了强化学习，其奖励机制关注结果、效率和用户偏好。利用ToolOrchestra，我们开发了Orchestrator，一个8B模型，它在比现有工具使用智能体更低的成本下实现了更高的准确性，同时符合用户对于给定查询应使用哪些工具的偏好。在HLE上，Orchestrator获得了37.1%的分数，优于GPT-5（35.1%），同时效率高出2.5倍。在tau2-Bench和FRAMES上，Orchestrator大幅超越GPT-5，而成本仅为其约30%。广泛分析表明，Orchestrator在多项指标下实现了性能与成本的最佳权衡，并对未见过工具具有鲁棒泛化能力。这些结果表明，通过轻量级编排模型组合多样化工具比现有方法更高效、更有效，为实用且可扩展的工具增强推理系统铺平了道路。|
|**2025-11-26**|[Escaping the Verifier: Learning to Reason via Demonstrations](http://arxiv.org/abs/2511.21667)|null|训练大语言模型 (LLMs) 进行推理通常依赖于结合任务特定的验证器的强化学习 (RL)。然而，许多真实世界的推理密集型任务缺乏验证器，尽管它们提供了大量的专家演示，但这些演示仍未得到充分利用，无法用于以推理为重点的训练。我们引入了 RARO (相对论对抗推理优化)，它通过逆向强化学习，仅从专家演示中学习强大的推理能力。我们的方法在策略 (生成器) 和相对论评论器 (判别器) 之间建立了一个对抗性交互：策略学习模仿专家答案，而评论器则学习比较和区分策略生成的答案与专家答案。我们的方法通过强化学习联合且持续地训练策略和评论器，并确定了鲁棒学习所需的关键稳定技术。经验上，RARO 在我们所有的评估任务——倒计时、DeepMath 和诗歌创作——上显著优于强大的无验证器基线方法，并展现出与强化学习在可验证任务上相同的鲁棒扩展趋势。这些结果表明，我们的方法仅从专家演示中就能有效激发出强大的推理性能，从而即使在任务特定验证器不可用的情况下也能实现鲁棒的推理学习。|
|**2025-11-26**|[Aligning LLMs Toward Multi-Turn Conversational Outcomes Using Iterative PPO](http://arxiv.org/abs/2511.21638)|null|优化大型语言模型（LLMs）以实现多轮对话结果仍然是一个重大挑战，尤其是在目标导向型场景中，例如通过消息平台促成交易的AI营销或销售代理。这种困难源于稀疏、长周期的奖励以及响应级别规划与令牌级别生成之间的差异。在这篇技术说明中，我们提出了一种将多轮强化学习（RL）问题形式化归约（reduction）为一系列单轮RLHF风格问题的方法。这通过将学习到的多轮Q函数设置为单轮问题的奖励模型来实现。我们演示并证明了一个关键见解：使用标准的令牌级别PPO解决这个单轮RL问题，等价于多轮问题中的一个策略改进步骤。这一见解自然引出了迭代PPO（Iterative PPO），这是一种批处理在线策略迭代算法，它在从记录的对话轨迹中拟合Q函数和改进策略之间交替进行。一个主要的实际优势是，迭代PPO直接利用了稳定、现成的单轮RLHF工具，使其易于实现。我们的方法介于完全在线和完全离线方法之间，在保留在线更新适应性的同时，获得了离线训练的稳定性优势。|
|**2025-11-26**|[BAMAS: Structuring Budget-Aware Multi-Agent Systems](http://arxiv.org/abs/2511.21572)|**[link](https://github.com/chunfenri/BAMAS)**|基于大型语言模型（LLM）的多智能体系统已成为一种强大的范式，用于使自主智能体解决复杂任务。随着这些系统复杂性的增加，成本成为实际部署的一个重要考量。然而，现有工作很少解决如何在明确的预算约束下构建多智能体系统。在本文中，我们提出了BAMAS，一种用于构建具有预算感知的多智能体系统的新颖方法。BAMAS首先通过建立和解决一个平衡性能与成本的整数线性规划问题来选择一组最优的LLM。然后，它通过利用一种基于强化学习的方法来选择交互拓扑，从而确定这些LLM应如何协作。最后，根据所选智能体及其协作拓扑，实例化并执行该系统。我们在三个代表性任务上评估了BAMAS，并将其与最先进的智能体构建方法进行了比较。结果表明，BAMAS在实现可比性能的同时，将成本降低了高达86%。|
|**2025-11-26**|[Monet: Reasoning in Latent Visual Space Beyond Images and Language](http://arxiv.org/abs/2511.21395)|**[link](https://github.com/NOVAglow646/Monet)**|“图像思考”已成为推进视觉推理的有效范式，它通过在中间推理步骤中注入视觉证据，超越了纯文本思维链。然而，现有方法未能达到类人抽象视觉思考水平，因为它们的灵活性从根本上受限于外部工具。在这项工作中，我们引入了Monet，一个训练框架，它通过生成作为中间视觉思考的连续嵌入，使多模态大语言模型（MLLM）能够直接在潜在视觉空间中进行推理。我们识别出训练MLLM进行潜在视觉推理的两个核心挑战：潜在视觉对齐中的高计算成本以及对潜在嵌入的监督不足，并通过一个三阶段蒸馏式监督微调（SFT）流程解决了这些挑战。我们进一步揭示了将GRPO应用于潜在推理的一个局限性：它主要增强基于文本的推理而非潜在推理。为了克服这一点，我们提出了VLPO（视觉-潜在策略优化），一种明确将潜在嵌入纳入策略梯度更新的强化学习方法。为了支持SFT，我们构建了Monet-SFT-125K，一个高质量的文本-图像交错式思维链（CoT）数据集，其中包含12.5万个真实世界、图表、OCR和几何思维链。我们的模型Monet-7B在真实世界感知和推理基准测试中表现出持续提升，并在具有挑战性的抽象视觉推理任务上展示了强大的域外泛化能力。我们还实证分析了每个训练组件的作用，并讨论了我们早期的失败尝试，为未来视觉潜在推理的发展提供了见解。我们的模型、数据和代码可在https://github.com/NOVAglow646/Monet获取。|
|**2025-11-26**|[Multi-Reward GRPO for Stable and Prosodic Single-Codebook TTS LLMs at Scale](http://arxiv.org/abs/2511.21270)|null|大型语言模型（LLMs）的最新进展彻底改变了文本到语音（TTS）合成，启发了将语音表示为离散编解码器（codec）token序列的自回归框架。其中，单码本TTS LLM已成为紧凑且可流式传输的架构，能够联合建模语义和声学整合。然而，尽管它们效率很高，这些模型经常表现出韵律不稳定、说话人漂移以及自然度下降。为了解决这些问题，我们提出了一种多奖励组相对策略优化（GRPO）框架，该框架直接优化单码本TTS LLM的token生成策略。除了标准的清晰度和说话人相似度目标之外，我们的设计还集成了三种基于规则的奖励：用于时长一致性的长度惩罚、用于解码稳定性的熵正则化奖励，以及一个LLM标注的韵律对齐奖励，该奖励明确监督节奏。在这种韵律奖励中，一个外部推理LLM通过上下文学习预测多个合理的停顿结构，为GRPO训练提供了一个与人类偏好对齐的监督信号。为了评估通用性，我们进一步在GRPO优化的自回归（AR）骨干网络之上附加了一个流匹配（FM）解码器，并观察到持续的额外增益，这表明我们的强化优化增强了固有的自回归策略。我们进一步进行了可扩展性分析，跨越不同数据量和模型规模，揭示了所提出的方法持续增强了单码本TTS LLM中的韵律稳定性、说话人相似度以及语音的整体自然度。|
|**2025-11-26**|[SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation](http://arxiv.org/abs/2511.21135)|null|遵守社会规范的具身导航仍然是一个开放的研究挑战。我们的SocialNav是一个用于社交感知导航的基础模型，具有分层“大脑-行动”架构，能够理解高层社会规范并生成低层、符合社交规范的轨迹。为了实现这种双重能力，我们构建了SocNav数据集，这是一个包含700万样本的大规模集合，包括(1)一个认知激活数据集，提供诸如思维链解释和社交可通行性预测等社交推理信号，以及(2)一个专家轨迹金字塔，汇集了来自互联网视频、模拟环境和真实机器人中的多样化导航演示。提出了一种多阶段训练流程以逐步注入并完善导航智能：我们首先通过模仿学习将通用导航技能和社交规范理解注入模型，然后通过精心设计的社交感知流探索GRPO (SAFE-GRPO)来完善这些技能，这是首个基于流的具身导航强化学习框架，明确奖励符合社交规范的行为。相较于最先进的方法，SocialNav实现了+38%的成功率和+46%的社交合规率，证明了在导航性能和社交合规性方面都有显著提升。我们的项目页面：https://amap-eai.github.io/SocialNav/|
|**2025-11-26**|[BRIDGE: Building Representations In Domain Guided Program Verification](http://arxiv.org/abs/2511.21104)|null|大语言模型（LLM）在代码生成方面取得了令人印象深刻的成果，但在程序验证方面，尤其是在Lean4等交互式证明框架中，仍面临挑战。核心挑战是可扩展性：验证性合成不仅需要代码，还需要精确的规约和正确性证明，而现有方法很少能涵盖所有这三个领域。我们提出了BRIDGE，这是首次对可扩展验证性程序生成中的结构化提示进行系统性研究。BRIDGE将验证分解为三个相互关联的领域：代码（可执行实现）、规约（形式化意图陈述）和证明（建设性正确性论证）。我们的核心思想是引出不同的推理行为——函数式、规约驱动和证明导向——作为中间表示，以保留语义结构并连接这些领域。通过系统性消融实验，我们表明这种方法在准确性和效率上均显著优于标准的错误反馈方法。例如，函数式推理使形式化语言（Lean4）中代码的正确性比直接基线提高了近1.5倍（pass@5）。在推理计算方面，函数式推理的效率也高出2倍，在更少的生成次数和更低的总采样预算下实现了更高的通过率。同样，我们发现规约驱动的提示将Python编程的通过率提升了高达17.5%。这些发现表明，结构化领域对齐是推进验证性合成的一个有前景的方向。BRIDGE为通过专家迭代或RLVR进行训练奠定了基础，使模型能够内化跨代码、规约和证明的这些推理策略。|
|**2025-11-26**|[Aligning LLMs with Biomedical Knowledge using Balanced Fine-Tuning](http://arxiv.org/abs/2511.21075)|null|有效的后训练对于使大型语言模型（LLMs）与专业的生物医学知识对齐，以加速生命科学研究至关重要。然而，当前的方法面临显著的局限性。首先，生物医学推理涉及复杂的机制，这些机制通常由稀疏的文本数据表示。标准的监督微调（SFT）容易过拟合到表层的指令模式，而未能有效内化这些碎片化的科学知识。其次，强化学习（RL）在该领域不切实际，因为定义有意义的奖励通常需要进行高成本的实验验证（例如，药物反应的湿实验室验证），这使得实时反馈不可行。我们提出了一种平衡微调（BFT）方法，这是一种高效的后训练方法，旨在从稀疏数据中学习复杂的推理，且无需外部奖励信号。BFT通过两层加权机制运作：1. 在token层面，它通过预测概率调整损失，以稳定梯度并防止过拟合；2. 在样本层面，它使用“最小组置信度”来自适应地增强对困难样本的学习。实验表明BFT显著优于SFT。在医学任务中，它使LLMs能够获取SFT所遗漏的知识。在生物学任务中，基于BFT的LLMs在生物过程推理方面超越了GeneAgent（一种用于生物学分析的精确智能体）。此外，BFT生成的文本嵌入可以直接应用于下游任务，例如基因相互作用和单细胞扰动响应预测。这些结果表明BFT促进了LLMs在生物医学研究中的广泛应用。|
|**2025-11-26**|[Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs](http://arxiv.org/abs/2511.21050)|null|用于下游任务的大型语言模型（LLMs）的微调通常表现出一种基本的安全-能力权衡，即任务性能的提升会损害安全对齐，即使在良性数据集上也是如此。这种退化在标准方法中持续存在，包括监督微调（SFT）和基于人类反馈的强化学习（RLHF）。尽管带有可验证奖励的强化学习（RLVR）已成为一种在客观可衡量任务上优化模型的有前景的替代方案，但其安全影响尚未被探索。我们首次对RLVR中的安全特性进行了全面的理论和实证分析。在理论上，我们推导了KL约束优化下安全漂移的上限，并证明了消除安全退化的条件。在实证方面，我们跨越五个对抗性安全基准进行了广泛实验，证明RLVR可以同时增强推理能力，同时保持或提升安全防护。我们的综合消融研究检查了优化算法、模型规模和任务领域的影响。我们的发现挑战了安全能力之间存在不可避免权衡的普遍假设，并确立了特定的训练方法可以同时实现这两个目标，为具备推理能力的LLMs的安全部署提供了见解。|
|**2025-11-25**|[RubricRL: Simple Generalizable Rewards for Text-to-Image Generation](http://arxiv.org/abs/2511.20651)|null|强化学习（RL）近来已成为一种使文本到图像生成模型与人类偏好对齐的有前景方法。然而，一个关键挑战在于设计有效且可解释的奖励。现有方法通常依赖于具有固定权重的复合指标（例如，CLIP、OCR和真实感分数），或从人类偏好模型中提取的单一标量奖励，这会限制可解释性和灵活性。我们提出RubricRL，一个简单通用的基于评分标准的奖励设计框架，它提供了更高的可解释性、可组合性和用户控制。RubricRL没有使用黑盒标量信号，而是为每个提示动态构建一个结构化的评分标准——一个根据输入文本量身定制的可分解的细粒度视觉标准清单，例如物体正确性、属性准确性、OCR忠实度和真实感。每个标准都由多模态判断器（例如o4-mini）独立评估，并且一个提示自适应的加权机制会强调最相关的维度。这种设计不仅为策略优化（例如GRPO或PPO）产生了可解释和模块化的监督信号，而且使用户能够直接调整奖励或惩罚哪些方面。使用自回归文本到图像模型进行的实验表明，RubricRL改进了提示忠实度、视觉细节和泛化能力，同时为跨文本到图像架构的可解释RL对齐提供了一个灵活可扩展的基础。|
|**2025-11-25**|[Reinforcing Action Policies by Prophesying](http://arxiv.org/abs/2511.20633)|**[link](https://github.com/LogosRoboticsGroup/ProphRL)**|视觉-语言-动作 (VLA) 策略在对齐语言、感知和机器人控制方面表现出色。然而，大多数VLA纯粹通过模仿进行训练，这会导致对演示的过拟合，并在分布偏移下表现脆弱。强化学习 (RL) 直接优化任务奖励，从而解决了这种不对齐问题，但真实机器人交互成本高昂，且传统模拟器难以工程化和迁移。我们通过学习到的世界模型和针对基于流的动作头定制的RL过程，解决了VLA后期训练中的数据效率和优化稳定性问题。具体来说，我们引入了Prophet，这是一种统一的动作到视频机器人执行器，它在大规模异构机器人数据上进行预训练，以学习可重用的动作-结果动态。它能够少量样本适应新的机器人、物体和环境，从而生成一个可用于采样的模拟器。在Prophet的基础上，我们使用Flow-action-GRPO (FA-GRPO) 强化动作策略，FA-GRPO将Flow-GRPO适应于VLA动作，并结合FlowScale，这是一种逐步重加权方法，可以重新缩放流头中每步的梯度。Prophet、FA-GRPO和FlowScale共同构成了ProphRL，为VLA后期训练提供了一条实用、数据和计算高效的途径。实验表明，在不同VLA变体上，ProphRL在公开基准测试中成功率提高了5-17%，在真实机器人上提高了24-30%。|
|**2025-11-25**|[DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs](http://arxiv.org/abs/2511.20468)|null|大语言模型（LLM）在多步推理和问题解决方面展现出令人印象深刻的能力。近期工作引入了多智能体反思框架，其中多个LLM智能体利用强化学习（RL）相互批判和完善彼此的输出。然而，这些方法通常依赖于单次响应，并且在推理探索中缺乏结构多样性。在本文中，我们提出了DRAFT-RL，一个新颖的框架，它将草稿链（CoD）推理整合到多智能体RL训练中。每个智能体不生成单个响应，而是为每次查询生成多个草稿，这些草稿随后由对等智能体和学习到的奖励模型进行评估，以识别最有前途的轨迹。这些选定的草稿通过演员-评论家学习来完善未来的推理策略。DRAFT-RL实现了显式多路径探索、对等引导的反思和奖励对齐的选择，从而使LLM智能体行为更加鲁棒和可解释。我们在代码合成、符号数学和知识密集型问答等复杂推理任务上评估了我们的方法，结果表明DRAFT-RL在准确性和收敛速度方面均以显著优势优于现有的反思型和基于RL的智能体。|
|**2025-11-25**|[Soft Adaptive Policy Optimization](http://arxiv.org/abs/2511.20347)|null|强化学习（RL）在增强大语言模型（LLMs）的推理能力方面发挥着越来越重要的作用，然而，稳定且高性能的策略优化仍然充满挑战。令牌级重要性比率通常表现出高方差——这种现象在专家混合模型（Mixture-of-Experts models）中尤为加剧——导致更新不稳定。现有的基于组的策略优化方法，如GSPO和GRPO，通过硬裁剪（hard clipping）来缓解这个问题，但这使得难以同时保持稳定性和有效学习。我们提出了软自适应策略优化（SAPO），它用一个平滑、温度控制的门（temperature-controlled gate）取代了硬裁剪，该门自适应地衰减离策略更新，同时保留有用的学习信号。与GSPO和GRPO相比，SAPO既序列一致（sequence-coherent）又令牌自适应（token-adaptive）。与GSPO类似，SAPO保持序列级一致性，但其软门控形成了一个连续的信任区域，避免了GSPO中使用的脆弱的硬裁剪区间。当一个序列包含少量高度离策略的令牌时，GSPO会抑制该序列的所有梯度，而SAPO仅选择性地降低那些“违规”令牌的权重，并保留接近在策略令牌的学习信号，从而提高了样本效率。相对于GRPO，SAPO用平滑、温度控制的缩放取代了硬的令牌级裁剪，从而实现了信息量更大、更稳定的更新。在数学推理基准上的实验结果表明，在可比较的训练预算下，SAPO表现出更高的训练稳定性和Pass@1性能。此外，我们采用SAPO训练了Qwen3-VL模型系列，结果表明SAPO在各种任务和不同模型尺寸上均产生了持续的性能提升。总体而言，SAPO为LLMs的强化学习训练提供了一种更可靠、可扩展且有效的优化策略。|
|**2025-11-25**|[NNGPT: Rethinking AutoML with Large Language Models](http://arxiv.org/abs/2511.20333)|null|构建自我改进的AI系统仍然是AI领域的一个基本挑战。我们提出了NNGPT，一个开源框架，它将一个大语言模型（LLM）转变为一个用于神经网络开发（主要针对计算机视觉）的自我改进的自动化机器学习（AutoML）引擎。与以往的框架不同，NNGPT通过生成新模型来扩展神经网络数据集，从而实现基于生成、评估和自我改进的闭环系统对LLM进行持续微调。它在一个统一的工作流中集成了五个协同的基于LLM的流水线：零样本架构合成、超参数优化（HPO）、代码感知的准确性/早期停止预测、范围封闭的PyTorch块的检索增强合成（NN-RAG）以及强化学习。NNGPT以LEMUR数据集作为经过审计的、具有可复现指标的语料库，能够从单个提示中生成并验证网络架构、预处理代码和超参数，端到端地执行它们，并从结果中学习。PyTorch适配器使NNGPT实现框架无关性，从而带来强大的性能：NN-RAG在1,289个目标上达到了73%的可执行性，3次提示显著提高了在常见数据集上的准确性，基于哈希的去重节省了数百次运行。单次预测与基于搜索的AutoML表现相当，减少了对大量试验的需求。LEMUR上的HPO达到了0.60的均方根误差（RMSE），优于Optuna（0.64），而代码感知预测器达到了0.14的RMSE，皮尔逊相关系数（r）为0.78。该系统已经生成了超过5K个经过验证的模型，证明NNGPT是一个自主的AutoML引擎。论文被接受后，代码、提示和检查点将公开发布，以实现可复现性并促进社区使用。|
|**2025-11-25**|[Improving Language Agents through BREW](http://arxiv.org/abs/2511.20297)|null|基于大型语言模型（LLM）的智能体正越来越多地应用于需要结构化推理、工具使用和环境适应的任务，例如数据操作、多步规划和计算机使用自动化。然而，尽管它们具有多功能性，当前用于模型权重优化方法（如PPO和GRPO）的训练范式因其策略收敛所需的高计算开销而仍然相对不切实际。此外，所产生的智能体策略难以解释、适应或增量改进。为了解决这个问题，我们研究了创建和完善智能体从其环境获得的经验学习的结构化记忆，作为智能体优化的替代途径。我们引入了BREW（Bootstrapping expeRientially-learned Environmental knoWledge），一个通过知识库（KB）构建和完善来实现下游任务智能体优化的框架。在我们的方法中，我们引入了一种有效的方法来划分智能体记忆，以实现更高效的检索和完善。BREW利用任务评分器和行为评估标准来学习见解，同时利用状态空间搜索以确保在自然语言的噪声和非特异性下保持鲁棒性。在真实世界、领域特定基准测试（OSWorld、 $τ^2$ Bench和SpreadsheetBench）上的实证结果表明，BREW在任务精度上实现了10-20%的提升，API/工具调用减少了10-15%（从而缩短了执行时间），同时保持了与基础模型相当的计算效率。与以往将记忆视为静态上下文的工作不同，我们将知识库（KB）建立为一个模块化且可控的基底，用于智能体优化——这是一个以透明、可解释和可扩展方式塑造行为的明确杠杆。|
|**2025-11-25**|[VKnowU: Evaluating Visual Knowledge Understanding in Multimodal LLMs](http://arxiv.org/abs/2511.20272)|null|尽管多模态大语言模型（MLLMs）已擅长识别物体，但它们常常缺乏对世界底层物理和社会原则的直观、类人理解。这种高级的、基于视觉的语义，我们称之为视觉知识，构成了感知与推理之间的桥梁，但在当前MLLMs中仍是一个未被充分探索的领域。为了系统地评估这种能力，我们提出了VKnowU，一个综合性基准，包含1,249个视频中的1,680个问题，涵盖以世界为中心（例如，直观物理）和以人为中心（例如，主观意图）两方面的8种核心视觉知识类型。对23个最先进的MLLMs进行评估表明，领先模型仍远低于人类表现，尤其在以世界为中心的方面存在显著差距。为了弥补这一差距，我们引入了一个新数据集VKnowQA，以及VideoKnow+，一个将视觉知识显式整合到MLLMs中的基线模型。VideoKnow+遵循结构化的“看-思-答”范式，并采用带有视觉知识奖励的强化学习，在VKnowU上实现了+3.7%的提升，并在MVBench、Video-MME和MMVU上取得了持续的提升。我们的工作强调视觉知识是构建更具泛化能力的MLLMs的缺失基石，这些模型不仅能“看”，还能真正理解我们的物理和社会世界。|
|**2025-11-25**|[The Image as Its Own Reward: Reinforcement Learning with Adversarial Reward for Image Generation](http://arxiv.org/abs/2511.20256)|null|可靠的奖励函数对于图像生成中的强化学习（RL）至关重要。大多数当前的RL方法依赖于输出标量奖励以近似人类偏好的预训练偏好模型。然而，这些奖励往往无法捕捉人类感知，并且容易受到奖励欺骗（reward hacking），即更高的分数并不意味着更好的图像。为了解决这个问题，我们引入了Adv-GRPO，这是一个具有对抗性奖励的RL框架，它迭代更新奖励模型和生成器。奖励模型使用参考图像作为正样本进行监督，可以在很大程度上避免被欺骗。与约束参数更新的KL正则化不同，我们学习到的奖励直接通过其视觉输出指导生成器，从而生成更高质量的图像。此外，尽管优化现有奖励函数可以缓解奖励欺骗，但它们固有的偏差仍然存在。例如，PickScore可能会降低图像质量，而基于OCR的奖励通常会降低美学保真度。为了解决这个问题，我们将图像本身作为奖励，利用参考图像和视觉基础模型（例如DINO）提供丰富的视觉奖励。这些密集的视觉信号，而不是单一标量，在图像质量、美学和任务特定指标方面带来了持续的提升。最后，我们表明将参考样本与基础模型奖励结合能够实现分布迁移和灵活的风格定制。在人工评估中，我们的方法优于Flow-GRPO和SD3，在图像质量和美学方面分别达到了70.0%和72.4%的胜率。代码和模型已发布。|
|**2025-11-25**|[CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents](http://arxiv.org/abs/2511.20216)|**[link](https://github.com/worv-ai/CostNav)**|现有导航基准侧重于任务成功指标，却忽视了经济可行性——这对于自主配送机器人的商业部署至关重要。我们引入了CostNav，一个微观导航经济测试平台，它通过与现实世界业务运营保持一致的综合成本-收入分析来评估具身智能体。CostNav建模了完整的经济生命周期，包括硬件、训练、能源、维护成本以及具有服务水平协议的配送收入，并使用行业衍生参数。据我们所知，CostNav是第一个定量揭示导航研究指标与商业可行性之间差距的工作，揭示了优化任务成功与优化经济部署之间存在根本性差异。我们的成本模型使用源自行业数据源的参数（能源费率、配送服务定价），并从缩减规模的模拟推断到实际配送。在此推断下，基线实现了43.0%的SLA合规性，但不具备商业可行性：每次运行亏损30.009美元，且没有有限的盈亏平衡点，因为运营成本主要由碰撞引起的维护成本主导，该成本占每次运行成本的99.7%，凸显了避碰是关键的优化目标。我们展示了一个基于学习的设备端导航基线，并为评估基于规则的导航、模仿学习和成本感知强化学习训练奠定了基础。CostNav弥合了导航研究与商业部署之间的差距，从而能够做出关于不同导航范式下经济权衡的数据驱动决策。|
|**2025-11-25**|[QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based High-Performance GPU Kernel Generation](http://arxiv.org/abs/2511.20100)|**[link](https://github.com/AKatydid/QiMeng-Kernel)**|开发高性能GPU内核对人工智能和科学计算至关重要，但由于其依赖专家手动编写和移植性差，仍然具有挑战性。尽管大语言模型（LLM）为自动化提供了希望，但通用和微调LLM都面临两个根本且相互冲突的局限性：正确性和效率。关键原因是现有基于LLM的方法直接生成整个优化的低级程序，这需要探索一个极其广阔的空间，涵盖优化策略和实现代码。为了解决探索难以处理的空间的挑战，我们提出了宏观思考微观编码（MTMC），这是一个受人类专家分阶段优化策略启发的层次化框架。它将优化策略与实现细节解耦，通过高级策略确保效率，通过低级实现确保正确性。具体而言，宏观思考采用强化学习来指导轻量级LLM有效探索和学习最大化硬件利用率的语义优化策略。微观编码利用通用LLM逐步实现宏观思考提出的分步优化方案，避免了完整内核生成错误。它们共同有效地导航广阔的优化空间和复杂的实现细节，使LLM能够生成高性能GPU内核。在广泛采用的基准测试上的综合结果证明了MTMC在GPU内核生成方面，无论是在准确性还是运行时间上都表现出卓越的性能。在KernelBench上，MTMC在级别1-2和级别3上分别达到了接近100%和70%的准确率，比最先进的通用和领域微调LLM高出50%以上，比LLM快高达7.3倍，比专家优化的PyTorch Eager内核快2.2倍。在更具挑战性的TritonBench上，MTMC实现了高达59.64%的准确率和34倍的加速。|
|**2025-11-21**|[Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination](http://arxiv.org/abs/2511.17490)|null|理解富文本视频需要阅读细小、瞬时的文本线索，这通常需要反复检查。然而，大多数视频问答模型依赖于对固定帧的单次感知，导致在处理细粒度证据时出现幻觉和失败。受人类暂停、放大和重读关键区域方式的启发，我们引入了Video-R4（通过视觉反刍强化富文本视频推理），这是一种执行视觉反刍的视频推理大规模多模态模型：它迭代选择帧、放大信息区域、重新编码检索到的像素，并更新其推理状态。我们构建了两个具有可执行反刍轨迹的数据集：用于监督实践的Video-R4-CoT-17k和用于强化学习的Video-R4-RL-30k。我们提出了一种多阶段反刍学习框架，通过监督微调（SFT）和基于GRPO的强化学习逐步微调一个7B大规模多模态模型，以学习原子级和混合视觉操作。Video-R4-7B在M4-ViteVQA上取得了最先进的结果，并进一步泛化到多页文档问答、幻灯片问答和通用视频问答，这表明迭代反刍是像素级多模态推理的有效范式。|
|**2025-11-21**|[Masked-and-Reordered Self-Supervision for Reinforcement Learning from Verifiable Rewards](http://arxiv.org/abs/2511.17473)|null|测试时缩放已被证明能显著提升大语言模型（LLM）的数学推理能力。然而，对于大部分数学语料，尤其是定理证明，RLVR的可扩展性有限：中间推理至关重要，而最终答案难以直接可靠地验证。同时，令牌级SFT常常退化为死记硬背，而不是诱导更长的思维链。受BERT自监督任务的启发，我们提出了MR-RLVR（Masked-and-Reordered RLVR），它通过“掩码然后填充”和“步骤重排序”构建过程级自监督奖励，从中间推理中提取可学习信号。我们的训练流程包含两个阶段：我们首先对采样的数学计算和证明数据进行自监督训练；然后，在仅结果可验证的数学计算数据集上进行RLVR微调。我们在Qwen2.5-3B和DeepSeek-R1-Distill-Qwen-1.5B上实现了MR-RLVR，并在AIME24、AIME25、AMC23和MATH500上进行了评估。在固定的采样和解码预算下，MR-RLVR相对于原始RLVR取得了平均相对提升，Pass@1提升了9.86%，Pass@5提升了5.27%，Pass@8提升了4.00%。这些结果表明，引入过程感知的自监督信号可以有效增强RLVR在仅结果可验证设置中的可扩展性和性能。|
|**2025-11-21**|[Beyond Multiple Choice: A Hybrid Framework for Unifying Robust Evaluation and Verifiable Reasoning Training](http://arxiv.org/abs/2511.17405)|null|多项选择题问答（MCQA）一直是评估和强化微调（RFT）现代多模态语言模型的常用格式。其受限的输出格式允许进行简化、确定性的自动验证。然而，我们发现选项可能会泄露可利用的信号，这使得准确性指标在指示真实能力方面不可靠，并鼓励在RFT期间出现显性或隐性的答案猜测行为。我们提出了ReVeL（基于LLM的重写与验证），这是一个将多项选择题重写为开放式问题，并在可能的情况下保持答案可验证的框架。该框架根据不同的答案类型对问题进行分类，并分别应用不同的重写和验证方案。当应用于RFT时，我们转换了2万个MCQA示例，并使用GRPO微调了Qwen2.5-VL模型。在ReVeL-OpenQA上训练的模型在多项选择基准测试中匹配了MCQA准确率，并将OpenQA准确率提高了约六个百分点，这表明比基于MCQA的训练具有更好的数据效率和更鲁棒的奖励信号。当用于评估时，ReVeL还揭示了MCQA基准测试中高达20个百分点的分数虚高（相对于OpenQA），提高了判断准确性，并降低了成本和延迟。我们将公开发布代码和数据。|
|**2025-11-21**|[MolSight: Optical Chemical Structure Recognition with SMILES Pretraining, Multi-Granularity Learning and Reinforcement Learning](http://arxiv.org/abs/2511.17300)|**[link](https://github.com/hustvl/MolSight)**|光学化学结构识别（OCSR）在现代化学信息学中扮演着关键角色，能够将科学文献、专利和教育材料中的化学结构图像自动化转换为机器可读的分子表示。这种能力对于大规模化学数据挖掘、药物发现流程以及相关领域的大语言模型（LLM）应用至关重要。然而，现有的OCSR系统在准确识别立体化学信息方面面临重大挑战，这归因于区分立体异构体的细微视觉线索，例如楔形键和虚线键、环构象以及空间排列。为了解决这些挑战，我们提出了MolSight，一个用于OCSR的综合学习框架，它采用三阶段训练范式。在第一阶段，我们对大规模但存在噪声的数据集进行预训练，以赋予模型对化学结构图像的基本感知能力。在第二阶段，我们使用具有更丰富监督信号的数据集进行多粒度微调，系统地探索辅助任务——特别是化学键分类和原子定位——如何有助于分子式识别。最后，我们采用强化学习进行训练后优化，并引入了一个新颖的立体化学结构数据集。值得注意的是，我们发现即使MolSight的参数规模相对紧凑，群体相对策略优化（GRPO）算法仍能进一步提升模型在立体分子方面的性能。通过对不同数据集的广泛实验，我们的结果表明MolSight在（立体）化学光学结构识别方面取得了最先进的性能。|
|**2025-11-21**|[Cross-cultural value alignment frameworks for responsible AI governance: Evidence from China-West comparative analysis](http://arxiv.org/abs/2511.17256)|null|随着大语言模型 (LLM) 越来越多地影响全球范围内的高风险决策，确保其与多元文化价值观保持一致已成为一个关键的治理挑战。本研究提出了一个负责任AI多层审计平台，通过四种集成方法系统性评估源自中国的和源自西方的LLM的跨文化价值观对齐情况：用于评估时间稳定性的伦理困境语料库、用于量化文化保真度的多样性增强框架 (DEF)、用于衡量分布准确性的首词概率对齐，以及用于可解释决策的多阶段推理框架 (MARK)。我们对Qwen、GPT-4o、Claude、LLaMA和DeepSeek等20余种主流模型进行的对比分析揭示了普遍挑战——价值观体系的根本不稳定性、年轻人口的系统性代表不足，以及模型规模与对齐质量之间的非线性关系——同时伴随着不同的区域发展轨迹。尽管源自中国的模型日益强调多语言数据集成以实现上下文特定优化，但西方模型展现出更大的架构实验性，却存在持续的以美国为中心的偏见。两种范式都未能实现稳健的跨文化泛化。我们发现Mistral系列架构在跨文化对齐方面显著优于LLaMA3系列，并且在多样化数据集上进行全参数微调在保留文化多样性方面优于人类反馈强化学习。|
|**2025-11-21**|[FireScope: Wildfire Risk Prediction with a Chain-of-Thought Oracle](http://arxiv.org/abs/2511.17171)|null|预测野火风险是一个推理密集型空间问题，需要整合视觉、气候和地理因素来推断连续的风险图。现有方法缺乏实现可靠泛化所需的因果推理和多模态理解能力。我们引入了FireScope-Bench，这是一个大规模数据集和基准，它将Sentinel-2卫星图像和气候数据与美国各地专家定义的风险栅格图以及欧洲的真实野火事件相结合，以进行跨大陆评估。在此数据集的基础上，我们提出了FireScope，一个基于VLM（视觉语言模型）的推理到生成框架，它通过强化学习和视觉监督进行学习，以预测具有互补推理轨迹的风险栅格图。FireScope在美国训练并在欧洲测试时，实现了显著的性能提升，同时专家反馈和自动化分析证实其推理轨迹忠实可靠且具有语义意义。我们的研究结果表明，推理可以为栅格预测模型提供基础，从而提高泛化能力和可解释性。据我们所知，这是第一个（1）证明基于语言的推理可以提高视觉生成中泛化能力的框架，（2）提出了一个可以跨大陆应用的高分辨率野火风险模型，以及（3）促进对多模态火灾风险模型鲁棒跨大陆泛化能力的系统研究的框架。我们相信FireScope-Bench有潜力成为推动推理驱动、可解释和可泛化空间建模的基础。数据和源代码将公开可用。|
|**2025-11-21**|[Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation](http://arxiv.org/abs/2511.17097)|null|视觉语言导航要求智能体在长时间跨度内连贯地行动，这不仅需要理解局部视觉上下文，还需要理解它们在多步指令中进展了多远。然而，近期的视觉语言动作模型侧重于直接动作预测，而早期的进展方法则预测数值成就；两者都忽略了观察序列和指令序列的单调协同进展特性。基于这一洞察，Progress-Think引入了语义进展推理，通过从视觉观察中预测指令风格的进展，从而实现更准确的导航。为了在无需昂贵标注的情况下实现这一点，我们提出了一个三阶段框架。在初始阶段，自对齐进展预训练通过视觉历史和指令前缀之间一种新颖的可微分对齐，引导一个推理模块。接着，进展引导策略预训练将学到的进展状态注入到导航上下文中，引导策略采取一致的行动。最后，进展-策略协同微调采用量身定制的进展感知强化目标共同优化这两个模块。在R2R-CE和RxR-CE上的实验显示了最先进的成功率和效率，证明了语义进展能够产生更一致的导航进展表示。|
|**2025-11-21**|[Predicting Talent Breakout Rate using Twitter and TV data](http://arxiv.org/abs/2511.16905)|null|在广告领域，早期检测新兴人才至关重要。本文定义了“人才爆发”的概念，并提出了一种在日本人才成名之前对其进行检测的方法。本研究的主要焦点是确定结合Twitter和电视数据在预测社交数据时间相关变化方面的有效性。尽管传统时间序列模型在许多应用中都表现出鲁棒性，但神经网络模型在各个领域（例如自然语言处理、计算机视觉、强化学习）的成功，持续激发了时间序列社区在实践中应用新技术的兴趣。因此，为了找到最佳建模方法，我们实验了传统方法、神经网络方法和集成学习方法。我们观察到，基于标准回归指标，集成学习方法优于传统模型和神经网络模型。然而，通过利用人才爆发的概念，我们能够评估模型的真实预测能力，在此方面，神经网络在精确率和召回率方面优于传统方法和集成学习方法。|
|**2025-11-21**|[R-AVST: Empowering Video-LLMs with Fine-Grained Spatio-Temporal Reasoning in Complex Audio-Visual Scenarios](http://arxiv.org/abs/2511.16901)|**[link](https://github.com/zhlllau/R-AVST)**|近来，多模态大语言模型（MLLM）取得了飞速发展，尤其是在视频理解任务中。然而，当前研究主要集中在简单视频场景，未能反映真实世界视频中视听事件的复杂多样性。为弥补这一不足，我们首先引入了R-AVST，一个用于视听推理的数据集，其特点是具有细粒度时空标注。在构建过程中，我们设计了一个包含基于LLM的关键对象提取、自动空间标注和人工质量检查的流程，最终生成了超过5K个未剪辑视频，其中包含2.7万个对象，涵盖100种视听事件类型。在此数据集的基础上，我们定义了视听场景中时空推理的三个核心任务，并生成了超过8K个高质量、均匀分布的问答对，以有效评估模型性能。为进一步提升推理能力，我们提出了AVST-Zero，一个基于强化学习的模型，该模型避免了中间监督，通过精心设计的多维奖励直接优化行为。大量实验验证了R-AVST在推动视听时空推理方面的有效性，在此基础上，AVST-Zero相较于现有模型展现出有竞争力的性能。据我们所知，R-AVST是首个为真实世界视听时空推理设计的数据集，而AVST-Zero则为应对该领域未来的挑战提供了新颖视角。|
|**2025-11-21**|[When Motion Learns to Listen: Diffusion-Prior Lyapunov Actor-Critic Framework with LLM Guidance for Stable and Robust AUV Control in Underwater Tasks](http://arxiv.org/abs/2511.16900)|null|自主水下航行器(AUV)是海洋探索不可或缺的工具；然而，它们的控制受到非线性水动力学、时变扰动和定位不确定性的阻碍。传统控制器仅提供有限的适应性，而强化学习(RL)尽管很有前景，却存在样本效率低下、长期规划能力弱和缺乏稳定性保证的问题，导致行为不可靠。为了解决这些挑战，我们提出了一种扩散先验Lyapunov演员-评论家框架，该框架统一了探索、稳定性、和语义适应性。具体来说，一个扩散模型生成平滑、多模态且抗扰动的候选动作；一个Lyapunov评论家进一步施加双重约束以确保稳定性；并且一个由大语言模型(LLM)驱动的外循环基于任务语义和训练反馈自适应地选择和优化Lyapunov函数。这种“生成-筛选-优化”机制不仅增强了样本效率和规划能力，而且使稳定性保证与多目标优化任务中的多样化任务需求相一致。在复杂海洋动力学下的大量模拟实验表明，与传统的强化学习和扩散增强基线相比，所提出的框架实现了更精确的轨迹跟踪、更高的任务完成率、更高的能源效率、更快的收敛速度和更高的鲁棒性。|
|**2025-11-20**|[Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation](http://arxiv.org/abs/2511.16671)|null|视觉生成领域的近期进展越来越关注探索推理能力的整合。它们在生成过程之前（作为预规划）或之后（作为后细化）整合了文本推理，即“思考”，但它们缺乏在生成过程中实时的多模态交互。在这项初步研究中，我们引入了边生成边思考 (TwiG)，这是首个交错式框架，能够实现文本推理在视觉生成过程中的协同演化。随着视觉内容逐步生成，文本推理被交错地融入，既指导即将生成的局部区域，又对先前合成的区域进行反思。这种动态的相互作用产生了更具上下文感知能力和语义更丰富的视觉输出。为了揭示该框架的潜力，我们研究了三种候选策略：零样本提示、在我们精心策划的 TwiG-50K 数据集上进行监督微调 (SFT)，以及通过定制的 TwiG-GRPO 策略进行强化学习 (RL)，每种策略都为交错推理的动态提供了独特的见解。我们希望这项工作能启发关于交错文本推理以增强视觉生成的进一步研究。代码将发布在：https://github.com/ZiyuGuo99/Thinking-while-Generating。|
|**2025-11-20**|[Learning to Think Fast and Slow for Visual Language Models](http://arxiv.org/abs/2511.16670)|null|面对复杂问题时，我们倾向于慢思考；相反，对于简单问题，我们则快速思考。这种双系统思维机制使我们能够有效分配认知资源，从而对直接问题做出快速决策，同时将更深层的分析性思考保留给更复杂的挑战。然而，现有的面向推理的视觉语言模型（VLM），无论是通过显式思维链标注还是基于规则的强化学习（RL）奖励进行训练，都主要追求冗长、详细的推理链，这通常会导致过高的计算成本。在这项工作中，我们提出了一种简单的强化学习方法，该方法使VLM能够根据任务难度自动在快思考和慢思考模式之间切换。该方法包含两个阶段：在第一阶段，我们根据模型输出长度将数据标记为需要快思考或慢思考，其灵感来源于预训练VLM通常针对不同类型问题产生不同长度答案的观察；在第二阶段，我们使用GRPO以及思维模式标签训练模型，以开发双模式思维。尽管其方法简单，但我们的模型DualMindVLM显著优于基础模型，并达到了与最先进的视觉推理模型相当的性能，同时保持了极高的token效率。|
|**2025-11-20**|[Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO](http://arxiv.org/abs/2511.16669)|**[link](https://github.com/KlingTeam/VANS)**|尽管语言模型已在许多实际应用中产生了深远影响，但视频生成仍主要局限于娱乐领域。受视频固有能力启发，其能展示仅凭语言难以传达的物理世界信息（例如，想象只用文字教别人打领带），我们发现了一个未充分利用的机会，即将视频扩展为下一事件预测（NEP）任务的一种新回答模态，并将其形式化为视频下一事件预测（VNEP）。既定的NEP任务以带有过程性或预测性问题的视频作为输入，以文本形式预测下一事件，而VNEP则需要动态的视频响应。这种从“告知”到“展示”的转变，为过程学习和创造性探索开启了更直观和个性化的答案。然而，这项任务对现有模型而言仍具挑战性，因为它需要理解多模态输入、指令条件推理以及生成具有视觉和语义一致性的视频。为解决此问题，我们引入了VANS，一个利用强化学习将视觉-语言模型（VLM）与视频扩散模型（VDM）对齐以实现VNEP的模型。VANS的核心是我们提出的Joint-GRPO，它协调VLM和VDM作为一个整体运行。在各自输出上由共享奖励驱动，它优化VLM以生成既准确又易于可视化的字幕，同时引导VDM生成忠实于这些字幕和输入视觉上下文的视频。为实现这种学习，我们构建了VANS-Data-100K，一个专用于VNEP任务的数据集。在过程性和预测性基准上的实验表明，VANS在视频事件预测和可视化两方面都取得了最先进的性能。代码已发布在https://github.com/KlingTeam/VANS。|
|**2025-11-20**|[Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter](http://arxiv.org/abs/2511.16665)|null|大语言模型（LLM）强大推理能力的出现标志着一个重要里程碑，为解决复杂问题开辟了新领域。然而，这些推理模型的训练（通常使用强化学习（RL））遇到了关键效率瓶颈：RL训练期间的响应生成呈现持续的长尾分布，其中少数非常长的响应占据了大部分执行时间，浪费了资源并增加了成本。为了解决这个问题，我们提出了TLT，一个通过集成自适应推测解码来无损加速推理RL训练的系统。在RL中应用推测解码具有挑战性，原因在于动态工作负载、不断演进的目标模型以及草稿模型训练开销。TLT通过两个协同组件克服了这些障碍：(1) 自适应草稿器，一个轻量级草稿模型，在长尾生成期间利用空闲GPU持续训练，以在无额外成本的情况下保持与目标模型的对齐；以及(2) 自适应Rollout引擎，它维护一个内存高效的预捕获CUDAGraphs池，并为每个输入批次自适应选择合适的SD策略。评估表明，TLT相较于最先进系统，实现了超过1.7倍的端到端RL训练加速，保持了模型准确性，并产生了一个高质量的草稿模型作为免费副产品，适用于高效部署。代码已在https://github.com/mit-han-lab/fastrl 发布。|
|**2025-11-20**|[Evolution Strategies at the Hyperscale](http://arxiv.org/abs/2511.16652)|null|我们引入了低秩学习演化引导通用优化 (EGGROLL)，这是一种演化策略 (ES) 算法，旨在将无反向传播优化扩展到具有数十亿参数的现代大型神经网络架构的大种群规模。ES是一组强大的黑盒优化方法，能够处理不可微或噪声目标，并通过并行化具有优秀的扩展潜力。朴素ES在规模化时变得成本过高，因为生成矩阵扰动 $E\in\mathbb{R}^{m\times n}$ 和计算每个成员前向传播所需的批处理矩阵乘法会带来计算和内存成本。EGGROLL通过生成随机矩阵 $A\in \mathbb{R}^{m\times r},\ B\in \mathbb{R}^{n\times r}$ (其中 $r\ll \min(m,n)$) 来形成低秩矩阵扰动 $A B^\top$，并用其替代全秩扰动 $E$，从而克服了这些瓶颈。由于整体更新是对N个工作节点种群的平均，这仍然会产生高秩更新，但显著节省了内存和计算，与全秩ES相比，每层的辅助存储从 $mn$ 减少到 $r(m+n)$，前向传播成本从 $\mathcal{O}(mn)$ 减少到 $\mathcal{O}(r(m+n))$。理论分析表明，我们的低秩更新以快速的 $\mathcal{O}\left(\frac{1}{r}\right)$ 速率收敛于全秩更新。我们的实验表明：(1) 尽管速度更快，EGGROLL在从零开始的强化学习 (RL) 设置中不损害ES的性能；(2) 作为改进大型语言模型 (LLM) 推理的技术，它与GRPO具有竞争力；(3) EGGROLL实现了纯粹在整数数据类型中运行的非线性循环语言模型的稳定预训练。|
|**2025-11-20**|[Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](http://arxiv.org/abs/2511.16602)|null|开发通用且多功能的具身智能系统面临两个主要挑战：一是关键的具身数据瓶颈，即真实世界数据稀缺且昂贵；二是现有方法的算法效率低下，资源消耗巨大。为解决这些局限性，我们引入了刻意练习策略优化（DPPO），这是一种元认知“元循环”训练框架，它动态交替进行监督微调（能力扩展）和强化学习（技能完善）。这使得系统能够自动识别弱点并进行定向资源分配，专门设计用于从稀疏、有限的数据中最大化学习效率。理论上，DPPO 可以被形式化为一个统一的偏好学习框架。经验上，使用 DPPO 训练一个名为 Pelican-VL 1.0 的视觉-语言具身模型，相较于基线模型性能提升了 20.3%，并超越了 1000 亿参数规模的开源模型 10.6%。我们正在开源模型和代码，这提供了第一个系统性框架，缓解了数据和资源瓶颈，并使社区能够高效地构建多功能具身智能体。|
|**2025-11-20**|[MiMo-Embodied: X-Embodied Foundation Model Technical Report](http://arxiv.org/abs/2511.16518)|null|我们开源了MiMo-Embodied，这是首个成功整合并在自动驾驶和具身智能两个领域均取得最先进性能的跨具身基础模型。MiMo-Embodied在涵盖任务规划、示能预测和空间理解的17个具身智能基准测试中创造了新纪录，同时在涵盖环境感知、状态预测和驾驶规划的12个自动驾驶基准测试中也表现出色。在这些任务中，MiMo-Embodied显著优于现有开源、闭源和专用基线。我们的结果表明，通过多阶段学习、精选数据构建和CoT/RL微调，这两个领域表现出强大的正向迁移并相互促进。我们提供了模型设计和训练方法的详细分析，以促进进一步研究。代码和模型可在https://github.com/XiaomiMiMo/MiMo-Embodied获取。|
|**2025-11-20**|[Large Language Model-Based Reward Design for Deep Reinforcement Learning-Driven Autonomous Cyber Defense](http://arxiv.org/abs/2511.16483)|null|在复杂动态环境中为自主网络攻防学习智能体设计奖励对领域专家而言是一项具有挑战性的任务。我们提出了一种基于大语言模型（LLM）的奖励设计方法，用于在深度强化学习（DRL）驱动的实验模拟环境中生成自主网络防御策略。我们精心设计了多个攻防智能体角色，以反映智能体行动的异质性，从而生成LLM引导的奖励设计，其中LLM首先被提供了上下文网络模拟环境信息。这些奖励结构随后在一个DRL驱动的攻防模拟环境中被利用，以学习一组网络防御策略。我们的结果表明，LLM引导的奖励设计能够带来针对多样化对抗行为的有效防御策略。|
|**2025-11-20**|[LAOF: Robust Latent Action Learning with Optical Flow Constraints](http://arxiv.org/abs/2511.16407)|null|从大规模视频中学习潜在动作对于可扩展具身基础模型的预训练至关重要，然而现有方法常难以处理与动作无关的干扰因素。尽管引入动作监督能减轻这些干扰，但其有效性受限于可用动作标签的稀缺性。光流表示连续帧之间的像素级运动，自然地抑制背景元素并强调移动物体。受此启发，我们提出了一种具有光流约束的鲁棒潜在动作学习方法，简称LAOF，这是一个伪监督框架，它利用智能体的光流作为动作驱动信号，以学习对干扰因素鲁棒的潜在动作表示。实验结果表明，LAOF学习到的潜在表示在下游模仿学习和强化学习任务中优于现有方法。这种卓越性能源于光流约束，它显著稳定了训练，并在极端标签稀缺条件下提高了潜在表示的质量，同时在动作标签比例增加到10%时仍然有效。重要的是，即使没有动作监督，LAOF也能达到或超越使用1%动作标签训练的动作监督方法。|
|**2025-11-20**|[OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](http://arxiv.org/abs/2511.16334)|**[link](https://github.com/EvolvingLMMs-Lab/OpenMMReasoner)**|大型推理模型的最新进展激发了将此类能力扩展到多模态领域的日益增长的兴趣。然而，尽管视觉推理取得了显著进展，但缺乏透明且可复现的数据整理和训练策略仍然是可扩展研究的主要障碍。在本文中，我们介绍了OpenMMReasoner，这是一种用于多模态推理的完全透明的两阶段方案，涵盖了监督微调（SFT）和强化学习（RL）。在SFT阶段，我们构建了一个包含87.4万个样本的冷启动数据集，并进行了严格的逐步验证，为推理能力提供了坚实的基础。随后的RL阶段利用了一个包含7.4万个样本的跨多样领域数据集，以进一步提升和稳定这些能力，从而实现更鲁棒和高效的学习过程。广泛的评估表明，我们的训练方案不仅超越了强大的基线，而且强调了数据质量和训练设计在塑造多模态推理性能方面的关键作用。值得注意的是，我们的方法在九个多模态推理基准测试中，相对于Qwen2.5-VL-7B-Instruct基线实现了11.6%的提升，为未来大规模多模态推理研究奠定了坚实的经验基础。我们已在https://github.com/EvolvingLMMs-Lab/OpenMMReasoner开源了我们所有的代码、流程和数据。|
|**2025-11-18**|[UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning](http://arxiv.org/abs/2511.14760)|null|我们提出UniGen-1.5，一个用于高级图像理解、生成和编辑的统一多模态大语言模型（MLLM）。在UniGen的基础上，我们全面增强了模型架构和训练流程，以加强图像理解和生成能力，同时解锁强大的图像编辑能力。尤其地，我们提出了一种统一的强化学习（RL）策略，通过共享奖励模型共同改进图像生成和图像编辑。为了进一步提升图像编辑性能，我们提出了一个轻量级的编辑指令对齐阶段，显著提高了编辑指令理解能力，这对于RL训练的成功至关重要。实验结果表明，UniGen-1.5展示了具有竞争力的理解和生成性能。具体而言，UniGen-1.5在GenEval和ImgEdit上分别取得了0.89和4.31的总分，超越了BAGEL等最先进模型，并达到了与GPT-Image-1等专有模型相当的性能。|
|**2025-11-18**|[ $π^{*}_{0.6}$: a VLA That Learns From Experience](http://arxiv.org/abs/2511.14759)|null|我们研究视觉-语言-动作 (VLA) 模型如何通过真实世界部署并借助强化学习 (RL) 进行改进。我们提出了一种通用方法，结合经验和修正的基于优势条件策略的强化学习 (RECAP)，该方法通过优势条件化为VLA的RL训练提供支持。我们的方法将异构数据整合到自我提升过程中，包括演示数据、来自策略内收集的数据以及在自主执行期间提供的专家远程操作干预。RECAP首先通过离线强化学习预训练一个通用VLA模型，我们称之为$π^{*}_{0.6}$，该模型随后可以通过机器人数据收集进行专门化，以在下游任务上实现高性能。我们展示了采用完整RECAP方法训练的$π^{*}_{0.6}$ 模型可以在真实家庭环境中叠衣物、可靠地组装盒子，并使用专业意式咖啡机制作意式浓缩咖啡饮品。在一些最困难的任务上，RECAP将任务吞吐量提高了一倍以上，并将任务失败率大致减半。|
|**2025-11-18**|[Failure to Mix: Large language models struggle to answer according to desired probability distributions](http://arxiv.org/abs/2511.14630)|**[link](https://github.com/BiostateAIresearch/failure-to-mix)**|科学思想的生成与选择需要遵循目标概率分布进行探索。与此相反，当前的AI基准具有客观正确的答案，通过强化学习针对这些基准训练大型语言模型（LLMs）会阻碍概率性探索。在本文中，我们进行了系统性实验，要求LLMs产生遵循简单概率分布的输出，结果发现所有测试的现代LLMs都严重未能遵循这些分布。例如，要求在49%的时间里输出二元结果“1”，模型却几乎100%的时间都产生答案“0”。这种几乎只生成具有边际最高概率的输出的类似阶跃函数的行为，甚至压倒了LLM固有的强烈偏见。|
|**2025-11-18**|[Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning](http://arxiv.org/abs/2511.14617)|null|强化学习 (RL) 对于推进现代大型语言模型 (LLMs) 至关重要，然而，现有同步强化学习系统面临严重的性能瓶颈。占据端到端迭代时间主导地位的推演阶段，由于固有的工作负载不平衡，存在显著的长尾延迟和资源利用率低下问题。我们提出 Seer，一种新颖的在线上下文学习系统，它通过利用共享相同提示的请求之间在输出长度和生成模式上以前被忽视的相似性来解决这些挑战。Seer 引入了三项关键技术：用于动态负载均衡的分段推演、上下文感知调度和自适应分组推测解码。这些机制共同作用，大幅减少了推演过程中的长尾延迟并提高了资源效率。在生产级强化学习工作负载上的评估表明，与最先进的同步强化学习系统相比，Seer 将端到端推演吞吐量提高了 74% 到 97%，并将长尾延迟降低了 75% 到 93%，显著加速了强化学习训练迭代。|
|**2025-11-18**|[XAttn-BMD: Multimodal Deep Learning with Cross-Attention for Femoral Neck Bone Mineral Density Estimation](http://arxiv.org/abs/2511.14604)|null|骨骼健康状况不佳是一个重要的公共卫生问题，而低骨密度（BMD）会导致骨折风险增加，这是骨质疏松症的一个关键特征。我们提出了XAttn-BMD（交叉注意力骨密度），这是一个多模态深度学习框架，它利用髋部X射线图像和结构化临床元数据来预测股骨颈骨密度。它利用一种新颖的双向交叉注意力机制，动态整合图像和元数据特征，以实现跨模态相互增强。我们定制了一种加权平滑L1损失，旨在解决骨密度不平衡问题并优先处理临床上重要的病例。在赫特福德郡队列研究数据上进行的大量实验表明，我们的模型在回归泛化能力和鲁棒性方面均优于基线模型。消融研究证实了交叉注意力融合和定制损失函数两者的有效性。实验结果表明，通过交叉注意力整合多模态数据优于未使用交叉注意力的简单特征拼接，将均方误差（MSE）降低了16.7%，将平均绝对误差（MAE）降低了6.03%，并将R2分数提高了16.4%，突出了该方法在股骨颈骨密度估计方面的有效性。此外，我们还在临床相关的股骨颈骨密度阈值下使用二分类评估了筛查性能，证明了该模型在现实世界场景中的潜力。|
|**2025-11-18**|[ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents](http://arxiv.org/abs/2511.14584)|null|使智能体能够从经验中学习并在没有任务特定训练的情况下泛化到各种任务，仍然是强化学习和决策制定中的一个基本挑战。尽管最近的方法独立地探索了剧集记忆（Reflexion）、基于梯度的提示优化（TextGrad）和分层任务分解，但它们的协同集成潜力尚未被探索。我们引入了ReflexGrad，这是一种新颖的架构，它紧密结合了三种互补机制：(1) 基于LLM的分层TODO分解用于战略规划，(2) 历史感知因果反思，分析最近的行动模式以识别失败的根本原因并实现试验内学习，以及 (3) 基于梯度的优化以实现系统改进。与依赖少量样本演示的现有工作不同，我们的系统通过纯粹的LLM语义推理实现了真正的零样本泛化，无需任务特定示例、微调或硬编码的相似性度量。在ALFWorld基准任务上进行评估，ReflexGrad在试验0上展示了67%的零样本成功率，没有任何先前的任务经验或演示，在首次接触时即建立了有效性能。通过实证分析，我们识别了支撑稳定收敛（零行动循环）和有效跨任务迁移（67%到78%的改进）的架构机制。我们的工作表明，互补学习机制的协同集成实现了鲁棒的零样本泛化，其性能接近现有工作的少量样本基线。|
|**2025-11-18**|[Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language](http://arxiv.org/abs/2511.14565)|null|机器人可以通过从演示中学习奖励函数来适应用户偏好，但在数据有限的情况下，奖励模型经常过拟合到虚假关联并且泛化失败。发生这种情况是因为演示只展示了机器人如何执行任务，但没有说明对该任务而言什么才是重要的，导致模型关注不相关的状态细节。自然语言可以更直接地指定机器人应该关注什么，并且原则上可以消除与演示一致的许多奖励函数之间的歧义。然而，现有的以语言为条件的奖励学习方法通常将指令视为简单的条件信号，没有充分利用其解决歧义的潜力。此外，真实的指令本身也常常是模糊的，因此简单的条件化是不可靠的。我们的关键见解是这两种输入类型携带互补信息：演示展示了如何行动，而语言则指定了什么是重要的。我们提出了掩码逆强化学习（Masked IRL），一个利用大型语言模型（LLMs）结合这两种输入类型优势的框架。Masked IRL从语言指令中推断出状态相关性掩码，并强制对不相关的状态分量保持不变性。当指令模糊时，它利用LLM推理在演示的上下文中澄清指令。在仿真和真实机器人上，Masked IRL比现有以语言为条件的IRL方法表现高出15%，同时使用的数据量减少了4.7倍，这表明其在样本效率、泛化能力和对模糊语言的鲁棒性方面有所提高。项目页面：https://MIT-CLEAR-Lab.github.io/Masked-IRL 和 代码：https://github.com/MIT-CLEAR-Lab/Masked-IRL|
|**2025-11-18**|[Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](http://arxiv.org/abs/2511.14476)|null|尽管大型语言模型（LLMs）正越来越多地利用人类反馈进行训练，以确保安全并与人类价值观保持一致，但对齐决策常常忽视人类社会的多样性。本研究通过系统评估对齐流程中的人口统计学差异和设计参数，考察了融入多元价值观如何影响LLM行为。我们收集了来自美国和德国参与者（N = 1,095，共27,375次评分）的对齐数据，他们对LLM的回复在五个维度上进行了评分：毒性、情感意识（EA）、敏感性、刻板印象偏见和帮助性。我们使用来自不同社会群体的偏好微调了多个大型语言模型和大型推理模型，同时改变了评分量表、异议处理方法和优化技术。结果揭示了系统性的人口统计学效应：男性参与者对回复的毒性评分比女性参与者低18%；保守派和黑人参与者对回复的情感意识评分分别比自由派和白人参与者高27.9%和44%。基于特定群体偏好微调的模型表现出不同的行为。技术设计选择显示出显著影响：保留评分者异议比多数投票实现了大约53%的毒性降低，5点量表比二元格式带来了大约22%的额外降低；直接偏好优化（DPO）在多价值观优化中始终优于群体相对策略优化（GRPO）。这些发现代表了回答一个关键问题的一个初步步骤：对齐应如何平衡专家驱动和用户驱动的信号，以确保安全和公平代表性？|
|**2025-11-18**|[Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning](http://arxiv.org/abs/2511.14460)|**[link](https://github.com/0russwest0/Agent-R1)**|大语言模型（LLM）正越来越多地被探索用于构建能够进行主动环境交互（例如，通过使用工具）以解决复杂问题的智能体。强化学习（RL）被认为是一种具有巨大潜力的关键技术，用于训练此类智能体；然而，强化学习在LLM智能体上的有效应用仍处于初级阶段，并面临诸多挑战。当前，这一新兴领域缺乏对专门为LLM智能体环境量身定制的强化学习方法的深入探索，以及缺乏为此目的设计的灵活且易于扩展的训练框架。为了推动这一领域的发展，本文首先通过系统地扩展马尔可夫决策过程（MDP）框架以全面定义LLM智能体的关键组成部分，从而重新审视并阐明针对LLM智能体的强化学习方法。其次，我们引入了Agent-R1，一个模块化、灵活且用户友好的训练框架，用于基于RL的LLM智能体，旨在实现对各种任务场景和交互环境的轻松适应。我们在多跳问答（Multihop QA）基准任务上进行了实验，为所提出方法和框架的有效性提供了初步验证。|
|**2025-11-18**|[Watchdogs and Oracles: Runtime Verification Meets Large Language Models for Autonomous Systems](http://arxiv.org/abs/2511.14435)|null|在涉及具备学习能力的组件和开放环境时，确保自主系统的安全性与可信赖性尤为困难。形式化方法提供强有力的保证，但其依赖于完整模型和静态假设。运行时验证 (RV) 通过在运行时监控执行来对其进行补充，并且在其预测变体中，通过预测潜在违规来发挥作用。与此同时，大型语言模型 (LLMs) 擅长于将自然语言转换为形式化产物和识别数据中的模式，然而它们仍然容易出错且缺乏形式化保证。本展望论文主张运行时验证 (RV) 与大型语言模型 (LLMs) 的共生集成。运行时验证 (RV) 可作为LLM驱动的自主性的护栏，而LLMs则可以通过辅助规范捕获、支持预见性推理和帮助处理不确定性来扩展RV。我们阐述了这种相互强化与现有综述和路线图的不同之处，讨论了挑战和认证影响，并确定了迈向可靠自主性的未来研究方向。|
|**2025-11-14**|[Drone Swarm Energy Management](http://arxiv.org/abs/2511.11557)|**[link](https://github.com/pkasyanov/Drone-Swarm-Energy-Management)**|本文提出了一种无人机蜂群系统在不确定性下进行决策的分析框架，该框架基于部分可观测马尔可夫决策过程（POMDP）与深度确定性策略梯度（DDPG）强化学习的集成。所提出的方法使得无人机（UAV）能够在认知AI平台中实现自适应控制和协作行为，其中每个智能体从动态环境状态中学习最优能量管理和导航策略。我们通过贝叶斯滤波推导出的信念状态表示扩展了标准DDPG架构，从而在部分可观测环境中实现鲁棒决策。本文中，在高斯情况下，我们数值比较了从DDPG导出的策略与原始连续问题的离散化版本的最优策略的性能。仿真结果表明，与基线方法相比，基于POMDP-DDPG的蜂群控制模型显著提高了任务成功率和能量效率。所提出的框架支持多个智能体之间的分布式学习和决策协调，为可扩展的认知蜂群自主性奠定了基础。本研究成果有助于推动智能多智能体系统节能控制算法的进步，并可应用于安全、环境监测和基础设施检查等场景。|
|**2025-11-14**|[W2S-AlignTree: Weak-to-Strong Inference-Time Alignment for Large Language Models via Monte Carlo Tree Search](http://arxiv.org/abs/2511.11518)|**[link](https://github.com/alexzdy/W2S-AlignTree)**|大型语言模型（LLMs）展现出令人印象深刻的能力，然而由于弱监督不足和缺乏细粒度控制，其输出结果常与人类偏好不一致。基于人类反馈的强化学习（RLHF）等训练时对齐方法面临专家监督成本过高和固有的可扩展性限制，并且在推理时提供的动态控制能力有限。因此，迫切需要可扩展且适应性强的对齐机制。为解决此问题，我们提出了W2S-AlignTree，这是一个首创的即插即用推理时对齐框架，首次协同结合了蒙特卡洛树搜索（MCTS）与弱到强泛化范式。W2S-AlignTree将LLM对齐表述为生成式搜索树中的一个最优启发式搜索问题。通过利用弱模型的实时、步级信号作为对齐代理，并引入熵感知探索机制，W2S-AlignTree在不修改强模型参数的情况下，实现了其生成过程中的细粒度指导。该方法在高维生成搜索树中动态平衡了探索与利用。在受控情感生成、摘要和指令遵循任务上的实验表明，W2S-AlignTree持续超越了强基线。值得注意的是，W2S-AlignTree将Llama3-8B在摘要任务上的性能从1.89提升到2.19，相对提升了15.9%。|
|**2025-11-14**|[Multi-Phase Spacecraft Trajectory Optimization via Transformer-Based Reinforcement Learning](http://arxiv.org/abs/2511.11402)|null|自主航天器在发射、上升、级间分离和入轨等任务阶段的控制仍然是一个严峻的挑战，因为需要能够泛化到动态特性不同的阶段的自适应策略。尽管强化学习（RL）在单个天体动力学任务中已展现潜力，但现有方法通常需要为不同的任务阶段设计单独的策略，这限制了适应性并增加了操作复杂性。本工作提出了一个基于Transformer的强化学习框架，该框架通过单一策略架构统一了多阶段轨迹优化，利用了Transformer建模扩展时间上下文的固有能力。在近端策略优化（PPO）的基础上，我们的框架用Transformer编码器-解码器结构取代了传统的循环网络，使智能体能够在关键操作中跨越持续数秒到数分钟的任务阶段保持连贯的记忆。通过集成门控Transformer-XL (GTrXL) 架构，该框架消除了手动阶段转换，同时保持了控制决策的稳定性。我们循序渐进地验证了我们的方法：首先在单阶段基准测试（双积分器和范德波尔振荡器）上展示了近乎最优的性能，然后扩展到多阶段航路点导航变体，最后解决了一个复杂的多阶段火箭上升问题，该问题包括大气层飞行、级间分离和真空操作。结果表明，基于Transformer的框架不仅在简单情况下与解析解匹配，而且有效地学习了跨越动态特性不同阶段的连贯控制策略，为可扩展的自主任务规划奠定了基础，减少了对阶段特定控制器的依赖，同时保持了与安全关键验证协议的兼容性。|
|**2025-11-14**|[MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism](http://arxiv.org/abs/2511.11373)|**[link](https://github.com/liushulinle/MarsRL)**|大语言模型（LLM）的近期进展得益于可验证奖励的强化学习（RLVR）和测试时扩展。然而，LLM有限的输出长度限制了单次推理过程中可达到的推理深度。多智能体推理系统提供了一个有前景的替代方案，通过采用包括求解器、验证器和纠正器在内的多个智能体来迭代优化解决方案。尽管它们在Gemini 2.5 Pro等闭源模型中表现出色，但由于批评和纠正能力不足，难以泛化到开源模型。为解决此问题，我们提出了MarsRL，一种新颖的强化学习框架，采用智能体流水线并行，旨在联合优化系统中的所有智能体。MarsRL引入了智能体特定的奖励机制以减轻奖励噪声，并采用流水线启发式训练以提高处理长轨迹的效率。应用于Qwen3-30B-A3B-Thinking-2507，MarsRL将AIME2025准确率从86.5%提高到93.3%，并将BeyondAIME从64.9%提高到73.8%，甚至超越了Qwen3-235B-A22B-Thinking-2507。这些发现突出了MarsRL推动多智能体推理系统发展并扩大其在多样化推理任务中适用性的潜力。|
|**2025-11-14**|[STaR: Towards Cognitive Table Reasoning via Slow-Thinking Large Language Models](http://arxiv.org/abs/2511.11233)|null|大语言模型（LLMs）的表格推理是构建能够理解和分析结构化数据的智能系统的基本途径。尽管最新进展显示出喜人成果，但它们仍面临两个主要局限：(i) 推理过程缺乏人类认知所特有的深度和迭代细化能力；(ii) 推理过程表现出不稳定性，这损害了其在下游应用中的可靠性。在这项工作中，我们提出了STaR（用于表格推理的慢思考），这是一个实现认知表格推理的新框架，其中大语言模型通过明确建模分步思考和不确定性感知推理而被赋予慢思考能力。在训练阶段，STaR采用了两阶段难度感知强化学习（DRL），在复合奖励下逐步从简单查询学习到复杂查询。在推理阶段，STaR通过整合token级置信度和答案一致性来执行轨迹级不确定性量化，从而能够选择更可信的推理路径。在基准测试中进行的大量实验表明，STaR取得了卓越的性能并增强了推理稳定性。此外，在域外数据集上展现的强大泛化能力进一步证明了STaR作为一种可靠且受认知启发的大语言模型表格推理解决方案的潜力。|
|**2025-11-14**|[VIDEOP2R: Video Understanding from Perception to Reasoning](http://arxiv.org/abs/2511.11113)|null|强化微调 (RFT) 作为一个由监督微调 (SFT) 和强化学习 (RL) 组成的两阶段框架，在提升大型语言模型 (LLMs) 的推理能力方面取得了可喜的成果。然而，将 RFT 扩展到大型视频语言模型 (LVLMs) 仍然具有挑战性。我们提出了 VideoP2R，这是一种新颖的流程感知视频 RFT 框架，它通过将感知和推理建模为不同的过程来增强视频推理能力。在 SFT 阶段，我们开发了一个三步流水线，用于生成 VideoP2R-CoT-162K，这是一个高质量、流程感知的感知和推理思维链 (CoT) 数据集。在 RL 阶段，我们引入了一种新颖的流程感知组相对策略优化 (PA-GRPO) 算法，该算法为感知和推理提供独立的奖励。大量实验表明，VideoP2R 在七个视频推理和理解基准测试中的六个上取得了最先进 (SotA) 的性能。消融研究进一步证实了我们的流程感知建模和 PA-GRPO 的有效性，并证明了模型的感知输出对于下游推理具有足够的信息。|
|**2025-11-14**|[ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving](http://arxiv.org/abs/2511.11079)|null|我们提出ARCTraj，这是一个用于在抽象推理语料库（ARC）中建模人类通过复杂视觉任务进行推理的数据集和方法论框架。尽管ARC启发了大量关于抽象推理的研究，但大多数现有方法依赖于静态的输入-输出监督，这限制了对推理如何随时间展开的洞察。ARCTraj通过记录按时间排序的、对象级的动作来解决这一空白，这些动作捕捉了人类如何迭代地将输入转换为输出，揭示了传统数据集所忽略的中间推理步骤。通过O2ARC网络界面收集，它包含大约10,000条轨迹，这些轨迹标注了任务标识符、时间戳和成功标签，涵盖了来自ARC-AGI-1基准的400个训练任务。它进一步定义了一个统一的推理管道，包括数据收集、动作抽象、马尔可夫决策过程（MDP）建模和下游学习，从而能够与强化学习、生成建模和序列建模方法集成，例如PPO、世界模型、GFlowNets、扩散智能体和决策Transformer。对空间选择、颜色归因和策略收敛的分析凸显了人类推理的结构和多样性。总之，这些贡献将ARCTraj定位为一个结构化且可解释的基础，用于研究类人推理，推动了可解释性、对齐和泛化智能的发展。|
|**2025-11-14**|[Data Poisoning Vulnerabilities Across Healthcare AI Architectures: A Security Threat Analysis](http://arxiv.org/abs/2511.11020)|null|医疗AI系统面临数据投毒的重大漏洞，而当前的防御措施和法规无法充分解决。我们分析了八种攻击场景，分为四个类别：针对卷积神经网络、大语言模型和强化学习智能体的架构攻击；利用联邦学习和医疗文档系统的基础设施攻击；影响器官移植和危机分流的关键资源分配攻击；以及针对商业基础模型的供应链攻击。我们的研究结果表明，攻击者只需访问100-500个样本即可危及医疗AI系统，无论数据集大小，成功率常超过60%，而检测估计需要6到12个月，或者有时根本无法检测到。医疗基础设施的分布式特性产生了许多入口点，内部人员通过常规访问即可用有限的技术技能发动攻击。HIPAA和GDPR等隐私法可能通过限制检测所需的分析，无意中保护了攻击者。供应链弱点允许一个受损供应商向50到200家机构的模型投毒。医疗抄写员Sybil场景展示了协调的虚假患者就诊如何在无需系统入侵的情况下，通过合法的临床工作流程投毒数据。当前法规缺乏强制性的对抗性鲁棒性测试，联邦学习可能通过模糊归因加剧风险。我们建议采取多层防御措施，包括强制性对抗性测试、基于集成的检测、隐私保护安全机制，以及在AI安全标准方面的国际协调。我们也质疑不透明的黑盒模型是否适用于高风险临床决策，建议转向具备可验证安全保障的可解释系统。|
|**2025-11-14**|[When Data is the Algorithm: A Systematic Study and Curation of Preference Optimization Datasets](http://arxiv.org/abs/2511.10985)|null|对齐大型语言模型（LLM）是后训练的一个核心目标，通常通过奖励建模和强化学习方法实现。其中，直接偏好优化（DPO）已成为一种广泛采用的技术，它通过对首选完成而非次优完成进行微调来优化LLM。尽管大多数前沿LLM不公开其精选的偏好对，广大的LLM社区已发布了多个开源DPO数据集，包括TuluDPO、ORPO、UltraFeedback、HelpSteer和Code-Preference-Pairs。然而，系统的比较仍然稀缺，这主要是由于高计算成本和缺乏丰富的质量标注，使得难以理解偏好是如何选择的、它们涵盖了哪些任务类型以及它们在每个样本层面反映人类判断的程度。在这项工作中，我们首次对流行开源DPO语料库进行了全面的、以数据为中心的分析。我们利用Magpie框架对每个样本进行任务类别、输入质量和偏好奖励的标注，偏好奖励是一种基于奖励模型的信号，它无需依赖人工标注即可验证偏好顺序。这使得能够对跨数据集的偏好质量进行可扩展的、细粒度的检查，揭示了奖励边距的结构性和质量差异。基于这些见解，我们系统地策划了一个新的DPO混合数据集UltraMix，该数据集有选择地从所有五个语料库中提取数据，同时移除噪声或冗余样本。UltraMix比性能最佳的单个数据集小30%，但在关键基准测试中超越了其性能。我们公开所有标注、元数据和我们策划的混合数据集，以促进未来在以数据为中心的偏好优化方面的研究。|
|**2025-11-13**|[From Efficiency to Adaptivity: A Deeper Look at Adaptive Reasoning in Large Language Models](http://arxiv.org/abs/2511.10788)|null|大型语言模型（LLMs）的近期进展已使推理成为评估智能的核心基准。以往的综述侧重于效率，通过研究如何缩短推理链或减少计算量，但这种观点忽略了一个根本性挑战：当前的LLMs无论任务复杂性如何都采用统一的推理策略，为简单问题生成冗长的轨迹，却未能为困难任务扩展推理。本综述从{适应性}的角度重新审视推理：即根据输入特征（例如难度和不确定性）分配推理工作量的能力。我们做出了三项贡献。首先，我们在LLM语境下形式化了演绎推理、归纳推理和溯因推理，将这些经典的认知范式与它们的算法实现联系起来。其次，我们将适应性推理形式化为一个控制增强的策略优化问题，该问题平衡了任务性能与计算成本，并区分了学习到的策略和推理时的控制机制。第三，我们提出了一个系统的分类法，将现有方法组织为基于训练的方法（通过强化学习、监督微调和学习控制器内化适应性）和免训练的方法（通过提示条件、反馈驱动的停止和模块化组合实现适应性）。这个框架阐明了不同的机制如何在实践中实现适应性推理，并能对不同策略进行系统比较。最后，我们通过识别自我评估、元推理和与人类对齐的推理控制方面的开放性挑战来总结。|
|**2025-11-07**|[Visual Spatial Tuning](http://arxiv.org/abs/2511.05491)|**[link](https://github.com/Yangr116/VST)**|从视觉输入中捕捉空间关系是类人通用智能的基石。此前研究曾尝试通过引入额外的专家编码器来提升视觉语言模型（VLM）的空间感知能力，但这会带来额外开销并通常损害通用能力。为提升通用架构中的空间能力，我们提出了视觉空间调优（VST），这是一个综合框架，旨在赋予VLM类人视觉空间能力，涵盖从空间感知到空间推理。我们首先尝试通过构建大规模数据集VST-P来增强VLM的空间感知能力，该数据集包含410万个样本，涵盖单视图、多图像和视频中的19项技能。随后，我们提出了一个包含13.5万个样本的精选数据集VST-R，用于指导模型进行空间推理。特别地，我们采用渐进式训练流程：首先进行有监督微调以构建基础空间知识，随后通过强化学习进一步提升空间推理能力。在不损害通用能力的前提下，所提出的VST在多个空间基准测试中持续取得最先进的结果，包括MMSI-Bench上的34.8%和VSIBench上的61.2%。结果表明，借助所提出的空间调优范式，视觉-语言-动作模型可以得到显著增强，为更具物理基础的AI铺平了道路。|
|**2025-11-07**|[PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization](http://arxiv.org/abs/2511.05393)|null|视觉质量评估 (QA) 旨在预测人类对视觉保真度的感知判断。尽管最近的多模态大语言模型 (MLLMs) 在图像和视频质量推理方面展现出潜力，但现有方法主要依赖于监督微调或仅基于排序的目标，导致浅层推理、糟糕的分数校准以及有限的跨领域泛化能力。我们提出了 PreResQ-R1，这是一个偏好-响应解耦强化学习框架，它在一个单一的推理驱动优化方案中统一了绝对分数回归和相对排序一致性。与之前的 QA 方法不同，PreResQ-R1 引入了一种双分支奖励公式，分别建模样本内响应一致性和样本间偏好对齐，并通过组相对策略优化 (GRPO) 进行优化。这种设计鼓励对感知质量进行细粒度、稳定且可解释的思维链推理。为了超越静态图像，我们进一步设计了一种用于视频质量评估的全局时序和局部空间数据流策略。值得注意的是，仅通过对 6K 图像和 28K 视频进行强化微调，PreResQ-R1 在 SRCC 和 PLCC 两种指标下，跨 10 个 IQA 和 5 个 VQA 基准取得了最先进的结果，在 IQA 任务中分别超越了 5.30% 和 2.15% 的幅度。除了定量收益之外，它还生成了与人类对齐的推理轨迹，揭示了质量判断背后的感知线索。代码和模型均已提供。|
|**2025-11-07**|[TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework](http://arxiv.org/abs/2511.05385)|null|检索增强生成（RAG）利用外部知识来增强大型语言模型（LLM）的可靠性。为了灵活性，智能体RAG采用自主、多轮的检索和推理来解决查询。尽管近期的智能体RAG通过强化学习得到了改进，但它们通常会因搜索和推理过程而产生大量的token开销。这种权衡优先考虑准确性而非效率。为了解决这个问题，本工作提出了TeaRAG，一个token高效的智能体RAG框架，能够压缩检索内容和推理步骤。1) 首先，通过使用简洁三元组的图检索来增强基于块的语义检索，从而压缩检索到的内容。然后，基于语义相似性和共现性构建一个知识关联图。最后，利用个性化PageRank来突出该图中的关键知识，从而减少每次检索的token数量。2) 此外，为了减少推理步骤，提出了迭代过程感知直接偏好优化（IP-DPO）。具体来说，我们的奖励函数通过知识匹配机制评估知识充分性，同时惩罚过多的推理步骤。这种设计可以生成高质量的偏好对数据集，支持迭代DPO以提高推理的简洁性。在六个数据集上，TeaRAG在Llama3-8B-Instruct和Qwen2.5-14B-Instruct上分别将平均精确匹配提高了4%和2%，同时将输出token减少了61%和59%。代码可在https://github.com/Applied-Machine-Learning-Lab/TeaRAG获取。|
|**2025-11-07**|[QUESTER: Query Specification for Generative Retrieval](http://arxiv.org/abs/2511.05301)|null|生成式检索（GR）通过将相关性存储在模型参数中并直接生成文档标识符，与传统的索引-然后-检索流程不同。然而，GR通常难以泛化且扩展成本高昂。我们引入了QUESTER（查询规范生成式检索），它利用（小型）大型语言模型将GR重新定义为查询规范生成，在此工作中，即生成由BM25处理的简单关键词查询。该策略使用强化学习技术（GRPO）进行训练。在域内和域外评估中，我们表明我们的模型比BM25更有效，并与神经信息检索（IR）模型具有竞争力，同时保持了良好的效率。|
|**2025-11-07**|[Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](http://arxiv.org/abs/2511.05286)|null|黑盒大语言模型（LLM）的个性化是一项关键但具有挑战性的任务。现有方法主要依赖于上下文注入，即将用户历史嵌入到提示中以直接指导生成过程。然而，这种单步范式给模型带来了双重负担：既要生成准确内容，又要同时与用户特定风格对齐。这通常会导致权衡，从而损害输出质量并限制精确控制。为了解决这种根本性的矛盾，我们提出了反射式个性化优化（RPO），这是一种新颖的框架，通过将内容生成与对齐解耦来重新定义个性化范式。RPO在两个不同的阶段运行：首先，一个基础模型生成高质量的通用响应；然后，一个外部反射模块明确地重写此输出，以与用户偏好对齐。该反射模块采用两阶段过程进行训练。首先，在结构化重写轨迹上采用有监督微调，以建立一个核心个性化推理策略，该策略建模从通用响应到用户对齐响应的转换。随后，应用强化学习以进一步完善和提高个性化输出的质量。在LaMP基准测试上进行的全面实验表明，RPO通过将内容生成与个性化解耦，显著优于最先进的基线。这些发现强调了显式响应塑造优于隐式上下文注入的优越性。此外，RPO引入了一个高效、模型无关的个性化层，可以与任何底层基础模型无缝集成，为以用户为中心的生成场景开辟了一个新的有效方向。|
|**2025-11-07**|[FM4Com: Foundation Model for Scene-Adaptive Communication Strategy Optimization](http://arxiv.org/abs/2511.05094)|null|第六代 (6G) 网络的出现预示着一个由AI原生空口驱动的智能通信生态系统。然而，当前通常遵循模块化和孤立优化范式的物理层设计，由于忽视了模块间依赖关系，未能实现全局端到端最优性。尽管大语言模型 (LLMs) 最近已被应用于波束预测和资源分配等通信任务，但现有研究仍局限于单任务或单模态场景，并且缺乏联合推理通信状态和用户意图以实现个性化策略适应的能力。为了解决这些局限性，本文提出了一种基于强化学习的新颖多模态通信决策模型。所提出的模型语义对齐信道状态信息 (CSI) 和文本用户指令，从而实现对物理层条件和通信意图的全面理解。它随后生成物理可实现、用户定制的链路构建策略，能够动态适应变化的环境和偏好趋势。采用了一个两阶段强化学习框架：第一阶段通过启发式探索和行为克隆扩展经验池以获取近似最优初始化，而第二阶段则通过考虑误码率、吞吐量和复杂度的多目标强化学习对模型进行微调。实验结果表明，所提出的模型在挑战性信道条件下显著优于传统的基于规划的算法，实现了鲁棒、高效和个性化的6G链路构建。|
|**2025-11-07**|[You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models](http://arxiv.org/abs/2511.04902)|null|大语言模型（LLM）的最新进展表明，无监督强化学习（RL）方法在无需外部监督的情况下增强推理能力方面具有广阔前景。然而，这些无标签RL方法对于推理能力有限的较小基础模型的泛化能力仍未被探索。在这项工作中，我们系统地研究了无标签RL方法在不同模型规模和推理能力（从0.5亿到70亿参数）上的性能。我们的实证分析揭示了关键局限性：无标签RL高度依赖于基础模型预先存在的推理能力，对于较弱的模型，其性能通常会下降到基线水平以下。我们发现，较小的模型无法生成足够长或多样化的思维链推理以实现有效的自我反思，并且训练数据的难度在决定成功中起着关键作用。为了解决这些挑战，我们提出了一种简单而有效的无标签RL方法，该方法利用课程学习在训练过程中逐步引入更难的问题，并在训练过程中屏蔽非多数派的推演。此外，我们引入了一个数据策展管道，用于生成具有预定义难度的样本。我们的方法在所有模型规模和推理能力上都显示出持续的改进，为更鲁棒的无监督RL提供了一条途径，能够引导资源受限模型中的推理能力。我们的代码可在https://github.com/BorealisAI/CuMa获取。|
|**2025-11-06**|[Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](http://arxiv.org/abs/2511.04800)|**[link](https://github.com/DawnLIU35/ERPO)**|可验证奖励强化学习（RLVR）已成为提高大语言模型（LLMs）推理能力的有效方法。组相对策略优化（GRPO）系列在使用RLVR训练LLMs方面表现出强大的性能。然而，随着模型训练时间增长和规模扩大，越来越多的训练提示成为残差提示，即那些奖励方差为零、不提供训练信号的提示。结果是，对训练有贡献的提示越来越少，从而降低了多样性并阻碍了有效性。为了充分利用这些残差提示，我们提出了策略优化中探索残差提示（ERPO）框架，该框架鼓励在残差提示上进行探索并重新激活它们的训练信号。ERPO为每个提示维护一个历史追踪器，并自适应地增加那些之前产生了所有正确响应的残差提示的采样温度。这鼓励模型生成更多样化的推理轨迹，引入不正确的响应，从而重新激活训练信号。在Qwen2.5系列上的实证结果表明，ERPO在多个数学推理基准上持续超越了强大的基线。|
|**2025-11-06**|[The Peril of Preference: Why GRPO fails on Ordinal Rewards](http://arxiv.org/abs/2511.04439)|null|群体相对策略优化（GRPO）的简洁性使其在使大型语言模型（LLMs）成为特定任务专家方面备受青睐。然而，当寻求通过更丰富、非二元的反馈来增强强化学习训练时，这种简洁性也使其适用性受限。当使用序数奖励来给予部分奖励时，GRPO的简洁性开始显现弊端，因为其群体平均基线通常会为失败轨迹分配正向优势，从而强化不正确行为。我们引入了正确性相对策略优化（CoRPO），这是一种解决该缺陷的新公式。CoRPO使用一个自适应基线，强制执行最低质量阈值，确保失败的解决方案永远不会得到正向强化。一旦策略持续达到此阈值，基线便会自动转换为相对偏好模式，推动模型寻找最优解决方案，而不仅仅是“可接受”的解决方案。我们通过代码验证任务对CoRPO进行了实验验证，结果表明它具有更稳定的收敛性和更好的域外泛化能力。这项工作代表了我们更广泛研究计划中的关键一步，旨在使LLMs通过强化学习学习真正的新能力。我们通过使LLMs能够从丰富、多维度的反馈中学习来实现这一目标——本项工作从二元奖励进展到序数奖励，并进一步迈向更密集、每步的监督。|
|**2025-11-06**|[GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](http://arxiv.org/abs/2511.04307)|null|我们介绍了GUI-360 $^\circ$，一个旨在推动计算机使用智能体（CUAs）发展的大规模综合性数据集和基准套件。CUAs带来了独特的挑战，并受到三个持续存在的空白所限制：真实世界CUA任务的稀缺性，缺乏多模态轨迹的自动化收集和标注流程，以及缺少一个统一的基准来联合评估GUI接地、屏幕解析和动作预测。GUI-360$^\circ$通过一个经LLM增强的、很大程度上自动化的流程来解决这些空白，该流程包括查询源获取、环境模板构建、任务实例化、批量执行和LLM驱动的质量过滤。发布的语料库包含在流行的Windows办公应用程序中跨数千条轨迹的超过120万个执行动作步骤，并包括全分辨率截图、可用时的辅助功能元数据、实例化的目标、中间推理轨迹以及成功和失败的动作轨迹。该数据集支持GUI接地、屏幕解析和动作预测这三种典型任务，以及反映现代智能体设计的混合GUI+API动作空间。在GUI-360$^\circ$上对最先进的视觉-语言模型进行基准测试，揭示了在接地和动作预测方面开箱即用时的显著不足；监督微调和强化学习产生了显著的提升，但未能弥合与人类级别可靠性之间的差距。我们发布了GUI-360$^\circ$ 及配套代码，以促进可复现研究并加速在鲁棒桌面CUAs方面的进展。完整数据集已公开发布在 https://huggingface.co/datasets/vyokky/GUI-360。|
|**2025-11-06**|[Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference](http://arxiv.org/abs/2511.04286)|null|从人类偏好中学习是使机器学习模型与主观人类判断对齐的基石。然而，收集此类偏好数据通常成本高昂且耗时，这促使人们需要更高效的学习范式。两种成熟的方法提供了互补优势：RLHF能有效扩展到大语言模型微调等高维任务，而PBO则通过主动查询实现了更高的样本效率。我们提出了一种混合框架，通过将一个采集驱动模块集成到RLHF流程中，统一了RLHF的可扩展性与PBO的查询效率，从而实现了主动且样本高效的偏好收集。我们在两个代表性领域验证了所提出的方法：(i) 高维偏好优化和 (ii) 大语言模型微调。实验结果表明，在这些任务中，样本效率和整体性能均得到了持续改进。|
|**2025-11-06**|[SSPO: Subsentence-level Policy Optimization](http://arxiv.org/abs/2511.04256)|**[link](https://github.com/yangkun0725/SSPO)**|作为大语言模型（LLMs）后训练的重要组成部分，可验证奖励强化学习（RLVR）显著提升了LLMs的推理能力。然而，GRPO（组相对策略优化）和GSPO（组序列策略优化）等一些RLVR算法，分别被观察到存在策略更新不稳定和采样数据利用率低的问题。GRPO的重要性比率在token级别计算，更侧重于优化单个token。这容易受异常值影响，导致模型训练崩溃。GSPO提出了响应级别的重要性比率计算方法，解决了GRPO重要性比率计算中高方差和训练噪声累积的问题。然而，由于所有响应token共享一个共同的重要性比率，极端值很容易抬高或拉低整体平均值，导致整个响应被错误地丢弃，从而降低采样数据的利用率。本文提出了SSPO，它应用句子级别的重要性比率，在GRPO和GSPO之间取得了平衡。SSPO不仅避免了训练崩溃和高方差，而且防止了整个响应token被裁剪机制丢弃。此外，我们将句子熵应用于PPO-CLIP，以稳健地调整裁剪边界，鼓励高熵token进行探索，并缩小低熵token的裁剪范围。特别地，SSPO在五个数据集上取得了46.57的平均分数，超过了GRPO（43.01）和GSPO（44.42），并在三个数据集上取得了最先进的性能。这些结果突出了SSPO在利用生成数据方面的有效性，它借鉴了GSPO的精髓但规避了其缺点。|
|**2025-11-06**|[Black-Box Guardrail Reverse-engineering Attack](http://arxiv.org/abs/2511.04215)|null|大语言模型（LLM）越来越多地采用护栏来对其输出施加道德、法律和应用特定的约束。尽管在缓解有害响应方面有效，这些护栏通过暴露可观测的决策模式引入了一类新的漏洞。在这项工作中，我们首次提出了对黑盒LLM护栏逆向工程攻击的研究。我们提出了护栏逆向工程攻击（GRA），这是一个基于强化学习的框架，它利用遗传算法驱动的数据增强来近似受害护栏的决策策略。通过迭代收集输入-输出对、优先处理分歧情况以及应用有针对性的变异和交叉，我们的方法逐步收敛到受害护栏的一个高保真度替代模型。我们在三个广泛部署的商业系统（即ChatGPT、DeepSeek和Qwen3）上评估了GRA，并证明它在API成本低于85美元的情况下，实现了超过0.92的规则匹配率。这些发现强调了护栏提取的实际可行性，并突出了当前LLM安全机制面临的重大安全风险。我们的发现揭示了当前护栏设计中的关键漏洞，并强调了在LLM部署中迫切需要更强大的防御机制。|
|**2025-11-06**|[BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](http://arxiv.org/abs/2511.04131)|null|为类人机器人构建行为基础模型（BFMs）有潜力将多样化的控制任务统一在一个单一的、可提示的通用策略之下。然而，现有方法要么只部署在模拟的类人角色上，要么专门用于特定任务，例如跟踪。我们提出了BFM-Zero，这是一个学习有效共享潜在表征的框架，它将运动、目标和奖励嵌入到一个共同空间中，使得一个单一策略无需重新训练即可用于多个下游任务。BFM-Zero中这种结构良好的潜在空间通过多种推理方法，包括零样本运动跟踪、目标达成、奖励优化以及少样本基于优化的适应，在现实世界中的宇树G1类人机器人上实现了多功能且鲁棒的全身技能。与之前的在线策略强化学习（RL）框架不同，BFM-Zero基于无监督RL和前向-后向（FB）模型的最新进展，它们提供了以目标为中心、可解释且平滑的全身运动潜在表征。我们通过关键的奖励整形、领域随机化和依赖历史的非对称学习进一步扩展了BFM-Zero，以弥合仿真到现实的鸿沟。这些关键设计选择在模拟中进行了定量消融研究。作为一种首创模型，BFM-Zero向可扩展的、可提示的全身类人机器人控制行为基础模型迈出了一步。|
|**2025-11-06**|[RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning](http://arxiv.org/abs/2511.04120)|**[link](https://github.com/LiXinyuan1015/RIDE)**|大语言模型（LLM）在数学推理方面表现优异，但这些结果可能因训练数据泄露或肤浅的模式匹配而非真正的推理而虚高。为此，需要一种基于对抗性扰动的评估方法来衡量其真实的数学推理能力。当前基于规则的扰动方法通常会生成不适定问题，阻碍了问题难度的系统评估和基准的演进。为弥补这一差距，我们提出了RIDE，这是一个新颖的对抗性问题重写框架，它利用项目反应理论（IRT）严格衡量问题难度，并生成本质上更具挑战性、更适定的数学问题变体。我们使用35个大语言模型模拟学生，并根据它们的响应构建了一个难度排序器。该排序器在强化学习过程中提供奖励信号，并指导一个问题重写模型在不同难度级别上重新表述现有问题。将RIDE应用于竞赛级别的数学基准，生成的扰动版本降低了先进大语言模型的性能，实验表明在26个模型上平均下降了21.73%，从而揭示了数学推理中有限的鲁棒性，并证实了我们评估方法的有效性。|
|**2025-11-06**|[RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](http://arxiv.org/abs/2511.03939)|null|人类反馈强化学习（RLHF）是对齐大语言模型（LLM）的标准方法，然而最近的进展已经超越了经典的基于文本的方法。本综述通过解决多模态对齐、文化公平性和低延迟优化方面的关键空白，综合了对齐研究的新前沿。为了系统地探索这些领域，我们首先回顾了包括PPO、DPO和GRPO在内的基础算法，然后详细分析了最新的创新。通过对这些技术进行比较性综合并概述开放性挑战，这项工作为构建更健壮、高效和公平的AI系统的研究人员提供了一个重要的路线图。|
|**2025-11-05**|[Scaling Agent Learning via Experience Synthesis](http://arxiv.org/abs/2511.03773)|null|强化学习（RL）可以通过交互实现自我提升，从而赋能大型语言模型（LLM）智能体，但由于昂贵的试运行、有限的任务多样性、不可靠的奖励信号以及基础设施复杂性等因素，其实际应用仍面临挑战，所有这些都阻碍了可扩展经验数据的收集。为应对这些挑战，我们引入了DreamGym，这是首个旨在以可扩展性为目标合成多样化经验的统一框架，以实现自主智能体有效的在线强化学习训练。DreamGym不依赖于昂贵的真实环境试运行，而是将环境动态提炼成一个基于推理的经验模型，该模型通过逐步推理推导出一致的状态转换和反馈信号，从而实现强化学习中可扩展的智能体试运行数据收集。为提高转换的稳定性和质量，DreamGym利用一个经验回放缓冲区，该缓冲区用离线真实世界数据初始化，并不断通过新的交互进行丰富，以积极支持智能体训练。为改善知识获取，DreamGym自适应地生成挑战当前智能体策略的新任务，从而实现更有效的在线课程学习。跨多样化环境和智能体骨干网络的实验表明，DreamGym在全合成设置和仿真到现实迁移场景中都显著提升了强化学习训练。在WebArena等非RL就绪任务上，DreamGym的性能超越所有基线30%以上。在RL就绪但成本高昂的设置中，它仅使用合成交互就达到了与GRPO和PPO相当的性能。当将纯粹在合成经验上训练的策略迁移到真实环境强化学习时，DreamGym在需要少得多的真实世界交互的同时，带来了显著的额外性能提升，为通用强化学习提供了一种可扩展的“热启动”策略。|
|**2025-11-05**|[Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning](http://arxiv.org/abs/2511.03724)|null|人工智能研究人员长期关注扑克类游戏，将其作为具有多玩家动态、不完全信息和不确定性推理特征环境的试验平台。尽管最近的突破已使AI在无限制德州扑克中达到人类精英玩家的水平，但其多玩家动态并不明显：大多数牌局在仅有两名玩家经过多轮叫价后迅速收敛。在本文中，我们提出了Solly，这是首个在简化版吹牛扑克（一种以广泛多玩家参与为特征的游戏）中达到人类精英玩家水平的AI智能体。我们使用无模型、演员-评论家深度强化学习算法，通过自博弈训练了Solly。在单挑和多玩家吹牛扑克中，Solly在胜率（赢得了超过50%的牌局）和收益（赢得的资金）方面都达到了人类精英水平。Solly还在相同指标上超越了大型语言模型（LLMs），包括那些具备推理能力的模型。Solly开发了新颖的叫价策略，有效地实现了随机化博弈，并且不易被世界级人类玩家利用。|
|**2025-11-04**|[MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning](http://arxiv.org/abs/2511.02805)|null|典型的搜索代理将整个交互历史拼接进LLM上下文，这保持了信息完整性但产生了冗长、嘈杂的上下文，导致高昂的计算和内存成本。相比之下，仅使用当前轮次可以避免这种开销，但会丢弃关键信息。这种权衡限制了搜索代理的可扩展性。为了解决这一挑战，我们提出了MemSearcher，这是一个代理工作流，它迭代地维护一个紧凑的内存并将其与当前轮次结合。在每个轮次中，MemSearcher将用户问题与内存融合，以生成推理轨迹、执行搜索操作并更新内存，从而仅保留解决任务所需的关键信息。这种设计稳定了多轮交互中的上下文长度，在不牺牲准确性的前提下提高了效率。为了优化这个工作流，我们引入了多上下文GRPO，这是一个端到端强化学习框架，它联合优化MemSearcher代理的推理、搜索策略和内存管理。具体而言，多上下文GRPO在不同上下文下采样轨迹组，并将轨迹级别的优势传播到其内部的所有对话中。在与Search-R1相同的数据集上进行训练，MemSearcher在七个公共基准测试中相比强大的基线取得了显著改进：在Qwen2.5-3B-Instruct上相对平均增益11%，在Qwen2.5-7B-Instruct上相对平均增益12%。值得注意的是，基于3B模型的MemSearcher甚至优于基于7B模型的基线，这表明在信息完整性和效率之间取得平衡，既能获得更高的准确性，又能降低计算开销。代码和模型将公开可用，网址为https://github.com/icip-cas/MemSearcher|
|**2025-11-04**|[Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning](http://arxiv.org/abs/2511.02755)|null|大型语言模型（LLM）在不同领域展现出互补的优势，并且具有不同的推理成本，这促使人们设计多智能体LLM系统，其中专业模型可以高效协作。现有方法主要依赖去中心化框架，这些框架对每个输入都会调用多个LLM，从而导致高昂且不可控的推理成本。在这项工作中，我们引入了一种集中式多LLM框架，其中一个控制器LLM以成本高效且成本可控的方式选择性地协调一组专家模型。我们将这种协调问题建模为具有双重目标的强化学习：最大化任务性能同时最小化总推理成本。此外，我们期望多智能体系统在推理过程中能够根据不同的预算条件调整其行为。为此，我们提出了CoRL，一个在可控多预算设置下优化性能成本权衡的强化学习框架。在四个不同基准上的实验表明，CoRL使单个系统能够在高预算设置下超越最佳专家LLM，同时在更经济的低预算模式下保持强大性能，这突显了集中式协调对于可扩展和成本高效的多智能体LLM系统的有效性。|
|**2025-11-04**|[VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation Models](http://arxiv.org/abs/2511.02712)|null|视频情感理解与预测在近期研究中获得了广泛关注，这得益于视频大语言模型 (VideoLLMs) 的进展。尽管先进方法在视频情感分析方面取得了进展，但情感的内在特性带来了严峻挑战。情感的特点是其动态性和线索依赖性，使得理解复杂且不断演变的情感状态并给出合理依据变得困难。为应对这些挑战，我们提出了一种新颖的情感线索引导推理框架，该框架以阶段式方式统一了基本属性感知、表达分析和高级情感理解。我们方法的核心是一系列视频情感基础模型 (VidEmo)，它们专门为情感推理和指令遵循而设计。这些模型经过两阶段调优过程：首先是用于注入情感知识的课程情感学习，其次是用于情感推理的情感树强化学习。此外，我们建立了一个基础数据基础设施，并引入了一个以情感为中心的细粒度数据集 (Emo-CFG)，该数据集包含210万个多样化的指令式样本。Emo-CFG包括可解释的情感问答、细粒度描述以及相关的推理依据，为推进情感理解任务提供了重要资源。实验结果表明，我们的方法取得了有竞争力的性能，并在15项面部感知任务中树立了新的里程碑。|
|**2025-11-04**|[Curriculum Design for Trajectory-Constrained Agent: Compressing Chain-of-Thought Tokens in LLMs](http://arxiv.org/abs/2511.02690)|null|在部署期间训练智能体在严格约束下运行，例如有限的资源预算或严格的安全要求，带来了巨大的挑战，尤其当这些约束使任务变得复杂时。在这项工作中，我们提出了一种课程学习策略，该策略在训练期间逐步收紧约束，使智能体能够逐步掌握部署要求。受无约束强化学习（RL）中自步学习技术的启发，我们的方法通过最初在简化版约束上进行训练并逐步引入完整的部署条件，促进了向挑战性环境的更平滑过渡。我们使用二叉树马尔可夫决策过程（MDP）中的RL智能体进行了一项理论分析，以证明我们的课程策略相对于从一开始就施加轨迹约束的基线方法可以加速训练。此外，我们通过实验验证了我们方法在RL和大型语言模型（LLM）智能体上的有效性和通用性，涵盖了多种设置，包括二叉树MDP、多任务导航领域以及具有两个基准的数学推理任务。这些结果凸显了课程设计在提高部署期间在复杂轨迹约束下运行的智能体效率和性能方面的潜力。此外，当应用于LLM时，我们的策略能够压缩输出思维链（chain-of-thought）token，在消费级硬件上实现了显著的推理加速，证明了其在资源受限部署中的有效性。|
|**2025-11-04**|[Auditable-choice reframing unlocks RL-based verification for open-ended tasks](http://arxiv.org/abs/2511.02463)|null|可验证奖励强化学习 (RLVR) 在增强大型语言模型 (LLMs) 的推理能力方面展现出巨大潜力，并在数学和编程等存在标准答案的领域取得了显著进展。然而，对于缺乏真实解决方案的开放式任务（例如创意写作和指令遵循），现有研究通常将其视为非推理场景，从而忽视了推理能力的潜在价值。这引出了一个关键问题：强化推理能否提升开放式任务的性能？为了解决这个问题，我们探索了将RLVR范式迁移到开放域。然而，由于RLVR本质上依赖于预设标准答案存在的验证器，它无法直接应用于开放式任务。为了克服这一挑战，我们引入了可验证多项选择重构 (VMR)，这是一种新颖的训练策略，它将开放式数据重构为可验证的多项选择格式，从而即使在缺乏明确真实答案的情况下也能实现有效训练。在多个基准测试上的实验结果验证了我们方法在提升LLM在开放式任务上性能的有效性。值得注意的是，在八个开放式基准测试中，我们基于VMR的训练相较于基线带来了平均5.99分的提升。代码将在论文被接受后发布，以促进可复现性。|
|**2025-11-04**|[ChartM $^3$: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension](http://arxiv.org/abs/2511.02415)|null|复杂图表理解任务对多模态大语言模型（MLLM）的先进视觉识别和推理能力提出了要求。然而，当前研究对复杂图表场景以及实际应用中普遍存在的计算密集型推理任务覆盖有限。本研究提出了一种自动化多阶段代码驱动的流水线，用于系统地生成视觉推理数据集，以解决这些局限性。该流水线集成了检索增强生成（RAG）以检索专业的图表模板，并采用思维链（CoT）策略生成模拟真实数据分布的推理代码，从而驱动图表渲染和问题相关的统计计算。通过基于模型的评估，该流水线增强了图表多样性和数据质量。利用此框架，我们构建了ChartM$^3$ ，一个多维度、多步骤的数据集，包含3.8万张图表和14.2万个问答对用于训练，以及2,871个高质量评估样本用于实际性能评估。监督微调（SFT）和强化学习（RL）实验表明，我们的数据集显著提高了推理能力和跨领域泛化性能，使小型模型在复杂图表理解方面能够达到与大型模型相当的性能。|
|**2025-11-04**|[Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation](http://arxiv.org/abs/2511.02303)|null|经过强化学习和可验证奖励训练的大语言模型（LLMs）在复杂推理任务上取得了显著成果。近期工作将这种范式扩展到多智能体环境，其中一个元思维智能体提出计划并监控进展，而一个推理智能体通过顺序对话轮次执行子任务。尽管性能喜人，我们发现了一个关键局限性：懒惰智能体行为，即一个智能体占据主导而另一个贡献甚少，这损害了协作并使设置退化为一个无效的单智能体。在本文中，我们首先提供理论分析，阐明了为何懒惰行为在多智能体推理中自然产生。接着我们引入一种稳定高效的因果影响衡量方法，以帮助缓解此问题。最后，随着协作的加剧，推理智能体面临在多轮交互中迷失并被之前嘈杂响应所困的风险。为此，我们提出一种可验证的奖励机制，通过允许推理智能体丢弃嘈杂输出、整合指令并在必要时重新启动其推理过程来鼓励深思熟虑。大量实验表明，我们的框架缓解了懒惰智能体行为，并释放了多智能体框架在复杂推理任务中的全部潜力。|
|**2025-11-04**|[SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning](http://arxiv.org/abs/2511.02280)|null|我们引入了SAIL-RL，一个强化学习(RL)后训练框架，它通过教导多模态大语言模型(MLLMs)何时以及如何思考来增强其推理能力。现有方法受限于仅基于结果的监督，这种监督奖励正确答案而不确保推理过程的合理性；同时，也受限于统一的思考策略，这经常导致在简单任务上过度思考而在复杂任务上思考不足。SAIL-RL通过一个双重奖励系统解决了这些挑战：思考奖励，它通过事实依据、逻辑连贯性和答案一致性来评估推理质量；以及判断奖励，它自适应地决定深度推理还是直接回答更合适。在最先进的SAIL-VL2上进行的实验表明，SAIL-RL在4B和8B两种规模下均提升了推理和多模态理解基准的表现，实现了与GPT-4o等商业闭源模型相比具有竞争力的性能，并显著减少了幻觉，使其成为构建更可靠、更具适应性的多模态大语言模型的原则性框架。代码将发布在https://github.com/BytedanceDouyinContent/SAIL-RL。|
|**2025-11-04**|[Training Proactive and Personalized LLM Agents](http://arxiv.org/abs/2511.02208)|null|现有工作主要关注任务成功，但我们认为，有效的真实世界智能体需要优化三个维度：生产力（任务完成）、主动性（提出关键问题）和个性化（适应多样化的用户偏好）。我们引入了UserVille，一个基于大型语言模型的用户模拟器交互式环境，能够实现多样化、可配置的用户偏好。利用UserVille，我们引入了PPP，这是一种多目标强化学习方法，共同优化了生产力、主动性和个性化这三个维度。在软件工程和深度研究任务上的实验表明，使用PPP训练的智能体相较于GPT-5等强大的基线模型取得了显著改进（平均提升21.6），展示了其提出有策略的澄清问题、适应未见过的用户偏好以及通过更好的交互提高任务成功率的能力。这项工作表明，明确地优化以用户为中心的交互对于构建实用且有效的AI智能体至关重要。|
|**2025-11-03**|[Automated Reward Design for Gran Turismo](http://arxiv.org/abs/2511.02094)|null|在设计强化学习（RL）智能体时，设计者通过定义奖励函数来传达期望的智能体行为，奖励函数是为智能体的行为提供奖励或惩罚的数值反馈。然而，将期望行为映射到奖励函数可能是一个困难的过程，尤其是在自动驾驶竞速等复杂环境中。在本文中，我们展示了当前的基础模型如何能够仅根据基于文本的指令，有效地搜索奖励函数空间，从而为《GT赛车7》赛车游戏生成期望的强化学习智能体。通过结合基于大语言模型（LLM）的奖励生成、基于视觉语言模型（VLM）偏好的评估以及人类反馈，我们展示了我们的系统如何能够生成与GT Sophy（一个冠军级强化学习赛车智能体）具有竞争力的赛车智能体，并生成新颖的行为，从而为现实世界应用中实用的自动化奖励设计铺平道路。|
|**2025-10-31**|[MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval](http://arxiv.org/abs/2510.27569)|null|大型语言模型（LLMs）擅长推理和生成，但受限于静态的预训练数据，导致事实性错误且对新信息适应性差。检索增强生成（RAG）通过将LLMs建立在外部知识之上来解决这一问题；然而，RAG的有效性关键取决于模型能否充分获取相关信息。现有RAG系统依赖单一检索器并采用固定的top-k选择，这限制了对语料库中狭窄且静态子集的访问。因此，这种单一检索器范式已成为全面获取外部信息的主要瓶颈，尤其是在需要语料库级别推理的任务中。为克服这一限制，我们提出了MARAG-R1，一个通过强化学习训练的多工具RAG框架，它使LLMs能够动态协调多种检索机制，以实现更广泛和更精确的信息获取。MARAG-R1为模型配备了四种检索工具——语义搜索、关键词搜索、过滤和聚合——并通过监督微调后接强化学习的两阶段训练过程，学习如何以及何时使用它们。这种设计使模型能够交错进行推理和检索，逐步收集足够的证据以进行语料库级别的综合。在GlobalQA、HotpotQA和2WikiMultiHopQA上的实验表明，MARAG-R1显著优于强大的基线，并在语料库级别推理任务中取得了新的最先进结果。|
|**2025-10-31**|[Interact-RAG: Reason and Interact with the Corpus, Beyond Black-Box Retrieval](http://arxiv.org/abs/2510.27566)|null|检索增强生成（RAG）通过引入外部信息显著增强了大语言模型（LLMs）。然而，当前主流的智能体RAG方法受限于一个关键缺陷：它们将检索过程视为黑盒查询操作。这将智能体的行动限制在查询发布上，阻碍了其处理复杂信息检索任务的能力。为解决此问题，我们引入了Interact-RAG，这是一种新范式，将LLM智能体从被动的查询发布者提升为检索过程的积极操作者。我们通过语料库交互引擎打破了黑盒，为智能体配备了一系列操作原语，以实现对信息检索的细粒度控制。为了进一步增强智能体在整个RAG流程中的能力，我们首先开发了一种推理增强型工作流，该工作流既支持零样本执行，又支持交互轨迹的合成。然后我们利用这些合成数据，通过监督微调（SFT）训练一个完全自主的端到端智能体，随后通过强化学习（RL）进行优化。在六个基准测试上的广泛实验表明，Interact-RAG显著优于其他先进方法，验证了我们推理交互策略的有效性。|
|**2025-10-31**|[VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision](http://arxiv.org/abs/2510.27462)|**[link](https://github.com/coder-gx/VCORE)**|对长链式思考 (CoT) 轨迹进行有监督微调 (SFT) 已成为增强大语言模型 (LLM) 推理能力的关键技术。然而，标准交叉熵损失对所有token一视同仁，忽略了它们在推理轨迹中异质的贡献。这种统一处理导致监督信号分配不当和泛化能力弱，特别是在复杂、长形式推理任务中。为解决此问题，我们提出方差控制优化重加权 (VCORE)，这是一个原则性框架，将CoT监督重新表述为一个约束优化问题。通过采用优化理论视角，VCORE实现了token之间原则性且自适应的监督分配，从而使训练目标更紧密地对齐鲁棒推理泛化的目标。实验评估表明，VCORE持续优于现有token重加权方法。在域内和域外设置下，VCORE在使用Qwen3系列 (4B, 8B, 32B) 和LLaMA-3.1-8B-Instruct模型时，在数学和编码基准上取得了显著的性能提升。此外，我们表明VCORE可作为后续强化学习的更有效初始化，为提升LLM推理能力奠定了更坚实的基础。代码将发布在https://github.com/coder-gx/VCORE。|
|**2025-10-31**|[MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models](http://arxiv.org/abs/2510.27267)|null|随着大语言模型（LLM）进入医疗领域，大多数基准测试侧重于问答或描述性推理，却忽视了对临床决策至关重要的定量推理。现有的数据集如MedCalc-Bench只涵盖少量计算任务，未能反映真实世界的计算场景。我们引入了MedCalc-Eval，这是评估LLM医学计算能力的最大基准测试，包含700多个任务，分为两类：基于公式的（例如Cockcroft-Gault、BMI、BSA）和基于规则的评分系统（例如Apgar、格拉斯哥昏迷量表）。这些任务涵盖内科、外科、儿科和心脏病学等多个专科，提供了更广泛、更具挑战性的评估环境。为了提升性能，我们进一步开发了MedCalc-Env，这是一个基于InternBootcamp框架构建的强化学习环境，能够实现多步骤临床推理和规划。在此环境中对Qwen2.5-32B模型进行微调，在MedCalc-Eval上取得了最先进的结果，在数值敏感性、公式选择和推理鲁棒性方面均有显著提升。仍然存在的挑战包括单位换算、多条件逻辑和上下文理解。代码和数据集可在https://github.com/maokangkun/MedCalc-Eval获取。|
|**2025-10-31**|[GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation](http://arxiv.org/abs/2510.27210)|**[link](https://github.com/Leon022/GUI-Rise)**|尽管多模态大语言模型（MLLM）推动了GUI导航智能体的发展，但当前方法在跨领域泛化能力和有效历史信息利用方面面临局限。我们提出了一个推理增强框架，该框架系统地整合了结构化推理、动作预测和历史信息摘要。结构化推理组件生成连贯的思维链分析，结合了进展估计和决策推理，为即时动作预测和未来步骤的紧凑历史信息摘要提供依据。基于此框架，我们通过对伪标注轨迹进行监督微调并结合使用群体相对策略优化（GRPO）的强化学习，训练了一个GUI智能体GUI-Rise。该框架采用专门的奖励机制，包括一个历史信息感知目标，直接将摘要质量与后续动作性能关联起来。在标准基准测试上的全面评估表明，在相同的训练数据条件下，该方法取得了最先进的结果，尤其在域外场景中表现尤为出色。这些发现验证了我们的框架在各种GUI导航任务中保持鲁棒推理和泛化能力。代码可在https://leon022.github.io/GUI-Rise获取。|
|**2025-10-31**|[Disrupting Networks: Amplifying Social Dissensus via Opinion Perturbation and Large Language Models](http://arxiv.org/abs/2510.27152)|null|我们研究了针对性内容注入如何能够策略性地扰乱社交网络。利用Friedkin-Johnsen (FJ) 模型，我们采用了一种社会异议度量，并表明 (i) 简单的FJ变体无法显著扰动网络，(ii) 扩展该模型可以得到有效的图结构，其中平衡态下的扰动超过了初始状态，以及 (iii) 改变个体固有观点可以最大化扰动。基于这些见解，我们设计了一个强化学习框架，用于微调大型语言模型 (LLM) 以生成面向扰乱的文本。在合成数据和真实世界数据上的实验证实，经过微调的LLM能够接近理论扰动极限。我们的发现对内容审核、对抗性信息战以及生成模型监管提出了重要的考虑。|
|**2025-10-31**|[Towards Understanding Self-play for LLM Reasoning](http://arxiv.org/abs/2510.27072)|null|由可验证奖励强化学习（RLVR）引领的大语言模型（LLM）推理的近期进展，启发了自博弈后训练，其中模型通过生成并解决自身问题来提升性能。尽管自博弈已展现出强大的域内和域外增益，但这些改进背后的机制仍知之甚少。在这项工作中，我们从“绝对零度推理器”（Absolute Zero Reasoner）的角度分析了自博弈的训练动态，并将其与RLVR和监督微调（SFT）进行比较。我们的研究考察了参数更新稀疏性、token分布的熵动态以及替代性的提案者奖励函数。我们进一步将这些动态与推理性能联系起来，使用pass@k评估。总之，我们的发现阐明了自博弈与其他后训练策略有何不同，强调了其固有的局限性，并指出了通过自博弈改进LLM数学推理的未来方向。|
|**2025-10-30**|[Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning](http://arxiv.org/abs/2510.27044)|null|数学推理是大语言模型（LLM）面临的核心挑战，它不仅要求给出正确答案，而且要求具备忠实的推理过程。可验证奖励强化学习（RLVR）已成为增强此类能力的一种有前景的方法；然而，其培养真正推理能力的效果仍不明确。我们在两个具有完全可验证解决方案的组合问题上研究了RLVR：活动调度和最长递增子序列，并使用了包含唯一最优解的精心策划的数据集。在多种奖励设计下，我们发现RLVR改进了评估指标，但这往往是通过强化肤浅的启发式方法而非习得新的推理策略实现的。这些发现揭示了RLVR泛化能力的局限性，强调了开发能够将真正的数学推理与捷径利用区分开来、并提供忠实的进展衡量标准的基准测试的重要性。代码可在 https://github.com/xashru/rlvr-seq-generalization 获取。|
|**2025-10-30**|[FlowMesh: A Service Fabric for Composable LLM Workflows](http://arxiv.org/abs/2510.26913)|null|AI部署正日益演变为数据转换、微调和智能体交互的流水线，而非单一的LLM任务；近期案例包括RLHF/RLAIF训练和智能体工作流。为应对这一转变，我们提出了FlowMesh，这是一种多租户服务架构，能够将这些工作负载作为一项共享服务而非独立的流水线进行执行和优化。它将工作流分解为细粒度操作符并记录其血缘关系，从而实现跨用户工作的去重，并在同一硬件上进行请求批处理，同时保留每个工作流的溯源性。一个全局控制平面维护一个集群范围内的就绪操作符池，并使用单一的效用函数来选择批次和工作器，在异构GPU上平衡吞吐量、成本和数据局部性。数据平面是一个由无状态工作器组成的弹性集群，由内容寻址存储支持，实现了快速、自动的横向扩展、抢占后的安全重试，以及在Kubernetes等托管集群和Vast.ai等地理分布式GPU市场上的可移植性。与基线解决方案相比，FlowMesh实现了高达3.8倍的成本降低和2.0倍的能耗降低，提供了相似或更优的延迟特性，并在动态和易故障条件下保持高效。|
|**2025-10-30**|[Defeating the Training-Inference Mismatch via FP16](http://arxiv.org/abs/2510.26788)|**[link](https://github.com/sail-sg/Precision-RL)**|大语言模型（LLM）的强化学习（RL）微调常常因训练策略与推理策略之间的数值不匹配而出现不稳定性。尽管以往的研究试图通过算法修正或工程对齐来缓解这一问题，但我们发现其根本原因在于浮点精度本身。广泛采用的BF16尽管具有较大的动态范围，却引入了大的舍入误差，从而破坏了训练与推理之间的一致性。在这项工作中，我们证明简单地改回FP16可以有效地消除这种不匹配。这一改变很简单，得到现代框架的全面支持，只需几行代码修改，并且无需修改模型架构或学习算法。我们的结果表明，统一使用FP16在各种任务、算法和框架上都能带来更稳定的优化、更快的收敛和更强的性能。我们希望这些发现能促使人们更广泛地重新审视RL微调中的精度权衡问题。|
|**2025-10-30**|[The Era of Agentic Organization: Learning to Organize with Language Models](http://arxiv.org/abs/2510.26658)|null|我们设想一个AI的新时代，称为“智能体组织”，其中智能体通过协同和并发工作解决复杂问题，从而实现超越个体智能的成果。为了实现这一愿景，我们引入了异步思维（AsyncThink）作为一种新的大型语言模型推理范式，它将内部思维过程组织成并发可执行的结构。具体而言，我们提出了一种思维协议，其中一个组织者动态地将子查询分配给工作者，合并中间知识，并产生连贯的解决方案。更重要的是，该协议中的思维结构可以通过强化学习进一步优化。实验表明，与并行思维相比，AsyncThink实现了28%的推理延迟降低，同时提高了数学推理的准确性。此外，AsyncThink能够泛化其学到的异步思维能力，无需额外训练即可有效处理未见过的任务。|
|**2025-10-30**|[InfoFlow: Reinforcing Search Agent Via Reward Density Optimization](http://arxiv.org/abs/2510.26575)|null|可验证奖励强化学习（RLVR）是一种有前景的增强代理式深度搜索的方法。然而，其应用常受限于深度搜索场景中的低奖励密度，在这些场景中，智能体需要付出大量的探索成本才能获得稀疏且通常为零的最终奖励。在本文中，我们将这一挑战形式化为奖励密度优化问题，旨在提升每单位探索成本所获得的奖励。本文引入InfoFlow，一个系统性框架，从三个方面解决这一问题：1) 子问题分解：将长程任务分解以分配过程奖励，从而提供更密集的学习信号。2) 失败引导提示：注入纠正性指导到停滞的轨迹中，以提高成功结果的概率。3) 双智能体精炼：采用双智能体架构以减轻深度探索的认知负担。一个精炼智能体综合搜索历史，有效地压缩了研究者的感知轨迹，从而降低了探索成本并提高了整体奖励密度。我们在多个代理式搜索基准上评估了InfoFlow，它显著优于强大的基线，使轻量级大型语言模型能够达到与先进专有大型语言模型相媲美的性能。|
|**2025-10-30**|[Data-Efficient RLVR via Off-Policy Influence Guidance](http://arxiv.org/abs/2510.26491)|null|数据选择是可验证奖励强化学习（RLVR）中增强大型语言模型（LLMs）推理能力的关键方面。当前的数据选择方法主要基于启发式，缺乏理论保证和泛化能力。本工作提出了一种理论基础的方法，利用影响力函数来估计每个数据点对学习目标的贡献。为了克服在线影响力估计所需的策略执行所带来的巨大计算成本，我们引入了一种离策略影响力估计方法，该方法利用预先收集的离线轨迹有效地近似数据影响力。此外，为了处理LLMs的高维梯度，我们采用稀疏随机投影来降低维度并提高存储和计算效率。利用这些技术，我们开发了带有离策略影响力指导的课程强化学习（CROPI），这是一个多阶段强化学习框架，它迭代选择对当前策略最有影响力的数据。在高达70亿参数模型上的实验表明，CROPI显著加速了训练。在15亿参数模型上，与全数据集训练相比，它实现了2.66倍的步级加速，同时每阶段仅使用10%的数据。我们的结果凸显了基于影响力的数据选择在高效RLVR中的巨大潜力。|
|**2025-10-30**|[ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems](http://arxiv.org/abs/2510.26475)|null|通过强化学习（RL）适应大型语言模型（LLMs）通常受生成阶段的瓶颈限制，该阶段可能消耗超过75%的训练时间。推测解码（SD）加速了服务系统中的自回归生成，但其在强化学习训练下的行为仍未得到充分探索。我们识别出阻碍SD简单集成到RL系统中的三个关键不足：在大批量大小下加速效果递减、在持续策略网络更新下草稿器陈旧以及草稿器引起的策略退化。为了解决这些不足，我们提出了ReSpec，一个通过三种互补机制将SD应用于RL的系统：动态调整SD配置、通过知识蒸馏演进草稿器以及根据rollout奖励加权更新。在通义千问模型（3B-14B）上，ReSpec实现了高达4.5倍的加速，同时保持了奖励收敛和训练稳定性，为高效的基于强化学习的LLM适应提供了一个实用解决方案。|
|**2025-10-30**|[Empowering RepoQA-Agent based on Reinforcement Learning Driven by Monte-carlo Tree Search](http://arxiv.org/abs/2510.26287)|null|仓库级软件工程任务要求大语言模型（LLMs）通过多轮工具交互，高效地导航并从复杂代码库中提取信息。现有方法面临显著局限性：免训练的上下文学习方法难以有效指导智能体进行工具利用和基于环境反馈的决策，而基于训练的方法通常依赖于从更大LLMs进行的昂贵蒸馏，在企业环境中引入数据合规性问题。为解决这些挑战，我们引入RepoSearch-R1，这是一种由蒙特卡洛树搜索（MCTS）驱动的新型智能体强化学习框架。该方法使智能体能够通过自训练生成多样化、高质量的推理轨迹，而无需模型蒸馏或外部监督。基于RepoSearch-R1，我们构建了一个专门为仓库问答任务设计的RepoQA-Agent。在仓库问答任务上的综合评估表明，RepoSearch-R1在答案完整性方面取得了显著提升：比无检索方法提高16.0%，比迭代检索方法提高19.5%，与通用智能体强化学习方法相比，训练效率提高33%。我们的冷启动训练方法消除了数据合规性问题，同时在仓库级推理任务中保持了鲁棒的探索多样性和答案完整性。|
|**2025-10-30**|[Graph-Enhanced Policy Optimization in LLM Agent Training](http://arxiv.org/abs/2510.26270)|null|基于群组的强化学习（RL）在复杂推理和数学任务上取得了令人印象深刻的结果。然而，当应用于训练多轮、交互式LLM智能体时，这些方法常遭遇结构盲区——即无法利用环境的底层连通性。这体现在三个关键挑战中：(1) 低效、无引导的探索，(2) 由于忽视关键状态导致的不精确信用分配，以及 (3) 由静态奖励折扣引起的短视规划。我们通过图增强策略优化（GEPO）解决了这些问题，该方法从智能体经验中动态构建状态-转移图，并利用图论中心性提供三个协同的学习信号：(1) 结构化内在奖励，引导探索高影响力的状态，(2) 用于拓扑感知信用分配的图增强优势函数，以及 (3) 适应每个状态战略价值的动态折扣因子。在ALFWorld、WebShop和专有Workbench基准测试中，GEPO表现出强大的性能，相较于竞争基线，实现了 +4.1%、+5.3% 和 +10.9% 的绝对成功率提升。这些结果强调，显式建模环境结构是一种稳健、可泛化的策略，可有效推进LLM智能体训练。|
|**2025-10-30**|[One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning](http://arxiv.org/abs/2510.26167)|null|奖励模型 (RM) 在使大型语言模型 (LLM) 与人类偏好对齐方面发挥着关键作用。然而，在工具学习领域，缺乏专门为函数调用任务设计的奖励模型，这限制了在实现更强大的智能体AI方面的进展。我们引入了ToolRM，这是一个为通用工具使用场景量身定制的轻量级生成式奖励模型系列。为构建这些模型，我们提出了一种新颖的流程，该流程利用基于规则的评分和多维采样来构建成对偏好数据。这产生了ToolPref-Pairwise-30K，一个多样化、平衡且具有挑战性的评估任务数据集，支持带有可验证反馈的强化学习。为评估工具使用奖励模型，我们还引入了TRBench $_{BFCL}$ ，这是一个基于智能体评估套件BFCL构建的基准。经我们构建的数据训练后，Qwen3-4B/8B 系列模型在成对奖励判断中实现了高达14.28%的准确率提升，大幅超越了Claude 4和OpenAI o3等前沿模型。除了训练目标，ToolRM还能泛化到更广泛的评估任务，包括N选一采样和自我修正。在ACEBench上的实验突显了其有效性和效率，实现了推理时扩展，并将输出token使用量减少了66%以上。我们发布了数据和模型检查点，以促进未来的研究。|
|**2025-10-30**|[Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math](http://arxiv.org/abs/2510.26143)|null|强化学习 (RL) 可以激发大语言模型 (LLMs) 强大的推理能力，然而，大多数开放性工作集中在数学和代码领域。我们提出了推理课程 (Reasoning Curriculum)，这是一种简单的两阶段课程，首先在与预训练对齐的领域（如数学）中激发推理能力，然后通过联合强化学习 (joint RL) 在其他领域中适应和完善这些能力。第一阶段执行一个简短的冷启动，然后进行仅限数学的强化学习，采用可验证的奖励以培养推理能力。第二阶段在混合领域数据上进行联合强化学习，以迁移和巩固这些能力。该课程是精简的，且与骨干模型无关，无需专门的奖励模型，仅需进行标准的可验证性检查。在多领域基准测试集上对Qwen3-4B和Llama-3.1-8B进行评估，推理课程取得了持续的提升。消融实验和认知技能分析表明，两个阶段都是必要的，并且数学优先的激发增加了对于解决复杂问题至关重要的认知行为。推理课程为通用推理提供了一种紧凑、易于采用的方法。|
|**2025-10-30**|[EgoExo-Con: Exploring View-Invariant Video Temporal Understanding](http://arxiv.org/abs/2510.26113)|**[link](https://github.com/minjoong507/EgoExo-Con)**|视频-LLM能否在视频从不同视角捕捉同一事件时实现一致的时间理解？为研究此问题，我们引入了EgoExo-Con (一致性)，这是一个包含全面同步的主观和客观视角视频对的基准，并配有自然语言的人工精炼查询。EgoExo-Con强调两项时间理解任务：时间验证和时间定位。它不仅评估正确性，还评估跨视角一致性。我们的分析揭示了现有视频-LLM的两个关键局限性：(1) 模型往往无法保持一致性，其结果远差于单视角表现。(2) 当使用两个视角的同步视频进行简单微调时，模型表现出改进的一致性，但其性能往往低于在单视角上训练的模型。为此，我们提出了View-GRPO，一个新颖的强化学习框架，它能有效增强视角特定的时间推理，同时鼓励跨视角的一致理解。我们的方法证明了其优于简单SFT和GRPO，尤其是在改进跨视角一致性方面。所有资源将公开发布。|
|**2025-10-28**|[Greedy Sampling Is Provably Efficient for RLHF](http://arxiv.org/abs/2510.24700)|null|人类反馈强化学习（RLHF）已成为大型语言模型后期训练的一项关键技术。尽管它取得了经验上的成功，但RLHF的理论理解仍然有限，因为仅凭偏好反馈学习KL正则化的目标与经典强化学习相比带来了额外的挑战。现有工作主要研究基于奖励的Bradley-Terry（BT）偏好模型，并扩展了利用乐观或悲观原则的经典设计。相反，本工作考虑了通用偏好模型（其在实践中的相关性最近已被观察到），并获得了性能保证，与现有工作相比取得了显著的数量级改进。令人惊讶的是，这些结果源于直接使用经验估计（即贪婪采样）的算法，而不是像以前的工作那样构建乐观或悲观估计。这一见解深植于KL正则化目标下最优策略类所独有的结构特性，我们进一步将其专门化到BT模型，突出了贪婪采样在RLHF中令人惊讶的充分性。|
|**2025-10-28**|[Repurposing Synthetic Data for Fine-grained Search Agent Supervision](http://arxiv.org/abs/2510.24694)|null|基于大型语言模型（LLM）的搜索代理越来越多地通过以实体为中心的合成数据进行训练，以解决复杂、知识密集型任务。然而，群体相对策略优化（GRPO）等主流训练方法却丢弃了这些丰富的实体信息，转而依赖于稀疏的、基于结果的奖励。这一关键限制使得它们无法区分有信息量的“接近正确”样本（即推理过程基本正确但最终答案有缺陷的样本）与完全失败的样本，从而丢弃了有价值的学习信号。我们通过利用在训练过程中被丢弃的实体来解决这一问题。我们的实证分析揭示，代理在推理过程中识别出的真实实体数量与最终答案的准确性之间存在显著的正相关性。基于这一洞察，我们引入了实体感知群体相对策略优化（E-GRPO），这是一个新颖的框架，它构建了一个密集的实体感知奖励函数。E-GRPO根据不正确样本的实体匹配率按比例分配部分奖励，使模型能够有效地从这些“接近正确”的样本中学习。在各种问答（QA）和深度研究基准上的实验表明，E-GRPO持续且显著优于GRPO基线。此外，我们的分析揭示，E-GRPO不仅实现了更高的准确性，而且诱导了更高效的推理策略，这些策略需要更少的工具调用，这展示了一种更有效和样本高效的对齐搜索代理的方法。|
|**2025-10-28**|[Evolving Diagnostic Agents in a Virtual Clinical Environment](http://arxiv.org/abs/2510.24654)|null|在本文中，我们提出了一个框架，用于通过强化学习训练大型语言模型（LLMs）作为诊断智能体，使其能够管理多轮诊断过程、自适应选择检查并确定最终诊断。与在静态病例摘要上训练的指令微调模型不同，我们的方法通过交互式探索和基于结果的反馈获取诊断策略。我们的贡献有四方面：(i) 我们提出了DiagGym，一个使用电子健康记录训练的诊断世界模型，它根据患者病史和推荐检查输出检查结果，作为一个虚拟临床环境，用于真实的诊断训练和评估；(ii) 我们通过端到端的多轮强化学习训练DiagAgent，以学习优化信息增益和诊断准确性的诊断策略；(iii) 我们引入了DiagBench，一个诊断基准，包含750个具有医生验证检查建议的病例以及99个标注了973条医生编写的诊断过程评估标准的病例；(iv) 我们展示了在多样化诊断场景中的卓越性能。DiagAgent显著优于10个最先进的LLMs，包括DeepSeek-v3和GPT-4o，以及两个提示工程智能体。在单轮设置中，DiagAgent的诊断准确性提高了9.34%，检查推荐命中率提高了44.03%。在端到端设置中，它使诊断准确性提高了15.12%，检查推荐F1分数提升了23.09%。在基于评估标准的评估中，它在加权评估标准得分方面超越了次优模型Claude-sonnet-4达7.1%。这些发现表明，在交互式临床环境中学习策略，能够赋予动态且具有临床意义的诊断管理能力，而这些能力是单纯通过被动训练无法实现的。|
|**2025-10-28**|[Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](http://arxiv.org/abs/2510.24650)|null|作物病害精准管理（SSDM）通过机器学习和深度学习（ML和DL）实现实时计算机视觉，发展迅速。研究从手工特征提取演变为大规模自动化特征学习。借助基础模型（FM），作物病害数据集现在以全新的方式进行处理。与传统神经网络不同，FM整合视觉和文本数据，以文本形式解读症状，推理症状与管理之间的关系，并支持种植者和教育工作者的交互式问答。机器人技术中的自适应学习和模仿学习进一步赋能田间病害管理。本综述筛选了大约40篇关于FM在SSDM中应用的文章，侧重于大语言模型（LLM）和视觉-语言模型（VLM），并讨论了它们在自适应学习（AL）、强化学习（RL）以及用于精准喷洒的数字孪生框架中的作用。主要发现包括：（a）FM在2023-24年间文献激增，获得关注；（b）VLM超越LLM，发表量增长5-10倍；（c）RL和AL在智能喷洒方面仍处于萌芽阶段；（d）带有RL的数字孪生可以虚拟仿真精准喷洒；（e）弥合虚拟与现实差距对于实际部署至关重要；（f）人机协作仍然有限，特别是在人在环方法中，机器人检测早期症状，人类验证不确定案例；（g）具有实时反馈的多模态FM将推动下一代SSDM。如需获取更新、资源和贡献，请访问https://github.com/nitin-dominic/AgriPathogenDatabase，提交论文、代码或数据集。|
|**2025-10-28**|[OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning](http://arxiv.org/abs/2510.24636)|null|奖励模型（RMs）已成为对齐大型语言模型（LLMs）的关键，在训练和推理阶段作为人类评估的可扩展代理。然而，现有奖励模型在知识密集型和长文本任务上表现不佳，因为评估正确性需要超越模型内部知识的依据。这一局限性阻碍了它们可靠地区分细微的质量差异，尤其是在需要外部证据时。为解决这一问题，我们引入了OpenRM，一种工具增强型长文本奖励模型，它通过调用外部工具收集相关证据，系统地判断开放式回答。我们使用组相对策略优化（GRPO），在通过可控数据合成框架生成的超过2.7万个合成成对示例上训练OpenRM。训练目标联合监督中间工具使用和最终结果准确性，激励我们的奖励模型学习有效的基于证据的判断策略。在三个新收集的数据集和两个广泛使用的基准测试上进行的大量实验表明，OpenRM显著优于现有奖励建模方法。作为进一步的步骤，我们将OpenRM整合到推理时响应选择和训练时数据选择中。这在下游LLM对齐任务中带来了持续的提升，突显了工具增强型奖励模型在扩展可靠长文本评估方面的潜力。|
|**2025-10-28**|[SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space](http://arxiv.org/abs/2510.24446)|null|多模态大语言模型（MLLM）在推理分割等视觉-语言任务中展现出令人印象深刻的能力，这些模型根据文本查询生成分割掩码。尽管先前的工作主要集中在扰动图像输入，但语义等效的文本释义——在用户以不同方式表达相同意图的现实世界应用中至关重要——仍未得到充分探索。为了解决这一空白，我们引入了一种新颖的对抗性释义任务：生成语法正确的释义，既保留原始查询含义，又会降低分割性能。为了评估对抗性释义的质量，我们开发了一个综合的自动化评估协议，并通过人工研究进行了验证。此外，我们引入了SPARTA——一种黑盒、句子级优化方法，该方法在文本自编码器的低维语义潜在空间中运行，并由强化学习指导。SPARTA取得了显著更高的成功率，在ReasonSeg和LLMSeg-40k数据集上，其性能比现有方法高出多达2倍。我们使用SPARTA和具有竞争力的基线来评估先进推理分割模型的鲁棒性。我们发现它们仍然容易受到对抗性释义的攻击——即使在严格的语义和语法约束下。所有代码和数据将在论文接收后公开发布。|
|**2025-10-28**|[MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation](http://arxiv.org/abs/2510.24431)|null|大语言模型（LLMs）最近的成功重新激发了人们对推荐系统能否实现类似规模化效益的兴趣。传统的推荐系统以庞大的嵌入表为主，其性能往往随着嵌入维度的增长而趋于饱和。相比之下，新兴的生成范式用自回归Transformer生成的紧凑语义ID（SID）序列来替代嵌入。然而，大多数工业部署仍然是闭源的，留下了两个基本问题待解决：（1）预期的规模法则在公共基准上是否成立？（2）实现有竞争力性能所需的最小后训练方案是什么？据我们所知，我们提出了MiniOneRec，这是第一个完全开源的生成式推荐框架，它提供了一个端到端的工作流程，涵盖了SID构建、有监督微调以及面向推荐的强化学习。我们通过残差量化VAE生成SID，并在Amazon评论数据集上对参数量从0.5B到7B的Qwen骨干模型进行后训练。我们的实验表明，随着模型规模的增大，训练损失和评估损失均呈现一致的下降趋势，验证了生成方法在参数效率方面的优势。为了进一步提升性能，我们提出了一个轻量级但有效的后训练流程，该流程（1）强制实现全流程SID对齐，并且（2）应用了结合受限解码和混合奖励的强化学习。这些技术共同在排序准确性和候选多样性方面带来了显著的改进。|
|**2025-10-28**|[Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards](http://arxiv.org/abs/2510.24302)|null|可验证奖励强化学习 (RLVR)，特别是结合组相对策略优化 (GRPO) 等算法，已被证明在增强大语言模型的推理能力方面高效。然而，当前流程中的一个关键瓶颈在于组式展开过程中采样轨迹的多样性有限。同质轨迹及其相关的奖励会削弱策略更新的回报信号，从而阻碍有效的策略学习。这种多样性缺乏主要源于词元级随机采样，其中局部变异很可能收敛到几乎相同的推理路径。为解决这一局限性，我们提出了前瞻树状Rollout (LATR)，这是一种新颖的rollout策略，旨在通过强制分支到可能产生不同后续的候选词元来显式促进轨迹级多样性。具体而言，LATR 迭代地分三个阶段运行：(1) 在高不确定性生成步骤进行分支，(2) 对每个新分支执行前瞻模拟，以及 (3) 剪枝在模拟过程中表现出长时间相似性的分支。与随机采样相比，LATR 平均加速策略学习131%，并在 GRPO 和动态采样策略优化 (DAPO) 算法上，在不同推理任务中将最终的 pass@1 性能提高了4.2%。我们的代码和数据已公开，网址为 https://github.com/starreeze/latr。|
|**2025-10-28**|[ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model](http://arxiv.org/abs/2510.24285)|null|细粒度视觉感知能力有限，构成了视觉-语言模型（VLMs）在实际应用中的关键瓶颈。解决这一问题极具挑战性，原因在于高质量数据的稀缺性以及现有方法的局限性：监督微调（SFT）通常会损害通用能力，而强化微调（RFT）则将文本推理置于视觉感知之上。为了弥合这一鸿沟，我们提出了一种新颖的两阶段任务，将视觉感知学习构建为一个从粗到细的渐进过程。基于这种任务表述，我们开发了ViPER，这是一个专门设计用于通过自我批评和自我预测实现迭代演化的自举框架。通过协同整合图像级和实例级重建与两阶段强化学习策略，ViPER建立了一个闭环训练范式，其中内部合成数据直接促进了感知能力的提升。应用于Qwen2.5-VL系列模型，ViPER产生了Qwen-Viper系列模型。在涵盖各种任务的七个综合基准测试中平均提升1.7%，在细粒度感知任务上最高提升6.0%，Qwen-Viper在不同视觉-语言场景中持续展现出卓越的性能，同时保持了泛化能力。除了实现感知能力的自我提升，ViPER还为生成与理解之间的相互关系提供了具体证据，这是开发更自主和更有能力的VLMs的一项突破。|
|**2025-10-28**|[Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?](http://arxiv.org/abs/2510.24259)|null|涌现式符号表示对于使发展式学习智能体能够进行跨任务规划和泛化至关重要。在这项工作中，我们研究了大型语言模型（LLMs）是否能将人类自然语言指令翻译成在分层强化学习过程中涌现的内部符号表示。我们应用了一个结构化评估框架来衡量常见的LLMs（如GPT、Claude、Deepseek和Grok）在Ant Maze和Ant Fall环境中，由分层强化学习算法生成的不同内部符号分区上的翻译性能。我们的发现表明，尽管LLMs在将自然语言翻译成环境动态的符号表示方面展现出一定的能力，但它们的性能对分区粒度和任务复杂度高度敏感。这些结果揭示了当前LLMs在表示对齐能力方面的局限性，强调了需要进一步研究语言与内部智能体表示之间鲁棒对齐的重要性。|
|**2025-10-23**|[KL-Regularized Reinforcement Learning is Designed to Mode Collapse](http://arxiv.org/abs/2510.20817)|null|人们普遍认为，优化反向KL散度会导致“模式搜索”，而优化前向KL则会导致“质量覆盖”，如果目标是从多个多样化模式中采样，则后者更受欢迎。我们通过数学和经验表明，这种直觉不一定能很好地迁移到使用反向/前向KL正则化进行强化学习（例如，在语言模型中常用）。相反，反向/前向KL的选择决定了最佳目标分布族，该分布族由正则化系数参数化。模式覆盖主要取决于其他因素，例如正则化强度以及奖励与参考概率之间的相对比例。此外，我们表明，常用的设置，如低正则化强度和相等的、可验证的奖励，往往会指定单峰目标分布，这意味着优化目标在构建上是非多样化的。我们利用这些见解构建了一个简单、可扩展且理论上合理的算法。它对奖励幅度做出了最小的改变，却能优化出一个对所有高质量采样模式赋予高概率的目标分布。在实验中，这种简单的修改能够对大型语言模型和化学语言模型进行后训练，以获得更高的解决方案质量和多样性，而无需任何外部多样性信号，并且在单独使用前向或反向KL会失败的情况下，该方法对两者都有效。|
|**2025-10-23**|[Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs](http://arxiv.org/abs/2510.20691)|null|知识图谱问答旨在通过对结构化知识图谱进行推理来回答自然语言问题。尽管大语言模型凭借其强大的推理能力推动了知识图谱问答的发展，但现有方法仍难以充分利用知识图谱中编码的丰富知识以及大语言模型的推理能力，尤其是在复杂场景中。它们通常假设知识图谱覆盖完整，缺乏判断何时需要外部信息的机制，并且其推理仍然是局部短视的，无法保持连贯的多步规划，导致即使存在相关知识也出现推理失败。我们提出了Graph-RFT，这是一种新颖的两阶段强化微调知识图谱问答框架，采用“思考时规划-知识图谱搜索-网络搜索”范式，使大语言模型能够在知识不完整条件下，跨知识图谱和网络资源执行自主规划和自适应检索调度。Graph-RFT引入了一种思维链微调方法，结合定制化的规划-检索数据集，激活结构化推理并解决了GRPO冷启动问题。随后，它引入了一种新颖的规划-检索引导强化学习过程，将显式规划和检索动作与多奖励设计相结合，实现了覆盖感知型检索调度。它采用了一个受笛卡尔启发的规划模块，将复杂问题分解为有序的子问题，并使用逻辑表达式来指导工具调用，以实现全局一致的多步推理。这种推理检索过程通过结合了结果和检索特定信号的多奖励进行优化，使模型能够学习何时以及如何有效地结合知识图谱和网络检索。|
|**2025-10-23**|[The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models](http://arxiv.org/abs/2510.20665)|null|评估大型语言模型推理轨迹的质量仍然研究不足、劳动密集且不可靠：当前实践依赖于专家评分标准、人工标注和缓慢的成对判断。自动化方法主要由量化结构连通性但未阐明高质量推理构成要素的基于图的代理主导；此类抽象对于本质上复杂的过程可能过于简化。我们引入了一个基于拓扑数据分析（TDA）的评估框架，该框架捕获推理轨迹的几何形状，并实现标签高效的自动化评估。在我们的实证研究中，拓扑特征在评估推理质量方面比标准图度量产生了显著更高的预测能力，这表明有效推理更好地由高维几何结构而非纯粹的关系图捕获。我们进一步表明，一组紧凑、稳定的拓扑特征可靠地指示轨迹质量，为未来的强化学习算法提供了一个实用信号。|
|**2025-10-23**|[EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence](http://arxiv.org/abs/2510.20578)|null|通用人工智能（AGI）的实现需要具身AI智能体，这些智能体应具备在物理环境中进行鲁棒的空间感知、有效的任务规划和自适应执行的能力。然而，当前用于具身任务的大语言模型（LLMs）和多模态大语言模型（MLLMs）存在主要局限性，包括模型设计与智能体需求之间的显著差距、实时延迟与性能之间不可避免的权衡，以及使用不真实、离线的评估指标。为解决这些挑战，我们提出了EmbodiedBrain，这是一种新颖的视觉-语言基础模型，具有7B和32B两种参数规模。我们的框架具有智能体对齐的数据结构，并采用强大的训练方法，该方法将大规模监督微调（SFT）与步骤增强组相对策略优化（Step-GRPO）相结合，通过将先行步骤整合为引导前驱来提升长程任务成功率。此外，我们还引入了一个全面的奖励系统，包括在基础设施层面进行加速的生成式奖励模型（GRM），以提高训练效率。为实现彻底验证，我们建立了一个涵盖通用、规划和端到端模拟基准的三部分评估系统，其亮点在于提出并开源了一个新颖且具有挑战性的模拟环境。实验结果表明，EmbodiedBrain在所有指标上均实现了卓越性能，为具身基础模型建立了新的最先进水平。为下一代通用具身智能体铺平道路，我们开源了所有数据、模型权重和评估方法，这些内容可在https://zterobot.github.io/EmbodiedBrain.github.io获取。|
|**2025-10-23**|[A Unified Framework for Zero-Shot Reinforcement Learning](http://arxiv.org/abs/2510.20542)|null|零样本强化学习（RL）已成为一种以无监督方式开发通用智能体的范式，能够无需在测试时进行额外训练或规划即可解决下游任务。与针对固定奖励优化策略的传统RL不同，零样本RL要求智能体编码足够丰富的表征，以支持对任何目标的即时适应，这与视觉和语言基础模型有异曲同工之处。尽管兴趣日益增长，该领域仍缺乏一个共同的分析视角。我们提出了第一个针对零样本RL的统一框架。我们的框架引入了一致的符号和分类法，组织了现有方法并允许它们之间进行直接比较。我们框架的核心是将算法分为两大家族：直接表征，其学习从奖励到策略的端到端映射；以及组合表征，其利用价值函数的子结构来分解表征。在此框架内，我们强调了各种方法的共同原则和主要区别，并为后继特征方法推导了一个扩展边界，为它们在零样本范式下的性能提供了新视角。通过在共同视角下整合现有工作，我们的框架为零样本RL的未来研究提供了原则性基础，并勾勒出开发更通用智能体的清晰路径。|
|**2025-10-23**|[Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence](http://arxiv.org/abs/2510.20470)|null|视频推理需要跨帧多步演绎，这对于多模态大语言模型（MLLM）来说仍然是一个主要挑战。尽管基于强化学习（RL）的方法能增强推理能力，但它们通常依赖于纯文本链，这会导致未能接地或产生幻觉的结论。相反，帧检索方法引入了视觉接地，但仍面临证据定位不准确的问题。为解决这些挑战，我们提出了Conan，一个用于证据接地多步视频推理的框架。Conan识别上下文帧和证据帧，对跨帧线索进行推理，并自适应地决定何时得出结论或进一步探索。为此，我们（1）构建了Conan-91K，一个包含帧识别、证据推理和动作决策的自动生成推理轨迹的大规模数据集，以及（2）设计了一种多阶段渐进式冷启动策略，并结合识别-推理-动作（AIR）RLVR训练框架，以共同增强多步视觉推理能力。在六个多步推理基准上的大量实验表明，Conan在准确性方面平均超越基线Qwen2.5-VL-7B-Instruct逾10%，实现了最先进的性能。此外，Conan能有效泛化到长视频理解任务，验证了其强大的可扩展性和鲁棒性。|
|**2025-10-23**|[LM-mixup: Text Data Augmentation via Language Model based Mixup](http://arxiv.org/abs/2510.20449)|null|指令微调对于对齐大型语言模型（LLMs）至关重要，然而指令遵循数据的质量差异很大。高质量数据至关重要，但往往稀缺；相反，大量丰富的低质量数据却经常被丢弃，导致大量信息损失。现有数据增强方法难以有效增强这些低质量数据，并且对此类技术的评估仍然定义不清。为解决此问题，我们正式定义了指令蒸馏任务：将多个低质量和冗余输入蒸馏成高质量和连贯的指令-输出对。具体而言，我们引入了一个全面的数据构建流程来创建MIXTURE，这是一个包含14.4万个样本的数据集，它将低质量或语义冗余的不完善指令簇与其高质量蒸馏结果配对。接着我们引入了LM-Mixup，首先在MIXTURE上进行监督微调，然后通过强化学习对其进行优化。此过程通过组相对策略优化（GRPO）利用了三种互补的奖励信号：质量、语义对齐和格式合规性。我们证明LM-Mixup能有效增强不完善的数据集：在仅占整个数据集约3%的蒸馏数据上对LLMs进行微调，不仅超越了在完整数据集上训练的效果，而且在多个基准测试中与最先进的高质量数据选择方法相媲美。我们的工作表明，当通过LM-Mixup正确蒸馏和增强时，低质量数据是一种宝贵的资源，显著提高了经过指令微调的LLMs的效率和性能。|
|**2025-10-23**|[Why DPO is a Misspecified Estimator and How to Fix It](http://arxiv.org/abs/2510.20413)|null|直接对齐算法，如直接偏好优化 (DPO)，基于偏好数据微调模型，仅使用监督学习而非两阶段人类反馈强化学习 (RLHF)。我们表明，DPO 编码了一个由参数化策略类诱导的奖励函数上的统计估计问题。当生成偏好的真实奖励函数无法通过策略类实现时，DPO 会出现错配，导致诸如偏好顺序反转、策略奖励恶化以及对输入偏好数据分布的高度敏感性等失败模式。另一方面，我们研究了参数化类两阶段 RLHF 的局部行为，并将其与策略空间中的自然梯度步长联系起来。我们细粒度的几何表征使我们能够提出 AuxDPO，该方法在 DPO 损失函数中引入了额外的辅助变量，以原则性方式帮助趋向 RLHF 解决方案，并缓解 DPO 中的错配问题。我们通过实验证明了 AuxDPO 在教学型多臂老虎机设置以及大语言模型对齐任务上的优越性能。|
|**2025-10-23**|[Ask a Strong LLM Judge when Your Reward Model is Uncertain](http://arxiv.org/abs/2510.20369)|null|奖励模型（RM）在基于人类反馈的强化学习（RLHF）中对齐大型语言模型（LLM）方面发挥着关键作用。然而，基于人类偏好训练的经典奖励模型容易受到奖励攻击，并且对分布外（OOD）输入的泛化能力差。相比之下，具备推理能力的强大LLM评判器即使没有额外训练也展现出卓越的泛化能力，但会带来显著更高的推理成本，限制了它们在在线RLHF中的适用性。在这项工作中，我们提出了一种基于不确定性的路由框架，可以有效地用一个强大但昂贵的LLM评判器来补充一个快速奖励模型。我们的方法将策略梯度（PG）方法中的优势估计公式化为成对偏好分类，从而实现有原则的不确定性量化以指导路由。不确定的对被转发给LLM评判器，而确定的对则由奖励模型评估。在奖励模型基准上的实验表明，我们的基于不确定性的路由策略在相同成本下显著优于随机调用评判器，并且下游对齐结果展示了其在改进在线RLHF方面的有效性。|
|**2025-10-23**|[ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows](http://arxiv.org/abs/2510.20279)|null|随着大型语言模型（LLM）的发展，它们在科学领域中的终极愿景正在浮现：我们可以构建一个人工智能协作者，有效地协助人类贯穿整个科学研究过程。我们将这种设想中的系统称为ResearchGPT。鉴于科学研究通过多个相互依存的阶段进行，实现这一愿景需要严谨的基准，这些基准评估端到端的工作流程，而非孤立的子任务。为此，我们贡献了CS-54k，一个计算机科学领域的高质量科学问答对语料库，该语料库基于1.4万篇CC许可论文构建。它通过一个可扩展的、以论文为基础的流水线构建，该流水线结合了检索增强生成（RAG）和多阶段质量控制，以确保事实依据。从这个统一的语料库中，我们派生出两个互补的子集：CS-4k，一个精心策划的基准，用于评估AI协助科学研究的能力；以及CS-50k，一个大规模训练数据集。大量实验表明，CS-4k将最先进的LLM分层为不同的能力等级。在CS-50k上采用监督训练和强化学习训练的开源模型显示出显著的改进。即使是7B规模的模型，经过适当训练后，也能超越许多更大的专有系统，例如GPT-4.1、GPT-4o和Gemini 2.5 Pro。这表明，使AI模型成为更好的研究助手，更多地依赖于高质量数据的领域对齐训练，而非预训练规模或通用基准性能。我们发布CS-4k和CS-50k，希望能促进人工智能系统成为计算机科学研究中可靠的协作者。|
|**2025-10-21**|[EffiReasonTrans: RL-Optimized Reasoning for Code Translation](http://arxiv.org/abs/2510.18863)|null|代码翻译是软件开发和维护中一项至关重要的任务。尽管大语言模型（LLMs）的最新进展提高了自动化代码翻译的准确性，但这些改进往往以增加推理延迟为代价，阻碍了涉及人工干预检查的实际开发工作流程。为解决这种权衡，我们提出了EffiReasonTrans，这是一个旨在提高翻译准确性同时平衡推理延迟的训练框架。我们首先通过提示一个更强大的语言模型DeepSeek-R1生成中间推理和目标翻译，从而构建了一个高质量的推理增强数据集。每个（源代码、推理、目标代码）三元组都经过自动化语法和功能检查，以确保可靠性。基于此数据集，我们采用两阶段训练策略：首先在推理增强样本上进行监督微调，然后通过强化学习进一步提高准确性并平衡推理延迟。我们在六个翻译对上评估了EffiReasonTrans。实验结果表明，它持续提高了翻译准确性（与基线模型相比，CA最高提高49.2%，CodeBLEU最高提高27.8%），同时减少了生成的token数量（最高减少19.3%），并在大多数情况下降低了推理延迟（最高降低29.0%）。消融研究进一步证实了该两阶段训练框架的互补优势。此外，当集成到基于代理的框架中时，EffiReasonTrans展现了改进的翻译准确性。我们的代码和数据可在https://github.com/DeepSoftwareAnalytics/EffiReasonTrans获取。|
|**2025-10-21**|[Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning](http://arxiv.org/abs/2510.18849)|null|忠实地个性化大语言模型 (LLM) 以使其与个体用户偏好对齐是一项关键但具挑战性的任务。尽管有监督微调 (SFT) 很快达到性能平台期，但标准的人类反馈强化学习 (RLHF) 也难以处理个性化的细微之处。基于标量的奖励模型容易受到奖励攻击，这会导致生成冗长且表面化个性化的响应。为解决这些局限性，我们提出了“批判-后编辑”（Critique-Post-Edit），这是一个鲁棒的强化学习框架，能够实现更忠实和可控的个性化。我们的框架整合了两个关键组件：(1) 一个个性化生成式奖励模型 (GRM)，它提供多维分数和文本批判以抵抗奖励攻击；以及 (2) 一个批判-后编辑机制，其中策略模型基于这些批判修改其自身输出，以实现更有针对性和高效的学习。在严格的长度控制评估下，我们的方法在个性化基准测试中显著优于标准的PPO。个性化的Qwen2.5-7B模型平均胜率提升11%，而个性化的Qwen2.5-14B模型超越了GPT-4.1的性能。这些结果表明了实现忠实、高效且可控的个性化的一条实用路径。|
|**2025-10-21**|[Search Self-play: Pushing the Frontier of Agent Capability without Supervision](http://arxiv.org/abs/2510.18821)|null|可验证奖励强化学习（RLVR）已成为训练大型语言模型（LLM）智能体的主流技术。然而，RLVR高度依赖精心设计的任务查询和相应的真实答案来提供准确奖励，这需要大量人力投入并阻碍了强化学习的扩展过程，尤其是在智能体场景下。尽管一些近期工作探索了任务合成方法，但生成的智能体任务的难度难以控制，从而无法提供有效的强化学习训练优势。为实现更高可扩展性的智能体RLVR，我们探索了深度搜索智能体的自博弈训练，其中学习型LLM利用多轮搜索引擎调用，并同时充当任务提出者和问题解决者。任务提出者旨在生成带有明确定义的真实答案和不断增加任务难度的深度搜索查询。问题解决者尝试处理生成的搜索查询并输出正确的答案预测。为确保每个生成的搜索查询都具有准确的真实性，我们将提出者轨迹中的所有搜索结果作为外部知识进行收集，然后进行检索增强生成（RAG），以测试所提出的查询是否可以在提供所有必要搜索文档的情况下被正确回答。在这种搜索自博弈（SSP）游戏中，提出者和解决者通过竞争与合作共同演化其智能体能力。凭借大量的实验结果，我们发现SSP能在从零开始和持续强化学习训练设置下，在没有任何监督的情况下，统一显著提升搜索智能体在各种基准测试上的性能。代码位于https://github.com/Alibaba-Quark/SSP。|
|**2025-10-21**|[Online SFT for LLM Reasoning: Surprising Effectiveness of Self-Tuning without Rewards](http://arxiv.org/abs/2510.18814)|**[link](https://github.com/ElementQi/OnlineSFT)**|我们提出了一种简单、自助式的大语言模型推理在线监督微调（OSFT）范式。在该范式中，模型生成自己的响应，并立即利用这些自生成数据进行微调。OSFT是一种用于大语言模型推理的高效训练策略，因为它无需奖励且默认仅使用一次推演。实验结果表明，OSFT在具有挑战性的数学推理任务上实现了与GRPO等强大的可验证奖励强化学习（RLVR）方法相当的下游性能。我们的消融研究进一步证明了OSFT的效率和鲁棒性。OSFT的主要机制在于促进模型自身从预训练中学习到的已有偏好（潜在知识），从而提升推理能力。我们相信OSFT为更复杂的、基于奖励的训练范式提供了一种高效且有前景的替代方案。我们的代码可在https://github.com/ElementQi/OnlineSFT获取。|
|**2025-10-21**|[Verifiable Accuracy and Abstention Rewards in Curriculum RL to Alleviate Lost-in-Conversation](http://arxiv.org/abs/2510.18731)|null|大型语言模型在单轮指令遵循方面表现出强大的能力，但在多轮对话设置中，随着信息逐步披露，其性能会下降，即存在对话迷失（LiC）问题。受可验证奖励强化学习（RLVR）当前进展的启发，我们提出了具备可验证准确性和弃权奖励的课程强化学习（RLAAR），这是一个鼓励模型不仅生成正确答案，还能在多轮对话设置中判断问题可解性的框架。我们的方法采用一种能力门控课程，该课程逐步增加对话难度（以指令碎片衡量），从而稳定训练并提升可靠性。RLAAR利用多轮、在策略（on-policy）的滚动（rollouts）和混合奖励系统，教导模型在问题解决和明智弃权之间取得平衡，从而减少导致LiC的过早回答行为。在LiC基准测试上进行评估，RLAAR显著缓解了LiC性能衰减（从62.6%到75.1%），并提高了校准弃权率（从33.5%到73.4%）。综上所述，这些结果为构建多轮可靠且值得信赖的LLM提供了一个实用的方案。|
|**2025-10-21**|[Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options](http://arxiv.org/abs/2510.18713)|null|我们研究在线基于偏好的强化学习 (PbRL)，旨在提高样本效率。尽管受PbRL近期经验成功（尤其是在对齐大型语言模型LLM方面）的启发，越来越多的理论工作已经出现，但大多数现有研究只关注成对比较。少数近期工作 (Zhu et al., 2023, Mukherjee et al., 2024, Thekumparampil et al., 2024) 探索了使用多重比较和排序反馈，但尽管有更丰富的信息可用，它们的性能保证未能随反馈长度的增加而改善，甚至可能恶化。为了解决这一空白，我们采用Plackett-Luce (PL) 模型进行动作子集的排序反馈，并提出M-AUPO算法，该算法通过最大化所提供子集内的平均不确定性来选择多个动作。我们证明M-AUPO实现了 $\tilde{\mathcal{O}}\left( \frac{d}{T} \sqrt{ \sum_{t=1}^T \frac{1}{\|S_t\|}} \right)$的次优性差距，其中T是总轮数，d是特征维度，且$\|S_t\|$是第t轮子集的大小。这一结果表明，更大的子集直接导致性能提升，值得注意的是，该界限避免了对未知参数范数的指数依赖，这是大多数先前工作中的一个根本性限制。此外，我们建立了$\Omega \left( \frac{d}{K \sqrt{T}} \right)$ 的接近匹配下界，其中K是最大子集大小。据我们所知，这是PbRL领域中第一个关于排序反馈的理论结果，明确表明样本效率是子集大小的函数而得到提升。|
|**2025-11-11**|[Socialized Learning and Emergent Behaviors in Multi-Agent Systems based on Multimodal Large Language Models](http://arxiv.org/abs/2510.18515)|null|本研究提出了多模态社会化学习框架（M-S2L），旨在通过将多模态大语言模型（M-LLMs）与社会学习机制相结合，培养AI智能体中涌现的社会智能。该框架赋予智能体多模态感知能力（视觉和文本）和结构化行动能力，使其能够进行物理操作和具身多模态通信（例如，带有视觉指示的文本）。M-S2L将直接强化学习与两种新颖的社会学习途径相结合：多模态观察学习和通信驱动的反馈学习，并辅以情景记忆系统以获取长期社会背景信息。我们在一个协同组装环境（CAE）中评估了M-S2L，在此环境中，智能体团队必须根据模糊的蓝图并在信息不对称的情况下组装复杂的设备。在复杂度不断增加的任务中，M-S2L智能体在任务完成率和完成时间方面始终优于仅文本和无社会学习基线，尤其是在动态问题解决场景中。消融研究证实了多模态和社会化学习两者均是必要的。我们的分析揭示了将视觉指示与简洁文本相结合的高效通信协议的涌现，以及快速的角色专业化，从而形成稳定的劳动分工。定性案例研究表明智能体具备共享意识、动态重新规划和自适应问题解决的能力，这表明了一种初级的机器社会认知形式。这些发现表明，将多模态感知与显式社会学习相结合对于在多智能体系统中开发类人协作智能至关重要。|
|**2025-10-21**|[Socialized Learning and Emergent Behaviors in Multi-Agent Systems based on Multimodal Large Language Models](http://arxiv.org/abs/2510.18515)|null|本文介绍了多模态社会化学习框架 (M-S2L)，旨在通过将多模态大语言模型 (M-LLMs) 与社会学习机制相结合，在AI智能体中培养新兴的社会智能。该框架为智能体配备了多模态感知能力（视觉和文本）和结构化动作能力，使其能够进行物理操作以及基于基础的多模态通信（例如，带有视觉指示的文本）。M-S2L将直接强化学习与两种新颖的社会学习途径相结合：多模态观察学习和通信驱动的反馈学习，并通过情景记忆系统增强以获取长期社会情境。我们在一个协作组装环境 (CAE) 中评估了M-S2L，其中智能体团队必须在信息不对称的情况下，根据模糊的蓝图构建复杂的设备。在复杂度不断增加的任务中，M-S2L智能体在任务完成率和完成时间方面始终优于仅文本和无社会学习基线，尤其是在动态问题解决场景中。消融研究证实了多模态和社会化学习两者均是必要的。我们的分析揭示了将视觉指示与简洁文本相结合的高效通信协议的出现，以及快速的角色专业化从而形成稳定的劳动分工。定性案例研究表明智能体具备共享意识、动态重新规划和自适应问题解决的能力，这表明了一种新兴的机器社会认知形式。这些发现表明，将多模态感知与显式社会学习相结合，对于在多智能体系统中开发类人协作智能至关重要。|
|**2025-10-21**|[CodeRL+: Improving Code Generation via Reinforcement with Execution Semantics Alignment](http://arxiv.org/abs/2510.18471)|null|尽管大语言模型（LLMs）通过学习海量代码语料库在代码生成方面表现出色，但在它们基于文本模式的训练与由形式化执行语义支配的功能正确性目标之间，仍存在一个根本性的语义鸿沟。可验证奖励强化学习（RLVR）方法试图通过利用执行测试用例产生的结果奖励来弥合这一鸿沟。然而，仅仅依靠二元的通过/失败信号，对于在代码的文本表示与其执行语义之间建立良好对齐的连接是低效的，尤其对于代码中细微的逻辑错误。在本文中，我们提出了CodeRL+，这是一种新颖的方法，它将执行语义对齐集成到代码生成的RLVR训练流程中。CodeRL+使模型能够推断变量级的执行轨迹，从而提供执行语义的直接学习信号。CodeRL+可以直接利用现有的在策略采样构建执行语义对齐，并能与各种强化学习算法无缝集成。大量实验表明，CodeRL+优于训练后基线方法（包括RLVR和蒸馏），在pass@1指标上实现了4.6%的平均相对提升。CodeRL+能有效地泛化到其他编码任务，在代码推理和测试输出生成基准上分别取得了15.5%和4.4%更高的准确率。CodeRL+在各种强化学习算法和大语言模型中都显示出强大的适用性。此外，探针分析提供了令人信服的证据表明CodeRL+加强了代码的文本表示与其底层执行语义之间的对齐。|
|**2025-10-21**|[Med-VRAgent: A Framework for Medical Visual Reasoning-Enhanced Agents](http://arxiv.org/abs/2510.18424)|null|视觉语言模型 (VLM) 在医学推理中取得了有前景的成果，但在幻觉、模糊描述、逻辑不一致和定位能力差等方面面临挑战。为了解决这个问题，我们提出了一个名为医学视觉推理智能体 (Med-VRAgent) 的智能体框架。该方法基于视觉引导和自我奖励范式以及蒙特卡洛树搜索 (MCTS)。通过将视觉引导与树搜索结合，Med-VRAgent 提升了 VLM 的医学视觉推理能力。我们利用 Med-VRAgent 收集的轨迹作为反馈，通过使用近端策略优化 (PPO) 目标对 VLM 进行微调，以进一步提高性能。在多个医学视觉问答 (VQA) 基准上的实验表明，我们的方法优于现有方法。|
|**2025-10-21**|[MENTOR: A Reinforcement Learning Framework for Model Enhancement via Teacher-Optimized Rewards in Small Models](http://arxiv.org/abs/2510.18383)|null|将大语言模型（LLMs）的工具使用能力蒸馏到更小、更高效的小语言模型（SLMs）中是其实际应用的关键挑战。主流方法有监督微调（SFT）存在泛化能力差的问题，因为它训练模型模仿一组静态的教师轨迹，而非学习一种鲁棒的方法论。尽管强化学习（RL）提供了一种替代方案，但使用稀疏奖励的标准强化学习未能有效指导SLMs，导致它们在低效探索中挣扎并采纳次优策略。为了解决这些不同的挑战，我们提出了MENTOR，一个协同结合了强化学习与教师指导蒸馏的框架。相较于简单的模仿，MENTOR采用了一种基于RL的过程，通过探索学习一种更具泛化能力的策略。此外，为了解决奖励稀疏性问题，它使用教师的参考轨迹来构建一种密集的、复合的教师指导奖励，从而提供细粒度指导。大量实验表明，与SFT和标准稀疏奖励RL基线相比，MENTOR显著提高了SLMs的跨领域泛化能力和策略能力。|
|**2025-10-16**|[Agentic Design of Compositional Machines](http://arxiv.org/abs/2510.14980)|**[link](https://github.com/DYCI2/Dicy2)**|复杂机器的设计既是人类智慧的标志，也是工程实践的基础。鉴于大型语言模型（LLM）的最新进展，我们探讨它们是否也能学会创造。我们通过组合式机器设计的视角来探讨这个问题：在这项任务中，机器由标准化组件组装而成，以在模拟物理环境中满足运动或操纵等功能需求。为了支持这项研究，我们引入了BesiegeField，这是一个基于机器建造游戏Besiege构建的测试平台，它支持基于零件的构建、物理模拟和奖励驱动的评估。利用BesiegeField，我们对采用智能体工作流的最新LLM进行了基准测试，并识别了成功所需的关键能力，包括空间推理、策略性组装和指令遵循。由于当前的开源模型表现不足，我们探索强化学习（RL）作为改进途径：我们整理了一个冷启动数据集，进行了RL微调实验，并强调了语言、机器设计和物理推理交叉领域的开放挑战。|
|**2025-10-16**|[Learning an Image Editing Model without Image Editing Pairs](http://arxiv.org/abs/2510.14978)|**[link](https://github.com/Sfedfcv/redesigned-pancake)**|最近的图像编辑模型在遵循自然语言编辑指令方面取得了令人瞩目的成果，但它们依赖于使用大量输入-目标对数据集进行的监督微调。这是一个关键瓶颈，因为这种自然产生的配对数据难以大规模收集。当前的解决方法是利用现有模型的零样本能力生成合成训练对。然而，这可能会将预训练模型的伪影传播并放大到最终训练模型中。在这项工作中，我们提出了一种新的训练范式，完全消除了对配对数据的需求。我们的方法通过在训练期间展开一个少步扩散模型，并利用视觉-语言模型（VLM）的反馈，直接对其进行优化。对于每个输入和编辑指令，VLM评估编辑是否遵循指令并保留未更改的内容，为端到端优化提供直接梯度。为了确保视觉保真度，我们引入了分布匹配损失（DMD），它约束生成的图像保持在预训练模型学习到的图像流形内。我们在标准基准上评估了我们的方法，并进行了广泛的消融研究。在没有任何配对数据的情况下，我们的方法在少步设置下，性能与各种在大量监督配对数据上训练的图像编辑扩散模型相当。在给定相同的VLM作为奖励模型时，我们的方法也优于Flow-GRPO等基于强化学习的技术。|
|**2025-10-16**|[Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents](http://arxiv.org/abs/2510.14967)|null|基于大型语言模型（LLM）的智能体正越来越多地通过强化学习（RL）进行训练，以增强其通过工具使用与外部环境交互的能力，特别是在需要多轮推理和知识获取的基于搜索的场景中。然而，现有方法通常依赖于仅在最终答案处提供的基于结果的奖励。这种奖励稀疏性在多轮设置中变得尤为突出，其中长轨迹会加剧两个关键问题：(i) 优势坍塌，即所有采样轨迹获得相同的奖励，无法提供有用的学习信号；以及 (ii) 缺乏细粒度信用分配，即轮次间的依赖关系变得模糊，尤其是在长周期任务中。在本文中，我们提出了基于信息增益的策略优化（IGPO），这是一种简单而有效的强化学习框架，为多轮智能体训练提供了密集且内在的监督。IGPO将每次交互轮次建模为获取关于真值的增量过程，并将轮次级别奖励定义为策略生成正确答案的概率的边际增量。与以往依赖外部奖励模型或昂贵蒙特卡洛估计的过程级奖励方法不同，IGPO直接从模型自身的信念更新中导出内在奖励。这些内在的轮次级别奖励与结果级别的监督相结合，形成密集的奖励轨迹。在域内和域外基准测试上进行的大量实验表明，IGPO在多轮场景中持续优于强大的基线，实现了更高的准确性并提高了样本效率。|
|**2025-10-16**|[LaSeR: Reinforcement Learning with Last-Token Self-Rewarding](http://arxiv.org/abs/2510.14943)|**[link](https://github.com/RUCBM/LaSeR)**|可验证奖励强化学习（RLVR）最近已成为增强大型语言模型（LLMs）推理能力的核心范式。为解决测试时缺乏验证信号的问题，先前研究将模型自我验证能力的训练纳入标准RLVR过程，从而在单个LLM中统一了推理和验证能力。然而，以往的做法要求LLM使用两个独立的提示模板顺序生成解决方案和自我验证，这显著降低了效率。在这项工作中，我们理论上揭示了自我验证的强化学习目标的封闭形式解可以简化为一种非常简单的形式：解决方案的真实推理奖励等于其最后一个token的自我奖励分数，该分数计算为策略模型在解决方案最后一个token处分配给任何预先指定token的下一个token对数概率与一个预先计算的常数之间的差值，并乘以KL系数。基于这一见解，我们提出了LaSeR（带最后一个token自我奖励的强化学习），这是一种算法，它通过均方误差（MSE）损失来增强原始RLVR损失，该损失将最后一个token的自我奖励分数与基于验证器的推理奖励对齐，从而联合优化LLMs的推理和自我奖励能力。优化后的自我奖励分数可以在训练和测试中利用，以提高模型性能。值得注意的是，我们的算法在生成后立即从最后一个token的预测下一个token概率分布中推导出这些分数，仅产生一个额外token推理的最小额外开销。实验表明，我们的方法不仅提高了模型的推理性能，而且赋予了它卓越的自我奖励能力，从而提升了其推理时的扩展性能。|
|**2025-10-16**|[Reasoning with Sampling: Your Base Model is Smarter Than You Think](http://arxiv.org/abs/2510.14901)|**[link](https://github.com/Aryia-Behroziuan/References)**|前沿推理模型在广泛的学科领域展现出惊人的能力，这得益于使用强化学习(RL)对大型语言模型(LLM)进行后训练。然而，尽管这种范式取得了广泛成功，许多文献致力于辨析在RL期间出现但在基础模型中不存在的真正新颖行为。在我们的工作中，我们从一个不同的角度探讨这个问题，转而提出是否可以在推理时，通过纯粹的采样，无需任何额外训练，从基础模型中引出可比的推理能力。受马尔可夫链蒙特卡洛(MCMC)技术用于从锐化分布中采样的启发，我们提出了一种简单的迭代采样算法，该算法利用基础模型自身的似然度。在不同的基础模型上，我们展示了我们的算法在推理方面提供了显著提升，其性能几乎与RL相当，甚至在MATH500、HumanEval和GPQA等各种单次任务上超越了RL。此外，我们的采样器避免了多样本多样性坍塌，这是强化学习后训练的典型特征。至关重要的是，我们的方法不需要训练、精心策划的数据集或验证器，这表明其具有超越易于验证领域的广泛适用性。|
|**2025-10-16**|[Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates](http://arxiv.org/abs/2510.14900)|null|企业智能平台必须集成来自众多第三方供应商的日志，以执行各种下游任务。然而，在测试时，供应商文档通常不可用。它可能放错位置、不匹配、格式不佳或不完整，这使得模式映射极具挑战性。我们引入了一种强化学习智能体，它可以在没有标记示例或模型权重更新的情况下进行自我改进。在推理过程中，该智能体：1) 识别模糊的字段映射尝试。2) 生成有针对性的网络搜索查询以收集外部证据。3) 应用基于置信度的奖励来迭代地完善其映射。为了演示这一概念，我们将Microsoft Defender for Endpoint日志转换为通用模式。我们的方法在使用GPT-4o经过100次迭代后，将映射准确性从56.4%（仅限LLM）提高到72.73%（RAG），再提高到93.94%。同时，它将需要专家审查的低置信度映射数量减少了85%。这种新方法为解决未来的行业问题提供了一种证据驱动、透明的方法，为更鲁棒、负责任、可扩展、高效、灵活、适应性强和协作的解决方案铺平了道路。|
|**2025-10-16**|[SimKO: Simple Pass@K Policy Optimization](http://arxiv.org/abs/2510.14807)|**[link](https://github.com/CLR-Lab/SimKO)**|可验证奖励强化学习（RLVR）提升了大语言模型（LLMs）的推理能力。然而，当前主流的RLVR方法表现出系统性地偏向利用而非探索，具体表现为pass@1性能提高但pass@K (K>1) 性能下降。为了理解这个问题，我们通过追踪词汇候选项上的词元级别概率分布来分析RLVR方法的训练动态。我们的分析揭示了一种一致的概率集中效应，即首位候选项逐渐积累概率质量并抑制了其他候选项的概率。更重要的是，更强的过度集中与更差的pass@K性能相关联。受此发现启发，我们提出了简单Pass@K优化（SimKO），这是一种旨在缓解过度集中问题，从而鼓励探索的方法。SimKO以非对称的方式运行。对于已验证的正确响应，它提升了前K个候选项的概率。对于已验证的错误响应，它对首位候选项施加更强的惩罚。我们观察到，当应用于高熵词元时，这种非对称设计在缓解过度集中方面特别有效。在各种数学和逻辑推理基准测试中，SimKO对于广泛的K值始终产生更高的pass@K，提供了一种简单的方法来改进RLVR的探索能力。|
|**2025-10-16**|[AutoRubric-R1V: Rubric-Based Generative Rewards for Faithful Multimodal Reasoning](http://arxiv.org/abs/2510.14738)|null|多模态大语言模型（MLLMs）已从感知任务迅速发展到复杂的多步推理，然而，可验证奖励强化学习（RLVR）常常导致虚假推理，因为只奖励最终答案的正确性。为了解决这一局限性，我们提出了AutoRubric-R1V，一个通过自动收集的基于评分标准的生成式奖励将RLVR与过程级监督相结合的框架。我们的关键创新在于一种可扩展的自聚合方法，该方法从成功的轨迹中提炼出一致的推理检查点，从而实现了问题特定的评分标准构建，无需人工标注或更强大的教师模型。通过联合利用基于评分标准的奖励和结果奖励，AutoRubric-R1V在六个多模态推理基准上取得了最先进的性能，并在专门评估中显著提高了推理的忠实性。|
|**2025-10-16**|[Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](http://arxiv.org/abs/2510.14702)|null|下一个兴趣点（POI）推荐任务旨在根据用户的偏好和历史签到预测他们紧接着的下一个目的地，在基于位置的服务中具有重要价值。近年来，大语言模型（LLMs）在推荐系统中展现出巨大潜力，它们以生成式方式处理下一个POI预测。然而，这些LLMs主要在大量非结构化文本语料库上进行预训练，缺乏下一个POI预测任务所需的对结构化地理实体和序列移动模式的内在理解。此外，在工业级POI预测应用中，融入世界知识和人类认知对齐，例如季节、天气条件、节假日以及用户画像（如习惯、职业和偏好），可以提升用户体验，同时提高推荐性能。为了解决这些问题，我们提出了CoAST（认知对齐的时空大语言模型），一个以自然语言为接口的框架，允许融入世界知识、时空轨迹模式、用户画像和情境信息。具体来说，CoAST主要包含两个阶段：(1) 推荐知识获取，通过在脱敏用户的丰富化时空轨迹数据上进行持续预训练；(2) 认知对齐，通过监督微调（SFT）和随后的强化学习（RL）阶段，使用丰富化的训练数据将认知判断与人类偏好对齐。在各种真实世界数据集上进行的大量离线实验以及部署在高德地图App首页“猜你去哪”功能中的在线实验，均证明了CoAST的有效性。|
|**2025-10-16**|[An Efficient Rubric-based Generative Verifier for Search-Augmented LLMs](http://arxiv.org/abs/2510.14660)|null|搜索增强赋予大型语言模型检索能力，以克服静态参数所带来的局限性。近来，强化学习利用定制化的奖励信号作为一种可行技术，提升LLM执行涉及搜索的任务。然而，现有针对搜索增强型LLM的奖励建模面临多项局限。基于规则的奖励（例如精确匹配）可验证但对表达变体脆弱，且无法应用于长篇工作负载。相比之下，生成式奖励提升了鲁棒性，但设计可验证且稳定的奖励以应对动态语料库中的长篇工作负载仍然具有挑战性，并且会带来高昂的计算成本。在本文中，我们提出了一种统一且可验证的范式——“信息点即评估标准”，它将原子信息点视为用于不同搜索增强工作负载的结构化评估标准。短篇任务对应单个评估标准，而长篇任务则扩展为与问题的所需信息对齐的多个评估标准。为支持长篇设置，我们设计了一个基于查询重写的自动评估标准构建流程，该流程能够自动检索与每个问题相关的段落，并从中提取评估标准，无论是从静态语料库还是动态在线网络内容中。此外，我们引入了Search-Gen-V，一个在我们提出的可验证范式下的40亿参数高效生成式验证器，其通过蒸馏思想和两阶段策略进行训练。实验结果表明，Search-Gen-V在不同工作负载下实现了强大的验证准确性，使其成为一个可扩展、鲁棒且高效的搜索增强型LLM可验证奖励构建器。|
|**2025-10-14**|[DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search](http://arxiv.org/abs/2510.12801)|null|多模态大型语言模型（MLLM）在实际应用中需要访问外部知识源，并且必须对动态且不断变化的现实世界信息保持响应，以处理信息查询和知识密集型用户请求。现有方法，例如检索增强生成（RAG）方法、搜索代理以及配备搜索功能的MLLM，常常面临管道僵化、过度搜索调用以及搜索查询构建不佳的问题，这些问题导致效率低下和次优结果。为了解决这些局限性，我们提出了DeepMMSearch-R1，这是首个能够执行按需、多轮网络搜索并为图像和文本搜索工具动态生成查询的多模态大型语言模型。具体而言，DeepMMSearch-R1可以根据输入图像中的相关裁剪区域启动网络搜索，从而使图像搜索更有效，并且可以基于检索到的信息迭代地调整文本搜索查询，从而实现自我反思和自我纠正。我们的方法依赖于一个两阶段训练管道：一个冷启动监督微调阶段，随后是在线强化学习优化。为了训练，我们引入了DeepMMSearchVQA，这是一个通过自动化管道创建并混合了来自网络搜索工具的真实世界信息的新颖多模态VQA数据集。该数据集包含多样化的多跳查询，整合了文本和视觉信息，教导模型何时搜索、搜索什么、使用哪个搜索工具以及如何对检索到的信息进行推理。我们在涵盖一系列知识密集型基准的广泛实验中证明了我们方法的优越性。最后，我们分析了结果并提供了对推动多模态网络搜索有价值的见解。|
|**2025-10-14**|[Detect Anything via Next Point Prediction](http://arxiv.org/abs/2510.12798)|**[link](https://github.com/IDEA-Research/Rex-Omni)**|目标检测长期以来一直由传统的基于坐标回归的模型主导，例如YOLO、DETR和Grounding DINO。尽管最近的努力尝试利用多模态大语言模型（MLLM）来解决这项任务，但它们面临低召回率、重复预测、坐标未对齐等挑战。在这项工作中，我们弥合了这一差距，并提出了Rex-Omni，一个30亿参数规模的多模态大语言模型，它实现了最先进的目标感知性能。在COCO和LVIS等基准上，Rex-Omni在零样本设置下取得了与基于回归的模型（例如DINO、Grounding DINO）媲美或超越的性能。这得益于三项关键设计：1）任务形式化：我们使用特殊token来表示0到999的量化坐标，从而降低了模型的学习难度并提高了坐标预测的token效率；2）数据引擎：我们构建了多个数据引擎来生成高质量的接地、指代和指向数据，为训练提供了语义丰富的监督；3）训练流程：我们采用两阶段训练过程，将2200万数据上的监督微调与基于GRPO的强化后训练相结合。这种强化学习后训练利用几何感知的奖励，有效弥合了离散到连续坐标预测的鸿沟，提高了边界框精度，并缓解了源自初始监督微调阶段教师引导特性所导致的重复预测等不良行为。除了传统检测，Rex-Omni固有的语言理解能力使其能够实现多功能能力，例如目标指代、指向、视觉提示、GUI接地、空间指代、OCR和关键点定位，所有这些都在专用基准上进行了系统评估。我们相信Rex-Omni为开发更通用、更具语言感知能力的视觉感知系统铺平了道路。|
|**2025-10-14**|[Reflection-Based Task Adaptation for Self-Improving VLA](http://arxiv.org/abs/2510.12710)|null|预训练视觉-语言-动作（VLA）模型代表了通用机器人领域的一大飞跃，然而，如何有效地将它们原位适应新颖、特定任务仍然是一个重大障碍。尽管强化学习（RL）是实现这种适应的一个有前景的途径，但其过程通常效率低下，阻碍了任务的快速掌握。我们引入了反思性自适应框架，旨在实现无需人工干预的快速、自主任务适应。我们的框架建立了一个自我改进的循环，智能体通过从自身经验中学习来提升策略和执行力。我们框架的核心是一个双通路架构，解决了完整的适应生命周期。首先，一个故障驱动的反思性强化学习通路通过利用VLM的因果推理，从故障分析中自动合成有针对性的密集奖励函数，从而实现了快速学习。这提供了一个集中的学习信号，显著加速了策略探索。然而，优化此类代理奖励引入了“奖励欺骗”的潜在风险，即智能体掌握了奖励函数但未能完成实际任务。为了解决这个问题，我们的第二通路，即成功驱动的质量引导SFT，将策略建立在整体成功的基础上。它识别并有选择地模仿高质量的成功轨迹，确保智能体与最终任务目标保持一致。该通路通过一个条件课程机制得到加强，以辅助初始探索。我们在具有挑战性的操作任务中进行了实验。结果表明，与代表性基线相比，我们的框架实现了更快的收敛和更高的最终成功率。我们的工作为创建能够高效可靠地适应新环境的自我改进智能体提供了一个鲁棒的解决方案。|
|**2025-10-14**|[ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning](http://arxiv.org/abs/2510.12693)|**[link](https://github.com/Embodied-Reasoning-Agent/embodied-reasoning-agent.github.io)**|具身智能的最新进展凸显了视觉语言模型（VLM）作为智能体在复杂环境中进行感知、推理和交互的潜力。然而，性能顶尖的系统依赖于部署成本高昂的大规模模型，而较小的VLM则缺乏成功所需的必要知识和技能。为了弥补这一差距，我们提出了具身推理智能体（ERA），这是一个整合了先验知识学习和在线强化学习（RL）的两阶段框架。第一阶段是具身先验学习，它从三种类型的数据中蒸馏基础知识：（1）轨迹增强先验，用更强模型生成的结构化推理来丰富现有轨迹数据；（2）环境锚定先验，提供环境内知识和基础监督；以及（3）外部知识先验，从环境外数据集中迁移通用知识。在第二阶段，我们开发了一个在线RL流程，该流程建立在这些先验之上，以进一步提升智能体性能。为了克服智能体RL中固有的挑战，包括长时序、稀疏奖励和训练不稳定性，我们引入了三个关键设计：用于上下文管理的自摘要、密集奖励塑形和轮次级策略优化。在高层规划（EB-ALFRED）和低层控制（EB-Manipulation）任务上进行的大量实验表明，ERA-3B超越了基于提示的大模型和先前的基于训练的基线。具体而言，相较于GPT-4o，它在EB-ALFRED上实现了8.4%的总体提升，在EB-Manipulation上实现了19.4%的总体提升，并对未见任务表现出强大的泛化能力。总的来说，ERA为可扩展的具身智能提供了一条实用路径，并为未来的具身AI系统提供了方法论上的见解。|
|**2025-10-14**|[Reasoning Pattern Matters: Learning to Reason without Human Rationales](http://arxiv.org/abs/2510.12643)|null|大型语言模型（LLMs）在广泛采用的SFT+RLVR范式下展现出卓越的推理能力，该范式首先对人工标注的推理轨迹（理由）进行监督微调（SFT）以建立初步的推理行为，然后应用可验证奖励强化学习（RLVR），使用可验证信号优化模型而无需黄金标准理由。然而，为SFT阶段标注高质量理由的成本仍然过高。本文研究了在不损害推理性能的情况下，何时以及如何能大幅降低理由标注成本。我们识别出一大类问题，称之为模式化推理任务，在这类任务中，推理遵循一个固定且程序化的策略，该策略在不同实例间保持一致。尽管实例在内容上有所不同，例如领域知识、事实信息或数值，但解决方案均源于应用一个共享的推理模式。我们认为SFT+RLVR在此类任务上的成功主要源于其使模型能够内化这些推理模式的能力。以数值语义匹配作为代表性任务，我们提供了因果和行为两方面的证据，表明推理模式而非理由的数量或质量是性能的关键决定因素。基于这些洞察，我们提出了模式感知型大型语言模型作为理由标注器（PARO），这是一个简单而有效的框架，它使LLMs能够生成与任务特定推理模式对齐的理由，而无需人工理由标注。实验表明，PARO生成的理由在SFT+RLVR性能上与数量是其10倍的人工理由相当。这些结果表明，大规模的人工理由标注可以被基于LLM的自动标注所取代，这种自动标注仅需对推理模式进行有限的人工监督。|
|**2025-10-14**|[Memory as Action: Autonomous Context Curation for Long-Horizon Agentic Tasks](http://arxiv.org/abs/2510.12635)|null|大语言模型在长周期智能体任务中面临挑战，因为其有限的记忆很容易被干扰性或不相关的上下文淹没。现有的工作记忆方法通常依赖于外部的、启发式的机制，这些机制与智能体的核心策略是解耦的。在这项工作中，我们重新将工作记忆管理定义为一种可学习的内在能力。我们提出了一个新颖的框架“记忆即行动”（Memory-as-Action），其中智能体通过执行显式的编辑操作作为统一策略的一部分来主动管理其工作记忆。这种表述允许通过强化学习训练的智能体在给定资源限制下，平衡记忆管理和长期任务目标。然而，这种记忆编辑行动打破了LLM交互中前缀连续增长的标准假设，导致我们称之为“轨迹断裂”的问题。这些非前缀变化破坏了标准策略梯度方法所需的因果连续性，使得这些方法不适用。为解决这个问题，我们提出了一种新算法“动态上下文策略优化”（Dynamic Context Policy Optimization），通过在记忆行动点对轨迹进行分段，并将轨迹级优势应用于由此产生的行动段，从而实现了稳定的端到端强化学习。我们的结果表明，以端到端方式联合优化任务推理和记忆管理，不仅降低了总体计算消耗，而且通过根据模型内在能力量身定制的自适应上下文管理策略，提高了任务性能。|
|**2025-10-14**|[Laminar: A Scalable Asynchronous RL Post-Training Framework](http://arxiv.org/abs/2510.12633)|null|强化学习（RL）对大语言模型（LLM）的后训练目前正扩展到大型集群，并长时间运行以提升模型推理性能。然而，现有RL框架的可扩展性受到限制，因为RL轨迹生成中极端的长尾偏斜导致严重的GPU利用率不足。当前的异步RL系统试图缓解此问题，但它们依赖于actor与所有rollout之间的全局权重同步，这导致了僵化的模型更新调度。这种全局同步不适用于RL训练中高度偏斜且不断变化的轨迹生成延迟分布，严重影响了训练效率。我们的关键见解是，高效扩展需要通过轨迹级别的异步来打破这种同步锁定，即独立生成和消费每个轨迹。我们提出了Laminar，一个构建于完全解耦架构之上的可扩展且鲁棒的RL后训练系统。首先，我们用充当分布式参数服务的一层中继工作者取代了全局更新。这实现了异步和细粒度的权重同步，允许rollout随时拉取最新权重而不会阻塞actor的训练循环。其次，动态重新打包机制将长尾轨迹整合到少数专用rollout上，从而最大化了生成吞吐量。完全解耦的设计还隔离了故障，确保了长时间运行作业的鲁棒性。我们在1024-GPU集群上的评估表明，Laminar相较于最先进的系统实现了高达5.48倍的训练吞吐量加速，同时减少了模型收敛时间。|
|**2025-10-14**|[ $\mathbf{T^3}$: Reducing Belief Deviation in Reinforcement Learning for Active Reasoning](http://arxiv.org/abs/2510.12264)|null|主动推理要求大型语言模型（LLM）与外部来源交互并策略性地收集信息以解决问题。这一过程的核心是信念跟踪：保持对问题状态以及解决问题所需缺失信息的连贯理解。然而，由于推理能力有限，基于LLM的智能体经常遭受信念偏差：它们难以正确建模信念，失去对问题状态的跟踪，并陷入无信息或重复的行动。一旦发生这种情况，错误会累积，强化学习（RL）训练也无法正确奖励关键的探索性步骤。为解决此问题，我们提出跟踪模型信念的偏差，并开发了$\mathbf{T^3}$，这是一种简单而有效的方法，它能检测过度的信念偏差并在训练期间截断轨迹以移除无信息的尾部。通过保留对信息性前缀的奖励，$\mathbf{T^3}$系统地改进了策略优化。在5项具有挑战性的任务中，$\mathbf{T^3}$ 持续增强了训练稳定性、令牌效率和最终性能，实现了高达30%的增益，同时将推出令牌减少了约25%。这些结果强调了信念控制是开发鲁棒且可泛化的基于LLM的主动推理器的关键原则。|
|**2025-10-14**|[PromptFlow: Training Prompts Like Neural Networks](http://arxiv.org/abs/2510.12246)|null|大型语言模型 (LLM) 在自然语言处理 (NLP) 任务中展现出深远的影响。然而，它们在不同领域的有效部署通常需要领域特定的适应策略，因为通用模型在面对专业数据分布时可能表现不佳。最近在提示工程 (PE) 方面的进展提供了一种有前景的替代方案，通过精炼输入指令使 LLM 输出与任务目标对齐，从而避免了大量的重新训练。这种范式已成为一种快速且通用的模型微调方法。尽管其潜力巨大，手动提示设计仍然劳动密集，并且严重依赖专业知识，通常需要反复的人工努力才能获得最佳表述。为了解决这一局限性，自动化提示工程方法已被开发出来，以系统地生成任务特定的提示。然而，目前的实现主要采用静态更新规则，并且缺乏动态策略选择机制，导致对不同 NLP 任务需求的适应性不佳。此外，大多数方法在每一步都将整个提示作为一个整体进行处理和更新，而没有考虑以更细的粒度编辑提示的各个部分。最后，特别是如何在 LLM 中循环利用经验的问题仍未得到充分探索。为此，我们提出了 PromptFlow，一个受 TensorFlow 启发的模块化训练框架，它集成了元提示、算子、优化和评估器。我们的框架可以配备最新的优化方法，并通过基于梯度的元学习自主探索最佳提示精炼轨迹，仅需最少的任务特定训练数据。具体而言，我们设计了一种强化学习方法，用于在 PE 过程中为 LLM 循环利用经验。最后，我们在各种数据集上进行了广泛的实验，并证明了 PromptFlow 的有效性。|
|**2025-10-14**|[Reinforced Preference Optimization for Recommendation](http://arxiv.org/abs/2510.12211)|**[link](https://github.com/sober-clever/ReRe)**|大语言模型（LLMs）的最新突破已将推荐系统从判别式范式根本性地转向生成式范式，其中用户行为建模通过基于历史交互生成目标物品来实现。然而，当前的生成式推荐器仍面临两个核心局限：缺乏高质量的负样本建模以及对隐式奖励的依赖。可验证奖励的强化学习（RLVR）通过实现更难负样本的在策略（on-policy）采样并将优化基于显式奖励信号，提供了一种自然解决方案。然而，将RLVR应用于生成式推荐器仍非易事。其独特的生成空间常导致无效或重复的物品，从而损害采样效率，并且由于大多数物品获得相同的零奖励，排序监督也因此变得稀疏。为解决这些挑战，我们提出了推荐强化偏好优化（ReRe），这是一种专为基于大语言模型的推荐器设计的强化范式，也是生成式推荐中的一个重要方向。ReRe结合了约束波束搜索以提高采样效率并多样化困难负样本，同时通过辅助排序奖励增强了基于规则的准确性奖励，以实现更细粒度的监督。在三个真实世界数据集上进行的大量实验表明，ReRe在排序性能方面持续优于传统推荐器和基于大语言模型的推荐器。进一步分析表明，ReRe不仅提升了基础模型和SFT（监督微调）初始化模型的性能，而且在不同的骨干架构系列和规模上都表现出鲁棒的泛化能力。除了经验性收益，我们还系统地研究了RLVR在推荐中的设计空间，涵盖生成、采样策略、奖励建模和优化算法，为未来研究提供了见解。|
|**2025-10-10**|[SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models](http://arxiv.org/abs/2510.09541)|**[link](https://github.com/facebookresearch/SPG)**|扩散大语言模型（dLLM）因其并行解码多个词元的能力，正成为自回归模型的一种有效替代方案。然而，通过强化学习（RL）将dLLM与人类偏好或任务特定奖励对齐具有挑战性，因为其难以处理的对数似然阻碍了标准策略梯度方法的直接应用。尽管先前工作使用证据下界（ELBO）等替代品，但这些单边近似会引入显著的策略梯度偏差。为解决此问题，我们提出了夹心策略梯度（SPG），它利用了真实对数似然的上限和下限。实验表明，SPG显著优于基于ELBO或单步估计的基线方法。具体而言，SPG将dLLM上最先进RL方法的准确性在GSM8K上提高了3.6%，在MATH500上提高了2.6%，在Countdown上提高了18.4%，在Sudoku上提高了27.0%。|
|**2025-10-10**|[Multimodal Policy Internalization for Conversational Agents](http://arxiv.org/abs/2510.09474)|**[link](https://github.com/MikeWangWZHL/TriMPI)**|现代对话式智能体，如ChatGPT和Alexa+，依赖于预定义策略来指定元数据、响应风格和工具使用规则。随着这些基于LLM的系统扩展以支持多样化的业务和用户查询，此类策略（通常作为上下文提示实现）正变得日益复杂和冗长，使得忠实遵循变得困难并带来巨大的固定计算成本。随着多模态智能体的兴起，管理视觉和多模态行为的策略至关重要，但仍未得到充分研究。先前的提示压缩工作主要缩短任务模板和演示，而现有的策略对齐研究仅关注基于文本的安全规则。我们引入多模态策略内化（MPI）——一项新任务，它将推理密集型多模态策略内化到模型参数中，从而实现更强的策略遵循能力，而无需在推理期间包含策略。MPI带来了独特的数据和算法挑战。我们构建了两个数据集，涵盖合成和真实世界的决策及工具使用任务，并提出了TriMPI，一个三阶段训练框架。TriMPI首先通过持续预训练注入策略知识，然后进行监督微调，最后应用PolicyRollout——一种GRPO风格的强化学习扩展，它通过策略感知响应增强轨迹以实现有根据的探索。TriMPI在端到端准确性、泛化能力和抗遗忘性方面取得了显著提升。作为多模态策略内化方面的首项工作，我们提供了数据集、训练方案和全面的评估，以促进未来的研究。项目页面：https://mikewangwzhl.github.io/TriMPI。|
|**2025-10-10**|[HINT: Helping Ineffective Rollouts Navigate Towards Effectiveness](http://arxiv.org/abs/2510.09388)|null|强化学习 (RL) 已成为增强大语言模型 (LLMs) 长链式思考 (CoT) 推理能力的关键驱动因素。然而，当任务难度超出模型能力时，GRPO 等普遍方法常常失效，导致奖励稀疏和训练效率低下。尽管现有工作试图通过使用离策略数据（例如将强化学习与监督微调 (SFT) 混合或使用提示）来缓解此问题，但它们经常误导策略更新。在这项工作中，我们确定了导致这些失败的一个核心问题，我们称之为低训练亲和度。这种情况源于外部指导与模型策略之间巨大的分布不匹配。为了诊断这一点，我们引入了亲和度，这是第一个用于监测探索效率和训练稳定性的量化指标。为了提高亲和度，我们提出了 HINT (Helping Ineffective rollouts Navigate Towards effectiveness)，这是一个自适应提示框架。HINT 不提供直接答案，而是提供启发式提示，引导模型自主发现解决方案，从而保留其自主推理能力。在数学推理任务上的大量实验表明，HINT 始终优于现有方法，在各种规模的模型上取得了最先进的结果，同时还展示了显著更稳定的学习和更高的数据效率。代码已在 Github 上提供。|
|**2025-10-10**|[Token-Level Policy Optimization: Linking Group-Level Rewards to Token-Level Aggregation via Markov Likelihood](http://arxiv.org/abs/2510.09369)|null|群体相对策略优化 (GRPO) 显著提升了大型语言模型 (LLMs) 的推理能力，特别是在数学性能方面。然而，GRPO 及相关的熵正则化方法仍面临源于思维链 (CoT) 内在稀疏 token 奖励的挑战。当前方法通常依赖于无差别的 token 级别熵调整，这常导致熵坍塌或模型坍塌。在这项工作中，我们提出了 TEPO，这是一种新颖的 token 级别框架，它通过 token 级别聚合，将马尔可夫似然（序列似然）与群体级别奖励和 token 关联起来。实验表明，TEPO 在关键指标（包括 @k 和准确率）上始终优于现有基线。它不仅在数学推理任务上树立了新的最新技术水平，而且显著提升了训练稳定性。|
|**2025-10-10**|[LLP: LLM-based Product Pricing in E-commerce](http://arxiv.org/abs/2510.09347)|null|与B2C（企业对消费者）电商平台（例如亚马逊）不同，在C2C（消费者对消费者）平台（例如eBay）上，经验不足的个人卖家经常面临高效地为他们的二手产品定价的巨大挑战。因此，许多研究被提出用于自动化价格预测。然而，它们大多数基于静态回归模型，泛化性能差并且未能捕捉市场动态（例如，二手iPhone的价格随时间下降）。受大型语言模型（LLMs）最新突破的启发，我们引入了LLP，首个基于LLM的生成式框架用于二手产品定价。LLP首先检索相似产品以更好地适应动态市场变化。之后，它利用LLM对自由格式文本中关键定价信息的细微理解以生成准确的价格建议。为了增强LLM对检索到的产品的领域推理能力，我们采用两阶段优化：监督微调（SFT）和群体相对策略优化（GRPO），在通过双向推理构建的数据集上。此外，LLP采用基于置信度的过滤机制以拒绝不可靠的价格建议。大量实验表明，LLP显著超越了现有方法，同时对未见类别表现出良好的泛化能力。我们已在闲鱼（中国最大的二手电商平台）成功部署了LLP，显著优于之前的定价方法。在相同的30%产品覆盖率下，它将静态采纳率（SAR）从40%提高到72%，即使在90%的召回率下，仍保持47%的强劲SAR。|
|**2025-10-10**|[Safety Game: Balancing Safe and Informative Conversations with Blackbox Agentic AI using LP Solvers](http://arxiv.org/abs/2510.09330)|null|确保大型语言模型（LLMs）符合安全要求是AI部署中的核心挑战。现有的对齐方法主要在训练阶段进行，例如通过微调或基于人类反馈的强化学习，但这些方法成本高昂且不灵活，每当有新要求出现时都需要重新训练。最近针对推理时对齐的努力缓解了其中一些局限性，但仍然假设可以访问模型内部，这既不切实际，也不适用于无法访问模型的第三方利益相关者。在这项工作中，我们提出了一种模型无关的黑盒安全对齐框架，它不需要重新训练或访问底层LLM架构。作为概念验证，我们解决了在生成安全但不提供信息的答案与有帮助但可能存在风险的答案之间进行权衡的问题。我们将这种困境表述为双人零和博弈，其最小最大均衡捕捉了安全性与有用性之间的最佳平衡。LLM智能体通过在推理时利用线性规划求解器来计算均衡策略，从而实现了这个框架。我们的结果证明了黑盒安全对齐的可行性，为包括小型组织和资源受限环境中的实体在内的利益相关者，在快速演进的LLM生态系统中强制执行安全提供了一条可扩展且易于访问的途径。|
|**2025-10-10**|[CLARity: Reasoning Consistency Alone Can Teach Reinforced Experts](http://arxiv.org/abs/2510.09278)|**[link](https://github.com/Infinite-set/CLARity)**|在数据稀缺的领域中训练专家级LLM很困难，往往依赖于选择题（MCQ）。然而，在MCQ上使用标准的基于结果的强化学习（RL）存在风险。尽管它可能提高准确性，但我们观察到它经常会降低推理质量，例如逻辑一致性。现有的监督推理的解决方案，例如大规模过程奖励模型（PRM），成本高得令人望而却步。为解决这个问题，我们提出了CLARity，这是一个经济高效的RL框架，它仅使用一个小型通用LLM即可增强推理质量。CLARity整合了一种一致性感知奖励机制与一个两阶段的“精炼-然后-监控”训练流程，以增强推理一致性，并采用一种动态数据重构策略来更好地利用有限数据。实验表明，相较于基线，CLARity将响应一致性提高了16.5%，准确性提高了7.5%。人工评估进一步证实了在连贯性和专业性方面的整体改进。因此，CLARity提供了一种通用解决方案，使得小型模型能够通过推理一致性有效地指导专家模型。我们的代码已在以下链接开源：https://github.com/Infinite-set/CLARity|
|**2025-10-10**|[Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models](http://arxiv.org/abs/2510.09259)|null|数据污染对大语言模型（LLM）的可靠评估构成了严峻威胁。这个问题源于基准样本可能无意中出现在训练集中，从而损害了所报告性能的有效性。尽管针对预训练和监督微调阶段已经开发了检测方法，但在日益重要的强化学习（RL）后训练阶段，仍存在一个关键的研究空白。鉴于RL后训练对提升LLM推理能力至关重要，在此范式下缺乏专门的污染检测方法构成了一个严重的脆弱性。为了解决这个问题，我们首次对RL后训练场景中的数据检测进行了系统性研究，并提出了Self-Critique方法。我们的方法基于一个关键观察：在RL阶段之后，LLM的输出熵分布倾向于坍缩为高度特定和稀疏的模式。Self-Critique探究了导致这种熵减少的潜在策略坍缩，即模型收敛到狭窄的推理路径。为了促进这项研究，我们还引入了RL-MIA，这是一个旨在模拟这种特定污染场景的基准。大量实验表明，Self-Critique在多个模型和污染任务上显著优于基线方法，AUC提升高达30%。现有方法对于RL阶段的污染检测接近于随机猜测，而我们的方法使检测成为可能。|
|**2025-10-10**|[Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2510.09156)|null|当前知识增强型大型语言模型（LLMs）依赖于静态的、预构建的知识库，这些知识库存在覆盖范围不足和时间上的过时性，限制了它们在动态信息环境中的有效性。我们提出了Agentic-KGR，这是一种新颖的框架，通过多轮强化学习（RL）实现了LLMs和知识图谱（KGs）之间的协同演化。我们的方法引入了三个关键创新：(1) 一种动态模式扩展机制，可在训练过程中系统地扩展图本体超出预定义边界；(2) 一种检索增强型记忆系统，通过持续优化实现了模型参数和知识结构之间的协同演化；(3) 一种可学习的多尺度提示压缩方法，通过自适应序列优化在保留关键信息的同时降低了计算复杂性。实验结果表明，在知识提取任务中，我们的方法相较于监督基线和单轮RL方法有显著改进。当与GraphRAG集成时，我们的方法在下游问答（QA）任务中取得了卓越性能，与现有方法相比，在准确性和知识覆盖率两方面都有显著提升。|
|**2025-10-10**|[AdaPM: a Partial Momentum Algorithm for LLM Training](http://arxiv.org/abs/2510.09103)|null|在大型语言模型训练中，动量被广泛使用，并经常被证明能够显著加速。然而，存储动量通常带来内存挑战。在本文中，我们提出AdaPM，这是一种自适应训练策略，它利用部分动量来实现内存高效的优化器。为此，AdaPM采用非均匀动量设计：对于大多数块，无需完整动量即可保持优化性能。在AdaPM的动量设计中，为了减轻由部分动量引起的偏差和性能损失，我们通过偏差校正技术增强了部分动量。经验上，我们验证了我们的方法将动量内存减少了90%以上，同时在预训练从60M到1.5B的各种语言模型以及监督微调和RLHF中保持了效率和性能。AdaPM通过结合二阶统计量的内存高效技术，可以将优化器状态的内存进一步减少高达95%，为预训练GPT-2 1.5B节省了30%以上的GPU小时。|
|**2025-10-09**|[Improving Reasoning for Diffusion Language Models via Group Diffusion Policy Optimization](http://arxiv.org/abs/2510.08554)|null|扩散语言模型 (DLM) 能够实现并行、与顺序无关的生成，并进行迭代细化，为自回归大型语言模型 (LLLM) 提供了一种灵活的替代方案。然而，由于难以处理的似然性，将强化学习 (RL) 微调应用于 DLM 仍然是一个开放的挑战。像 diffu-GRPO 这样的开创性工作通过一步去掩码估计了 token 级似然。尽管计算效率高，但这种方法存在严重偏差。一个更具原则性的基础在于序列级似然性，其中证据下界 (ELBO) 作为替代。然而，尽管存在这种清晰的数学联系，但由于似然评估的成本过高，基于 ELBO 的方法应用有限。在这项工作中，我们重新审视了 ELBO 估计并分离了其方差来源。这种分解促使我们通过沿着几个关键维度进行快速、确定性积分近似来减少方差。基于这一见解，我们引入了群扩散策略优化 (GDPO)，这是一种专为 DLM 量身定制的新型 RL 算法。GDPO 利用简单但有效的半确定性蒙特卡洛方案，以减轻在普通双重蒙特卡洛采样下 ELBO 估计器的方差爆炸问题，在严格的评估预算下产生一个可证明的低方差估计器。在实验中，GDPO 在预训练检查点上取得了持续的增益，并在大多数数学、推理和编码基准上优于 diffu-GRPO（一种最先进的基线）。|
|**2025-10-09**|[Entropy Regularizing Activation: Boosting Continuous Control, Large Language Models, and Image Classification with Activation as Entropy Constraints](http://arxiv.org/abs/2510.08549)|**[link](https://github.com/nothingbutbut/era)**|我们提出ERA，一种新范式，通过对模型输出应用特别设计的激活函数，将采样熵约束在给定阈值之上。我们的方法在不同领域展现出广泛的有效性：1) 对于大型语言模型(LLMs)，将Qwen2.5-Math-7B的AIME 2025分数提升了37.4%；2) 对于连续控制强化学习智能体，在具有挑战性的HumanoidBench上，相较于SAC等强基线，性能提升超过30%；3) 对于图像分类，将ResNet-50的ImageNet top-1准确率提高了0.69%。这些提升是在计算开销低于7%的情况下实现的。我们的工作验证了输出激活函数作为熵控制的强大工具，为设计更简单、更鲁棒的算法开辟了新方向。|
|**2025-10-09**|[MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](http://arxiv.org/abs/2510.08540)|**[link](https://github.com/PhoenixZ810/MM-HELIX)**|当前多模态大语言模型(MLLMs)在数学和逻辑等推理任务中已展现出熟练的能力，但它们在长链式反思推理方面的能力却在很大程度上尚未得到充分探索，而这正是解决复杂现实世界问题的先决条件。在这项工作中，我们首先进行了一项广泛的实证研究以评估这种能力。利用精心设计的数据合成引擎，我们构建了MM-HELIX，一个包含1,260个样本的多模态基准，涵盖42个需要迭代思维和回溯的挑战性合成任务。在此基准上的实证结果表明，现有MLLMs在长链式反思推理方面存在显著的性能缺陷。为了解决这一局限性，我们生成了后训练数据，并进一步探索了利用这些数据的学习范式。我们首先开发了“步骤启发式响应生成”(Step-Elicited Response Generation) 流水线，以创建MM-HELIX-100K，一个包含10万条高质量反思推理轨迹的大规模数据集，用于指令微调阶段。鉴于标准强化学习在复杂任务上表现不佳，原因在于稀疏的奖励信号和监督微调后的灾难性遗忘，我们提出了自适应混合策略优化(Adaptive Hybrid Policy Optimization, AHPO)，一种新颖的训练策略，它将离线监督和在线优化动态地统一到一个阶段中。这种策略使模型能够在奖励稀疏时从专家数据中学习，并在熟练后进行独立探索。将我们的方法应用于Qwen2.5-VL-7B基线模型时，在MM-HELIX基准上取得了18.6%的准确率提升，并在一般数学和逻辑任务上展现出强大的泛化能力，平均性能提升了5.7%。我们的工作表明MLLMs中的反思推理可以被有效地学习和泛化，为开发更强大的MLLMs铺平了道路。|
|**2025-10-09**|[On the optimization dynamics of RLVR: Gradient gap and step size thresholds](http://arxiv.org/abs/2510.08539)|null|可验证奖励强化学习（RLVR）使用简单的二元反馈对大型语言模型进行后训练，并已显示出显著的经验成功。然而，对其工作原理的原理性理解一直缺乏。本文通过在完整响应（轨迹）和词元层面分析RLVR的训练过程，为其建立了理论基础。我们分析的核心是一个称为“梯度差距”（Gradient Gap）的量，它形式化了从响应空间的低奖励区域到高奖励区域的改进方向。我们证明收敛性关键取决于将更新方向与此梯度差距对齐。此外，我们推导出了一个基于梯度差距大小的精确步长阈值：低于此阈值，学习收敛，而高于此阈值，性能崩溃。我们的理论进一步预测了临界步长必须如何随响应长度和成功率缩放，从而解释了为什么长度归一化等实际启发式方法能提高稳定性，并表明在固定学习率下，成功率可能严格停滞在100%以下。我们通过受控赌博机模拟和大型语言模型实验验证了这些预测，包括使用GRPO训练Qwen2.5-7B。|
|**2025-10-09**|[SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models](http://arxiv.org/abs/2510.08531)|**[link](https://github.com/ZJU-REAL/SpatialLadder)**|空间推理仍然是视觉-语言模型（VLM）面临的一个基本挑战，尽管近期有所进展，但当前方法仍难以实现稳健的性能。我们发现这一局限性源于一个关键的空白：现有方法试图直接学习空间推理，而没有建立感知和理解的层级基础。为了解决这一挑战，我们提出了一种逐步构建空间智能的全面方法。我们引入了SpatialLadder-26k，这是一个多模态数据集，包含26,610个样本，涵盖对象定位、单图像、多视角和视频空间推理任务，通过标准化流程构建，确保了跨模态的系统性覆盖。基于该数据集，我们设计了一个三阶段渐进式训练框架，该框架(1)通过对象定位建立空间感知，(2)通过多维空间任务发展空间理解，以及(3)通过带有可验证奖励的强化学习强化复杂推理。这种方法产生了SpatialLadder，一个30亿参数模型，在空间推理基准测试中实现了最先进的性能，相较于基础模型平均提高了23.4%，分别超越GPT-4o 20.8%和Gemini-2.0-Flash 10.1%。值得注意的是，SpatialLadder保持了强大的泛化能力，在域外基准测试中提高了7.2%，证明了从感知到推理的渐进式训练对于稳健的空间智能至关重要。|
|**2025-10-09**|[CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards](http://arxiv.org/abs/2510.08529)|**[link](https://github.com/xxyQwQ/CoMAS)**|自我进化是使基于大型语言模型（LLM）的智能体在预训练之后持续提升其能力的核心研究课题。近期研究见证了从不依赖强化学习（RL）的方法到基于强化学习的方法的转变。当前基于强化学习的方法要么依赖于密集的外部奖励信号，要么从LLM自身提取内在奖励信号。然而，这些方法偏离了人类智能中观察到的自我进化机制，在人类智能中，个体通过相互讨论和协作进行学习和提升。在这项工作中，我们引入了协同进化多智能体系统（CoMAS），这是一种新颖的框架，它使智能体能够通过从智能体间交互中学习而自主提升，无需外部监督。CoMAS从丰富的讨论动态中生成内在奖励，采用“LLM即法官”机制来制定这些奖励，并通过RL优化每个智能体的策略，从而实现去中心化和可扩展的协同进化。实验结果表明，CoMAS持续优于未训练的智能体，并在大多数评估设置中达到了最先进的性能。消融研究证实了基于交互的奖励信号的必要性，并揭示了随着智能体数量和多样性的增加而带来的有前景的可扩展性。这些发现将CoMAS确立为LLM智能体自我进化的一种新颖而有效的范式。|
|**2025-10-09**|[Which Heads Matter for Reasoning? RL-Guided KV Cache Compression](http://arxiv.org/abs/2510.08525)|null|推理大语言模型通过扩展的思维链生成展现出复杂的推理行为，这在解码阶段造成了前所未有的键值（KV）缓存开销。现有KV缓存压缩方法在推理模型上表现不佳：词元丢弃方法通过丢弃关键信息破坏了推理完整性，而注意力头重分配方法则错误地压缩了对推理至关重要的注意力头，因为它们是为检索任务设计的，导致随着压缩率的增加性能显著下降。我们假设KV头在推理模型中表现出功能异质性——一些头对思维链的一致性至关重要，而其他头则可被压缩。为了验证和利用这一见解，我们提出了RLKV，一个新颖的推理关键头识别框架，它使用强化学习直接优化每个头的缓存使用量与推理质量之间的关系。由于RLKV在训练过程中从实际生成的样本中产生奖励，它自然地识别出与推理行为相关的头。然后我们将完整的KV缓存分配给这些头，同时对其他头应用压缩的恒定KV缓存，以实现高效推理。我们的实验表明，只有一小部分注意力头对推理至关重要，这使得我们的KV压缩方法优于基线方法，同时实现了20-50%的缓存缩减，与未压缩结果相比性能接近无损。|
|**2025-10-09**|[Video-STAR: Reinforcing Open-Vocabulary Action Recognition with Tools](http://arxiv.org/abs/2510.08480)|null|多模态大语言模型（MLLMs）在连接视觉和文本推理方面展现出显著潜力，然而，它们对以文本为中心的先验知识的依赖常常限制了其在开放词汇场景中解耦语义相似动作的能力。为解决此问题，我们提出了Video-STAR，一个将上下文子动作分解与工具增强强化学习相结合以实现开放词汇动作识别（OVAR）的框架。与将动作视为单一实体的现有方法不同，我们的方法创新性地将动作分解为判别性子动作以进行细粒度匹配，同时动态调用领域特定工具进行跨模态交织，从而实现了类别特定的推理能力并减少了跨模态幻觉。此外，通过设计一个平衡工具使用效率、子动作相关性以及推理中结构连贯性的分层奖励，我们的方法无需明确监督即可自主利用外部工具来优先考虑子动作模式，从而实现了从以文本为中心的推理到视觉接地推理的转变。在HMDB-51、UCF-101、SSv2、Kinetics-400和Kinetics-600数据集上的广泛评估证明了我们最先进的性能，在区分细粒度动作和处理跨模态幻觉方面优于现有方法，验证了我们出色的鲁棒性和泛化能力。|
|**2025-10-09**|[xRouter: Training Cost-Aware LLMs Orchestration System via Reinforcement Learning](http://arxiv.org/abs/2510.08439)|**[link](https://github.com/SalesforceAIResearch/xRouter)**|现代LLM部署面临日益扩大的成本-性能范围：高级模型提供强大的推理能力但昂贵，而轻量级模型经济但在复杂任务上表现脆弱。静态升级规则和关键词启发式方法未能充分利用这一范围，也无法适应不同任务类型。我们提出了xRouter，一个基于工具调用的路由系统，其中一个学习型路由器可以直接回答或调用一个或多个外部模型。该路由器通过强化学习进行端到端训练，使用编码了成本-性能权衡的明确的、成本感知的奖励，从而消除了对人工设计路由规则的需求。我们的实现涵盖了完整的强化学习框架，包括奖励和成本核算，以及部署和评估流程。在各种基准测试中，xRouter实现了强大的成本-性能权衡（例如，在相近的任务完成率下大幅降低成本），并提供了关于什么能可靠地帮助学习型路由以及什么不能的实证见解，范围从模型可训练性到在小型开源模型中引发复杂编排行为的难度。我们希望这些发现和我们的开源实现能成为一个实用的基础，以推进学习型、成本感知LLM编排。|
|**2025-10-09**|[Reinforcing Diffusion Models by Direct Group Preference Optimization](http://arxiv.org/abs/2510.08425)|**[link](https://github.com/Luo-Yihong/DGPO)**|强化学习方法（如群组相对偏好优化，GRPO）已显著提升大型语言模型，但将其应用于扩散模型仍具挑战。特别是，GRPO需要随机策略，然而最具成本效益的扩散采样器基于确定性常微分方程（ODE）。近期工作通过使用低效的基于随机微分方程（SDE）的采样器引入随机性来解决此问题，但这种对模型无关的高斯噪声的依赖导致收敛缓慢。为解决这一冲突，我们提出了直接群组偏好优化（DGPO），这是一种新型在线强化学习算法，它完全摒弃了策略梯度框架。DGPO直接从群组级偏好中学习，这些偏好利用组内样本的相对信息。这种设计消除了对低效随机策略的需求，从而可以利用高效的确定性ODE采样器并实现更快的训练。大量实验结果表明，DGPO的训练速度比现有最先进方法快约20倍，并且在域内和域外奖励指标上均取得了卓越性能。代码可在https://github.com/Luo-Yihong/DGPO获取。|
|**2025-10-07**|[Stratified GRPO: Handling Structural Heterogeneity in Reinforcement Learning of LLM Search Agents](http://arxiv.org/abs/2510.06214)|null|大语言模型（LLM）智能体在解决复杂的多步骤问题时越来越依赖搜索引擎等外部工具，而强化学习（RL）已成为训练这些智能体的关键范式。然而，搜索智能体的轨迹是结构异质的，搜索调用的次数、位置和结果的变化导致了根本不同的答案方向和奖励分布。使用单一全局基线的标准策略梯度方法存在我们发现并形式化为跨层偏置的问题——即对异质轨迹进行“橘子与苹果”式的比较。这种跨层偏置扭曲了信用分配，阻碍了对复杂多步骤搜索策略的探索。为了解决这个问题，我们提出了分层GRPO，其核心组件分层优势归一化（SAN）根据轨迹的结构特性将其划分为同质层，并在每个层内局部计算优势。这确保了轨迹只与其真正的同类进行评估。我们的分析证明，SAN消除了跨层偏置，在每个层内产生了条件无偏的单位方差估计，并保留了标准归一化所具有的全局无偏性和单位方差特性，从而产生了更纯净、尺度稳定的学习信号。为了提高有限样本情况下的实际稳定性，我们进一步将SAN与全局估计器进行线性融合。对多样化的单跳和多跳问答基准进行的广泛实验表明，分层GRPO持续且显著优于GRPO，性能提升高达11.3个百分点，实现了更高的训练奖励、更大的训练稳定性和更有效的搜索策略。这些结果确立了分层作为大语言模型搜索智能体强化学习中结构异质性的一种原则性补救措施。|
|**2025-10-07**|[Peeking inside the Black-Box: Reinforcement Learning for Explainable and Accurate Relation Extraction](http://arxiv.org/abs/2510.06198)|null|本文提出了一个用于关系抽取（RE）的框架，旨在提高准确性和可解释性。该框架包含两个关键组件：(i) 一个推理机制，将关系抽取表述为一系列受认知科学启发的文本处理步骤；(ii) 一个由强化学习（RL）驱动的优化过程，采用新颖的奖励函数，旨在同时提高任务准确性和解释质量。我们将我们的方法称为CogRE。我们的框架通过促进包含重要关系关键词的输出来解决传统RE中缺乏基于语言解释监督的问题。这些关键词来源于一个使用大型语言模型（LLM）自动构建的高质量词典。我们使用两个LLM和两个RE数据集对我们的方法在单次关系抽取（one-shot RE）任务上进行了评估。我们的实验表明，CogRE通过解决单次RE中的两个常见失败模式（即注意力集中不足和单次学习能力有限）提高了解释质量。例如，我们使用Qwen2.5-15B-Instruct在One-shot NYT29上进行的认知结构化推理达到了24.65%的F1分数，超越了先前的基于推理的设计。使用我们的奖励函数通过RL优化此方法使性能进一步提高了+23.46%（绝对值）。最后，人工评估表明，我们的最佳模型生成的关系关键词与黄金标签高度一致，将人工解释质量评分提高了54%（相对值）。|
|**2025-10-07**|[The Alignment Auditor: A Bayesian Framework for Verifying and Refining LLM Objectives](http://arxiv.org/abs/2510.06096)|null|大型语言模型（LLM）隐式优化的目标仍然危险地不透明，这使得可信对齐和审计成为一个巨大挑战。虽然逆向强化学习（IRL）可以从行为中推断奖励函数，但现有方法要么产生单一、过度自信的奖励估计，要么未能解决任务的根本模糊性（不可辨识性）。本文引入了一种原则性的审计框架，将奖励推断从一个简单的估计任务重新定义为一个全面的验证过程。我们的框架利用贝叶斯逆向强化学习，不仅能够恢复目标分布，还能实现三项关键审计能力：(i) 通过展示连续多轮证据的后验收缩，量化并系统性地减少不可辨识性；(ii) 提供可操作的、不确定性感知的诊断，揭示虚假捷径并识别推断目标不可信的分布外提示；以及 (iii) 通过表明精炼的、低不确定性奖励可以直接用于RLHF，以实现与真实对齐过程相当的训练动态和毒性降低，从而验证策略层面的效用。经验上，我们的框架成功审计了一个解毒LLM，产生了一个良好校准且可解释的目标，强化了对齐保证。总而言之，这项工作为审计人员、安全团队和监管机构提供了一个实用工具包，以验证LLM真正试图实现什么，推动我们走向更值得信赖和负责任的人工智能。|
|**2025-10-07**|[Learning from Failures: Understanding LLM Alignment through Failure-Aware Inverse RL](http://arxiv.org/abs/2510.06092)|null|人类反馈强化学习 (RLHF) 使大型语言模型 (LLM) 与人类偏好对齐，然而它们内化的潜在奖励信号仍然是隐藏的，这对可解释性和安全性构成了严峻挑战。现有方法尝试使用逆强化学习 (IRL) 提取这些潜在激励，但它们平等对待所有偏好对，常常忽略信息最丰富的信号：即提取的奖励模型误分类或赋分几乎相等的示例，我们称之为“失败”。我们引入了一种新颖的“失败感知”IRL算法，该算法侧重于误分类或困难的示例，以恢复定义模型行为的潜在奖励。通过从这些失败中学习，我们的失败感知IRL提取的奖励函数能更好地反映RLHF背后的真实目标。我们证明，在应用于LLM去毒时，失败感知IRL在多个指标上优于现有IRL基线，且无需外部分类器或监督。至关重要的是，失败感知IRL产生的奖励能更好地捕捉RLHF期间学习到的真实激励，从而实现比标准IRL更有效的再RLHF训练。这将失败感知IRL确立为一种鲁棒、可扩展的方法，用于审计模型对齐并减少IRL过程中的歧义。|
|**2025-10-07**|[ASPO: Asymmetric Importance Sampling Policy Optimization](http://arxiv.org/abs/2510.06062)|null|近期的大语言模型（LLM）后训练方法在强化学习（RL）过程中依赖于词元级裁剪机制。然而，我们发现这种结果监督强化学习（OSRL）范式存在一个根本性缺陷：正优势词元的重要性采样（IS）比率不匹配，导致正负词元的加权不平衡。这种不匹配抑制了低概率词元的更新，同时过度放大了已是高概率的词元。为解决此问题，我们提出了非对称重要性采样策略优化（ASPO），它采用一种简单而有效的策略，翻转正优势词元的IS比率，使其更新方向与负词元的学习动态对齐。AIS进一步引入了一种软双重裁剪机制，以稳定极端更新并保持梯度流。在编码和数学推理基准上的全面实验表明，ASPO显著缓解了过早收敛，提高了训练稳定性，并相较于强大的基于GRPO的基线增强了最终性能。我们的分析为OSRL中词元级加权的作用提供了新见解，并强调了在LLM强化学习中纠正IS的关键重要性。ASPO的代码和模型可在https://github.com/wizard-III/Archer2.0获取。|
|**2025-10-07**|[VideoMiner: Iteratively Grounding Key Frames of Hour-Long Videos via Tree-based Group Relative Policy Optimization](http://arxiv.org/abs/2510.06040)|**[link](https://github.com/caoxinye/VideoMiner)**|借助多模态大语言模型（MM-LLM）理解长达一小时的视频，丰富了以人为中心的AI应用领域。然而，对于使用大语言模型进行端到端视频理解而言，随着视频长度的增加，均匀采样视频帧会导致大语言模型被大量无关信息淹没。现有的分层关键帧提取方法提高了视频理解的准确性，但仍面临两个关键挑战。1) 如何减轻长视频中大量冗余信息的干扰？2) 模型如何动态适应复杂的层级结构，同时准确识别关键帧？为解决这些问题，我们提出了VideoMiner，它迭代地对长视频进行分割、标注和聚类，形成一个分层树结构。所提出的VideoMiner从长视频到事件再到帧逐步推进，同时保持时间连贯性，有效地解决了第一个挑战。为了精确地定位关键帧，我们引入了T-GRPO，这是一种基于树的群组相对策略优化强化学习方法，用于指导VideoMiner的探索。所提出的T-GRPO专为树结构设计，在事件层面整合时空信息，同时受问题引导，从而解决了第二个挑战。我们在所有长视频理解任务中都取得了卓越的性能，并发现了几个有趣的见解。我们提出的T-GRPO令人惊讶地促使模型自发生成推理链。此外，设计的树生长素动态调整扩展深度，从而提高了准确性和效率。代码已公开，网址为https://github.com/caoxinye/VideoMiner。|
|**2025-10-07**|[EARL: Efficient Agentic Reinforcement Learning Systems for Large Language Models](http://arxiv.org/abs/2510.05943)|null|强化学习（RL）已成为大语言模型（LLM）后训练的关键组成部分，而智能体式强化学习（agentic RL）则通过多轮交互和工具使用将此范式扩展为智能体操作。扩展此类系统会暴露两个实际瓶颈：（1）训练期间上下文长度快速增长，导致内存使用和延迟增加，并触发内存不足（OOM）故障；（2）中间张量随上下文长度累积，使跨设备数据移动成为主要的系统瓶颈。我们提出了EARL，一个用于高效智能体式强化学习的可扩展系统。EARL设计了一个并行度选择器，可根据序列长度和系统负载动态调整跨RL阶段的模型并行度和训练并行度，以及一个数据调度器，可执行布局感知、去中心化的中间数据批次交换。这些组件共同作用，提高了吞吐量，减少了长上下文故障，并实现了智能体式LLM的稳定大规模训练，而不依赖于上下文长度的硬性限制或惩罚。|
|**2025-10-07**|[Prompt reinforcing for long-term planning of large language models](http://arxiv.org/abs/2510.05921)|null|大型语言模型（LLMs）在广泛的自然语言处理任务中取得了显著成功，并可通过提示进行适配。然而，在多轮交互中，它们仍表现不佳，常常依赖不正确的早期假设，且未能随时间推移跟踪用户目标，这使得此类任务特别具有挑战性。对话系统中的先前工作表明，长期规划对于处理交互式任务至关重要。在这项工作中，我们提出了一个受强化学习启发的提示优化框架，该框架通过仅修改基于LLM的智能体的任务指令提示来实现上述规划。通过生成逐轮反馈并利用经验回放进行提示重写，我们提出的方法在文本到SQL和面向任务的对话等多轮任务中显示出显著改进。此外，它可以在不同的基于LLM的智能体之间泛化，并能利用各种LLM作为元提示智能体。这为未来在受强化学习启发的无参数优化方法方面的研究提供了依据。|
|**2025-10-07**|[EEPO: Exploration-Enhanced Policy Optimization via Sample-Then-Forget](http://arxiv.org/abs/2510.05837)|null|在LLMs的可验证奖励强化学习（RLVR）中，平衡探索与利用仍然是一个核心挑战。当前的RLVR方法往往过度强调利用，导致熵坍缩、探索能力下降，并最终限制了性能提升。尽管增加策略随机性的技术可以促进探索，但它们却常常无法摆脱主导行为模式。这形成了一个自我强化的循环——即反复采样并奖励主导模式——从而进一步侵蚀了探索能力。我们引入了探索增强策略优化（EEPO），这是一个通过结合自适应遗忘的两阶段采样来促进探索的框架。在第一阶段，模型生成一半的轨迹；然后它经历一个轻量级的遗忘步骤，以暂时抑制这些已采样的响应，从而迫使第二阶段探索输出空间的不同区域。这种先采样后遗忘的机制打破了自我强化的循环，并在采样过程中促进了更广泛的探索。在五个推理基准测试中，EEPO优于GRPO，在Qwen2.5-3B上实现了24.3%的平均相对增益，在Llama3.2-3B-Instruct上实现了33.0%，在Qwen3-8B-Base上实现了10.4%。|
|**2025-10-07**|[EMORL-TTS: Reinforcement Learning for Fine-Grained Emotion Control in LLM-based TTS](http://arxiv.org/abs/2510.05758)|null|近期基于大型语言模型（LLM）的文本到语音（TTS）系统实现了强大的语音质量和零样本能力，但由于其依赖离散语音tokens，缺乏细粒度的情感控制。现有方法要么将情感限制为分类标签，要么无法泛化到基于LLM的架构。我们提出了EMORL-TTS（基于强化学习的细粒度情感可控TTS），这是一个统一了VAD空间中的全局强度控制与局部强调调节的框架。我们的方法结合了有监督微调与由针对情感类别、强度和强调的任务特定奖励指导的强化学习。此外，我们进一步研究了强调位置如何调节细粒度情感强度。实验表明，EMORL-TTS提高了情感准确性、强度区分度和强调清晰度，同时保持了与强大的基于LLM的基线相当的合成质量。|
|**2025-10-03**|[Reward Models are Metrics in a Trench Coat](http://arxiv.org/abs/2510.03231)|null|强化学习在大语言模型后训练中的兴起，引发了对奖励模型的广泛兴趣。奖励模型评估采样模型输出的质量，以生成训练信号。评估指标也执行此任务，它们监控AI模型的性能。我们发现这两个研究领域大部分是分离的，导致术语冗余和重复的陷阱。常见的挑战包括易受虚假相关性影响、对下游奖励劫持的冲击、提高数据质量的方法以及元评估方法。我们的立场论文认为，这两个领域之间更紧密的协作有助于克服这些问题。为此，我们展示了指标在特定任务上如何优于奖励模型，并对这两个领域进行了广泛综述。基于这项综述，我们指出了多个研究主题，在这些主题中，更紧密的协同可以改进奖励模型和指标，例如偏好启发方法、避免虚假相关性和奖励劫持，以及校准感知的元评估。|
|**2025-10-03**|[Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment](http://arxiv.org/abs/2510.03223)|null|大型语言模型（LLMs）在解决复杂推理任务时，基于提示的方法提供了一种轻量级的替代方案，以取代微调和强化学习。然而，随着推理链条的延长，关键的中间步骤和原始提示会被上下文淹没，导致关注度不足并引发错误。在本文中，我们提出了一种名为Self-Anchor的新颖流程，它利用推理的内在结构来引导LLM的注意力。Self-Anchor将推理轨迹分解为结构化规划，并自动将模型的注意力对齐到最相关的推理步骤，从而使模型在整个生成过程中保持专注。我们的实验表明，Self-Anchor在六个基准测试中均优于最先进的提示方法。值得注意的是，Self-Anchor显著缩小了“非推理”模型与专门推理模型之间的性能差距，有望使大多数LLMs无需重新训练即可处理复杂的推理任务。|
|**2025-10-03**|[Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward](http://arxiv.org/abs/2510.03222)|null|可验证奖励强化学习（RLVR）推动了大型语言模型在复杂推理方面的发展，然而，其可扩展性常受训练瓶颈的阻碍，即随着策略熵的坍缩，性能趋于平稳，这预示着探索能力的丧失。先前方法通常通过维持高策略熵来解决此问题，然而，控制有意义探索的精确机制仍未得到充分探索。我们的分析表明，不加选择地关注熵可能会放大不相关的标记并使训练不稳定。本文研究了RLVR中的探索动态，并识别出一个关键问题：有价值的低概率探索性标记（我们称之为“推理火花”）的逐步消除。我们发现，尽管这些火花在预训练模型中大量存在，但在RLVR过程中，由于过度惩罚，它们被系统性地消除，导致探索能力的退化。为解决此问题，我们引入了低概率正则化（Lp-Reg）。其核心机制是将策略正则化至一个启发式代理分布。该代理通过过滤掉推定的噪声标记并对剩余候选的分布进行重新归一化来构建。结果是一个噪声更小的代理，其中“推理火花”的概率被放大，然后作为软正则化目标，通过KL散度保护这些有价值的标记不被消除。实验表明，Lp-Reg能够实现约1000步的稳定在轨策略训练，在此范围内，基线熵控制方法会崩溃。这种持续的探索带来了最先进的性能，在五个数学基准测试中取得了60.17%的平均准确率，比先前方法提高了2.66%。代码可在https://github.com/CarlanLark/Lp-Reg获取。|
|**2025-10-03**|[MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning](http://arxiv.org/abs/2510.03142)|null|视觉导航策略因其模仿人类使用以自我为中心的视觉观测进行导航而被广泛认为是一个有前景的方向。然而，视觉观测的光学信息难以像激光雷达点云或深度图那样被明确建模，这随后需要智能模型和大规模数据。为此，我们提出利用视觉-语言-动作（VLA）模型的智能，以教师-学生的方式从合成的专家数据中学习多样化的导航能力。具体来说，我们将VLA模型MM-Nav实现为一个多视角VLA（具有360度观测），该模型基于预训练的大型语言模型和视觉基础模型。对于大规模导航数据，我们从三个强化学习（RL）专家那里收集专家数据，这些专家在三个具有挑战性的定制环境中，使用特权深度信息进行训练，以学习不同的导航能力：到达、挤压和避障。我们迭代地训练我们的VLA模型，使用从RL专家在线收集的数据，其中训练比例根据在各个能力上的表现进行动态平衡。通过在合成环境中进行广泛实验，我们证明我们的模型实现了强大的泛化能力。此外，我们发现我们的学生VLA模型优于RL教师，证明了整合多种能力的协同效应。广泛的真实世界实验进一步证实了我们方法的有效性。|
|**2025-10-03**|[Self-Reflective Generation at Test Time](http://arxiv.org/abs/2510.02919)|null|大语言模型（LLM）越来越多地通过长链式思维解决复杂推理任务，但其前向自回归生成过程是脆弱的；早期词元错误会级联，这明确表明需要自我反思机制。然而，现有的自我反思要么是对完整草稿进行修订，要么是通过昂贵的训练学习自我修正，两者本质上都是被动且低效的。为了解决这个问题，我们提出了测试时自反思生成（SRGen），这是一个轻量级的测试时框架，它在不确定点生成之前进行反思。在词元生成过程中，SRGen利用动态熵阈值来识别高不确定性词元。对于每个识别出的词元，它训练一个特定的修正向量，该向量充分利用已生成的上下文进行自我反思生成，以修正词元概率分布。通过回溯性分析部分输出，这种自我反思能够实现更可靠的决策，从而显著降低高度不确定点出现错误的概率。在具有挑战性的数学推理基准和多样化的大语言模型上进行评估，SRGen能够持续增强模型推理能力：单次通过质量的提升也转化为更强的自洽性投票。特别是在AIME2024数据集上，使用DeepSeek-R1-Distill-Qwen-7B模型时，SRGen在Pass@1上产生了+12.0%的绝对提升，在Cons@5上产生了+13.3%的绝对提升。此外，我们的研究结果表明SRGen是一种即插即用的方法，它将反思整合到生成过程中，以实现可靠的LLM推理，在有限开销下获得持续增益，并与其他的训练时（例如RLHF）和测试时（例如SLOT）技术具有广泛的可组合性。|
|**2025-10-03**|[RoiRL: Efficient, Self-Supervised Reasoning with Offline Iterative Reinforcement Learning](http://arxiv.org/abs/2510.02892)|null|强化学习(RL)对提升大语言模型(LLMs)的推理能力至关重要，但通常需要真实奖励。测试时强化学习(TTRL)通过使用多数投票奖励消除了这一需求，但它依赖于大量的在线强化学习并产生高昂的计算成本。我们提出了RoiRL：一种利用离线迭代强化学习进行推理的方法，这是一系列轻量级离线学习替代方案，能够实现相同的正则化最优策略。与TTRL不同，RoiRL消除了维护参考模型的需要，转而优化加权对数似然目标，从而在显著降低内存和计算需求的情况下实现稳定训练。实验结果表明，RoiRL训练速度快2.5倍，并在推理基准上持续优于TTRL，为实现无需标签的自改进大语言模型开辟了一条可扩展的路径。|
|**2025-10-03**|[Reward Model Routing in Alignment](http://arxiv.org/abs/2510.02850)|null|人类或AI反馈强化学习（RLHF / RLAIF）已成为对齐大语言模型（LLMs）的标准范式。然而，大多数流程依赖于单一奖励模型（RM），这限制了对齐质量并存在过拟合风险。近期工作探索了奖励模型路由——从候选池中动态选择一个奖励模型以利用互补优势，同时维持 $O(1)$ 次奖励模型调用——但现有方法存在冷启动和探索不足的问题。我们提出了BayesianRouter，一个混合路由框架，它结合了离线奖励模型优势学习和在线贝叶斯选择。在离线阶段，一个多任务路由器基于偏好数据进行训练，以估计每个奖励模型的可靠性。在在线阶段，一个贝叶斯汤普森采样路由器执行每查询奖励模型选择，使用离线嵌入作为高斯先验来初始化奖励模型特定的权重向量，并利用在线奖励自适应地更新它们的后验，以适应不断演变的策略分布。在指令遵循（AlpacaEval-2、Arena-Hard、MT-Bench）和推理（GSM8K、MMLU）基准测试上进行的大量实验表明，BayesianRouter始终优于单个奖励模型、奖励模型集成和现有路由方法。|
|**2025-10-03**|[The Path of Self-Evolving Large Language Models: Achieving Data-Efficient Learning via Intrinsic Feedback](http://arxiv.org/abs/2510.02752)|null|强化学习 (RL) 在增强大型语言模型 (LLM) 的推理能力方面已展现出潜力，但此类训练通常需要大量的数据创建和标注工作。在这项工作中，我们探索通过最少数据利用强化学习来改进LLM。我们的方法是让LLM交替进行任务提出和尝试解决任务。为了最小化对数据的依赖，我们引入了两种基于自我意识的新机制：(1) 自我意识难度预测，模型学习评估任务相对于自身能力的难度，并优先处理具有挑战性但可解决的任务，以及 (2) 自我意识突破极限，模型识别出任务超出自身能力边界时，主动请求外部数据以突破该极限。在九个基准测试上进行的广泛实验表明，在额外数据少于1.2%的情况下，相对改进达到53.8%，这证明了自我意识强化学习的有效性，并强调了自我进化智能体训练的广阔前景。|
|**2025-10-03**|[Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval](http://arxiv.org/abs/2510.02745)|null|DeepSeek-R1的成功展示了使用强化学习（RL）来增强大型语言模型（LLMs）推理能力的巨大潜力。本文介绍了Retrv-R1，这是第一个R1风格的多模态大型语言模型（MLLM），专为多模态通用检索设计，通过采用逐步推理来产生更准确的检索结果，从而实现更高的性能。我们发现将DeepSeek-R1的方法直接应用于检索任务并不可行，这主要是由于(1) 带有推理过程的多个候选需要大量token消耗导致的高计算成本，以及(2) 直接应用强化学习训练检索任务时存在的不稳定性和次优结果。为了解决这些问题，Retrv-R1引入了一个带有细节检查机制的信息压缩模块，该模块通过减少token数量来提高计算效率，同时确保保留了挑战性候选的关键信息。此外，本文提出了一种新的训练范式，包括一个使用为检索量身定制的合成CoT数据集进行激活的阶段，以实现更有效的优化，随后是采用新颖课程奖励的强化学习，以提高性能和效率。结合这些新颖设计，Retrv-R1在多项基准和任务的实验中展示了最先进（SOTA）的性能、高效率和强大的泛化能力。|
|**2025-10-02**|[On the Role of Temperature Sampling in Test-Time Scaling](http://arxiv.org/abs/2510.02611)|null|大语言模型（LLM）可以通过测试时缩放（TTS）在推理时提高推理能力，其中生成多个推理轨迹并选择最佳的一个。先前工作表明，增加样本数量 K 可以持续提高准确性。在本文中，我们证明了这种趋势并非无限期成立：在 K 值较大时，进一步的缩放不会带来收益，并且无论轨迹数量多少，某些难题仍未解决。有趣的是，我们发现不同的采样温度解决了不同子集的问题，这暗示着单一温度缩放仅探索了模型潜力的一部分。因此，我们提出沿温度维度进行缩放，这扩大了 LLM 的推理边界。在通义千问3（0.6B、1.7B、4B、8B）和五个代表性推理基准（AIME 2024/2025、MATH500、LiveCodeBench、Hi-ToM）上的平均结果显示，温度缩放比单一温度的 TTS 额外提高了 7.3 分。温度缩放还使基础模型能够达到与经过强化学习（RL）训练的对应模型相当的性能，而无需额外的后训练。我们进一步对这种现象进行了全面分析，并设计了一种多温度投票方法，以降低温度缩放的开销。总的来说，我们的发现表明 TTS 比之前认为的更强大，并且温度缩放提供了一种简单有效的方法来释放基础模型的潜在潜力。|
|**2025-10-02**|[Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming Attacks](http://arxiv.org/abs/2510.02286)|null|尽管人工智能安全领域近期取得了快速进展，但当前大型语言模型在多轮交互设置中仍然容易受到对抗性攻击，在这些设置中，攻击者在会话轮次中策略性地调整其提示，构成了一个更关键也更现实的挑战。现有发现安全漏洞的方法要么依赖人类专家进行手动红队测试，要么采用使用预定义模板和人工策划攻击数据的自动化方法，其中大多数侧重于单轮攻击。然而，这些方法并未探索多轮攻击的广阔可能性空间，未能考虑由复杂对话动态和策略性会话规划所产生的新型攻击路径。这一差距尤为关键，鉴于近期研究发现大型语言模型（LLMs）对多轮攻击的脆弱性显著高于单轮攻击。我们提出了DialTree-RPO，这是一个结合了树搜索的在策略强化学习框架，它通过将对话视为一个序列决策问题，自主发现多样化的多轮攻击策略，从而无需人工策划数据即可实现系统探索。通过广泛实验，我们的方法与以往最先进的方法相比，在10个目标模型上实现了超过25.9%的攻击成功率（ASR）提升，而且通过学习最优对话策略，有效地揭示了新的攻击策略，这些策略能在多轮交互中最大化攻击成功率。|
|**2025-10-02**|[VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL](http://arxiv.org/abs/2510.02282)|null|随着AI生成视频的快速发展，迫切需要有效的检测工具来减轻虚假信息和声誉损害等社会风险。除了准确分类之外，检测模型提供可解释的解释以确保监管机构和最终用户的透明度也至关重要。为应对这些挑战，我们提出了VidGuard-R1，这是首个通过群体相对策略优化（GRPO）微调多模态大语言模型（MLLM）的视频真实性检测器。我们的模型能够提供高度准确的判断和富有洞察力的推理。我们构建了一个包含14万个由最先进生成模型产生的真实和AI生成视频的挑战性数据集，并精心设计了生成过程以最大化判别难度。随后，我们使用GRPO和两个分别针对时序伪影和生成复杂性的专门奖励模型对Qwen-VL进行了微调。大量实验表明，VidGuard-R1在现有基准上实现了最先进的零样本性能，并通过额外训练将准确率提升至95%以上。案例研究进一步表明，VidGuard-R1能够为其预测提供精确且可解释的依据。代码已公开，网址为https://VidGuard-R1.github.io。|
|**2025-10-02**|[ExGRPO: Learning to Reason from Experience](http://arxiv.org/abs/2510.02245)|null|可验证奖励强化学习（RLVR）是一种新兴范式，用于提升大型语言模型的推理能力。然而，标准的在策略训练在单次更新后会丢弃采样经验，导致计算效率低下和不稳定性。尽管之前的强化学习工作强调了重用过去经验的好处，但经验特征在塑造大型推理模型学习动态中的作用仍未得到充分探索。在本文中，我们首次研究了是什么使得推理经验有价值，并将采样正确性和熵确定为经验价值的有效指标。基于这些洞察，我们提出了ExGRPO（经验分组相对策略优化），这是一个组织和优先处理有价值经验的框架，并采用混合策略目标以平衡探索和经验利用。在五种主干模型（1.5B-8B参数）上的实验表明，ExGRPO持续提升了在数学/通用基准上的推理性能，相较于在策略RLVR，平均提升了+3.5/7.6个点。此外，ExGRPO稳定了训练，在更强和更弱的模型上表现良好，而这些模型上在策略方法会失败。这些结果强调了有原则的经验管理是实现高效和可扩展RLVR的关键要素。|
|**2025-10-02**|[RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning](http://arxiv.org/abs/2510.02240)|**[link](https://github.com/fscdc/RewardMap)**|细粒度视觉推理仍然是多模态大语言模型（MLLM）的核心挑战。最近提出的ReasonMap通过展示即使是先进的MLLM在交通地图等结构化和信息丰富的场景中也难以进行空间推理，凸显了这一差距，而这是一项具有明确实践和科学重要性的任务。然而，在这类任务上，标准强化学习（RL）受到稀疏奖励和不稳定优化的阻碍。为了解决这个问题，我们首先构建了ReasonMap-Plus，这是一个扩展数据集，通过视觉问答（VQA）任务引入密集奖励信号，从而实现了细粒度视觉理解技能的有效冷启动训练。接下来，我们提出了RewardMap，一个多阶段RL框架，旨在提高MLLM的视觉理解和推理能力。RewardMap融合了两个关键设计。首先，我们引入了一种难度感知奖励设计，该设计融入了细节奖励，直接解决了稀疏奖励问题，同时提供了更丰富的监督。其次，我们提出了一种多阶段RL方案，该方案从简单的感知任务引导训练到复杂的推理任务，与传统监督微调（SFT）相比，提供了一种更有效的冷启动策略。在ReasonMap和ReasonMap-Plus上的实验表明，RewardMap的每个组件都带来了持续的性能提升，而它们的结合产生了最佳结果。此外，使用RewardMap训练的模型在涵盖空间推理、细粒度视觉推理和交通地图之外的通用任务的6个基准上实现了平均3.47%的性能提升，强调了其增强的视觉理解和推理能力。|
|**2025-10-02**|[The Reasoning Boundary Paradox: How Reinforcement Learning Constrains Language Models](http://arxiv.org/abs/2510.02230)|null|可验证奖励强化学习（RLVR）已成为提升大型语言模型推理能力的关键方法，然而，近期证据表明它可能矛盾地缩小而非扩大推理边界。本文通过分析RLVR的学习动态来研究其缩小问题，并揭示了两个解释这一失败的关键现象。首先，我们揭示了RLVR中的负面干扰，即学习解决某些训练问题会主动降低解决其他问题的正确解的可能性，导致Pass@ $k$性能下降，Pass@$k$指的是在$k$次尝试中生成正确解的概率。其次，我们揭示了赢者通吃现象：RLVR不成比例地强化了基础模型下具有高可能性正确解的问题，同时抑制了其他初始可能性较低的问题。通过对多个数学推理基准进行广泛的理论和实证分析，我们表明这种效应源于标准强化学习目标中固有的在策略采样，导致模型收敛到狭窄的解决方案策略。基于这些见解，我们提出了一种简单而有效的数据管理算法，该算法将RLVR学习集中在低可能性问题上，显著提高了Pass@$k$ 性能。我们的代码可在https://github.com/mail-research/SELF-llm-interference获取。|
|**2025-10-02**|[More Than One Teacher: Adaptive Multi-Guidance Policy Optimization for Diverse Exploration](http://arxiv.org/abs/2510.02227)|**[link](https://github.com/SII-Enigma/AMPO)**|可验证奖励强化学习 (RLVR) 是一种有前景的范式，用于增强大语言模型 (LLMs) 的推理能力。然而，当前主流方法主要依赖于自我探索或单一离策略教师模型来引出长链式思考 (LongCoT) 推理，这可能引入固有的模型偏差并限制探索，最终限制了推理的多样性和性能。借鉴知识蒸馏中的多教师策略，我们引入了自适应多指导策略优化 (AMPO)，这是一种新颖的框架，它仅当在线策略模型未能生成正确解决方案时，才自适应地利用来自多个熟练教师模型的指导。这种“按需指导”方法扩展了探索，同时保留了自我发现的价值。此外，AMPO 结合了一种基于理解的选择机制，促使学生从其最有可能理解的推理路径中学习，从而平衡了广泛探索和有效利用。大量实验表明，AMPO 显著优于强大的基线 (GRPO)，在数学推理任务上提升了 4.3%，在分布外任务上提升了 12.2%，同时显著提升了 Pass@k 性能并实现了更多样化的探索。值得注意的是，我们的方法使用四个规模相当的教师模型，取得了与利用单一、更强大的教师模型（例如 DeepSeek-R1）并拥有更多数据的方法可比的结果。这些结果表明了一条实现卓越推理能力和泛化能力的更高效、更具扩展性的路径。我们的代码可在 https://github.com/SII-Enigma/AMPO 获取。|
|**2025-10-02**|[DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via Reinforcement Learning](http://arxiv.org/abs/2510.02212)|null|我们提出DiFFPO（扩散快速激进策略优化），这是一个统一框架，用于训练掩码扩散大语言模型（dLLMs），使其通过强化学习（RL）不仅能更好地（激进地）推理，而且推理速度更快。首先，我们通过提出离策略强化学习来训练替代策略，其似然作为真实dLLM策略的近似更易处理，从而统一了现有基线方法（例如d1）。这自然促使我们结合重要性采样校正，提出更准确、信息更丰富的两阶段似然近似，从而产生具有更好样本效率和卓越任务性能的广义RL算法。其次，我们提出了联合训练dLLM策略高效采样器/控制器的新方向。通过RL，我们激励dLLM的自然多令牌预测能力，让模型学习为每个提示自适应地分配推理阈值。通过联合训练采样器，与仅训练模型相比，我们以更少的函数评估次数（NFEs）获得了更好的准确性，在改善dLLM推理时计算的帕累托前沿方面取得了最佳性能。我们通过在基准数学和规划任务上训练开源大型扩散语言模型，展示了我们流水线的有效性。|
|**2025-10-02**|[GRACE: A Language Model Framework for Explainable Inverse Reinforcement Learning](http://arxiv.org/abs/2510.02180)|null|逆向强化学习旨在从专家演示中恢复奖励模型，但传统方法产生的“黑箱”模型难以解释和调试。在这项工作中，我们引入了GRACE（Generating Rewards As CodE），一种利用大型语言模型在进化搜索中直接从专家轨迹中逆向工程生成可解释的、基于代码的奖励函数的方法。所产生的奖励函数是可执行代码，可以被检查和验证。我们通过在BabyAI和AndroidWorld基准测试上进行经验验证，GRACE即使在复杂的多任务设置中也能高效学习到高精度的奖励。此外，我们证明了与竞争性的模仿学习以及使用真实奖励的在线强化学习方法相比，所产生的奖励能够带来强大的策略。最后，我们展示了GRACE能够在多任务设置中构建复杂的奖励API。|
|**2025-10-02**|[Learning to Reason for Hallucination Span Detection](http://arxiv.org/abs/2510.02173)|null|大语言模型（LLMs）经常产生幻觉——即缺乏事实支持并损害可靠性的内容。虽然大多数现有工作将幻觉检测视为一个二元任务，但许多实际应用需要识别幻觉片段，这是一个多步骤的决策过程。这自然引出了一个问题：显式推理是否能帮助完成检测幻觉片段这一复杂任务。为了回答这个问题，我们首先评估了采用和不采用思维链（CoT）推理的预训练模型，并表明CoT推理在多次采样时有潜力生成至少一个正确答案。受此启发，我们提出了RL4HS，一个使用片段级奖励函数激励推理的强化学习框架。RL4HS基于群体相对策略优化，并引入了类别感知策略优化以缓解奖励不平衡问题。在RAGTruth基准（包括摘要生成、问答和数据到文本任务）上的实验表明，RL4HS超越了预训练推理模型和监督微调，证明了采用片段级奖励的强化学习对于检测幻觉片段的必要性。|
|**2025-10-02**|[Veri-R1: Toward Precise and Faithful Claim Verification via Online Reinforcement Learning](http://arxiv.org/abs/2510.01932)|null|大语言模型（LLM）的事实核查最近引起了广泛关注，这得益于它们相比传统只提供答案的判断所展现出的卓越推理能力和透明的验证路径。在线事实核查需要迭代的证据检索和推理，然而现有方法主要依赖于提示工程或预设的推理工作流，未能提供统一的训练范式来提升所需技能。因此，我们引入了Veri-R1，这是一个在线强化学习（RL）框架，它使大语言模型能够与搜索引擎交互，并接收奖励信号，这些信号明确地塑造其规划、检索和推理行为。模型与检索系统之间的动态交互更准确地反映了真实世界的事实核查场景，并培养了全面的核查技能。实验结果表明，Veri-R1将联合准确率提高了多达30%，使证据分数翻倍，并且常常超越规模更大的同类模型。消融研究进一步揭示了奖励组成部分的影响以及输出logit与标签准确性之间的联系。我们的结果突出了在线强化学习在精确和忠实的事实核查中的有效性，并为未来的研究奠定了基础。我们发布了代码，以支持社区在LLM赋能的事实核查领域的进展。|
|**2025-09-30**|[Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models](http://arxiv.org/abs/2509.26628)|null|强化学习（RL）在提升大语言模型（LLMs）的推理能力方面取得了显著成功。相比基于结果的强化学习，过程监督强化学习（PSRL）已成为一种更有效的范式。然而，现有的PSRL方法在分支位置和采样方面都存在探索效率有限的问题。在本文中，我们提出了一种新颖的PSRL框架（AttnRL），它能为推理模型实现高效探索。受初步观察的启发，即表现出高注意力分数（attention scores）的步骤与推理行为相关，我们提出从高价值位置进行分支。此外，我们开发了一种自适应采样策略，该策略考虑了问题难度和历史批次大小，确保整个训练批次保持非零优势值（advantage values）。为了进一步提高采样效率，我们为PSRL设计了一种单步离策略训练流程。在多项具有挑战性的数学推理基准上进行的广泛实验表明，我们的方法在性能以及采样和训练效率方面始终优于先前的方法。|
|**2025-09-30**|[Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models](http://arxiv.org/abs/2509.26626)|null|测试时扩展方法通过增加推理过程中用于进行预测的计算量来提升大语言模型（LLMs）的能力。推理时计算可以并行扩展，通过选择多个独立解决方案实现；也可以顺序扩展，通过自我完善实现。我们提出了递归自聚合（RSA），这是一种受进化方法启发的测试时扩展方法，它结合了并行和顺序扩展的优势。RSA的每一步通过子集的聚合来细化一组候选推理链，从而产生一组改进的解决方案，这些解决方案随后被用作下一轮迭代的候选池。RSA利用了蕴含在推理链中的丰富信息——不仅仅是最终答案——并能够从不同思维链中部分正确的中间步骤进行自举。经验上，随着计算预算的增加，RSA在不同任务、模型系列和规模上都带来了显著的性能提升。值得注意的是，RSA使Qwen3-4B-Instruct-2507能够与更大的推理模型（包括DeepSeek-R1和o3-mini (high)）达到有竞争力的性能，同时在AIME-25、HMMT-25、Reasoning Gym、LiveCodeBench-v6和SuperGPQA等基准测试中优于纯粹的并行和顺序扩展策略。我们进一步证明，通过一种新颖的聚合感知强化学习方法训练模型来结合解决方案，可带来显著的性能提升。代码可在https://github.com/HyperPotatoNeo/RSA获取。|
|**2025-09-30**|[MENLO: From Preferences to Proficiency -- Evaluating and Modeling Native-like Quality Across 47 Languages](http://arxiv.org/abs/2509.26601)|null|确保大语言模型（LLM）响应在多种语言中达到地道性质量具有挑战性。为解决此问题，我们引入了MENLO，一个基于受众设计启发机制将地道性响应质量评估操作化的框架。利用MENLO，我们创建了一个包含6,423个人工标注的提示-响应偏好对的数据集，该数据集涵盖四个质量维度，在47种语言变体中具有较高的标注者间一致性。我们的评估表明，零样本LLM判断器显著受益于成对评估和我们结构化的标注标准，然而它们在我们的数据集上仍不如人类标注者。我们通过使用强化学习、奖励塑形和多任务学习方法进行微调，展示了显著的改进。此外，我们表明经过强化学习训练的判断器可以作为生成式奖励模型，以增强LLM的多语言能力，尽管与人类判断仍存在差异。我们的发现为可扩展的多语言评估和偏好对齐提供了有前景的方向。我们发布了我们的数据集和评估框架，以支持多语言LLM评估领域的进一步研究。|
|**2025-09-30**|[Linking Process to Outcome: Conditional Reward Modeling for LLM Reasoning](http://arxiv.org/abs/2509.26578)|null|过程奖励模型（PRM）已成为一种有前景的方法，通过引导大型语言模型（LLM）的分步推理趋向最终答案来增强其推理能力。然而，现有的PRM要么孤立地处理每个推理步骤，未能捕获步骤间的依赖关系，要么难以将过程奖励与最终结果对齐。因此，奖励信号未能遵循序列推理中的时序因果关系，并面临模糊的信用分配问题。这些局限性使下游模型容易受到奖励欺骗并导致次优性能。在这项工作中，我们提出了条件奖励建模（CRM），它将LLM推理框架化为一个最终导向正确答案的时序过程。每个推理步骤的奖励不仅取决于前面的步骤，而且明确地与推理轨迹的最终结果相关联。通过强制执行条件概率规则，我们的设计捕获了推理步骤之间的因果关系，与结果的关联使得每个中间步骤能够被精确归因，从而解决了信用分配的模糊性。此外，通过这种一致的概率建模，CRM产生的奖励能够实现更可靠的跨样本比较。在Best-of-N采样、集束搜索和强化学习方面的实验表明，CRM持续优于现有奖励模型，为增强LLM推理提供了一个原则性的框架。特别是，CRM对奖励欺骗更具鲁棒性，并带来了稳定的下游改进，而不依赖于从真实值导出的可验证奖励。|
|**2025-09-30**|[Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement Learning](http://arxiv.org/abs/2509.26383)|null|知识图谱检索增强生成（KG-RAG）将大语言模型（LLMs）与结构化、可验证的知识图谱（KGs）结合，以减少幻觉并揭示推理路径。然而，许多KG-RAG系统包含多个LLM模块（例如规划、推理和响应），这增加了推理成本，并将行为绑定到特定的目标知识图谱。为此，我们引入了KG-R1，一个基于强化学习（RL）的智能体式知识图谱检索增强生成（KG-RAG）框架。KG-R1利用单个智能体，将知识图谱作为其环境进行交互，学习在每一步进行检索，并将检索到的信息整合到其推理和生成中。该过程通过端到端强化学习进行优化。在知识图谱问答（KGQA）基准测试的受控实验中，我们的方法展现出效率和可迁移性：使用Qwen-2.5-3B，KG-R1在生成更少token的情况下提高了答案准确性，优于使用更大基础模型或微调模型的先前多模块工作流方法。此外，KG-R1实现了即插即用：训练后，它在新的知识图谱上无需修改即可保持高准确性。这些特性使KG-R1成为一个有前景的、适用于实际部署的KG-RAG框架。我们的代码已公开发布在https://github.com/Jinyeop3110/KG-R1。|
|**2025-09-30**|[EditReward: A Human-Aligned Reward Model for Instruction-Guided Image Editing](http://arxiv.org/abs/2509.26346)|null|最近，我们见证了自然语言指令图像编辑方面的巨大进步。几个闭源模型，如GPT-Image-1、Seedream和Google-Nano-Banana，已展现出非常有前景的进展。然而，开源模型仍然滞后。主要瓶颈在于缺乏可靠的奖励模型来扩展高质量的合成训练数据。为解决这一关键瓶颈，我们构建了\mname，它使用我们新的大规模人类偏好数据集进行训练，该数据集由训练有素的专家遵循严格协议精心标注，包含超过20万个偏好对。\mname在指令引导的图像编辑任务中展现出与人类偏好卓越的一致性。实验表明，\mname在GenAI-Bench、AURORA-Bench、ImagenHub以及我们新的\benchname等已有的基准测试中，在人类相关性方面达到了最先进水平，优于广泛的VLM-as-judge模型。此外，我们使用\mname从现有的嘈杂的ShareGPT-4o-Image数据集中选择了一个高质量子集。我们在所选子集上训练了Step1X-Edit，这相比在完整数据集上训练显示出显著的改进。这证明了\mname能够作为奖励模型来扩展用于图像编辑的高质量训练数据。此外，其强大的对齐性预示着其在基于强化学习的后训练和图像编辑模型的测试时扩展等高级应用中的潜力。\mname及其训练数据集将被发布，以帮助社区构建更多高质量的图像编辑训练数据集。|
|**2025-09-30**|[One-Token Rollout: Guiding Supervised Fine-Tuning of LLMs with Policy Gradient](http://arxiv.org/abs/2509.26313)|null|监督微调 (SFT) 是适应大型语言模型 (LLM) 的主要方法，但与强化学习 (RL) 相比，它在泛化能力上常常表现不佳。在这项工作中，我们认为这种性能差异不仅源于损失函数，更源于一个根本性区别：SFT 从固定的、预先收集的数据集中学习，而 RL 则利用从当前策略中采样的在策略数据。基于这一假设，我们引入了单令牌回滚 (OTR)，这是一种新颖的微调算法，它使用策略梯度方法指导 SFT。OTR 通过将每个令牌生成视为一个单步强化学习轨迹来重新构建自回归学习过程。在每一步中，它通过从当前策略的分布中采样多个候选令牌来执行蒙特卡洛“回滚”。然后，利用监督数据中的真实令牌为这些样本提供奖励信号。在策略梯度的指导下，我们的算法将静态的、离策略的监督数据转化为令牌级别的动态、在策略信号，从而捕获了在策略学习的泛化优势，同时避免了完整句子生成的高昂开销。通过在涵盖数学推理、代码生成和通用领域推理的各种挑战性基准上进行的大量实验，我们证明了 OTR 始终优于标准 SFT。我们的研究结果确立了 OTR 作为微调 LLM 的强大且实用的替代方案，并提供了令人信服的证据，表明数据的在策略性质是泛化的关键驱动因素，为 LLM 的微调提供了一个有前景的新方向。|
|**2025-09-30**|[Interactive Learning for LLM Reasoning](http://arxiv.org/abs/2509.26306)|null|现有的多智能体学习方法已开发出交互式训练环境，以明确促进多个大型语言模型（LLM）之间的协作，从而构建更强大的多智能体系统（MAS）。然而，在推理过程中，它们需要重新执行MAS才能获得最终解决方案，这与人类认知相悖，即个体可以通过与他人互动来增强其推理能力并在未来独立解决问题。为了探究多智能体交互是否能增强LLM的独立问题解决能力，我们引入了ILR，这是一个新颖的MAS协同学习框架，集成了两个关键组件：动态交互（Dynamic Interaction）和感知校准（Perception Calibration）。具体而言，动态交互首先根据问题难度和模型能力自适应地选择协作或竞争策略。LLM随后通过Idea3（思想共享、思想分析和思想融合）交换信息，这是一种旨在模仿人类讨论的创新交互范式，然后得出各自的最终答案。在感知校准中，ILR采用组相对策略优化（GRPO）来训练LLM，同时将一个LLM的奖励分布特征整合到另一个LLM的奖励函数中，从而增强多智能体交互的凝聚力。我们在分属两个不同规模模型家族的三个LLM上验证了ILR，并在五个数学基准和一个编码基准上评估了性能。实验结果表明，ILR始终优于单智能体学习，相比最强的基线，性能提升高达5%。我们进一步发现，Idea3可以在多智能体推理过程中增强更强大的LLM的鲁棒性，并且与纯协作或纯竞争策略相比，动态交互类型可以促进多智能体学习。|
|**2025-09-30**|[PRPO: Paragraph-level Policy Optimization for Vision-Language Deepfake Detection](http://arxiv.org/abs/2509.26272)|null|合成媒体的迅速兴起使得深度伪造检测成为网络安全和信任的关键挑战。进展仍受限于大规模、高质量数据集的稀缺性。尽管多模态大语言模型（LLMs）展现出强大的推理能力，但它们在深度伪造检测上的表现不佳，经常产生与视觉证据不符或幻觉式的解释。为了解决这一局限性，我们引入了一个用于深度伪造检测的推理标注数据集，并提出了段落级相对策略优化（PRPO），这是一种在段落级别上将LLM推理与图像内容对齐的强化学习算法。实验表明，PRPO大幅提升了检测准确性，并获得了4.55/5.0的最高推理分数。消融研究进一步证明，在测试时条件下，PRPO显著优于GRPO。这些结果强调了将多模态推理建立在视觉证据之上的重要性，以实现更可靠和可解释的深度伪造检测。|
|**2025-09-30**|[Diversity-Incentivized Exploration for Versatile Reasoning](http://arxiv.org/abs/2509.26209)|null|可验证奖励强化学习 (RLVR) 已成为激励大型语言模型 (LLM) 推理能力的关键范式。由于推理任务中状态-动作空间巨大和奖励稀疏，现有方法常面临探索不足和样本效率低下的问题。本文提出了 DIVER（多样性激励的多功能推理探索），这是一个创新框架，强调了全局序列级多样性在激励多功能推理深度探索中的关键作用。我们首先进行了一项初步的实证研究，揭示了全局多样性与推理能力之间存在强烈的正相关性。基于这一洞察，我们引入了全局多样性激励作为一种内在奖励，以促进在语义结构化空间中的深度探索。结合内在奖励，我们开发了一种基于势函数的奖励整形机制以保持最优策略不变性，并设计了简单的启发式方法来减轻可能的奖励作弊问题。实验结果表明，DIVER 在域内和域外任务上均优于采用各种探索策略的竞争性 RLVR 基线，并在 Pass@1 和 Pass@k 评估中均表现出色。我们的代码可在 https://github.com/NJU-RL/DIVER 获取。|
|**2025-09-26**|[CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning](http://arxiv.org/abs/2509.22647)|**[link](https://github.com/InternLM/CapRL)**|图像字幕生成是一项连接视觉和语言领域的基本任务，在预训练大型视觉-语言模型（LVLMs）中扮演着关键角色。当前最先进的字幕生成模型通常通过有监督微调（SFT）进行训练，这种范式依赖于由人类或专有模型标注的昂贵且不可扩展的数据。这种方法经常导致模型记忆特定的真实答案，限制了它们的泛化能力以及生成多样化、创意性描述的能力。为了克服SFT的局限性，我们提出将可验证奖励强化学习（RLVR）范式应用于开放式图像字幕生成任务。然而，一个主要挑战是为构成“好”字幕的固有主观性设计一个客观的奖励函数。我们引入了字幕强化学习（CapRL），这是一种新颖的训练框架，通过其效用重新定义字幕质量：一个高质量的字幕应该使非视觉语言模型能够准确回答关于对应图像的问题。CapRL采用解耦的两阶段流程，其中一个LVLM生成字幕，客观奖励则来源于一个独立的、无视觉的LLM仅基于该字幕回答多项选择题的准确性。作为首次将RLVR应用于主观图像字幕生成任务的研究，我们证明CapRL显著提升了多种设置下的性能。在由CapRL-3B标注的CapRL-5M字幕数据集上进行预训练，在12个基准测试中带来了显著的提升。此外，在用于字幕质量评估的Prism框架内，CapRL取得了与Qwen2.5-VL-72B相当的性能，同时平均超越基线8.4%。代码可在此处获取：https://github.com/InternLM/CapRL。|
|**2025-09-26**|[WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning](http://arxiv.org/abs/2509.22644)|null|基于大型语言模型（LLM）的智能体系统在仓库级别的代码生成任务上展现了令人印象深刻的性能。然而，对于诸如网站代码库生成这类严重依赖视觉效果和用户交互反馈的任务，当前的代码智能体仅依赖简单的代码执行进行反馈和验证。这种方法未能捕捉到所生成代码的实际质量。在本文中，我们提出了WebGen-Agent，这是一种新颖的网站生成智能体，它利用全面且多层次的视觉反馈来迭代地生成和完善网站代码库。视觉语言模型（VLM）会生成关于网站屏幕截图和GUI智能体测试的详细且富有表达力的文本描述和建议，并提供量化其质量的分数。屏幕截图和GUI智能体分数进一步与回溯和择优机制相结合，从而提升了智能体的性能。利用WebGen-Agent工作流程中固有的准确视觉分数，我们进一步引入了带有屏幕截图和GUI智能体反馈的Step-GRPO，以提高LLM作为WebGen-Agent推理引擎的能力。通过将每一步的屏幕截图和GUI智能体分数作为Step-GRPO中的奖励，我们提供了一个密集且可靠的过程监督信号，这有效地提高了模型的网站生成能力。在WebGen-Bench数据集上，WebGen-Agent将Claude-3.5-Sonnet的准确率从26.4%提高到51.9%，并将其外观分数从3.0提高到3.9，超过了此前最先进的智能体系统。此外，我们的Step-GRPO训练方法将Qwen2.5-Coder-7B-Instruct的准确率从38.9%提高到45.4%，并将外观分数从3.4提高到3.7。|
|**2025-09-26**|[Towards Efficient Online Exploration for Reinforcement Learning with Human Feedback](http://arxiv.org/abs/2509.22633)|null|人类反馈强化学习 (RLHF) 通过从人类偏好数据中学习奖励模型，然后优化策略以偏好期望的响应，已成为使大型语言模型 (LLM) 与人类偏好对齐的核心范式。在本文中，我们研究了在线RLHF的探索原则，其目标是以数据高效的方式自适应地收集新的偏好数据，以改进奖励模型和策略。通过检查现有的基于乐观主义的探索算法，我们发现其采样协议存在一个缺陷：它们倾向于收集未能减少奖励差异中最具信息量的不确定性的比较，并且我们证明了下界，表明此类方法在指数级长的周期内可能导致线性遗憾。受此启发，我们提出了一种新的探索方案，该方案将偏好查询导向减少与策略改进最相关的奖励差异中的不确定性。在RLHF的多臂老虎机模型下，我们建立了阶数为 $T^{(\beta+1)/(\beta+2)}$ 的遗憾界，其中 $\beta>0$ 是一个用于平衡奖励最大化与减轻分布漂移的超参数。据我们所知，这是第一个遗憾随所有模型参数呈多项式增长的在线RLHF算法。|
|**2025-09-26**|[UML-CoT: Structured Reasoning and Planning with Unified Modeling Language for Robotic Room Cleaning](http://arxiv.org/abs/2509.22628)|null|思维链 (CoT) 提示可提升大型语言模型 (LLMs) 的推理能力，但其对非结构化文本的依赖限制了在具身任务中的可解释性和可执行性。先前工作探索了使用场景图或逻辑图的结构化思维链，但这些方法仍存在根本性限制：它们仅建模低阶关系，缺乏继承或行为抽象等构造，并且未提供序列式或条件式规划的标准化语义。我们提出了 UML-CoT，一个结构化推理与规划框架，它利用统一建模语言 (UML) 来生成符号化思维链和可执行动作规划。UML 类图捕获组合式对象语义，而活动图建模过程控制流。我们的三阶段训练流程结合了监督微调与群体相对策略优化 (GRPO)，包括从仅含答案的数据中进行奖励学习。我们在 MRoom-30k 上评估了 UML-CoT，这是一个新的杂乱房间清理场景基准。UML-CoT 在可解释性、规划连贯性和执行成功率方面均优于非结构化思维链，突出了 UML 作为一种更具表现力且更具可操作性的结构化推理形式化。|
|**2025-09-26**|[SPARK: Synergistic Policy And Reward Co-Evolving Framework](http://arxiv.org/abs/2509.22624)|**[link](https://github.com/InternLM/Spark)**|近年来，大型语言模型（LLMs）和大型视觉-语言模型（LVLMs）越来越多地采用强化学习（RL）进行预训练后微调，例如针对客观任务的可验证奖励强化学习（RLVR）和针对主观任务的人类反馈强化学习（RLHF）。然而，RLHF由于依赖人类偏好而导致成本高昂且可能存在奖励-策略不匹配问题，而RLVR在每次更新后都会丢弃轨迹和正确性信号，从而浪费了监督信息。为应对这些挑战，我们引入了协同策略与奖励协同进化框架（SPARK），这是一种基于RLVR的高效、在线策略且稳定的方法。SPARK没有丢弃轨迹和正确性数据，而是回收这些有价值的信息，同时训练模型本身作为一个生成式奖励模型。这种辅助训练采用了多种目标，例如逐点奖励分数、成对比较以及基于进一步反思响应的评估，以教授模型评估和改进自身响应的能力。我们的方法消除了对独立奖励模型和昂贵的人类偏好数据的需求。SPARK创建了一个积极的协同进化反馈循环：改进的奖励准确性产生更好的策略梯度，这反过来又生成更高质量的轨迹，进一步完善奖励模型。我们的统一框架支持通过自反思进行测试时扩展，无需外部奖励模型及其相关成本。我们表明SPARK在多个LLM和LVLM模型以及多个推理、奖励模型和通用基准测试上取得了显著的性能提升。例如，SPARK-VL-7B在7个推理基准测试上平均实现了9.7%的提升，在2个奖励基准测试上实现了12.1%的提升，在8个通用基准测试上实现了1.5%的提升，相较于基线模型，这展示了其鲁棒性和广泛的泛化能力。|
|**2025-09-26**|[Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective](http://arxiv.org/abs/2509.22613)|null|最近的强化学习（RL）方法大幅提升了大语言模型（LLMs）的规划能力，然而其有效性的理论基础仍然难以捉摸。在这项工作中，我们通过一种易于处理的基于图的抽象来研究RL的优点和局限性，重点关注策略梯度（PG）和Q-学习方法。我们的理论分析表明，有监督微调（SFT）可能会引入基于共现的虚假解，而RL主要通过探索实现正确的规划，强调了探索在实现更好泛化能力中的作用。然而，我们也表明PG存在多样性崩溃问题，即在训练过程中输出多样性下降，即使在达到完美准确度后仍然存在。相比之下，Q-学习提供了两个关键优势：离策略学习和收敛时的多样性保持。我们进一步证明，精心设计的奖励对于防止Q-学习中的奖励作弊是必要的。最后，将我们的框架应用于真实世界规划基准Blocksworld，我们证实这些行为在实践中也表现出来。|
|**2025-09-26**|[Quantile Advantage Estimation for Entropy-Safe Reasoning](http://arxiv.org/abs/2509.22611)|**[link](https://github.com/junkangwu/QAE)**|可验证奖励强化学习（RLVR）能增强大型语言模型（LLM）的推理能力，但其训练过程常在熵塌缩和熵爆炸之间振荡。我们将这两种风险归因于无价值强化学习（如GRPO和DAPO）中使用的均值基线，该基线在奖励异常值下会不当地惩罚负优势样本。我们提出了分位数优势估计（QAE），用组内K分位数基线取代了均值基线。QAE引入了一个响应级别的双机制门控：对于困难查询（p <= 1 - K），它强化罕见的成功案例；对于简单查询（p > 1 - K），它针对剩余的失败案例。在一阶softmax更新下，我们证明了双边熵安全性，给出了单步熵变化的下限和上限，从而遏制了熵爆炸并防止了熵塌缩。经验上，这一微小修改稳定了熵，稀疏化了信用分配（在调整后的K值下，大约80%的响应获得了零优势），并在AIME 2024/2025和AMC 2023数据集上，为Qwen3-8B/14B-Base模型带来了持续的pass@1性能提升。这些结果表明，基线设计——而非token级别的启发式方法——是扩展RLVR的主要机制。|
|**2025-09-26**|[Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning](http://arxiv.org/abs/2509.22601)|null|强化学习（RL）是提升大语言模型（LLMs）在长周期、稀疏奖励智能体任务中战略性工具使用能力的主导范式，但它面临着探索-利用困境这一根本性挑战。现有研究通过策略熵来促进探索，但这种机械式的熵最大化由于多轮分布偏移，容易导致RL训练不稳定。在本文中，我们旨在智能体自身经验的指导下实现渐进式探索-利用平衡，避免陷入熵崩溃或失控发散。我们提出SPEAR，一种基于课程的自我模仿学习（SIL）方法，用于训练智能体大语言模型。它扩展了香草版SIL框架，在该框架中，经验回放缓冲区存储自我生成的有前景轨迹用于离策略更新，通过在不同阶段逐步将策略演化引导至一个良好平衡的熵范围。具体而言，我们的方法引入了一个课程来管理探索过程，利用内在奖励培养技能层面探索，并通过SIL促进动作层面探索。最初，辅助工具调用奖励在工具使用技能的积累中扮演关键角色，使得智能体能够广泛接触环境反馈的陌生分布，并呈现出熵上升趋势。随着训练的进行，自我模仿得到强化，利用回放经验中现有的成功模式进行比较性的动作层面探索，从而加速解决方案迭代，同时避免无限熵增长。为了进一步稳定训练，我们重新校准了经验回放缓冲区中经验的优势值，以解决潜在的策略漂移问题。我们引入了正则化，例如对概率与优势之间具有高协方差的token进行裁剪，以进行轨迹层面的熵控制，从而抑制过度自信。|
|**2025-09-26**|[EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning](http://arxiv.org/abs/2509.22576)|null|在稀疏奖励的多轮交互环境中训练大语言模型智能体，其中完成单个任务在一个回合内需要30多个交互轮次，这对强化学习提出了一个基本挑战。我们识别出该设置特有的一个关键失效模式：探索-利用级联失效。这种级联始于早期策略过早收敛，即稀疏反馈导致智能体采纳有缺陷的低熵策略。随后，智能体进入晚期策略崩溃，此时传统的熵正则化变得适得其反，促进了混乱的探索，从而破坏了训练的稳定性。我们提出了熵正则化策略优化 (EPO)，这是一个通过三种协同机制打破这种失效循环的通用框架：(1) 在多轮设置中采用熵正则化以增强探索，(2) 一种熵平滑正则化器，它将策略熵限制在历史平均值范围内以防止突然波动，以及 (3) 一种自适应的基于阶段的权重分配，它在整个训练过程中平衡了探索与利用。我们的分析证明，EPO保证了熵方差的单调递减，同时保持了收敛性。EPO在ScienceWorld上实现了高达152%的性能提升，在ALFWorld上实现了高达19.8%的性能提升。我们的工作表明，多轮稀疏奖励设置需要与传统强化学习根本不同的熵控制，这对大语言模型智能体训练具有广泛影响。|
|**2025-09-26**|[StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models](http://arxiv.org/abs/2509.22558)|**[link](https://github.com/0xzhouchenyu/StepORLM)**|大语言模型（LLMs）在解决运筹学（OR）问题方面展现出巨大的潜力。尽管强化学习是LLM在运筹学问题训练上的强大范式，但现有工作普遍面临两个主要局限。首先，结果奖励存在信用分配问题，即正确的最终答案可能会强化有缺陷的推理。其次，传统的判别式过程监督是短视的，未能整体评估运筹学建模中相互依赖的步骤。为此，我们引入了StepORLM，这是一种采用生成式过程监督的新颖自演化框架。StepORLM的核心是一个协同演化循环，其中策略模型和生成式过程奖励模型（GenPRM）相互迭代改进。该循环由双重反馈机制驱动：来自外部求解器的明确的、基于结果的验证，以及来自GenPRM的细致入微的、整体的过程评估。组合信号用于通过加权直接偏好优化（W-DPO）来校准策略，并同时改进GenPRM。我们得到的80亿参数StepORLM在六个基准测试中建立了新的最先进水平，显著超越了规模大得多的通用模型、智能体方法和专用基线。此外，协同演化的GenPRM能够作为一个强大且普适的过程验证器，大幅提升了我们自己的模型以及其他现有LLM的推理扩展性能。|
|**2025-09-25**|[SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines](http://arxiv.org/abs/2509.21320)|null|我们提出了一个科学推理基础模型，它将自然语言与异构科学表示对齐。该模型在包含2060亿个词元的语料库上进行预训练，涵盖科学文本、纯序列和序列-文本对，然后通过在4000万条指令上进行SFT（监督微调）、采用退火冷启动自举法以引出长格式思维链，以及使用带有任务特定奖励塑形的强化学习进行对齐，从而灌输审慎的科学推理能力。它支持四大能力族，涵盖跨工作流的103项任务：(i) 文本与科学格式之间的忠实翻译，(ii) 文本/知识提取，(iii) 属性预测，(iv) 属性分类，(v) 无条件和有条件的序列生成与设计。与专业系统相比，我们的方法拓宽了指令覆盖范围，提高了跨领域泛化能力，并增强了保真度。我们详细介绍了数据整理和训练过程，并表明跨学科学习能增强迁移能力和下游可靠性。该模型、指令微调数据集和评估代码已开源，位于 https://huggingface.co/SciReason 和 https://github.com/open-sciencelab/SciReason。|
|**2025-09-25**|[RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards](http://arxiv.org/abs/2509.21319)|null|人类反馈强化学习 (RLHF) 和可验证奖励强化学习 (RLVR) 是大语言模型后训练中使用的主要强化学习范式，各具优势。然而，RLHF在可解释性和奖励作弊方面面临挑战，因为它依赖通常缺乏明确标准的人类判断；而RLVR的适用范围受到限制，因为它侧重于基于正确性的验证器。我们提出了二元灵活反馈强化学习 (RLBFF)，它结合了人类驱动偏好的多功能性与基于规则验证的精确性，使奖励模型能够捕获响应质量超越单纯正确性的细微方面。RLBFF从自然语言反馈中提取可以以二元方式回答的原则 (例如，信息准确性：是，或代码可读性：否)。这些原则随后可用于将奖励模型训练转化为蕴含任务 (即，响应是否满足任意原则)。我们展示了以这种方式训练的奖励模型在数据匹配的情况下可以超越Bradley-Terry模型，并在RM-Bench (86.2%) 和 JudgeBench (81.4%，截至2025年9月24日位列排行榜第一) 上取得了顶尖性能。此外，与Bradley-Terry模型不同，用户可以在推理时指定感兴趣的原则，以定制我们奖励模型的关注点。最后，我们提出了一个完全开源的方案 (包括数据)，使用RLBFF和我们的奖励模型对Qwen3-32B进行对齐，以匹配或超越o3-mini和DeepSeek R1在MT-Bench、WildBench和Arena Hard v2等通用对齐基准上的性能 (推理成本低于5%)。|
|**2025-09-25**|[It's Not You, It's Clipping: A Soft Trust-Region via Probability Smoothing for LLM RL](http://arxiv.org/abs/2509.21282)|null|使用PPO和GRPO等强化学习（RL）方法训练大语言模型（LLM）通常依赖于比例裁剪来稳定更新。尽管裁剪能有效防止不稳定，但它会丢弃信息并引入梯度不连续性。我们提出了概率平滑策略优化（PSPO），它在计算重要性比率之前，将当前策略的概率向旧（行为）策略进行平滑，类似于标签平滑。与裁剪不同，PSPO保留了梯度信号，而向旧策略的插值创建了一个软信任区域，从而阻止了大规模、不稳定的更新，并提供了形式化保证。我们在GRPO中实例化了PSPO（GR-PSPO），并在GSM8K上微调了Qwen2.5-0.5B和Qwen2.5-1.5B模型，评估了它们在GSM8K测试集上的性能以及在SVAMP、ASDiv和MATH-500上的跨数据集泛化能力。相对于未裁剪的GRPO（单次迭代；无数据重用，比例始终为1），GR-PSPO取得了相似的性能，但改进了推理能力，从而产生了更清晰、更简洁且更具逻辑性的响应。与裁剪的GRPO相比，GR-PSPO显著提升了0.5B和1.5B模型的性能，在GSM8K上提升了20%以上（0.5B模型从17.6%提升到39.7%，1.5B模型从37.8%提升到59.4%）。|
|**2025-09-25**|[Tree Search for LLM Agent Reinforcement Learning](http://arxiv.org/abs/2509.21240)|**[link](https://github.com/AMAP-ML/Tree-GRPO)**|强化学习（RL）的最新进展显著增强了大型语言模型（LLM）的智能体能力。在长期和多轮智能体任务中，现有仅由结果奖励驱动的方法常常面临稀疏监督问题。为了解决这一挑战，我们提出了基于树的组相对策略优化（Tree-GRPO），这是一种基于树搜索的分组智能体强化学习方法，其中每个树节点代表完整的智能体交互步骤。通过共享共同前缀，树搜索采样在固定令牌或工具调用预算内增加了可实现的轨迹数量。此外，我们发现树状结构轨迹即使仅使用结果奖励，也能自然地构建逐步过程监督信号。基于此，Tree-GRPO在树内和树间两个层面估计了分组相对优势。通过理论分析，我们证明了树内层面组相对策略优化的目标等价于步级直接偏好学习的目标。在11个数据集和3种问答任务上的实验证明了所提出的基于树的强化学习方法相较于基于链的强化学习方法的优越性。|
|**2025-09-25**|[GRPO is Secretly a Process Reward Model](http://arxiv.org/abs/2509.21154)|**[link](https://github.com/coli-saar/grpo-prm)**|我们理论上证明，在关于跨补全的token序列组内重叠的某些假设下，GRPO强化学习算法会诱导一个非平凡的过程奖励模型（PRM）。然后我们经验性地表明，这些假设在真实世界条件下得到满足：GRPO确实诱导了一个非平凡的PRM。利用“GRPO即PRM”的框架，我们发现了GRPO目标函数中的一个缺陷：非均匀分布的过程步骤在不同条件下会阻碍探索和利用。我们提出了一个简单的算法修改来缓解这一缺陷（ $\lambda$-GRPO），并表明使用$\lambda$ -GRPO训练的大语言模型比使用标准GRPO训练的模型在验证准确率和下游推理任务表现上更高，并且更快地达到峰值性能。我们的结果质疑了昂贵、显式定义的PRM对GRPO的优势：我们展示了可以转而利用原始GRPO算法中隐藏的、内置的PRM结构来提升模型性能，同时对训练时间和成本的影响可忽略不计。|
|**2025-09-25**|[ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective](http://arxiv.org/abs/2509.21134)|null|大语言模型（LLM）已被用于在复杂场景中做出决策，这些场景要求模型进行深入思考、逻辑推理和明智决策。许多现有研究仅关注社交任务或模拟环境中的多轮对话，而忽略了不同类型的决策及其相互依赖性。当前的强化学习方法在训练过程中难以考虑其他个体的策略。为解决这些问题，我们首先定义了一个包含两种类型决策及其时间依赖性的战略决策问题。此外，我们提出了心智理论策略优化（ToMPO）算法，以优化对其他个体策略和博弈局势趋势的感知。与群体相对策略优化（GRPO）算法相比，ToMPO主要通过以下方式增强了LLM的战略决策能力：1) 基于对其他个体策略的推理生成轨迹，2) 在图级别和样本级别估计优势，以及3) 平衡全局和局部奖励。ToMPO算法在模型输出符合度和合作结果方面比GRPO方法高出35%。此外，与参数规模大100倍的模型相比，其性能提升了18%。这表明ToMPO算法在增强模型战略决策能力方面的有效性。|
|**2025-09-25**|[RL Squeezes, SFT Expands: A Comparative Study of Reasoning LLMs](http://arxiv.org/abs/2509.21128)|null|大语言模型 (LLMs) 通常通过带可验证奖励的强化学习 (RLVR) 和基于推理轨迹的监督微调 (SFT) 进行训练，以提高其推理能力。然而，这些方法如何塑造推理能力仍然很大程度上不清楚。本文超越了仅基于准确性来调查这两个组件如何塑造推理过程的方法，引入了一种新颖的分析框架，该框架量化了推理路径并捕捉了它们在每种训练过程下（使用在数学领域拥有1.5B、7B和14B参数的模型）的定性变化。具体而言，我们从两个粒度级别研究推理过程：轨迹级别，该级别检查完整的推理输出；以及步骤级别，该级别分析推理图，其节点对应于单个推理步骤。值得注意的是，对独特推理轨迹的聚类显示出互补效应：RL压缩了不正确的轨迹，而SFT扩展了正确的轨迹。步骤级别分析表明，RL使推理图中节点访问频率、度数和中介中心性分布的衰减率变得更陡峭（约2.5倍），而SFT则使其趋于平坦（减少到约三分之一）。这表明RL将推理功能集中到一小部分步骤中，而SFT则将其均匀分布到许多步骤中。此外，通过从多个角度评估推理图的拓扑结构，我们描绘了RL和SFT的共享和独特特征。我们的工作提出了一种新颖的推理路径视角，解释了为什么当前SFT后接RL的两阶段训练最佳实践是成功的，并为数据构建和更有效的学习方法提供了实际启示。|
|**2025-09-25**|[Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning](http://arxiv.org/abs/2509.21126)|null|在线强化学习在复杂任务中耗时巨大，因为需要大量的交互步骤来学习最优Q函数。视觉-语言动作（VLA）策略代表了解决各种任务的一个有前景的方向；然而，它们在低层控制上的性能仍然有限，并且有效的部署通常需要任务特定的专家演示来进行微调。在本文中，我们提出了VARL（VLM作为在线强化学习的动作建议者），一个利用视觉-语言模型（VLM）领域知识为强化学习智能体提供动作建议的框架。与以往方法不同，VARL提供动作建议而非设计启发式奖励，从而保证了最优性和收敛性不变。这些建议动作增加了样本多样性，最终提高了样本效率，尤其是在稀疏奖励任务中。为了验证VARL的有效性，我们在各种环境和智能体设置中对其进行了评估。结果表明，VARL大幅提高了样本效率，而没有引入显著的计算开销。这些优势使得VARL成为一个用于在线强化学习的通用框架，并使其能够将强化学习从零开始直接应用于真实世界环境。|
|**2025-09-25**|[Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns](http://arxiv.org/abs/2509.21124)|null|大型推理模型在具有挑战性的数学推理方面的最新进展得益于强化学习（RL）。在中期训练中融入长链式思考（CoT）数据，也被证明能够大幅提升推理深度。然而，当前方法常常不加区分地使用CoT数据，这使得哪种数据类型能最有效地增强模型推理能力这一关键问题悬而未决。在本文中，我们首次将基础模型的推理潜力定义为正确回答问题所需的独立尝试次数的倒数，这与最终模型性能密切相关。随后，我们提出利用富含高价值推理模式的多样化数据来扩展推理潜力。具体而言，我们从CoT序列中抽象出以通用性和归纳能力为特征的原子推理模式，并利用它们构建了一个富含宝贵推理模式的核心参考集。此外，我们提出了一种涉及推理模式链和token熵的双粒度算法，以有效从与核心集对齐的数据池中选择高价值CoT数据（CoTP），从而训练模型有效掌握推理。仅100亿token的CoTP数据使85A6B专家混合（MoE）模型在具有挑战性的AIME 2024和2025上提升了9.58%，并将下游RL性能的上限提高了7.81%。|
|**2025-09-25**|[MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning](http://arxiv.org/abs/2509.21113)|null|视频推理已成为多模态大语言模型（MLLMs）的一项关键能力，要求模型超越静态感知，实现对复杂场景中时间动态性的连贯理解。然而，现有MLLMs常表现出过程不一致性，即便是最终答案正确，中间推理也可能偏离视频动态，从而损害了可解释性和鲁棒性。为解决此问题，我们引入了MOSS-ChatV，一个采用基于动态时间规整（DTW）的过程奖励的强化学习框架。这种基于规则的奖励将推理轨迹与时间上基础的参考对齐，从而无需辅助奖励模型即可实现高效的过程监督。我们进一步将动态状态预测确定为视频推理的关键衡量标准，并构建了MOSS-Video，这是一个带有标注推理轨迹的基准数据集，其中训练集用于微调MOSS-ChatV，预留集用于评估。MOSS-ChatV在MOSS-Video（测试集）上取得了87.2%的成绩，并提高了在MVBench和MMVU等通用视频基准上的性能。该框架在Qwen2.5-VL和Phi-2等不同架构上持续取得增益，证实了其广泛适用性。使用GPT-4o作为评判者的评估进一步表明，MOSS-ChatV生成了更一致和稳定的推理轨迹。|
|**2025-09-23**|[Reinforcement Learning on Pre-Training Data](http://arxiv.org/abs/2509.19249)|**[link](https://github.com/synlp/ChiMed-GPT)**|计算资源的指数级扩展与高质量文本数据的有限增长之间日益扩大的差距，目前限制了大型语言模型（LLMs）的传统扩展方法。为了应对这一挑战，我们引入了预训练数据上的强化学习（RLPT），这是一种用于优化LLMs的新型训练时扩展范式。与以往主要通过监督学习扩展训练的方法不同，RLPT使策略能够自主探索有意义的轨迹，从而从预训练数据中学习并通过强化学习（RL）提高其能力。尽管现有的强化学习策略，例如基于人类反馈的强化学习（RLHF）和可验证奖励的强化学习（RLVR），依赖人工标注来构建奖励，但RLPT通过直接从预训练数据中获取奖励信号消除了这种依赖。具体而言，它采用了一种下一片段推理目标，奖励策略基于前文语境准确预测后续文本片段。这种表述使得强化学习可以在预训练数据上进行扩展，鼓励在更广泛的语境中探索更丰富的轨迹，从而培养更具泛化性的推理能力。在通用领域和数学推理基准上对多个模型进行的大量实验验证了RLPT的有效性。例如，当应用于Qwen3-4B-Base时，RLPT在MMLU、MMLU-Pro、GPQA-Diamond、KOR-Bench、AIME24和AIME25上分别带来了3.0、5.1、8.1、6.0、6.6和5.3的绝对提升。结果进一步表明了良好的扩展行为，预示着在更多计算资源下有持续提升的巨大潜力。此外，RLPT提供了一个坚实的基础，扩展了LLMs的推理边界并增强了RLVR的性能。|
|**2025-09-23**|[Online Process Reward Leanring for Agentic Reinforcement Learning](http://arxiv.org/abs/2509.19199)|null|大型语言模型 (LLM) 越来越多地通过强化学习 (RL) 进行训练，成为在交互式环境中进行长期推理和行动的自主智能体。然而，稀疏且有时不可验证的奖励使得时间信用分配极具挑战性。最近的工作尝试将过程监督整合到智能体学习中，但存在标注偏差、奖励欺骗、过细粒度信号导致的高方差，或在状态重叠罕见时失效等问题。因此，我们引入了在线过程奖励学习 (OPRL)，这是一种通用的智能体强化学习信用分配策略，它与标准在轨策略算法无缝集成，无需额外回溯或显式步骤标签。在 OPRL 中，我们通过基于轨迹的 DPO 目标，交替优化隐式过程奖励模型 (PRM) 和智能体策略，将轨迹偏好转换为隐式步骤奖励。这些步骤奖励随后被用于计算步骤级优势，并与来自结果奖励的回合级优势相结合以更新策略，从而形成一个自我强化的循环。理论研究结果保证所学到的步骤奖励与轨迹偏好一致，并作为基于势函数的塑形奖励，提供有界梯度以稳定训练。在实证方面，我们在三个不同的智能体基准上评估了 OPRL，包括 WebShop 和 VisualSokoban，以及 SOTOPIA 中具有不可验证奖励的开放式社交互动。至关重要的是，OPRL 在各个领域都表现出优于前沿大型语言模型和强大的强化学习基线模型的性能，以更高的样本效率和更低的训练方差实现了最先进的结果。进一步分析还表明，OPRL 使用更少的动作实现了高效探索，这突显了其在现实世界场景中进行智能体学习的潜力。|
|**2025-09-23**|[Soft Tokens, Hard Truths](http://arxiv.org/abs/2509.19170)|**[link](https://github.com/rprokap/entremanure)**|在推理大型语言模型（LLMs）的思维链（CoT）阶段使用连续而非离散的token近来受到关注，其直觉是离散token的连续混合可以同时模拟多个推理路径的叠加。理论结果已正式证明连续token具有更强的表达能力，并能更高效地解决特定问题。然而，连续token的实际应用受限于强大的训练难度：之前的工作要么仅在推理时将连续token应用于预训练的离散token模型，要么必须从真实离散CoT中蒸馏出连续CoT，并面临计算成本，使得CoT仅限于极少数token。这是首次引入一种可扩展方法，通过强化学习（RL）来学习连续CoT，无需从参考离散CoT中进行蒸馏。我们使用“软”token：token的混合以及输入嵌入上的噪声，以提供RL探索。计算开销最小，使我们能够学习包含数百个token的连续CoT。在高达8B参数的Llama和Qwen模型上的数学推理基准测试中，使用连续CoT进行训练，在pass@1指标上与离散token CoT持平，并在pass@32指标上超越它们，表明CoT的多样性更强。在系统比较中，表现最佳的场景是使用连续CoT token进行训练，然后在推理时使用离散token，这意味着“软”模型可以以标准方式部署。最后，我们展示了连续CoT强化学习训练能更好地保留基础模型在域外任务上的预测，从而为基础模型提供了更温和的干预。|
|**2025-09-23**|[PipelineRL: Faster On-policy Reinforcement Learning for Long Sequence Generatio](http://arxiv.org/abs/2509.19128)|null|强化学习 (RL) 正越来越多地被用于增强大语言模型 (LLM) 的推理能力。然而，有效扩展这些RL方法面临显著挑战，这主要是因为在不生成损害常见RL算法的陈旧离策略数据的前提下，难以维持高AI加速器利用率。本文介绍了一种名为PipelineRL的方法，旨在为LLM训练实现硬件效率和数据在策略性之间的卓越权衡。PipelineRL采用并发异步数据生成和模型训练，其特点是新颖的飞行中权重更新。这种机制允许LLM生成引擎在生成token序列期间以最小中断接收更新的模型权重，从而最大化加速器利用率和训练数据的新鲜度。使用128个H100 GPU在长文本推理任务上进行的实验表明，与传统RL基线相比，PipelineRL实现了大约2倍的学习速度提升，同时保持了高度在策略的训练数据。作为一项关键贡献，PipelineRL的一个可扩展且模块化的开源实现也已发布。|
|**2025-09-23**|[DRO-REBEL: Distributionally Robust Relative-Reward Regression for Fast and Efficient LLM Alignment](http://arxiv.org/abs/2509.19104)|**[link](https://github.com/sharansahu/distributionally_robust_rebel)**|人类反馈强化学习（RLHF）对于使大语言模型（LLM）与人类意图对齐至关重要。然而，现有离线RLHF方法存在过度优化问题，即模型对奖励误设定过拟合，并偏离训练中观察到的偏好行为。我们引入了DRO-REBEL，这是一个统一的鲁棒REBEL更新族，包含 $p$型Wasserstein、KL和$\chi^2$模糊集。利用Fenchel对偶性，每个更新都简化为简单的相对奖励回归，从而保持可扩展性并避免PPO风格的裁剪或辅助价值网络。在标准线性奖励和对数线性策略类以及数据覆盖条件下，我们建立了$O(n^{-1/4})$的估计界限，其常数比先前的DRO-DPO方法更紧密，并通过局部Rademacher复杂度分析恢复了极小极大最优的$O(n^{-1/2})$速率。同样的分析弥补了Wasserstein-DPO和KL-DPO的差距，表明两者也达到了最优参数速率。我们为所有三种散度推导了实用的SGD算法：梯度正则化（Wasserstein）、重要性采样（KL）和快速一维对偶求解（$\chi^2$）。在情感对齐、大规模ArmoRM多目标基准和HH对齐上的实验证明了在未见偏好混合、模型规模和数据规模下强大的最坏情况鲁棒性，其中$\chi^2$-REBEL持续显示出强大的经验性能。一项受控的半径-覆盖率研究验证了“没有免费午餐”的权衡：比经验散度集中速率收缩更快的半径能够达到极小极大最优参数速率但牺牲了覆盖率，而保证覆盖率的半径则会导致$O(n^{-1/4})$ 的速率。|
|**2025-09-23**|[Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards](http://arxiv.org/abs/2509.19003)|**[link](https://github.com/baaivision/CoS)**|思维链推理在大语言模型中取得了显著成功，但其在视觉-语言推理中的应用仍然是一个开放性挑战，且最佳实践尚不明确。现有尝试通常采用粗粒度推理链，这难以执行细粒度结构化推理，更重要的是，难以评估中间推理的奖励和质量。在这项工作中，我们深入研究了视觉-语言模型的步骤链推理，从而能够精确评估推理步骤质量，并利用细粒度奖励实现有效的强化学习和推理时扩展。我们提出了一个简单、有效且完全透明的框架，包括步骤级推理数据、过程奖励模型（PRM）和强化学习训练。凭借所提出的方法，我们的模型在具有挑战性的视觉-语言基准上建立了强大的基线，并取得了持续改进。更重要的是，我们进行了彻底的实证分析和消融研究，揭示了每个组件的影响以及推理时扩展的一些有趣特性。我们相信本文可作为视觉-语言模型的基线，并为更复杂的多模态推理提供见解。我们的数据集、PRM和代码将可在https://github.com/baaivision/CoS获取。|
|**2025-09-23**|[Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](http://arxiv.org/abs/2509.18864)|null|用户画像作为用户理解的核心技术，旨在从用户信息中推断结构化属性。大语言模型（LLMs）为用户画像提供了有前景的途径，然而，进展受到缺乏全面基准的阻碍。为了弥补这一空白，我们提出了ProfileBench，这是一个源自真实世界视频平台的工业基准，它包含异构用户数据和结构良好的画像分类体系。然而，由于难以收集大规模真实标签，以及异构且嘈杂的用户信息可能会损害LLMs的可靠性，画像任务仍然具有挑战性。为了实现无标签且可靠的用户画像，我们提出了一个置信度驱动的画像推理框架Conf-Profile，它采用两阶段范式。我们首先利用带有置信度提示的先进LLMs合成高质量标签，接着通过置信度加权投票提高准确性，并通过置信度校准实现平衡分布。多个画像结果、理由和置信度分数被聚合并蒸馏到一个轻量级LLM中。我们通过置信度引导的无监督强化学习进一步增强了推理能力，该学习利用置信度进行难度过滤、准真实标签投票和奖励加权。实验结果表明，Conf-Profile通过两阶段训练提供了显著的性能，在Qwen3-8B上将F1提高了13.97。|
|**2025-09-23**|[NGRPO: Negative-enhanced Group Relative Policy Optimization](http://arxiv.org/abs/2509.18851)|null|RLVR增强了大语言模型（LLMs）在各种任务中的推理能力。然而，作为一种代表性的RLVR算法，GRPO存在一个关键局限：当一个组内的所有响应要么完全正确，要么完全不正确时，模型无法从这些同质响应中学习。这对于同质不正确组尤其成问题，因为GRPO的优势函数会产生零值，导致零梯度并丢失有价值的学习信号。为了克服这个问题，我们提出了NGRPO（负增强组相对策略优化），这是一种旨在将同质错误转化为鲁棒学习信号的算法。首先，NGRPO引入了优势校准。该机制假设在优势计算过程中存在一个虚拟的最大奖励样本，从而改变组内奖励的均值和方差，并确保同质不正确样本的优势不再为零。其次，NGRPO采用了非对称裁剪，该方法放宽了对正样本的更新幅度，同时对负样本施加了更严格的约束。这有助于稳定由优势校准引入的探索压力。我们在Qwen2.5-Math-7B上的实验表明，NGRPO在MATH500、AMC23和AIME2025等数学基准测试中显著优于PPO、GRPO、DAPO和PSR-NSR等基线方法。这些结果验证了NGRPO从同质错误中学习的能力，从而在数学推理方面带来稳定且显著的改进。我们的代码可在https://github.com/nangongrui-ngr/NGRPO获取。|
|**2025-09-23**|[MAPO: Mixed Advantage Policy Optimization](http://arxiv.org/abs/2509.18849)|**[link](https://github.com/WenkeHuang/MAPO)**|针对基础模型的强化学习（例如组相对策略优化GRPO）的最新进展，显著提升了基础模型在推理任务上的性能。值得注意的是，优势函数在GRPO中作为对轨迹重要性进行排序的核心机制。然而，现有探索遇到了优势反转和优势镜像问题，这阻碍了在不同查询样本之间进行合理的优势分配。在这项工作中，我们提出了一种简单但有效的GRPO策略：混合优势策略优化 (MAPO)。我们揭示了轨迹以不同的确定性出现，并针对高确定性轨迹的样本提出了优势百分比偏差。此外，我们动态地重新加权具有不同轨迹确定性的样本的优势函数，从而自适应地配置优势函数以考虑样本特有特性。与相关最先进方法的比较，以及针对不同优势变体的消融研究，验证了我们方法的有效性。|
|**2025-09-23**|[Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](http://arxiv.org/abs/2509.18847)|null|工具增强型大型语言模型（LLM）通常通过监督模仿学习或优化单次工具调用的粗粒度强化学习进行训练。当前的自我反思实践依赖于启发式提示或单向推理：模型被敦促“多思考”，而不是学习错误诊断和修复。这在多轮交互中是脆弱的；在失败后，模型往往会重复相同的错误。我们提出了结构化反思，它将从错误到修复的路径转化为一个显式、可控且可训练的动作。智能体生成一个简短而精确的反思：它利用前一步的证据诊断故障，然后提出一个正确且可执行的后续调用。为了进行训练，我们将DAPO和GSPO目标与针对工具使用定制的奖励机制相结合，优化“反思-调用-结束”的逐步策略。为了评估，我们引入了Tool-Reflection-Bench，这是一个轻量级基准，它通过编程方式检查结构有效性、可执行性、参数正确性和结果一致性。任务被构建为错误调用、反思和纠正调用的微型轨迹，具有不相交的训练集和测试集划分。在BFCL v3和Tool-Reflection-Bench上的实验表明，多轮工具调用成功率和错误恢复能力显著提高，并且冗余调用减少。这些结果表明，使反思显式化并直接优化它，可以提高工具交互的可靠性，并为智能体从失败中学习提供了可复现的路径。|
|**2025-09-19**|[Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning](http://arxiv.org/abs/2509.16136)|null|设计有效的奖励函数仍然是强化学习（RL）中的一个主要挑战，通常需要大量人类专业知识和迭代优化。最近的进展利用大语言模型（LLMs）进行自动化奖励设计，但这些方法受限于幻觉、对人类反馈的依赖以及处理复杂多步骤任务的挑战。在这项工作中，我们引入了基于思绪图的奖励演化（RE-GoT），这是一个新颖的双层框架，它通过结构化图基推理增强LLMs，并集成视觉语言模型（VLMs）以进行自动化轨迹评估。RE-GoT首先将任务分解为文本属性图，从而实现全面分析和奖励函数生成，然后利用来自VLMs的视觉反馈迭代优化奖励，无需人工干预。在10个RoboGen任务和4个ManiSkill2任务上进行的大量实验表明，RE-GoT持续优于现有的基于LLM的基线。在RoboGen上，我们的方法将平均任务成功率提高了32.25%，在复杂多步骤任务上取得了显著提升。在ManiSkill2上，RE-GoT在四个多样化操作任务中实现了93.73%的平均成功率，显著超越了先前的基于LLM的方法，甚至超过了专家设计的奖励。我们的结果表明，将LLMs和VLMs与思绪图推理相结合，为RL中的自主奖励演化提供了一种可扩展且有效的解决方案。|
|**2025-09-19**|[BaseReward: A Strong Baseline for Multimodal Reward Model](http://arxiv.org/abs/2509.16127)|null|多模态大语言模型（MLLMs）的快速发展使得使其与人类偏好对齐成为一个严峻挑战。奖励模型（RMs）是实现此目标的核心技术，然而，目前学术界和工业界都缺乏构建最先进多模态奖励模型（MRMs）的系统性指南。本文旨在通过详尽的实验分析，为构建高性能MRMs提供一个清晰的“秘籍”。我们系统性地研究了MRM开发流程中的每个关键组成部分，包括奖励建模范式（例如，朴素-RM、基于评论员的RM和生成式RM）、奖励头架构、训练策略、数据筛选（涵盖十余个多模态和纯文本偏好数据集）、主干模型和模型规模以及集成方法。基于这些实验见解，我们引入了BaseReward，一个强大而高效的多模态奖励建模基线。BaseReward采用了一种简单而有效的架构，它建立在Qwen2.5-VL主干之上，具有优化的两层奖励头，并在一组精心筛选的高质量多模态和纯文本偏好数据混合上进行训练。我们的结果表明，BaseReward在MM-RLHF-奖励基准、VL-奖励基准和多模态奖励基准等主要基准上建立了新的SOTA，优于以往模型。此外，为了验证其超越静态基准的实际效用，我们将BaseReward集成到一个真实的强化学习流程中，成功提升了MLLM在各种感知、推理和对话任务中的性能。这项工作不仅交付了一个顶级的MRM，更重要的是，为社区提供了一个清晰、有经验支持的指南，用于开发下一代MLLMs的稳健奖励模型。|
|**2025-09-19**|[Rethinking Molecule Synthesizability with Chain-of-Reaction](http://arxiv.org/abs/2509.16084)|null|分子生成模型的一个众所周知的不足是它们不能保证生成可合成的分子。尽管已为此问题进行了大量尝试，但鉴于可合成分子指数级大的组合空间，现有方法在空间覆盖率和分子优化性能方面表现不佳。为解决这些问题，我们引入了ReaSyn，这是一个用于可合成投影的生成框架，模型通过生成能产生可合成类似物的路径，来探索给定分子在可合成空间中的邻域。为了充分利用合成路径中包含的化学知识，我们提出了一种新颖的视角，将合成路径类比于大语言模型（LLM）中的推理路径。具体而言，受LLM中思维链（CoT）推理的启发，我们引入了反应链（CoR）表示法，该表示法明确说明了路径中每一步的反应物、反应类型和中间产物。借助CoR表示法，ReaSyn可以在每个反应步骤中获得密集监督，从而在监督训练期间明确学习化学反应规则并执行逐步推理。此外，为了进一步增强ReaSyn的推理能力，我们提出了基于强化学习（RL）的微调和专为可合成投影定制的目标导向测试时计算扩展。ReaSyn在可合成分子重建中实现了最高的重建率和路径多样性，在可合成目标导向分子优化中实现了最高的优化性能，并在可合成命中扩展方面显著优于先前的可合成投影方法。这些结果突出了ReaSyn在探索组合学上巨大的可合成化学空间方面的卓越能力。|
|**2025-09-19**|[AI Methods for Permutation Circuit Synthesis Across Generic Topologies](http://arxiv.org/abs/2509.16020)|null|本文研究了用于在通用拓扑结构上合成和转译置换电路的人工智能 (AI) 方法。我们的方法采用强化学习 (RL) 技术，实现了多达 25 量子比特置换电路的近乎最优合成。我们没有为单个拓扑结构开发专用模型，而是在通用矩形格子上训练了一个基础模型，并采用掩码机制在合成过程中动态选择拓扑结构的子集。这使得置换电路能够在任何可嵌入矩形格子的拓扑结构上进行合成，而无需重新训练模型。本文展示了 5x5 格子的结果，并将其与之前面向拓扑的AI模型和经典方法进行比较，结果表明它们优于经典启发式方法，与之前的专用AI模型性能相当，甚至能够对训练中未见过的拓扑结构进行合成。我们进一步表明，该模型可以通过微调来增强对特定感兴趣拓扑结构的性能。这种方法使得单一训练模型能够高效地在不同拓扑结构上合成电路，从而使其能够实际集成到转译工作流程中。|
|**2025-09-19**|[Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search](http://arxiv.org/abs/2509.15927)|null|自动出价是广告主提升广告效果的重要工具。最新进展表明，AI生成式出价 (AIGB) 将自动出价建模为轨迹生成任务，并在离线数据上训练基于条件扩散模型的规划器，相比于典型的基于离线强化学习 (RL) 的自动出价方法，取得了卓越且稳定的性能。然而，现有的AIGB方法由于忽视了细粒度的生成质量评估以及无法探索静态数据集之外的内容，仍然面临性能瓶颈。为解决此问题，我们提出了AIGB-Pearl (意为通过RL进行评估器引导的规划)，这是一种融合了生成式规划和策略优化的新颖方法。AIGB-Pearl的关键在于构建一个非自举的轨迹评估器，用于分配奖励并指导策略搜索，从而使规划器能够通过交互迭代地优化其生成质量。此外，为提升离线设置中轨迹评估器的准确性，我们引入了三项关键技术：(i) 基于大语言模型 (LLM) 的架构以获得更好的表示能力，(ii) 混合点式和对式损失以获得更好的分数学习，以及 (iii) 专家反馈的自适应集成以获得更好的泛化能力。在模拟和真实世界的广告系统上进行的大量实验证明了我们方法的最先进性能。|
|**2025-09-19**|[Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds](http://arxiv.org/abs/2509.15915)|null|尽管从零开始的强化学习在利用高效模拟器解决序列决策任务方面取得了令人瞩目的成果，但现实世界中交互成本高昂的应用需要更具样本效率的智能体。基础模型（FM）因其广泛的知识和推理能力，自然成为提高样本效率的候选者，但目前尚不清楚如何有效地将它们整合到强化学习框架中。在本文中，我们预测并（最重要的是）评估了两种有前景的策略。首先，我们考虑使用基础世界模型（FWM），它们利用FM的先验知识，从而能够通过模拟交互来训练和评估智能体。其次，我们考虑使用基础智能体（FA），它们利用FM的推理能力进行决策。我们在一系列适合当前一代大型语言模型（LLM）的网格世界环境中凭经验评估了这两种方法。我们的结果表明，LLM的改进已经转化为更好的FWM和FA；基于当前LLM的FA已经能够为足够简单的环境提供优秀的策略；并且FWM与强化学习智能体的结合对于具有部分可观察性和随机元素的更复杂环境非常有前景。|
|**2025-09-19**|[CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair](http://arxiv.org/abs/2509.15690)|null|C++编译错误的自动化修复是一个重大挑战，其解决对于提高开发者生产力至关重要。该领域的进展受两个主要因素的限制：大规模、高保真数据集的稀缺性，以及传统监督方法的局限性，这些方法往往无法生成语义正确的补丁。本文通过引入一个具有三个核心贡献的综合框架来解决这些空白。首先，我们提出了CCrepair，这是一个通过精密生成与验证流程构建的新颖、大规模C++编译错误数据集。其次，我们提出了一种由混合奖励信号引导的强化学习（RL）范式，将重点从仅仅是可编译性转移到修复的语义质量。最后，我们建立了一个提供此信号的鲁棒两阶段评估系统，其核心是一个“LLM作为判官”的模型，该模型的可靠性已根据人类专家小组的集体判断进行了严格验证。这种集成方法使训练目标与生成高质量、非平凡且语法和语义都正确的补丁相一致。我们的方法通过实验证明了其有效性。我们经过RL训练的Qwen2.5-1.5B-Instruct模型达到了与Qwen2.5-14B-Instruct模型相当的性能，验证了我们训练范式的效率。我们的工作为研究社区提供了一个有价值的新数据集和一种更有效的训练与评估鲁棒编译修复模型的范式，为开发更实用和可靠的自动化编程助手铺平了道路。|
|**2025-09-19**|[PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models](http://arxiv.org/abs/2509.15607)|null|基于偏好的强化学习 (PbRL) 已成为一种无需奖励工程即可教会机器人复杂行为的有前景的范式。然而，其有效性常受限于两个关键挑战：对大量人类输入的依赖以及在奖励学习过程中解决查询歧义和信用分配的固有困难。本文引入 PRIMT，一个旨在通过利用基础模型 (FMs) 进行多模态合成反馈和轨迹合成来克服这些挑战的 PbRL 框架。与以往依赖单模态基础模型评估的方法不同，PRIMT 采用一种分层神经符号融合策略，整合了大语言模型和视觉语言模型在评估机器人行为方面的互补优势，以获得更可靠、更全面的反馈。PRIMT 还结合了预见性轨迹生成，通过用引导样本预热轨迹缓冲区来减少早期查询歧义；以及回溯性轨迹增强，它结合因果辅助损失实现了反事实推理，以改进信用分配。我们在各种基准上对 PRIMT 进行了 2 个运动任务和 6 个操作任务的评估，证明了其性能优于基于基础模型和脚本的基线。|
|**2025-09-19**|[BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent](http://arxiv.org/abs/2509.15566)|null|在AI驱动的人机图形界面交互自动化领域，尽管多模态大语言模型和强化微调技术的快速发展取得了显著进步，但一个根本挑战依然存在：它们的交互逻辑显著偏离了自然的人机图形界面通信模式。为了弥补这一空白，我们提出了“闪视-思考-连接”（Blink-Think-Link，简称BTL）框架，这是一个受大脑启发的、模仿用户与图形界面之间人类认知过程的人机图形界面交互框架。该系统将交互分解为三个生物学上合理的阶段：（1）闪视（Blink）——快速检测并关注相关屏幕区域，类似于眼跳运动；（2）思考（Think）——高级推理和决策，映射认知规划；（3）连接（Link）——生成用于精确运动控制的可执行命令，模拟人类的行动选择机制。此外，我们为BTL框架引入了两项关键技术创新：（1）闪视数据生成（Blink Data Generation）——一个专门为闪视数据优化的自动化标注流程，以及（2）BTL奖励（BTL Reward）——首个基于规则的奖励机制，能够驱动由过程和结果共同决定的强化学习。基于此框架，我们开发了一个名为BTL-UI的图形界面智能体模型，该模型在综合基准测试中，于静态GUI理解和动态交互任务中均展示了持续的最先进性能。这些结果为该框架在开发高级GUI智能体方面的有效性提供了确凿的经验验证。|
|**2025-09-19**|[Reward Hacking Mitigation using Verifiable Composite Rewards](http://arxiv.org/abs/2509.15557)|**[link](https://github.com/healthylaife/Composite-LLM-Reward-Model)**|可验证奖励强化学习（RLVR）最近表明，大型语言模型（LLMs）无需直接监督即可发展出自己的推理能力。然而，在医疗领域的应用，特别是问答任务中，推理阶段容易受到严重的奖励欺骗。我们的工作解决了这种行为的两种主要形式：一是提供最终答案而无前置推理，二是采用非标准推理格式来利用奖励机制。为了缓解这些问题，我们引入了一种复合奖励函数，对这些行为施加了特定的惩罚。我们的实验表明，将RLVR与我们提出的奖励模型结合，能够产生格式更规范的推理，减少了奖励欺骗，并与基线相比具有良好的准确性。这种方法标志着向减少奖励欺骗和增强利用RLVR的模型的可靠性迈进了一步。|
|**2025-09-18**|[Generalizable Geometric Image Caption Synthesis](http://arxiv.org/abs/2509.15217)|null|多模态大语言模型拥有各种要求强大推理能力的实际应用。尽管最近取得了进展，这些模型在解决复杂几何问题方面仍然面临挑战。一个关键挑战源于缺乏用于理解几何图像的高质量图像-文本对数据集。此外，大多数基于模板的数据合成管道通常无法泛化到超出其预定义模板的问题。在本文中，我们通过将可验证奖励强化学习 (RLVR) 这一互补过程引入数据生成管道来弥补这一空白。通过采用RLVR来细化从50种基本几何关系合成的几何图像的描述，并利用源自数学问题解决任务的奖励信号，我们的管道成功捕捉了几何问题解决的关键特征。这使得任务泛化能力得到提升，并带来了显著改进。此外，即使在分布外场景中，所生成的数据集也增强了多模态大语言模型的通用推理能力，在MathVista和MathVerse数据集中针对非几何输入图像的统计、算术、代数和数值任务中，准确率提高了2.8%-4.8%，同时在MMMU的艺术、设计、技术和工程任务中也实现了2.4%-3.9%的改进。|
|**2025-09-18**|[FlowRL: Matching Reward Distributions for LLM Reasoning](http://arxiv.org/abs/2509.15207)|null|我们提出FlowRL：在大语言模型（LLM）强化学习（RL）中，通过流平衡来匹配完整的奖励分布，而非最大化奖励。近期的先进推理模型采用奖励最大化方法（例如，PPO和GRPO），这些方法倾向于过度优化主导奖励信号，同时忽视不那么频繁但有效的推理路径，从而降低了多样性。相比之下，我们将标量奖励转换为使用可学习配分函数的归一化目标分布，然后最小化策略与目标分布之间的逆KL散度。我们将这一思想实现为一种流平衡优化方法，该方法促进多样化探索和可泛化的推理轨迹。我们在数学和代码推理任务上进行了实验：FlowRL在数学基准测试中，相较于GRPO平均实现了10.0%的显著提升，相较于PPO平均实现了5.1%的显著提升，并在代码推理任务上表现持续更好。这些结果突出表明，奖励分布匹配是迈向LLM强化学习中高效探索和多样化推理的关键一步。|
|**2025-09-18**|[Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation](http://arxiv.org/abs/2509.15194)|**[link](https://github.com/YujunZhou/EVOL-RL)**|大型语言模型（LLM）正越来越多地通过基于可验证奖励的强化学习（RLVR）进行训练，然而，实际部署需要模型能够在没有标签或外部评判的情况下进行自我改进。现有的无标签方法，如置信度最小化、自我一致性或多数投票目标，能稳定学习但会逐渐减少探索，导致熵坍塌：生成内容变得更短、多样性降低且脆弱。与先前方法（例如测试时强化学习（TTRL），其主要使模型适应当前的无标签数据集）不同，我们的目标更广阔：在不牺牲模型固有的探索能力和泛化能力（即进化）的情况下实现普遍改进。我们形式化了这个问题，并提出了面向进化的无标签强化学习（EVOL-RL），它是一种在无标签设置下将稳定性与变异性相结合的简单规则。EVOL-RL将多数投票答案作为稳定锚点（选择），同时添加了新颖性感知奖励，该奖励偏好推理与已生成内容不同（变异）的响应，并在语义空间中进行衡量。EVOL-RL使用GRPO实现，还利用非对称裁剪来保留强信号和熵正则化器来维持探索。这种多数选择+新颖变异的设计可以防止坍塌，保持更长、信息量更大的思维链，并提高pass@1和pass@n。EVOL-RL持续优于仅基于多数投票的TTRL基线；例如，在无标签AIME24上训练，将Qwen3-4B-Base模型在AIME25上的pass@1从TTRL的4.6%提升到16.4%，pass@16从18.5%提升到37.9%。EVOL-RL不仅防止了多样性坍塌，还实现了更强的跨领域泛化能力（例如，GPQA）。此外，我们证明EVOL-RL在RLVR设置中也能提升性能，突显了其广泛适用性。|
|**2025-09-18**|[Self-Improving Embodied Foundation Models](http://arxiv.org/abs/2509.15155)|**[link](https://github.com/self-improving-efms/self-improving-efms.github.io)**|基于海量网络数据训练的基础模型彻底改变了机器人技术，但其在低级控制中的应用仍主要局限于行为克隆。借鉴大型语言模型微调中强化学习阶段的成功经验，我们提出了一种用于机器人的两阶段后训练方法。第一阶段为监督微调（SFT），它利用行为克隆和剩余步数预测目标来微调预训练的基础模型。在第二阶段，即自我改进阶段，剩余步数预测使得能够提取形态良好的奖励函数和鲁棒的成功检测器，从而使机器人集群能够在最少人工监督下自主练习下游任务。通过在真实世界和模拟机器人实体上进行的大量实验，我们新颖的后训练方案在具身基础模型上取得了显著成果。首先，我们证明了SFT和自我改进的结合比扩展监督学习的模仿数据收集效率显著更高，并能带来成功率显著提升的策略。进一步的消融实验强调，海量网络预训练和自我改进的结合是实现这种样本效率的关键。其次，我们证明了我们提出的组合独特地解锁了一种当前方法无法实现的能力：自主练习和获取新技能，这些技能的泛化能力远超训练中使用的模仿学习数据集中观察到的行为。这些发现突出了将预训练基础模型与在线自我改进相结合，以实现在机器人技术中自主技能获取的变革性潜力。我们的项目网站可在 https://self-improving-efms.github.io 找到。|
|**2025-09-18**|[Stochastic Bilevel Optimization with Heavy-Tailed Noise](http://arxiv.org/abs/2509.14952)|null|本论文研究了平滑双层优化问题，其中下层问题是强凸的，上层问题可能为非凸。我们关注随机设置，即算法可以访问带有重尾噪声的无偏随机梯度评估，这在许多机器学习应用中普遍存在，例如训练大型语言模型和强化学习。我们提出了一种嵌套循环归一化随机双层近似（N $^2$SBA）算法，用于找到一个$\epsilon$-驻点，其随机一阶预言机（SFO）复杂度为$\tilde{\mathcal{O}}\big(\kappa^{\frac{7p-3}{p-1}} \sigma^{\frac{p}{p-1}} \epsilon^{-\frac{4 p - 2}{p-1}}\big)$，其中$\kappa$是条件数，$p\in(1,2]$是噪声中心矩的阶数，$\sigma$是噪声水平。此外，我们将我们的思想专门应用于求解非凸-强凹极小极大优化问题，实现了$\epsilon$-驻点，其SFO复杂度为$\tilde{\mathcal O}\big(\kappa^{\frac{2p-1}{p-1}} \sigma^{\frac{p}{p-1}} \epsilon^{-\frac{3p-2}{p-1}}\big)$。上述所有上限在有界方差设置的特殊情况（即$p=2$ ）下均与已知最佳结果相匹配。|
|**2025-09-18**|[Empathy-R1: A Chain-of-Empathy and Reinforcement Learning Framework for Long-Form Mental Health Support](http://arxiv.org/abs/2509.14851)|null|同理心对于有效的心理健康支持至关重要，尤其是在处理长篇咨询文本（LCTs）时。然而，现有的大型语言模型（LLMs）通常生成的回复在语义上很流畅，但缺乏真正心理支持所需的结构化推理能力，尤其是在中文语境下。为了弥合这一鸿沟，我们引入了Empathy-R1，这是一个新颖的框架，它将同理心链（CoE）推理过程与强化学习（RL）相结合，以提升LCTs的回复质量。受认知行为疗法的启发，我们的CoE范式引导模型顺序推理求助者的情绪、原因和意图，使其思维过程既透明又可解释。我们的框架得益于一个新的大规模中文数据集Empathy-QA和两阶段训练过程。首先，监督微调灌输了CoE的推理结构。随后，在专用奖励模型的指导下，强化学习优化了最终回复的治疗相关性和上下文适宜性。实验表明，Empathy-R1在关键自动指标上取得了强大性能。更重要的是，人工评估证实了其优越性，显示出对强大基线的明显偏好，并在我们的新基准上实现了44.30%的Win@1比率。通过实现可解释且上下文细致入微的回复，Empathy-R1代表了在开发负责任且真正有益于心理健康支持的人工智能方面的一项重大进展。|
|**2025-09-18**|[ToolSample: Dual Dynamic Sampling Methods with Curriculum Learning for RL-based Tool Learning](http://arxiv.org/abs/2509.14718)|null|虽然强化学习（RL）越来越多地用于基于LLM的工具学习，但其效率常受到过多的简单样本的阻碍，这些样本随着训练的进行提供的学习价值逐渐递减。现有的动态采样技术不适用于工具学习固有的多任务结构和细粒度奖励机制。本文提出了带有课程学习的动态采样（DSCL）框架，该框架专门设计用于解决这一挑战，通过针对工具学习的独特特点：其多个相互依赖的子任务和多值奖励函数。DSCL包含两个核心组件：基于奖励的动态采样，它利用多维奖励统计数据（均值和方差）来优先处理有价值的数据；以及基于任务的动态课程学习，它自适应地将训练重点放在掌握程度较低的子任务上。通过广泛的实验，我们证明DSCL相较于强大的基线方法显著提升了训练效率和模型性能，在BFCLv3基准上取得了3.29%的提升。我们的方法提供了一种定制的解决方案，有效利用了工具学习中复杂的奖励信号和子任务动态，以取得卓越的成果。|
|**2025-09-18**|[RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](http://arxiv.org/abs/2509.14693)|null|日志构成了表明软件系统运行状态的一种证据形式。自动化日志异常检测对于确保现代软件系统的可靠性至关重要。然而，现有方法面临显著局限性：传统深度学习模型缺乏可解释性和泛化能力，而利用大型语言模型的方法常常因不可靠性和事实不准确性而受阻。为解决这些问题，我们提出了RationAnomaly，一个新颖的框架，它通过协同思维链（CoT）微调与强化学习来增强日志异常检测。我们的方法首先使用CoT引导的监督微调灌输专家级的推理模式，该微调基于通过严格的专家驱动过程校正的高质量数据集。随后，一个采用多方面奖励函数的强化学习阶段优化了准确性和逻辑一致性，有效缓解了幻觉现象。实验结果表明，RationAnomaly优于最先进的基线，在关键基准测试中实现了更高的F1分数，同时提供透明、分步的分析输出。我们已发布相应的资源，包括代码和数据集。|
|**2025-09-18**|[LEED: A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2509.14680)|null|多智能体强化学习（MARL）在复杂环境中的智能决策方面具有巨大的潜力。然而，随着智能体数量的增加，它面临着协调性和可扩展性瓶颈。为了解决这些问题，我们提出了用于多智能体强化学习的基于大型语言模型赋能的专家演示框架（LEED）。LEED由两个组件组成：一个演示生成（DG）模块和一个策略优化（PO）模块。具体而言，DG模块利用大型语言模型生成与环境交互的指令，从而产生高质量的演示。PO模块采用去中心化训练范式，其中每个智能体利用生成的演示来构建专家策略损失，并将其与自身的策略损失相结合。这使得每个智能体能够基于专家知识和个体经验有效地个性化和优化其局部策略。实验结果表明，与最先进的基线相比，LEED在样本效率、时间效率和鲁棒的可扩展性方面表现出卓越的性能。|
|**2025-09-17**|[Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents](http://arxiv.org/abs/2509.14480)|null|有效的交互式工具使用要求智能体掌握工具集成推理（TIR）：这是一个涉及多轮规划和长上下文对话管理的复杂过程。为了训练智能体应对这一动态过程，特别是在多模态场景中，我们引入了一个支持交错语音-文本推演的强化学习（RL）沙盒环境。我们的核心策略，轮次级裁决强化学习（TARL），通过采用大型语言模型（LLM）作为评判者提供轮次级评估，解决了长周期任务中信用分配的挑战。为了增强探索，我们将混合任务训练课程与数学推理问题相结合。这种统一方法使基于文本的 $\tau$ -bench 上的任务通过率比强大的强化学习基线提高了6%以上。关键的是，我们展示了我们的框架适用于为智能体任务微调多模态基础模型。通过在交错语音-文本推演上训练基础多模态LLM，我们赋予其工具使用能力，为更自然、语音驱动的交互式智能体铺平了道路。|
|**2025-07-10**|[Skywork-R1V3 Technical Report](http://arxiv.org/abs/2507.06167)|null|我们介绍了Skywork-R1V3，这是一款先进的开源视觉语言模型（VLM），它开创了一种新的视觉推理方法。其核心创新在于有效地将纯文本大型语言模型（LLM）的推理能力迁移到视觉任务中。Skywork-R1V3的强大性能主要源于我们精心设计的后训练强化学习（RL）框架，该框架能有效激活并增强模型的推理能力，而无需额外的持续预训练。通过该框架，我们进一步揭示了连接器模块在实现多模态推理模型中鲁棒跨模态对齐方面的基础作用。此外，我们引入了一种独特的推理能力指标——关键推理token的熵，该指标在强化学习训练期间的检查点选择中被证明非常有效。Skywork-R1V3在MMMU数据集上取得了最先进的结果，从64.3%显著提升至76.0%。这一性能与入门级人类能力相当。值得注意的是，我们强化学习驱动的后训练方法使得即使是38B参数的模型也能与顶级的闭源VLM媲美。该实现成功地将数学推理迁移到其他科目相关的推理任务中。我们还包括了对课程学习和强化微调策略的分析，以及对多模态推理的更广泛讨论。Skywork-R1V3代表着多模态推理领域的一个重大飞跃，展示了强化学习作为推动开源VLM能力发展的强大引擎。|
|**2025-07-05**|[A Technical Survey of Reinforcement Learning Techniques for Large Language Models](http://arxiv.org/abs/2507.04136)|null|强化学习 (RL) 已成为一种变革性方法，用于对大型语言模型 (LLM) 进行对齐和增强，解决指令遵循、伦理对齐和推理能力方面的关键挑战。本综述提供了关于 RL 与语言模型集成方面的全面基础，重点介绍了近端策略优化 (PPO)、Q-学习和 Actor-Critic 方法等著名算法。此外，它还提供了专门针对 LLM 的 RL 技术的广泛技术概述，包括来自人类反馈的强化学习 (RLHF) 和来自 AI 反馈的强化学习 (RLAIF) 等基础方法，以及直接偏好优化 (DPO) 和组相对策略优化 (GRPO) 等高级策略。我们系统地分析了它们在各个领域的应用，即从代码生成到工具增强推理。我们还提出了一种基于奖励建模、反馈机制和优化策略的比较分类法。我们的评估突出了主要趋势。RLHF 在对齐方面仍占主导地位，而基于结果的 RL (例如 RLVR) 显著改善了逐步推理能力。然而，奖励欺骗、计算成本和可扩展反馈收集等持续存在的挑战，强调了持续创新的必要性。我们进一步讨论了新兴方向，包括混合 RL 算法、验证器引导训练和多目标对齐框架。本综述为推动 RL 驱动的 LLM 发展的研究人员提供了一份路线图，旨在平衡能力增强与安全性及可扩展性。|
|**2025-07-02**|[Kwai Keye-VL Technical Report](http://arxiv.org/abs/2507.01949)|null|尽管多模态大语言模型（MLLMs）在静态图像上展现出卓越的能力，但在理解动态的、信息密集的短视频方面却常常力有不逮，而短视频正是当今数字领域的主导媒介。为了弥合这一差距，我们引入了Kwai Keye-VL，这是一个拥有80亿参数的多模态基础模型，旨在短视频理解方面达到领先性能，同时保持强大的通用视觉-语言能力。Keye-VL的开发基于两大核心支柱：一个超过6000亿token的海量高质量数据集（尤其侧重于视频），以及一种创新的训练方案。该方案包含一个四阶段的预训练过程以实现稳固的视觉-语言对齐，随后是一个精细的两阶段后训练过程。第一个后训练阶段增强了指令遵循等基础能力，而第二个阶段则侧重于激发高级推理能力。在第二个阶段中，一个关键创新是我们提出的五种模式的“冷启动”数据混合，其中包括“思考”、“不思考”、“自动思考”、“带图像思考”以及高质量视频数据。这种混合数据教会模型何时以及如何进行推理。随后的强化学习（RL）和对齐步骤进一步增强了这些推理能力，并纠正了异常模型行为，例如重复输出。为了验证我们的方法，我们进行了广泛的评估，结果显示Keye-VL在公共视频基准上取得了最先进的成果，并且在通用图像任务上保持了高度竞争力（图1）。此外，我们开发并发布了KC-MMBench，这是一个专为真实世界短视频场景量身定制的新基准，在此基准上，Keye-VL展现出显著优势。|
|**2025-06-15**|[Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models](http://arxiv.org/abs/2506.12822)|null|设计有效的奖励函数仍然是强化学习（RL）中的一个基本挑战，因为它通常需要大量的人力投入和领域专业知识。尽管基于人类反馈的强化学习在使智能体与人类意图对齐方面取得了成功，但获取高质量反馈成本高昂且劳动密集，限制了其可扩展性。基础模型的最新进展提供了一个有前景的替代方案——利用AI生成的反馈来减少奖励学习中对人工监督的依赖。基于这一范式，我们引入了ERL-VLM，这是一种增强的基于评分的强化学习方法，能有效地从AI反馈中学习奖励函数。与依赖成对比较的现有方法不同，ERL-VLM查询大型视觉-语言模型（VLM）以获取单个轨迹的绝对评分，从而实现了更具表达力的反馈并提高了样本效率。此外，我们针对基于评分的强化学习提出了关键的增强，解决了由数据不平衡和噪声标签引起的不稳定性问题。通过涵盖低级和高级控制任务的广泛实验，我们证明ERL-VLM显著优于现有的基于VLM的奖励生成方法。我们的结果展示了AI反馈在以最少的人工干预扩展强化学习方面的潜力，为更自主和高效的奖励学习铺平了道路。|
|**2025-09-19**|[Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward](http://arxiv.org/abs/2506.07218)|**[link](https://github.com/tongxiao2002/Perception-R1)**|增强多模态大语言模型（MLLMs）的多模态推理能力是一项具有挑战性的任务，并已引起社区越来越多的关注。最近，一些研究将基于可验证奖励的强化学习（RLVR）应用于多模态领域，以增强MLLMs的推理能力。然而，这些工作在很大程度上忽视了MLLMs多模态感知能力的提升，而多模态感知能力是复杂多模态推理的核心先决条件和基础组成部分。通过McNemar检验，我们发现现有的RLVR方法未能有效增强MLLMs的多模态感知能力，从而限制了它们在多模态推理方面的进一步提升。为了解决这一局限性，我们提出了Perception-R1，它引入了一种新颖的视觉感知奖励，明确鼓励MLLMs准确感知视觉内容，从而可以有效激励它们的多模态感知和推理能力。具体而言，我们首先从多模态问题的CoT轨迹中收集文本视觉标注，这些标注将作为奖励分配的视觉参考。在RLVR训练过程中，我们使用一个判断型大语言模型来评估视觉标注与MLLM生成的响应之间的一致性，并根据这些一致性判断分配视觉感知奖励。在多个多模态推理基准上进行的大量实验证明了我们的Perception-R1的有效性，它仅使用1,442个训练数据就在大多数基准上实现了最先进的性能。|
|**2025-06-05**|[MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning](http://arxiv.org/abs/2505.24871)|null|可验证奖励强化学习（RLVR）最近已成为后训练大型语言模型（LLM）的强大范式，在需要结构化、可验证答案的任务上取得了最先进的性能。将RLVR应用于多模态大型语言模型（MLLM）带来了重要的机遇，但也因视觉-语言任务更广泛、异构的性质而变得复杂，这些任务需要细致的视觉、逻辑和空间能力。因此，使用RLVR在多个数据集上训练MLLM可能是有益的，但由于不同数据集之间交互产生的目标冲突，也带来了挑战，凸显了对最佳数据集混合策略的需求，以提高泛化能力和推理能力。我们提出了一个系统的多模态LLM RLVR后训练框架，包含严谨的数据混合问题表述和基准实现。具体而言，(1) 我们通过整理一个包含不同可验证视觉-语言问题的数据集，并支持使用不同可验证奖励的多领域在线强化学习，开发了一个用于多数据集后训练的多模态RLVR框架；(2) 我们提出了一种数据混合策略，该策略学习从数据混合分布中预测RL微调结果，并因此优化了最佳混合。综合实验表明，多领域RLVR训练与混合预测策略相结合，可以显著提升MLLM的通用推理能力。我们提出的最佳混合策略将后训练模型在分布外基准测试上的准确性平均提高了5.24%，相较于使用均匀数据混合进行后训练的相同模型，而相较于预微调基线则总共提高了20.74%。|
|**2025-05-21**|[Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models](http://arxiv.org/abs/2504.21277)|null|强化学习（RL）在增强多模态大语言模型（MLLMs）推理能力方面的应用是一个快速发展的研究领域。尽管MLLMs将大语言模型（LLMs）扩展到处理视觉、音频和视频等多种模态，但实现跨多模态输入的鲁棒推理仍然具有挑战性。本文系统综述了MLLMs中基于RL的推理的最新进展，涵盖了关键算法设计、奖励机制创新和实际应用。我们强调了两种主要的RL范式，即无模型值方法和基于模型值方法，并分析了RL如何通过优化推理轨迹和对齐多模态信息来增强推理能力。此外，我们广泛概述了基准数据集、评估协议和当前局限性，并提出了未来的研究方向，以解决稀疏奖励、低效的跨模态推理和实际部署限制等挑战。我们的目标是为基于RL的多模态推理提供一份全面而结构化的指南。|
|**2024-10-30**|[GenRL: Multimodal-foundation world models for generalization in embodied agents](http://arxiv.org/abs/2406.18043)|null|学习能够解决不同领域多种任务的通用具身智能体是一个长期存在的问题。强化学习（RL）难以扩展，因为它需要为每项任务设计复杂的奖励。相比之下，语言能够以更自然的方式指定任务。当前的基础视觉-语言模型（VLM）由于显著的领域鸿沟，通常需要微调或其他适应性修改才能应用于具身环境中。然而，此类领域多模态数据的匮乏阻碍了具身应用基础模型的开发。在这项工作中，我们通过提出多模态基础世界模型克服了这些问题，该模型能够在无需任何语言标注的情况下，连接和对齐基础VLM的表示与用于RL的生成式世界模型的潜在空间。由此产生的智能体学习框架GenRL允许通过视觉和/或语言提示指定任务，将它们根植于具身领域的动态中，并在想象中学习相应的行为。通过在运动和操作领域进行的大型多任务基准测试评估，GenRL实现了基于语言和视觉提示的多任务泛化。此外，通过引入一种无数据策略学习策略，我们的方法为使用生成式世界模型进行基础策略学习奠定了基础。网站、代码和数据：https://mazpie.github.io/genrl/|
|**2024-09-03**|[RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback](http://arxiv.org/abs/2309.00267)|null|基于人类反馈的强化学习 (RLHF) 已被证明能有效使大型语言模型 (LLMs) 与人类偏好对齐，但收集高质量的偏好标签成本高昂。由Bai等人提出的基于AI反馈的强化学习 (RLAIF) 提供了一种有前景的替代方案，它使用现成的LLM生成的偏好来训练奖励模型 (RM)。在摘要、有益对话生成和无害对话生成等任务上，我们表明RLAIF实现了与RLHF相当的性能。此外，我们通过证明RLAIF即使在AI标注器与策略模型大小相同，甚至与初始策略模型是完全相同的检查点时，也能优于监督微调基线，从而向“自我提升”迈进了一步。最后，我们引入了直接RLAIF (d-RLAIF)，这是一种通过在强化学习过程中直接从现成的LLM获取奖励来规避奖励模型训练的技术，它实现了优于传统RLAIF的性能。我们的结果表明，RLAIF能够实现与使用人类反馈相当的性能，为RLHF的可扩展性限制提供了一个潜在的解决方案。|

## 大模型持续学习

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-12-18**|[Compression is Routing: Reconstruction Error as an Intrinsic Signal for Modular Language Models](http://arxiv.org/abs/2512.16963)|null|Current Large Language Models (LLMs) face three major challenges: context length limitations, high inference costs, and catastrophic forgetting during continual learning. While Mixture-of-Experts (MoE) architectures mitigate some of these conflicts, their routing mechanisms typically rely on explicitly trained auxiliary classifiers. This not only increases system complexity but also often lacks interpretability when handling mixed-domain inputs.   Building upon the premise that ``Compression is Intelligence,'' this paper proposes a novel architectural philosophy: \textbf{``Compression is Routing.''} We trained an 87M-parameter end-to-end Transformer Autoencoder, achieving a \textbf{64x sequence length compression} (compressing 512 tokens into 8 latent vectors). Experimental results demonstrate that this compressor possesses extreme domain discriminative capability: it achieves a reconstruction accuracy of \textbf{99.47\%} on the in-domain (code) validation set; accuracy drops sharply to \textbf{47.76\%} on a semi-out-of-distribution domain (Wiki text); and further plummets to just \textbf{0.57\%} on a fully out-of-distribution domain (random sequences).   This extreme and systematic performance discrepancy establishes the validity of reconstruction error as an \textbf{Intrinsic Distribution Fingerprint}. Based on this, we propose that expert modules can be automatically scheduled using reconstruction residuals directly, without the need for explicit gating networks. This mechanism offers excellent scalability. Furthermore, this architecture provides a new perspective on ``VRAM compression'' for handling ultra-long contexts. This report aims to verify the physical validity of this foundational architecture, offering a new research perspective for the next generation of scalable modular neural networks.|
|**2025-12-17**|[Photorealistic Phantom Roads in Real Scenes: Disentangling 3D Hallucinations from Physical Geometry](http://arxiv.org/abs/2512.15423)|null|Monocular depth foundation models achieve remarkable generalization by learning large-scale semantic priors, but this creates a critical vulnerability: they hallucinate illusory 3D structures from geometrically planar but perceptually ambiguous inputs. We term this failure the 3D Mirage. This paper introduces the first end-to-end framework to probe, quantify, and tame this unquantified safety risk. To probe, we present 3D-Mirage, the first benchmark of real-world illusions (e.g., street art) with precise planar-region annotations and context-restricted crops. To quantify, we propose a Laplacian-based evaluation framework with two metrics: the Deviation Composite Score (DCS) for spurious non-planarity and the Confusion Composite Score (CCS) for contextual instability. To tame this failure, we introduce Grounded Self-Distillation, a parameter-efficient strategy that surgically enforces planarity on illusion ROIs while using a frozen teacher to preserve background knowledge, thus avoiding catastrophic forgetting. Our work provides the essential tools to diagnose and mitigate this phenomenon, urging a necessary shift in MDE evaluation from pixel-wise accuracy to structural and contextual robustness. Our code and benchmark will be publicly available to foster this exciting research direction.|
|**2025-12-17**|[CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications](http://arxiv.org/abs/2512.15231)|**[link](https://github.com/Cangling-Agent/cangling-agent.github.io)**|The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--across diverse RS applications. To address this gap, this paper introduces CangLing-KnowFlow, a unified intelligent agent framework that integrates a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and an Evolutionary Memory Module. The PKB, comprising 1,008 expert-validated workflow cases across 162 practical RS tasks, guides planning and substantially reduces hallucinations common in general-purpose agents. During runtime failures, the Dynamic Workflow Adjustment autonomously diagnoses and replans recovery strategies, while the Evolutionary Memory Module continuously learns from these events, iteratively enhancing the agent's knowledge and performance. This synergy enables CangLing-KnowFlow to adapt, learn, and operate reliably across diverse, complex tasks. We evaluated CangLing-KnowFlow on the KnowFlow-Bench, a novel benchmark of 324 workflows inspired by real-world applications, testing its performance across 13 top Large Language Model (LLM) backbones, from open-source to commercial. Across all complex tasks, CangLing-KnowFlow surpassed the Reflexion baseline by at least 4% in Task Success Rate. As the first most comprehensive validation along this emerging field, this research demonstrates the great potential of CangLing-KnowFlow as a robust, efficient, and scalable automated solution for complex EO challenges by leveraging expert knowledge (Knowledge) into adaptive and verifiable procedures (Flow).|
|**2025-12-16**|[RePo: Language Models with Context Re-Positioning](http://arxiv.org/abs/2512.14391)|**[link](https://github.com/SakanaAI/repo)**|In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_φ$ , to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.|
|**2025-12-15**|[MIDUS: Memory-Infused Depth Up-Scaling](http://arxiv.org/abs/2512.13751)|null|Scaling large language models (LLMs) demands approaches that increase capacity without incurring excessive parameter growth or inference cost. Depth Up-Scaling (DUS) has emerged as a promising strategy by duplicating layers and applying Continual Pre-training (CPT), but its reliance on feed-forward networks (FFNs) limits efficiency and attainable gains. We introduce Memory-Infused Depth Up-Scaling (MIDUS), which replaces FFNs in duplicated blocks with a head-wise memory (HML) layer. Motivated by observations that attention heads have distinct roles both across and within layers, MIDUS assigns an independent memory bank to each head, enabling head-wise retrieval and injecting information into subsequent layers while preserving head-wise functional structure. This design combines sparse memory access with head-wise representations and incorporates an efficient per-head value factorization module, thereby relaxing the usual efficiency-performance trade-off. Across our CPT experiments, MIDUS exhibits robust performance improvements over strong DUS baselines while maintaining a highly efficient parameter footprint. Our findings establish MIDUS as a compelling and resource-efficient alternative to conventional FFN replication for depth up-scaling by leveraging its head-wise memory design.|
|**2025-12-15**|[Towards Effective Model Editing for LLM Personalization](http://arxiv.org/abs/2512.13676)|null|Personalization is becoming indispensable for LLMs to align with individual user preferences and needs. Yet current approaches are often computationally expensive, data-intensive, susceptible to catastrophic forgetting, and prone to performance degradation in multi-turn interactions or when handling implicit queries. To address these challenges, we conceptualize personalization as a model editing task and introduce Personalization Editing, a framework that applies localized edits guided by clustered preference representations. This design enables precise preference-aligned updates while preserving overall model capabilities. In addition, existing personalization benchmarks frequently rely on persona-based dialogs between LLMs rather than user-LLM interactions, or focus primarily on stylistic imitation while neglecting information-seeking tasks that require accurate recall of user-specific preferences. We introduce User Preference Question Answering (UPQA), a short-answer QA dataset constructed from in-situ user queries with varying levels of difficulty. Unlike prior benchmarks, UPQA directly evaluates a model's ability to recall and apply specific user preferences. Across experimental settings, Personalization Editing achieves higher editing accuracy and greater computational efficiency than fine-tuning, while outperforming prompting-based baselines in multi-turn conversations and implicit preference questions settings.|
|**2025-12-15**|[Embedding-Based Rankings of Educational Resources based on Learning Outcome Alignment: Benchmarking, Expert Validation, and Learner Performance](http://arxiv.org/abs/2512.13658)|null|As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective automation of evaluating alignment between educational resources and intended learning outcomes. Using human-generated materials, we benchmarked LLM-based text-embedding models and found that the most accurate model (Voyage) achieved 79% accuracy in detecting alignment. We then applied the optimal model to LLM-generated resources and, via expert evaluation, confirmed that it reliably assessed correspondence to intended outcomes (83% accuracy). Finally, in a three-group experiment with 360 learners, higher alignment scores were positively related to greater learning performance, chi-squared(2, N = 360) = 15.39, p < 0.001. These findings show that embedding-based alignment scores can facilitate scalable personalization by confirming alignment with learning outcomes, which allows teachers to focus on tailoring content to diverse learner needs.|
|**2025-12-15**|[Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models](http://arxiv.org/abs/2512.13072)|null|Multimodal biomedical Vision-Language Models (VLMs) exhibit immense potential in the field of Continual Learning (CL). However, they confront a core dilemma: how to preserve fine-grained intra-modality features while bridging the significant domain gap across different modalities. To address this challenge, we propose a comprehensive framework. Leveraging our 18-million multimodal and comprehensive medical retrieval database derived from PubMed scientific papers, we pioneer the integration of Retrieval-Augmented Generation (RAG) into CL. Specifically, we employ a multi-modal, multi-layer RAG system that provides real-time guidance for model fine-tuning through dynamic, on-demand knowledge retrieval. Building upon this, we introduce a dynamic knowledge distillation framework. This framework precisely resolves the aforementioned core dilemma by dynamically modulating the importance of the parameter space, the granularity of the distilled knowledge, and the data distribution of the reference dataset in accordance with the required level of detail. To thoroughly validate the clinical value of our strategy, we have designed a more rigorous \textbf{M}edical Generalist Task Incremental Learning (MGTIL) benchmark. This benchmark is engineered to simultaneously evaluate the model's capacity for adaptation to significant domain shifts, retention of subtle intra-domain features, and real-time learning of novel and complex medical tasks. Extensive experimental results demonstrate that our proposed method achieves state-of-the-art (SOTA) performance across all metrics. The code is provided in the supplementary materials.|
|**2025-12-14**|[A Disproof of Large Language Model Consciousness: The Necessity of Continual Learning for Consciousness](http://arxiv.org/abs/2512.12802)|null|The requirements for a falsifiable and non-trivial theory of consciousness significantly constrain such theories. Specifically, recent research on the Unfolding Argument and the Substitution Argument has given us formal tools to analyze requirements for a theory of consciousness. I show via a new Proximity Argument that these requirements especially constrain the potential consciousness of contemporary Large Language Models (LLMs) because of their proximity to systems that are equivalent to LLMs in terms of input/output function; yet, for these functionally equivalent systems, there cannot be any non-trivial theory of consciousness that judges them conscious. This forms the basis of a disproof of contemporary LLM consciousness. I then show a positive result, which is that theories of consciousness based on (or requiring) continual learning do satisfy the stringent formal constraints for a theory of consciousness in humans. Intriguingly, this work supports a hypothesis: If continual learning is linked to consciousness in humans, the current limitations of LLMs (which do not continually learn) are intimately tied to their lack of consciousness.|
|**2025-12-14**|[D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation](http://arxiv.org/abs/2512.12622)|null|Embodied agents face a critical dilemma that end-to-end models lack interpretability and explicit 3D reasoning, while modular systems ignore cross-component interdependencies and synergies. To bridge this gap, we propose the Dynamic 3D Vision-Language-Planning Model (D3D-VLP). Our model introduces two key innovations: 1) A Dynamic 3D Chain-of-Thought (3D CoT) that unifies planning, grounding, navigation, and question answering within a single 3D-VLM and CoT pipeline; 2) A Synergistic Learning from Fragmented Supervision (SLFS) strategy, which uses a masked autoregressive loss to learn from massive and partially-annotated hybrid data. This allows different CoT components to mutually reinforce and implicitly supervise each other. To this end, we construct a large-scale dataset with 10M hybrid samples from 5K real scans and 20K synthetic scenes that are compatible with online learning methods such as RL and DAgger. Our D3D-VLP achieves state-of-the-art results on multiple benchmarks, including Vision-and-Language Navigation (R2R-CE, REVERIE-CE, NavRAG-CE), Object-goal Navigation (HM3D-OVON), and Task-oriented Sequential Grounding and Navigation (SG3D). Real-world mobile manipulation experiments further validate the effectiveness.|
|**2025-12-13**|[The Data Efficiency Frontier of Financial Foundation Models: Scaling Laws from Continued Pretraining](http://arxiv.org/abs/2512.12384)|null|Domain-adaptive pretraining (DAPT) offers a practical path to specializing large language models for high-value domains without full retraining. We conduct an early-stage scaling-law analysis of continued pretraining on U.S. SEC filings, training 1B and 3B-parameter Llama-3.2 models on a 400M-token financial corpus with validation checkpoints at 50M, 100M, 200M, and 400M tokens. Results show consistent improvements in SEC-domain validation loss for both models, with the largest gains occurring within the first 200M tokens and diminishing returns thereafter. Power-law fits reveal shallow exponents, indicating that financial language is highly regular and efficiently learnable under continued pretraining. General-domain validation loss remains effectively unchanged across all token budgets, suggesting minimal drift and no signs of catastrophic forgetting. A data-efficiency frontier further shows that both models move toward improved specialization with negligible mixed-domain degradation. Together, these findings provide early empirical guidance for scaling financial foundation models, suggesting that meaningful domain adaptation can be achieved with comparatively modest token budgets and that larger model scales (7B-70B) remain tractable under projected data requirements.|
|**2025-12-12**|[Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning](http://arxiv.org/abs/2512.11485)|null|Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base of abstracted error patterns. Unlike prior instance/single-trajectory memory methods, MNL uses batch-wise error abstraction: it extracts generalizable guidance from multiple failures, stores insights in a dynamic notebook, and retains only baseline-outperforming guidance via hold-out validation (ensuring monotonic improvement). We show MNL nearly matches Supervised Fine-Tuning (93.9% vs 94.3% on GSM8K) and outperforms training-free alternatives on GSM8K, Spider, AIME, and KaggleDBQA. On KaggleDBQA (Qwen3-8B), MNL hits 28% accuracy (47% relative gain), outperforming Memento (15.1%) and Training-Free GRPO (22.1) - proving it's a strong training-free alternative for complex reasoning.|
|**2025-12-12**|[Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy](http://arxiv.org/abs/2512.11218)|null|The pursuit of out-of-distribution generalization in Vision-Language-Action (VLA) models is often hindered by catastrophic forgetting of the Vision-Language Model (VLM) backbone during fine-tuning. While co-training with external reasoning data helps, it requires experienced tuning and data-related overhead. Beyond such external dependencies, we identify an intrinsic cause within VLA datasets: modality imbalance, where language diversity is much lower than visual and action diversity. This imbalance biases the model toward visual shortcuts and language forgetting. To address this, we introduce BayesVLA, a Bayesian factorization that decomposes the policy into a visual-action prior, supporting seeing-to-act, and a language-conditioned likelihood, enabling prompt-to-specify. This inherently preserves generalization and promotes instruction following. We further incorporate pre- and post-contact phases to better leverage pre-trained foundation models. Information-theoretic analysis formally validates our effectiveness in mitigating shortcut learning. Extensive experiments show superior generalization to unseen instructions, objects, and environments compared to existing methods. Project page is available at: https://xukechun.github.io/papers/BayesVLA.|
|**2025-12-11**|[Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution](http://arxiv.org/abs/2512.10696)|null|Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\textbf{ReMe}$ ($\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\texttt{reme.library}$ dataset to facilitate further research.|
|**2025-12-11**|[Multi-Objective Reward and Preference Optimization: Theory and Algorithms](http://arxiv.org/abs/2512.10601)|null|This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.|
|**2025-12-11**|[XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs](http://arxiv.org/abs/2512.10545)|null|Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.|
|**2025-12-10**|[Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning](http://arxiv.org/abs/2512.10150)|null|The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.|
|**2025-12-10**|[Representation Calibration and Uncertainty Guidance for Class-Incremental Learning based on Vision Language Model](http://arxiv.org/abs/2512.09441)|null|Class-incremental learning requires a learning system to continually learn knowledge of new classes and meanwhile try to preserve previously learned knowledge of old classes. As current state-of-the-art methods based on Vision-Language Models (VLMs) still suffer from the issue of differentiating classes across learning tasks. Here a novel VLM-based continual learning framework for image classification is proposed. In this framework, task-specific adapters are added to the pre-trained and frozen image encoder to learn new knowledge, and a novel cross-task representation calibration strategy based on a mixture of light-weight projectors is used to help better separate all learned classes in a unified feature space, alleviating class confusion across tasks. In addition, a novel inference strategy guided by prediction uncertainty is developed to more accurately select the most appropriate image feature for class prediction. Extensive experiments on multiple datasets under various settings demonstrate the superior performance of our method compared to existing ones.|
|**2025-12-09**|[Prompt-Based Continual Compositional Zero-Shot Learning](http://arxiv.org/abs/2512.09172)|null|We tackle continual adaptation of vision-language models to new attributes, objects, and their compositions in Compositional Zero-Shot Learning (CZSL), while preventing forgetting of prior knowledge. Unlike classical continual learning where classes are disjoint, CCZSL is more complex as attributes and objects may reoccur across sessions while compositions remain unique. Built on a frozen VLM backbone, we propose the first Prompt-based Continual Compositional Zero-Shot Learning (PromptCCZSL) framework that retains prior knowledge through recency-weighted multi-teacher distillation. It employs session-aware compositional prompts to fuse multimodal features for new compositions, while attribute and object prompts are learned through session-agnostic fusion to maintain global semantic consistency, which is further stabilized by a Cosine Anchor Loss (CAL) to preserve prior knowledge. To enhance adaptation in the current session, an Orthogonal Projection Loss (OPL) ensures that new attribute and object embeddings remain distinct from previous ones, preventing overlap, while an Intra-Session Diversity Loss (IDL) promotes variation among current-session embeddings for richer, more discriminative representations. We also introduce a comprehensive protocol that jointly measures catastrophic forgetting and compositional generalization. Extensive experiments on UT-Zappos and C-GQA benchmarks demonstrate that PromptCCZSL achieves substantial improvements over prior VLM-based and non-VLM baselines, setting a new benchmark for CCZSL in closed-world settings.|
|**2025-12-09**|[rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection](http://arxiv.org/abs/2512.08300)|null|Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Language Models (RLMs), where the hallmark of this advanced reasoning is ``aha'' moments when they start to perform strategies, such as self-reflection and deep thinking, within chain of thoughts (CoTs). Motivated by this, this paper proposes a novel reinforced strategy injection mechanism (rSIM), that enables any LLM to become an RLM by employing a small planner to guide the LLM's CoT through the adaptive injection of reasoning strategies. To achieve this, the planner (leader agent) is jointly trained with an LLM (follower agent) using multi-agent RL (MARL), based on a leader-follower framework and straightforward rule-based rewards. Experimental results show that rSIM enables Qwen2.5-0.5B to become an RLM and significantly outperform Qwen2.5-14B. Moreover, the planner is generalizable: it only needs to be trained once and can be applied as a plug-in to substantially improve the reasoning capabilities of existing LLMs. In addition, the planner supports continual learning across various tasks, allowing its planning abilities to gradually improve and generalize to a wider range of problems.|
|**2025-12-08**|[Investigating Training and Generalization in Faithful Self-Explanations of Large Language Models](http://arxiv.org/abs/2512.07288)|null|Large language models have the potential to generate explanations for their own predictions in a variety of styles based on user instructions. Recent research has examined whether these self-explanations faithfully reflect the models' actual behavior and has found that they often lack faithfulness. However, the question of how to improve faithfulness remains underexplored. Moreover, because different explanation styles have superficially distinct characteristics, it is unclear whether improvements observed in one style also arise when using other styles. This study analyzes the effects of training for faithful self-explanations and the extent to which these effects generalize, using three classification tasks and three explanation styles. We construct one-word constrained explanations that are likely to be faithful using a feature attribution method, and use these pseudo-faithful self-explanations for continual learning on instruction-tuned models. Our experiments demonstrate that training can improve self-explanation faithfulness across all classification tasks and explanation styles, and that these improvements also show signs of generalization to the multi-word settings and to unseen tasks. Furthermore, we find consistent cross-style generalization among three styles, suggesting that training may contribute to a broader improvement in faithful self-explanation ability.|
|**2025-12-04**|[STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models](http://arxiv.org/abs/2512.05107)|null|在大型语言模型和基于强化学习的微调推动下，视觉-语言-动作（VLA）模型的最新进展在机器人操作方面取得了显著进步。现有方法通常将长时序动作视为语言序列，并应用轨迹级别优化方法，如轨迹级偏好优化（TPO）或近端策略优化（PPO），但这会导致粗粒度的信用分配和不稳定的训练。然而，与语言不同，语言中统一的语义意义在灵活的句子顺序中得以保留，而动作轨迹通过具有不同学习难度的因果链式阶段进展。这促使了渐进式阶段优化。为此，我们提出了阶段感知强化（STARE），一个将长时序动作轨迹分解为语义有意义的阶段，并提供密集、可解释且与阶段对齐的强化信号的模块。将STARE集成到TPO和PPO中，我们分别得到了用于离线阶段式偏好的阶段感知TPO（STA-TPO）和用于在线阶段内交互的阶段感知PPO（STA-PPO）。进一步基于有监督微调作为初始化，我们提出了模仿 -> 偏好 -> 交互（IPI），一个用于提高VLA模型动作准确性的串行微调流程。在SimplerEnv和ManiSkill3上的实验证明了显著的提升，在SimplerEnv上达到了98.0%的最先进成功率，在ManiSkill3任务上达到了96.4%的最先进成功率。|
|**2025-12-04**|[Model-Free Assessment of Simulator Fidelity via Quantile Curves](http://arxiv.org/abs/2512.05024)|null|复杂系统仿真最初应用于制造业和排队论。如今，它广泛应用于研究、教育和消费者调查中的大规模机器学习系统。然而，对于日益复杂的机器学习系统，量化仿真器与真实情况之间的差异仍然具有挑战性。我们提出了一种计算上可行的方法来估计模拟结果分布与真实结果分布之间差异的分位数函数。我们的方法侧重于输出不确定性，并将仿真器视为黑盒，对其内部不施加任何建模假设，因此广泛适用于从伯努利和多项式模型到连续向量值设置等多种参数族。得到的这一分位数曲线支持对未见场景的置信区间构建、对仿真与真实差异的风险感知摘要（例如，VaR/CVaR）以及仿真器性能的比较。我们在一个应用中展示了我们的方法，该应用评估了WorldValueBench数据集上涵盖四个大型语言模型的LLM仿真保真度。|
|**2025-12-04**|[Environment-Aware Channel Inference via Cross-Modal Flow: From Multimodal Sensing to Wireless Channels](http://arxiv.org/abs/2512.04966)|null|准确的信道状态信息（CSI）是可靠高效无线通信的基础。然而，通过导频估计获取CSI会产生大量开销，尤其是在高多普勒环境下运行的大规模多输入多输出（MIMO）系统中。通过利用日益增长的环境感知数据，本文研究了无导频信道推断，该方法直接从多模态观测数据中估计完整的CSI，这些观测数据包括相机图像、激光雷达点云和GPS坐标。与依赖预定义信道模型的现有研究不同，我们开发了一种数据驱动的框架，将感知到信道的映射公式化为一个跨模态流匹配问题。该框架将多模态特征融合到信道域中的潜在分布，并学习一个速度场，该速度场持续地将潜在分布转换为信道分布。为了使这种公式化具有可操作性和高效性，我们将问题重新公式化为一个等价的条件流匹配目标并引入模态对齐损失，同时采用低延迟推理机制以实现实时CSI估计。在实验中，我们基于Sionna和Blender构建了一个程序化数据生成器，以支持感知场景和无线传播的真实建模。系统级评估表明，相比基于导频和基于感知的基准，我们的方法在信道估计精度和下游波束成形任务的频谱效率方面均有显著提升。|
|**2025-12-04**|[SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs](http://arxiv.org/abs/2512.04868)|null|基于知识的对话式问答（KBCQA）在指代消解、上下文依赖建模和复杂逻辑推理执行方面面临持续挑战。现有方法，无论是端到端语义解析还是逐步的基于代理的推理，常常存在结构不准确性和过高的计算成本，尤其是在处理大型知识图谱上的复杂查询时。为解决这些局限性，我们引入了SEAL，一种新颖的两阶段语义解析框架，其基于自演化代理学习。在第一阶段，大型语言模型（LLM）提取一个最小的S-表达式核心，捕捉输入查询的基本语义。该核心随后由一个代理校准模块进行精炼，该模块纠正语法不一致性并将实体和关系精确地与底层知识图谱对齐。第二阶段采用基于模板的补全，在问题类型预测和占位符实例化指导下，构建一个完全可执行的S-表达式。这种分解不仅简化了逻辑形式生成，而且显著提升了结构保真度和链接效率。关键在于，SEAL整合了一个自演化机制，该机制将局部和全局记忆与一个反思模块相结合，使得能够根据对话历史和执行反馈进行持续适应，而无需显式地重新训练。在SPICE基准测试上进行的大量实验表明，SEAL达到了最先进的性能，尤其是在多跳推理、比较和聚合任务中。结果验证了在结构准确性和计算效率方面的显著提升，突显了该框架在鲁棒且可扩展的对话推理方面的能力。|
|**2025-12-04**|[Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates](http://arxiv.org/abs/2512.04844)|**[link](https://github.com/gucci-j/ssu)**|Expanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce Source-Shielded Updates (SSU), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.3% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.|
|**2025-12-04**|[SIMA 2: A Generalist Embodied Agent for Virtual Worlds](http://arxiv.org/abs/2512.04797)|null|我们介绍了SIMA 2，一个通用具身智能体，能够在各种3D虚拟世界中理解并行动。SIMA 2基于Gemini基础模型构建，代表着迈向具身环境中主动的、目标导向的交互的重要一步。与以往仅限于简单语言指令的工作（例如SIMA 1）不同，SIMA 2作为一个交互式伙伴，能够对高层目标进行推理，与用户进行对话，并处理通过语言和图像给出的复杂指令。在多样化的游戏组合中，SIMA 2大幅缩小了与人类表现的差距，并展示了对先前未见环境的鲁棒泛化能力，同时保留了基础模型的核心推理能力。此外，我们展示了其开放式自我提升的能力：通过利用Gemini生成任务并提供奖励，SIMA 2能够在新环境中从零开始自主学习新技能。这项工作验证了迈向创建适用于虚拟世界以及最终的物理世界的多功能且持续学习的智能体的一条路径。|
|**2025-12-04**|[EtCon: Edit-then-Consolidate for Reliable Knowledge Editing](http://arxiv.org/abs/2512.04753)|null|知识编辑旨在无需完全重新训练的情况下更新大语言模型（LLMs）中的特定事实。以往的研究尝试调整LLMs的知识层，这被证明对进行选择性编辑是有效的。然而，在受控的、教师引导式评估中的表现与在终身学习场景中的真实世界有效性之间存在显著差距，这极大地限制了它们的实际应用性。本工作的经验分析揭示了与这一差距相关的两个普遍存在的问题：(1) 大多数传统方法导致编辑后的模型对新事实过拟合，从而损害预训练能力；(2) 关键性地缺失知识巩固阶段，使得新事实在自回归生成下未能充分融入LLMs的推理时行为，从而导致参数化知识与实际生成行为之间的不匹配。为此，我们提出了“先编辑后巩固”（Edit-then-Consolidate），这是一种新颖的知识编辑范式，旨在弥合理论知识编辑方法与其实际应用性之间的差距。具体而言，(1) 我们的框架通过目标近端监督微调（TPSFT）来缓解过拟合，该方法通过信赖域目标来定位编辑以限制策略漂移；(2) 随后，利用组相对策略优化（GRPO）的巩固阶段通过在全面奖励信号下优化轨迹级行为，将编辑后的知识与基于CoT的推理策略对齐。大量实验表明，我们的框架在真实世界评估中持续提升了编辑可靠性和泛化能力，同时更好地保持了局部性和预训练能力。|
|**2025-12-04**|[POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?](http://arxiv.org/abs/2512.04702)|null|现代软件生态系统日益增长的规模、复杂性、互联性和自主性引入了前所未有的不确定性，挑战了传统自适应的基础。现有方法，通常是规则驱动的控制器或孤立的学习组件，难以泛化到新颖上下文或在分布式子系统之间协调响应，使得它们无法有效应对突发的未知未知情况。最近关于自适应2.0的讨论强调人工智能与自适应系统之间的平等伙伴关系，将学习驱动的智能与自适应控制相结合，以实现预测性和主动性行为。在此基础上，我们引入POLARIS，一个三层多智能体自适应框架，超越了反应式自适应。POLARIS集成了：(1) 一个用于监控和安全执行的低延迟适配器层，(2) 一个透明的推理层，利用具工具感知能力的可解释智能体生成并验证计划，以及(3) 一个元层，用于记录经验并随时间推移元学习改进的自适应策略。通过共享知识和预测模型，POLARIS处理不确定性，从过去的行动中学习，并演进其策略，从而使系统能够预测变化并保持弹性、目标导向的行为。对两个自适应范例SWIM和SWITCH的初步评估表明，POLARIS始终优于最先进的基线。我们认为这标志着向自适应3.0的转变，类似于软件3.0：一种系统不仅从环境中学习，而且还能对其自身的自适应过程进行推理和演进的范式，持续改进以应对新颖挑战。|
|**2025-12-04**|[ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning](http://arxiv.org/abs/2512.04555)|null|我们提出了ADAPT，一种元学习算法，能够在明确的token预算下学习多任务指令微调的任务采样比例。ADAPT并非手动固定任务权重，而是维护一个连续的任务分布，并根据一个平滑的最坏情况验证目标的元梯度对其进行更新，从而生成一个自适应课程，将更多token分配给有用的任务，同时避免模型崩溃。我们在三个约10亿参数的开源大型语言模型（Gemma-3-1B、LLaMA-3.2-1B、Qwen-0.6B）上实例化了ADAPT，在20种自然指令任务类型上进行训练，使用的预算分别为可用监督token的1%、5%和10%，并与采用均匀混合和按比例混合的强大监督微调基线进行了比较。我们在11个涵盖推理、阅读理解、代码生成和指令遵循的域外基准上进行了评估，发现ADAPT的平均下游性能与最佳静态混合方式相比持平或略有提升，同时使用了更少的有效训练token，并将预算重新分配给更困难、与基准对齐的任务。|
|**2025-12-04**|[VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management](http://arxiv.org/abs/2512.04540)|null|超长视频理解仍然是一个悬而未决的挑战，因为现有的视觉语言模型(VLM)由于有限的上下文长度和低效的长期记忆保留而难以处理此类内容。为解决此问题，近期工作尝试构建外部知识库及相应的检索增强生成(RAG)系统，但这会产生巨大的存储和计算开销。在本文中，我们提出了VideoMem，一个通过自适应内存管理，首次将长视频理解建模为序列生成任务的新颖框架。具体来说，VideoMem动态更新一个全局内存缓冲区，该缓冲区在整个视频时间轴上自适应地保留关键信息并丢弃冗余内容。为了高效地训练VLM处理此类长期任务，VideoMem集成了渐进式分组相对策略优化(PRPO)算法，该算法配备了两个核心模块：渐进式状态传播(PSP)自适应地保留有效的当前状态，将其传播到下一个推出步骤，并逐步缩小模型探索空间。时序级联奖励(TCR)进一步缓解奖励稀疏性，提高样本利用率并加速收敛。大量实验表明，VideoMem在超长视频理解任务的各种基准测试中显著优于现有开源模型。|
|**2025-12-02**|[BOOM: Beyond Only One Modality KIT's Multimodal Multilingual Lecture Companion](http://arxiv.org/abs/2512.02817)|null|教育全球化和在线学习的快速增长使得教育内容本地化成为一个严峻的挑战。讲座材料本质上是多模态的，结合了口语音频和视觉幻灯片，这需要能够处理多种输入模态的系统。为了提供无障碍且完整的学习体验，翻译必须保留所有模态：用于阅读的文本、用于视觉理解的幻灯片和用于听觉学习的语音。我们提出了BOOM，一个多模态多语言讲座伴侣，它联合翻译讲座音频和幻灯片，以在三种模态下生成同步输出：翻译文本、保留视觉元素的本地化幻灯片和合成语音。这种端到端方法使学生能够以他们的母语访问讲座，同时旨在完整地保留原始内容。我们的实验表明，幻灯片感知转录文本也为摘要和问答等下游任务带来了连锁效益。我们在https://github.com/saikoneru/image-translator发布了我们的幻灯片翻译代码，并将其集成到https://gitlab.kit.edu/kit/isl-ai4lt/lt-middleware/ltpipeline的讲座翻译器中（所有发布的Hadoop代码和模型均采用MIT许可证授权）。|
|**2025-12-02**|[RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning](http://arxiv.org/abs/2512.02729)|null|我们引入了Robowheel，一个数据引擎，能够将人手与物体交互（HOI）视频转换成可用于跨形态机器人学习的训练就绪监督信号。从单目RGB或RGB-D输入中，我们执行高精度HOI重建，并通过一个强化学习（RL）优化器强制实现物理合理性，该优化器在接触和穿透约束下细化手与物体的相对姿态。重建的、富含接触信息的轨迹随后被重定向到跨形态的机器人，包括带有简单末端执行器的机械臂、灵巧手和人形机器人，从而产生可执行的动作和执行轨迹。为了扩大覆盖范围，我们在Isaac Sim上构建了一个模拟增强框架，具有多样化的领域随机化（形态、轨迹、物体检索、背景纹理、手部动作镜像），这丰富了轨迹和观测的分布，同时保留了空间关系和物理合理性。整个数据管道形成了一个从视频、重建、重定向到增强数据采集的端到端流程。我们在主流的视觉语言动作（VLA）和模仿学习架构上验证了这些数据，证明了我们管道生成的轨迹与通过远程操作生成的轨迹一样稳定，并产生了可比的持续性能提升。据我们所知，这提供了第一个量化证据，表明HOI模态可以作为机器人学习的有效监督信号。与远程操作相比，Robowheel是轻量级的，单个单目RGB(D)相机足以提取一种通用的、与形态无关的运动表示，可以灵活地重定向到不同形态的机器人。我们进一步构建了一个大规模多模态数据集，结合了多相机捕获、单目视频和公共HOI语料库，用于训练和评估具身模型。|
|**2025-12-02**|[SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction](http://arxiv.org/abs/2512.02609)|null|机器人抓取中的模仿学习常受到多模态问题的困扰：当场景中包含多个有效目标时，抓取不同对象的示范会产生冲突的训练信号。标准模仿学习策略通过将这些不同的动作平均为一个单一的、无效的动作而失败。在本文中，我们引入了SAM2Grasp，一个新颖的框架，通过将任务重新表述为单模态、提示条件预测问题来解决这个问题。我们的方法利用冻结的SAM2模型来使用其强大的视觉时间跟踪能力，并引入了一个轻量级、可训练的动作头，该动作头与其原生分割头并行运行。这种设计允许仅在SAM2预计算的时间-视觉特征上训练小型动作头。在推理过程中，一个初始提示（例如由上游目标检测模型提供的边界框）指定要抓取的特定对象。这个提示使动作头能够预测仅针对该对象的独特、明确的抓取轨迹。在所有后续视频帧中，SAM2内置的时间跟踪能力自动保持对所选对象的稳定跟踪，使我们的模型能够从视频流中持续预测抓取轨迹，而无需进一步的外部引导。这种时间提示方法有效地消除了视觉运动策略中的模糊性。我们通过广泛的实验证明，SAM2Grasp在杂乱多目标抓取任务中实现了最先进的性能。|
|**2025-12-02**|[GoRL: An Algorithm-Agnostic Framework for Online Reinforcement Learning with Generative Policies](http://arxiv.org/abs/2512.02581)|null|强化学习（RL）面临一个长期存在的矛盾：优化稳定的策略通常过于简单，无法表示复杂控制所需的多模态动作分布。高斯策略提供了可处理的似然和平滑的梯度，但其单峰形式限制了表达能力。相反，基于扩散或流匹配的生成式策略可以建模丰富的多模态行为；然而，在在线强化学习中，由于难以处理的似然和通过深度采样链传播的噪声梯度，它们经常不稳定。我们通过一个关键的结构原则解决了这一矛盾：将优化与生成解耦。基于这一见解，我们引入了GoRL（生成式在线强化学习），一个通过优化可处理的潜在策略并利用条件生成解码器合成动作的框架。双时间尺度更新策略使潜在策略能够稳定学习，同时解码器稳步提高表达能力，而无需可处理的动作似然。在一系列连续控制任务中，GoRL持续优于高斯策略和近期生成式策略基线。值得注意的是，在HopperStand任务上，它达到了超过870的归一化回报，是最强基线的3倍以上。这些结果表明，将优化与生成分离为实现既稳定又具有高度表达能力的策略提供了一条实用途径。|
|**2025-12-02**|[EZYer: A simulacrum of high school with generative agent](http://arxiv.org/abs/2512.02561)|null|随着在线教育和大语言模型的快速发展，现有教育工具在课件生成、交互式笔记和内容质量保证方面仍面临服务不完善、性能不足和交互性弱等挑战。为此，本文提出了生成式智能体EZYer：1）教师模块：整合了文本语料检索和深度生成技术，它能自动生成符合高中数学教学大纲的结构化教学材料和LaTeX Beamer课件，并支持用户自定义图片插入。2）学生模块：通过教师、助教、优等生和学困生四种角色的协作互动，笔记记录者总结并生成学习笔记，以增强学习的深度和趣味性。3）控制器：设置了关键词过滤系统、内容评分系统、角色协同验证系统和动态内容纠正系统，这确保了EZYer输入和输出的学术严谨性和教学适宜性。为了评估EZYer，本文设计了内容准确性、知识覆盖度、可用性、格式正确性和视觉设计与吸引力五维评估指标，并分别由五个大语言模型对EZYer生成的100份Beamer课件和笔记进行了评分，结果表明EZYer生成内容的质量优异，具有良好的应用前景。|
|**2025-12-02**|[WeMMU: Enhanced Bridging of Vision-Language Models and Diffusion Models via Noisy Query Tokens](http://arxiv.org/abs/2512.02536)|null|多模态大语言模型（MLLMs）的最新进展凸显了如何高效地将预训练视觉-语言模型（VLMs）与扩散模型连接起来的挑战。尽管使用固定数量可学习查询标记的方法提供了计算效率，但它们面临任务泛化崩溃的问题，难以适应与其预训练任务相距甚远的新任务。为了克服这一问题，我们提出了噪声查询标记（Noisy Query Tokens），通过端到端优化在VLM和扩散模型之间学习一个分布式表示空间，从而增强持续学习能力。此外，我们引入了一个带有线性投影的VAE分支，以恢复细粒度图像细节。实验结果证实，我们的方法缓解了泛化崩溃，并在各种任务上实现了稳定的持续学习。|
|**2025-12-02**|[VACoT: Rethinking Visual Data Augmentation with VLMs](http://arxiv.org/abs/2512.02361)|null|尽管视觉数据增强仍然是训练鲁棒视觉模型的基石，但在视觉语言模型（VLM）中受到的关注有限，VLM主要依赖于大规模真实数据采集或合成多样性。因此，它们可能难以处理传统模型能够可靠应对的基本感知任务。考虑到VLM预训练和微调的巨大成本，在增强数据上继续训练会带来有限且递减的收益。在本文中，我们提出了视觉增强思维链（VACoT），这是一个在模型推理期间动态调用图像增强的框架。通过结合去噪等后验变换，VACoT显著提高了在具有挑战性和分布外输入上的鲁棒性，尤其是在OCR相关的对抗性场景中。与仅限于局部裁剪的现有方法不同，VACoT整合了一系列结构化的通用视觉增强，通过高效的智能体强化学习拓宽了查询图像的视角，同时减少了训练复杂性和计算开销。我们提出了一种条件奖励机制，鼓励必要的增强，同时惩罚冗余响应，从而确保感知任务中推理的简洁性和有效性。我们通过在13个感知基准上进行的大量实验证明了VACoT的优越性，并进一步引入AdvOCR以突出后验视觉增强在对抗性场景中的泛化优势。|
|**2025-12-02**|[Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games](http://arxiv.org/abs/2512.02358)|null|优化数值系统和机制设计对于增强大型多人在线（MMO）游戏中的玩家体验至关重要。传统的优化方法依赖于大规模在线实验或基于预定义统计模型的参数调优，这些方法成本高昂、耗时，并可能扰乱玩家体验。尽管简化的离线模拟系统常被用作替代方案，但其有限的保真度阻碍了智能体准确模仿真实玩家的推理过程和对干预的反应。为解决这些局限性，我们提出了一种由大型语言模型（LLMs）驱动的基于生成式智能体的MMO模拟系统。通过对大规模真实玩家行为数据应用有监督微调（SFT）和强化学习（RL），我们将LLMs从通用先验知识适应到游戏特定领域，从而实现真实且可解释的玩家决策。与此同时，一个基于真实游戏日志训练的数据驱动环境模型重构了动态的游戏内系统。实验结果表明，该系统与真实世界玩家行为高度一致，并在干预下产生了合理的因果响应，为数据驱动的数值设计优化提供了一个可靠、可解释且经济高效的框架。|
|**2025-12-01**|[Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence](http://arxiv.org/abs/2512.02280)|null|人工智能在感知、语言、推理和多模态等领域取得了快速发展。然而，尽管取得了这些成就，现代人工智能系统在动态环境中自主监控、自我纠正和行为自律的能力方面仍然受到根本限制。本文识别并分析了限制当代人工智能模型的七个核心缺陷：缺乏内在的自我监控、缺乏元认知意识、固定且非自适应的学习机制、无法重构目标、缺乏表征维护、不足的具身反馈以及缺乏内在能动性。在识别这些局限性的同时，我们还概述了一个前瞻性的视角，探讨人工智能如何能够通过模仿神经认知原理的架构来超越它们。我们认为，这些结构性限制阻碍了当前架构（包括深度学习和基于Transformer的系统）实现鲁棒泛化、终身适应性和现实世界自主性。借鉴人工系统与生物认知[7]的比较分析，并整合了人工智能研究、认知科学和神经科学的见解，我们概述了当前模型中为何缺乏这些能力，以及为何单纯的规模扩展无法解决它们。我们最后倡导一场范式转变，转向以认知为基础的人工智能（认知自主性），它能够实现自主适应、动态表征管理和有意的、目标导向的行为，并辅以改革性的监督机制[8]，以确保自主系统保持可解释性、可治理性并与人类价值观保持一致。|
|**2025-12-01**|[Lightweight Latent Reasoning for Narrative Tasks](http://arxiv.org/abs/2512.02240)|null|大语言模型（LLMs）通过生成长串的思维链或“推理轨迹”来处理复杂任务，这些轨迹在给定查询生成输出时充当潜在变量。模型生成此类轨迹的能力可以通过强化学习（RL）进行优化，以提高它们在预测答案方面的效用。这种优化伴随着高昂的计算成本，尤其是对于涉及检索和处理大量tokens的叙事相关任务。为此，我们提出了LiteReason，这是一种潜在推理方法，可以与标准token采样交织使用，并且可以轻松地与RL技术结合。LiteReason采用一个轻量级的推理投影器模块，该模块经过训练以生成连续的潜在tokens，帮助模型“跳过”推理步骤。在强化学习过程中，策略模型决定何时激活投影器，根据需要切换潜在推理和离散推理。在情节漏洞检测和书籍章节生成任务上的实验结果表明，我们的方法优于潜在推理基线，并且接近非潜在强化学习训练的性能，同时将最终推理长度减少了77-92%。总之，LiteReason将强化学习训练引导至性能-计算权衡曲线中更高效的部分。|
|**2025-11-28**|[ThetaEvolve: Test-time Learning on Open Problems](http://arxiv.org/abs/2511.23473)|**[link](https://github.com/ypwang61/ThetaEvolve)**|大语言模型 (LLMs) 的最新进展使得数学发现取得了突破，例如AlphaEvolve，这是一个闭源系统，它通过演化程序来改进开放问题的边界。然而，它依赖于前沿LLM集成来实现新的边界，并且是一个纯推理系统，模型无法内化其演化策略。我们引入了ThetaEvolve，这是一个开源框架，它简化并扩展了AlphaEvolve，以在测试时有效地扩展上下文学习和强化学习 (RL)，从而使模型能够从改进开放优化问题的经验中持续学习。ThetaEvolve具有单一LLM、用于增强探索的大型程序数据库、用于更高吞吐量的批量采样、用于阻止停滞输出的惰性惩罚以及用于稳定训练信号的可选奖励塑形等特点。ThetaEvolve是第一个能够使小型开源模型（如DeepSeek-R1-0528-Qwen3-8B）在AlphaEvolve中提及的开放问题（圆堆积和第一自相关不等式）上达到新的最佳已知边界的演化框架。此外，在两个模型和四个开放任务中，我们发现带有测试时RL的ThetaEvolve持续优于仅推理基线，并且模型确实学习了演化能力，因为经过RL训练的检查点在已训练的目标任务和其他未见过的任务上都展现出更快的进展和更好的最终性能。我们公开了代码：https://github.com/ypwang61/ThetaEvolve|
|**2025-11-28**|[Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent](http://arxiv.org/abs/2511.23436)|null|我们引入了SuperIntelliAgent，一个智能体学习框架，它将一个可训练的小型扩散模型（学习器）与一个冻结的大型语言模型（验证器）相结合，以通过自监督交互实现持续的智能增长。与传统的监督微调不同，SuperIntelliAgent无需标注即可自主学习：学习器生成候选输出，验证器通过逐步推理评估这些输出，它们的交互产生用于直接偏好优化（DPO）的选定/拒绝对。这将每个输入转换为一个用于持续改进的伪训练信号。该框架集成了双尺度记忆：短期语境记忆，用于在细化周期中保留推理轨迹；以及通过轻量级即时微调来巩固所获取知识的长期记忆。一个重放缓冲区保留显示可验证进度的样本，并将其作为辅助监督进行重放，在形成自适应课程的同时强化近期学习。SuperIntelliAgent不依赖于特定基础设施，并且可以插入到现有的智能体框架中，同时将普通的推理循环转变为一个终身优化过程。我们认为，将可训练的学习器与具备推理能力的验证器配对，构成了不断增长的智能的最小可靠单元，因为配对反馈和部分历史重放能够产生更丰富的学习课程和更强的偏好对齐。仅使用少量自动生成的DPO对，学习器在所有基准测试中均有所改进，这表明该机制为持续智能积累和实际部署提供了一个有前景的方向。|
|**2025-11-28**|[VQRAE: Representation Quantization Autoencoders for Multimodal Understanding, Generation and Reconstruction](http://arxiv.org/abs/2511.23386)|null|在构建统一模型时，在单个分词器中统一多模态理解、生成和重建表示仍然是一个关键挑战。先前的研究主要尝试在双编码器范式中解决这个问题，例如，分别利用独立的编码器进行理解和生成，或通过对比损失平衡语义表示和低级特征。在本文中，我们提出了VQRAE，一种表示自编码器的矢量量化版本，它首次探索了统一表示，以在统一分词器内为图像理解生成连续语义特征，并为视觉生成生成离散令牌。具体而言，我们基于带有对称ViT解码器的预训练视觉基础模型，并采用两阶段训练策略：首先，它冻结编码器，并利用像素重建目标学习一个高维语义VQ码本；然后，通过自蒸馏约束共同优化编码器。这种设计使得在保持多模态理解能力的同时，语义信息损失可忽略不计，并能产生兼容生成的离散令牌和细粒度重建。此外，我们发现在量化语义编码器时，它们依赖高维码本，这与之前图像重建中常用的低维码本实践形成对比，展现了一个有趣的特性。语义VQ码本在1536的维度下可以达到100%的利用率。VQRAE在视觉理解、生成和重建的多个基准测试中展现出有竞争力的性能，并由于其离散的优点，在自回归范式中展现出有前景的扩展能力。|
|**2025-11-28**|[Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning](http://arxiv.org/abs/2511.23262)|null|近期的视觉-语言模型 (VLM) 展现出强大的感知推理能力，然而，它们在面对测试时的新颖任务时往往难以有效适应。相比之下，人类利用带有记忆的元认知模型，当面临新挑战时，通过元认知控制实现策略的持续完善。为弥合这一差距，我们提出了元认知测试时推理 (MCTR)，这是一个通过元认知自我更新，赋予模型在测试时学习、适应和改进能力的框架。受人类元认知双重结构的启发，MCTR 包含元级和对象级 VLM 推理模块，每个模块都配备了专门的记忆系统，用于分层自适应推理。具体而言，MCTR 由 (1) 一个元推理模块组成，该模块通过从测试时观察中发现并以自然语言描述的形式存储任务相关规则、环境模式和行动-结果关系，逐步构建结构化记忆；以及 (2) 一个行动推理模块，该模块通过动态检索和整合记忆中的知识，通过上下文感知感知和策略推理来确定最优行动。行动推理模块通过提出的元认知测试时强化学习不断更新其策略，并随着知识记忆的演变而适应。我们在 45 款 Atari 游戏中评估了 MCTR (33 款已见，12 款未见)。MCTR 展示了强大的测试时适应能力，与基线相比，在未见游戏中取得了 12 款中的 9 款第一名结果。通过消融实验、学习动态和案例研究进行的分析揭示了两个组件的互补贡献，并表明元推理正朝着类人适应策略发展。|
|**2025-11-28**|[Evolutionary Discovery of Heuristic Policies for Traffic Signal Control](http://arxiv.org/abs/2511.23122)|null|交通信号控制（TSC）涉及一个具有挑战性的权衡：经典启发式算法高效但过度简化，而深度强化学习（DRL）性能高但存在泛化能力差和策略不透明的问题。在线大型语言模型（LLMs）提供通用推理能力，但延迟高且缺乏环境特定的优化。为了解决这些问题，我们提出了交通时序策略演化，它使用LLMs作为演化引擎来导出专门的启发式策略。该框架引入了两个关键模块：（1）结构化状态抽象（SSA），将高维交通数据转换为用于推理的时序逻辑事实；以及（2）信用分配反馈（CAF），追踪有缺陷的微观决策到糟糕的宏观结果，以便进行有针对性的批评。交通时序策略演化完全在提示级别操作，无需训练，产生针对特定交通环境优化的轻量级、鲁棒的策略，其性能优于启发式算法和在线LLM执行器。|
|**2025-11-28**|[DM $^3$T: Harmonizing Modalities via Diffusion for Multi-Object Tracking](http://arxiv.org/abs/2511.22896)|null|多目标跟踪（MOT）是计算机视觉中的一项基础任务，在自动驾驶和机器人技术中具有关键应用。集成可见光和热红外信息的多模态MOT对于鲁棒的自动驾驶系统尤为重要。然而，有效融合这些异构模态具有挑战性。拼接或相加等简单策略往往无法弥合其特征表示之间显著的非线性分布鸿沟，这可能导致模态冲突并降低跟踪精度。受多模态MOT与扩散模型中迭代细化之间联系的启发，本文提出了DM$^3$T，这是一种新颖的框架，将多模态融合重新表述为迭代特征对齐过程，以生成准确且时间连贯的目标轨迹。我们的方法通过所提出的跨模态扩散融合（C-MDF）模块进行迭代的跨模态协调。在此过程中，来自两种模态的特征提供相互指导，迭代地将它们投影到共享的、一致的特征流形上。这使得互补信息的学习成为可能，并与传统方法相比实现了更深层次的融合。此外，我们引入了即插即用的扩散细化器（DR）来增强和细化统一的特征表示。为了进一步提高跟踪鲁棒性，我们设计了一个自适应处理置信度估计的分层跟踪器。DM$^3$ T将目标检测、状态估计和数据关联统一到一个无需复杂后处理的全面在线跟踪框架中。在VT-MOT基准上进行的大量实验表明，我们的方法达到了41.7 HOTA，相对现有最先进方法提高了1.54%。代码和模型可在https://vranlee.github.io/DM-3-T/获取。|
|**2025-11-28**|[Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation](http://arxiv.org/abs/2511.22862)|**[link](https://github.com/Luchicken/BriMPR)**|测试时自适应 (TTA) 仅使用未标记测试数据实现模型在线自适应，旨在弥合源域和目标域分布之间的差距。然而，在多模态场景中，不同模态之间不同程度的分布偏移导致了单模态浅层特征偏移与跨模态高层语义错位的复杂耦合效应，这给将现有 TTA 方法扩展到多模态领域带来了巨大障碍。为应对这一挑战，我们提出了一种新颖的多模态测试时自适应 (MMTTA) 框架，命名为通过渐进式重对齐连接模态 (BriMPR)。BriMPR 由两个渐进增强模块组成，采用分而治之的策略来解决耦合效应。具体而言，我们首先将 MMTTA 分解为多个单模态特征对齐子问题。通过利用提示微调 (prompt tuning) 强大的函数逼近能力，我们将单模态全局特征分布校准到各自的源域分布，从而实现跨模态的初始语义重对齐。随后，我们将可信伪标签分配给掩蔽和完整模态的组合，并引入模态间实例级对比学习，以进一步增强模态之间的信息交互并细化对齐。在 MMTTA 任务（包括基于损坏和真实世界域偏移基准）上的大量实验证明了我们方法的优越性。我们的源代码可在 [this URL](https://github.com/Luchicken/BriMPR) 获取。|
|**2025-11-27**|[Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM Integration](http://arxiv.org/abs/2511.22769)|null|开发鲁棒的音译技术以提高将罗马化文字转换为本地文字的效率，对于自然语言处理（NLP）任务，包括情感分析、语音识别、信息检索和智能个人助理而言至关重要。尽管取得了显著进展，但最先进的多语言模型在处理罗马化文字方面仍面临挑战，即罗马字母被用来表示不同语言的语音结构。在南亚地区，印欧语系语言的罗马化文字在社交媒体和数字通信平台上的使用非常普遍，这种用法对尖端多语言模型持续构成重大挑战。虽然印欧语系语言的音译数据集和模型数量有限，但它们普遍缺乏发音和拼写变体的多样性、足够的代码混合数据用于大型语言模型（LLM）训练，以及低资源适应能力。为了弥补这一研究空白，我们为两种流行的印欧语系语言——印地语和孟加拉语（分别位列全球使用人数第三和第七的语言）引入了一种新颖的音译数据集。我们的数据集包含近180万对印地语和100万对孟加拉语的音译对。除此之外，我们还利用所开发的数据集预训练了一个基于Marian架构的定制多语言seq2seq大型语言模型。实验结果表明，与现有相关模型相比，在BLEU和CER指标方面取得了显著改进。|
|**2025-11-27**|[All Centers Are at most a Few Tokens Apart: Knowledge Distillation with Domain Invariant Prompt Tuning](http://arxiv.org/abs/2511.22739)|**[link](https://github.com/amirezzati/dipt)**|计算病理学 (CPath) 中的域泛化至关重要，原因在于临床中心间染色方案、扫描设备和成像设置的差异导致固有的域偏移。视觉-语言模型 (VLM)，例如PLIP（一个在不同域的图像-文本对上训练的、专为病理学调整的CLIP），是强大的知识蒸馏源。然而，由于对提示变化的敏感性，它们使用预定义提示的零样本性能仍然有限。此外，与自然图像不同，组织病理学中心缺乏语义描述符（例如“草图”），这使得为临床中心定义域特定提示变得困难。这需要一种数据驱动方法来学习域特定并最终类别通用的连续提示。我们提出了用于知识蒸馏过程的域不变提示微调 (DIPT)，这是一个新颖的步骤，可以为每个域学习多个输入token。这些token为每个域分别训练，并在域间进行平均，从而产生域不变提示。我们的学生模型随后利用DIPT学习到的提示，从PLIP的文本编码器中蒸馏知识。这使得视觉特征与域不变嵌入对齐，通过在多个域上训练来增强泛化能力。我们的方法在组织病理学数据集的域泛化中，使现有最先进 (SOTA) 知识蒸馏方法的平均F1分数得到了显著提升。这项工作有助于在具有异构数据源的实际临床问题中部署鲁棒的CPath模型。|
|**2025-11-27**|[SuRe: Surprise-Driven Prioritised Replay for Continual LLM Learning](http://arxiv.org/abs/2511.22367)|null|持续学习是指在不遗忘先前习得知识的前提下，系统适应一系列任务的能力，这仍然是机器学习领域的一个主要挑战，也是人工智能与人类智能之间的一个关键差距。尽管正则化和重放技术在视觉领域表现良好，但它们在大语言模型（LLMs）的多任务学习中，特别是在大规模多任务情境下，仍显不足。我们重新审视了重放技术，并认为两种失败模式导致了这一差距：选择（重演什么）和整合（如何巩固新知识）。为解决选择问题，我们提出了一种名为惊喜优先重放（SuRe）的方法，这是一个简单、与架构无关的规则，它对最具“惊喜度”（高负对数似然）的序列进行排序并存储。SuRe在大量任务（LNT）设置中实现了最先进的性能，并在标准持续学习（Standard CL）和LNT基准测试中均取得了最佳的整体平均表现。为解决整合问题，我们增加了一个双学习器设计，其中快速和慢速LoRA适配器通过指数移动平均（EMA）进行合并，这使得系统能够快速适应，同时稳定长期知识。将SuRe与双学习器结合，带来了进一步的提升，包括在LNT任务上相对于之前最先进水平（SOTA）高达5个准确率点的改进。消融研究证实，我们提出的方法在降低重放频率和使用小缓冲区大小的情况下仍然保持稳健，这证明了其有效性和样本效率。综上所述，我们的结果确立了重放作为LLM持续微调的强大基线，并证明了基于惊喜的选择和慢速权重巩固是减轻灾难性遗忘的互补组成部分。|
|**2025-11-26**|[Agentic Learner with Grow-and-Refine Multimodal Semantic Memory](http://arxiv.org/abs/2511.21678)|**[link](https://github.com/weihao-bo/ViLoMem)**|多模态大型语言模型（MLLMs）在独立查询上表现出强大的推理能力，但它们是“从头开始”运行的——独立解决每个问题，并经常重复同样的错误。现有的记忆增强型智能体主要存储过去的轨迹以供重用。然而，基于轨迹的记忆存在简短偏误，逐渐丢失必要的领域知识。更关键的是，即使在真正的多模态问题解决场景中，它也只记录过去行为的单模态痕迹，未能保留视觉注意力和逻辑推理如何共同促成了解决方案。这与人类认知从根本上不一致：语义记忆是多模态且整合的，通过协调但不同的表征流来保留视觉和抽象知识。因此，我们引入了ViLoMem，一个构建紧凑的、基于模式的记忆的双流记忆框架。它分别编码视觉干扰模式和逻辑推理错误，使MLLMs能够从成功和失败的经验中学习。遵循“增长与完善”原则，该系统逐步积累和更新多模态语义知识——在保留稳定、可泛化策略的同时，避免灾难性遗忘。在六个多模态基准测试中，ViLoMem持续提高pass@1准确率，并大幅减少重复的视觉和逻辑错误。消融实验证实了具有明确干扰-幻觉分离的双流记忆的必要性，证明了错误感知的多模态记忆对于终身和跨领域智能体学习的价值。我们的项目页面将发布在https://weihao-bo.github.io/ViLoMeo-page。|
|**2025-11-26**|[Escaping the Verifier: Learning to Reason via Demonstrations](http://arxiv.org/abs/2511.21667)|null|训练大型语言模型 (LLMs) 进行推理通常依赖于使用任务特定验证器的强化学习 (RL)。然而，许多现实世界中推理密集型任务缺乏验证器，尽管它们提供了大量专家演示，但这些演示在专注于推理的训练中仍未被充分利用。我们引入了 RARO (相对对抗推理优化)，它通过逆强化学习仅从专家演示中学习强大的推理能力。我们的方法在策略 (生成器) 和相对评论器 (判别器) 之间建立了一种对抗性交互：策略学习模仿专家答案，而评论器则学习比较和区分策略与专家答案。我们的方法通过强化学习联合且持续地训练策略和评论器，并且我们确定了实现鲁棒学习所需的关键稳定技术。经验上，RARO 在我们所有的评估任务——倒计时、DeepMath 和诗歌创作——上显著优于强大的无验证器基线，并且在可验证任务上展现出与强化学习相同的鲁棒扩展趋势。这些结果表明，我们的方法仅从专家演示中就能有效引发强大的推理性能，从而即使在任务特定验证器不可用的情况下也能实现鲁棒的推理学习。|
|**2025-11-26**|[Aligning LLMs Toward Multi-Turn Conversational Outcomes Using Iterative PPO](http://arxiv.org/abs/2511.21638)|null|优化大语言模型（LLMs）以实现多轮对话结果仍然是一个重大挑战，尤其是在目标导向型场景中，例如通过消息平台促成交易的AI营销或销售代理。这一困难源于稀疏、长期的奖励，以及响应级别规划与词元级别生成之间的差异。在本技术笔记中，我们提出将多轮强化学习（RL）问题形式化地归约为一系列单轮RLHF（基于人类反馈的强化学习）风格的问题。这通过将一个学习到的多轮Q函数设置为单轮问题的奖励模型来实现。我们论证并证明了一个关键见解：用标准的词元级别PPO解决这个单轮RL问题，等同于多轮问题中的一个策略改进步骤。这一见解自然而然地引出了迭代PPO（Iterative PPO），这是一种批处理在线策略迭代算法，它在从记录的对话轨迹中拟合Q函数和改进策略之间交替进行。一个主要的实际优势是，迭代PPO直接利用了稳定、现成的单轮RLHF工具，使其易于实现。我们的方法介于完全在线和完全离线方法之间，既保留了在线更新的适应性，又获得了离线训练的稳定性优势。|
|**2025-11-26**|[ $\mathcal{E}_0$ : Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion](http://arxiv.org/abs/2511.21542)|null|视觉-语言-动作（VLA）模型通过整合视觉感知、语言理解和控制生成，为机器人操作提供了一个统一框架。然而，现有的VLA模型在多样化任务、场景和摄像机视角下仍然难以泛化，并且常常产生粗糙或不稳定的动作。我们引入了E0，一个连续化离散扩散框架，它将动作生成建模为对量化动作令牌的迭代去噪。与连续扩散策略相比，E0提供两个关键优势：(1) 离散动作令牌与预训练VLM/VLA骨干网络的符号结构自然对齐，从而实现更强的语义条件作用；(2) 离散扩散符合真实世界机器人控制的真实量化特性——其硬件约束（例如，编码器分辨率、控制频率、执行延迟）内在地离散化连续信号——因此受益于建模正确离散动作分布的贝叶斯最优去噪器，从而实现更强的泛化能力。与离散自回归和基于掩码的离散扩散模型相比，E0支持显著更大、更细粒度的动作词汇，并避免了由基于掩码的损坏引入的分布不匹配，从而实现更精确的细粒度动作控制。我们进一步引入了一种球面视角扰动增强方法，以在无需额外数据的情况下提高对摄像机位移的鲁棒性。在LIBERO、VLABench和ManiSkill上的实验表明，E0在14个多样化环境中实现了最先进的性能，平均优于强基线10.7%。在Franka机械臂上的真实世界评估证实，E0提供了精确、鲁棒和可迁移的操作，将离散扩散确立为可泛化VLA策略学习的一个有前景的方向。|
|**2025-11-26**|[MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning](http://arxiv.org/abs/2511.21460)|null|在任务规划过程中确保具身AI智能体的安全对于现实世界部署至关重要，尤其是在危险指令可能构成重大风险的家庭环境中。现有方法常面临高计算成本（源于偏好对齐训练）或使用单智能体安全提示时过度拒绝的问题。为解决这些局限性，我们提出了MADRA，一个免训练的多智能体辩论风险评估框架，它利用集体推理在不牺牲任务性能的前提下增强安全意识。MADRA采用多个基于LLM的智能体来辩论给定指令的安全性，并由一个关键评估器指导，该评估器根据逻辑严谨性、风险识别、证据质量和清晰度对响应进行评分。通过迭代审议和共识投票，MADRA显著减少了误拒，同时保持了对危险任务的高敏感度。此外，我们引入了一个分层认知协作规划框架，该框架整合了安全、记忆、规划和自进化机制，通过持续学习提高任务成功率。我们还贡献了SafeAware-VH，一个用于VirtualHome中安全感知任务规划的基准数据集，包含800条标注指令。在AI2-THOR和VirtualHome上进行的大量实验表明，我们的方法实现了超过90%的非安全任务拒绝率，同时确保安全任务的拒绝率较低，在安全性和执行效率两方面均优于现有方法。我们的工作为构建可信赖的具身智能体提供了一种可扩展、模型无关的解决方案。|
|**2025-11-26**|[From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings](http://arxiv.org/abs/2511.21428)|**[link](https://github.com/jiajiezhang7/latent-action-primitive-segmenter)**|我们提出了一种新颖的无监督框架，用于从连续工业视频流中释放大量未标注的人类演示数据，以进行视觉-语言-动作 (VLA) 模型预训练。我们的方法首先训练一个轻量级运动分词器来编码运动动态，然后利用一种新颖的“潜在动作能量”度量，采用无监督动作分割器来发现并分割语义连贯的动作基元。该流程输出分割后的视频片段及其相应的潜在动作序列，提供了直接适用于VLA预训练的结构化数据。在公共基准数据集和专有电机组装数据集上的评估表明，该方法能够有效分割人类在工作站上执行的关键任务。通过视觉-语言模型进行的进一步聚类和定量评估证实了所发现动作基元的语义连贯性。据我们所知，这是首个从非结构化工业视频中提取和组织VLA预训练数据的全自动化端到端系统，为具身AI在制造业中的整合提供了一种可扩展的解决方案。|
|**2025-11-26**|[Monet: Reasoning in Latent Visual Space Beyond Images and Language](http://arxiv.org/abs/2511.21395)|**[link](https://github.com/NOVAglow646/Monet)**|“图像思维”已成为一种推进视觉推理的有效范式，它通过在中间推理步骤中注入视觉证据，超越了纯文本思维链。然而，现有方法未能实现类人抽象视觉思维，因为其灵活性从根本上受限于外部工具。在这项工作中，我们引入了Monet，这是一个训练框架，它通过生成作为中间视觉思维的连续嵌入，使多模态大型语言模型（MLLMs）能够直接在潜在视觉空间中进行推理。我们识别出训练MLLMs进行潜在视觉推理的两个核心挑战：潜在视觉对齐的高计算成本和对潜在嵌入的监督不足，并用三阶段蒸馏式监督微调（SFT）流程解决了这些挑战。我们进一步揭示了将GRPO应用于潜在推理的一个局限性：它主要增强基于文本的推理而非潜在推理。为了克服这一点，我们提出了VLPO（视觉-潜在策略优化），这是一种强化学习方法，它将潜在嵌入明确地纳入策略梯度更新中。为了支持SFT，我们构建了Monet-SFT-125K，这是一个高质量的文本-图像交错式思维链（CoT）数据集，包含12.5万个真实世界、图表、OCR和几何思维链实例。我们的模型Monet-7B在真实世界感知和推理基准测试中表现出持续的提升，并在具有挑战性的抽象视觉推理任务上展现出强大的分布外泛化能力。我们还经验性地分析了每个训练组件的作用，并讨论了我们早期不成功的尝试，为未来视觉潜在推理的发展提供了见解。我们的模型、数据和代码可在https://github.com/NOVAglow646/Monet获取。|
|**2025-11-26**|[Discovery and recovery of crystalline materials with property-conditioned transformers](http://arxiv.org/abs/2511.21299)|**[link](https://github.com/C-Bone-UCL/CrystaLLM-pi)**|生成模型最近在加速新型功能材料的设计和发现方面展现出巨大潜力。条件生成通过允许逆向设计增强了这种能力，即在生成过程中可以请求特定的期望属性。然而，基于Transformer的方法的条件化尤其受限于离散分词方案以及在微调过程中发生灾难性遗忘的风险。本工作引入了CrystaLLM-π（属性注入），这是一个条件自回归框架，它将连续属性表示直接集成到Transformer的注意力机制中。本文提出了两种架构：属性-键-值（PKV）前缀注意力和PKV残差注意力。这些方法绕过了低效的序列级分词，并保留了从以晶体学信息文件（CIFs）作为文本输入的无监督预训练中获得的基础知识。我们通过系统的鲁棒性研究确立了这些机制的有效性，并评估了该框架在两项不同任务中的多功能性。首先，在结构恢复任务中，该模型处理高维、异构的X射线衍射图，实现了与专用模型相当的结构准确性，并展示了在实验结构恢复和多晶型物区分方面的应用。其次，在材料发现任务中，该模型在一个专门的光伏数据集上进行微调，以生成经密度泛函理论（DFT）验证的新颖、稳定的候选材料。它隐式地学习了如何针对实现高光伏效率的最佳带隙区域，展示了映射复杂结构-属性关系的能力。CrystaLLM-π为逆向材料设计提供了一个统一、灵活且计算高效的框架。|
|**2025-11-26**|[Co-Training Vision Language Models for Remote Sensing Multi-task Learning](http://arxiv.org/abs/2511.21272)|**[link](https://github.com/VisionXLab/RSCoVLM)**|随着Transformer模型在个体遥感（RS）任务上取得杰出性能，我们正通过多任务学习（MTL）接近实现一个在多项任务中表现卓越的统一模型。与单任务方法相比，MTL方法提供了改进的泛化能力、增强的可扩展性和更高的实际应用性。近期，视觉语言模型（VLM）已分别在遥感图像理解、语义接地和超高分辨率（UHR）图像推理方面取得了可喜成果。此外，统一的基于文本的接口在MTL中展现出巨大潜力。因此，在这项工作中，我们提出了RSCoVLM，一个用于遥感MTL的简单而灵活的VLM基线。首先，我们创建了数据管理引擎，包括数据采集、离线处理与集成，以及在线加载与加权。该数据引擎有效解决了复杂的遥感数据环境问题，并生成灵活的视觉-语言对话。此外，我们提出了一种统一的动态分辨率策略，以解决遥感图像固有的多样化图像尺度问题。对于UHR图像，我们引入了缩放链机制及其对应的数据集LRS-VQA-Zoom。这些策略灵活且有效减轻了计算负担。此外，我们显著增强了模型的目标检测能力，并提出了一种新颖的评估协议，以确保VLM与传统检测模型之间的公平比较。广泛的实验表明，RSCoVLM在各种任务中取得了最先进的性能，超越了现有遥感VLM，甚至能与专用专家模型相媲美。所有训练和评估工具、模型权重和数据集均已完全开源，以支持可复现性。我们期望该基线能推动通用遥感模型的进一步发展。|
|**2025-11-26**|[BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data](http://arxiv.org/abs/2511.21194)|null|基础模型已展示出在图像、文本和音频等多种模态中学习丰富、可迁移表征的卓越能力。在现代机器学习流程中，这些表征通常取代原始数据，成为下游任务的主要输入。本文旨在解决在不从头开始重新训练或产生显著计算成本的情况下，调整预训练基础模型以注入领域特定知识的挑战。为此，我们引入了BotaCLIP，一个轻量级多模态对比框架，它通过将高分辨率航空影像与植物群落调查数据对齐，来调整一个预训练的地球观测基础模型（DOFA）。与通用嵌入不同，BotaCLIP通过对比学习和一种减轻灾难性遗忘的正则化策略，内化了生态结构。一旦训练完成，所得嵌入可作为下游预测器的可迁移表征。受生物多样性建模中实际应用的启发，我们评估了BotaCLIP表征在三个生态任务中的表现：植物存在预测、蝴蝶出现建模和土壤营养群丰度估计。结果显示，与源自DOFA和有监督基线的结果相比，BotaCLIP取得了持续改进。更广泛地说，这项工作阐明了基础模型的领域感知适应如何将专家知识注入数据稀缺环境，从而实现经济高效的表征学习。|
|**2025-11-25**|[Advances and Challenges in Solar Flare Prediction: A Review](http://arxiv.org/abs/2511.20465)|null|太阳耀斑作为太阳活动最显著的表现之一，对地球空间环境和人类活动都产生着深远影响。因此，准确的太阳耀斑预报已成为空间天气研究中的一个核心课题。近年来，得益于空间观测技术的快速发展和数据处理能力的持续提升，太阳耀斑预报领域取得了实质性进展。本文对该领域的研究现状进行了全面综述，尤其侧重于追溯数据驱动方法的发展演变——从早期的统计学习技术发展到更复杂的机器学习和深度学习范式，以及最近多模态大模型的兴起。此外，本研究还考察了现有耀斑预报平台的实际表现，阐明了它们在业务化空间天气应用中的局限性，从而为未来技术优化和系统设计提供了实用参考。|
|**2025-11-25**|[Object-Centric Vision Token Pruning for Vision Language Models](http://arxiv.org/abs/2511.20439)|null|在视觉语言模型（VLM）中，相较于语言 tokens，视觉 tokens 数量庞大但信息分散，因此消耗了过多不必要的计算。旨在提高 VLM 推理效率的冗余视觉 tokens 剪枝方法已持续得到研究，但所有现有方法都采用间接且非保证的方式。我们提出了 OC-VTP，这是一种直接且有保证的方法，用于选择最具代表性的视觉 tokens，以实现高效率且保持准确性的 VLM 推理。我们的 OC-VTP 仅需要对一个小型以对象为中心的视觉 token 剪枝器进行轻量级预训练，然后即可将其插入到现有 VLM 中，无需对任何模型在任何数据集上进行微调。通过最小化从选定 tokens 重建原始未剪枝 tokens 的误差，我们保证保留最具代表性的视觉 tokens。在任何视觉剪枝比例（即推理效率）下，我们的 OC-VTP 始终帮助主流 VLM 保持最高的推理准确性。我们的剪枝方法也展示了有趣的可解释性。我们的代码可在 https://github.com/GarryLarry010131/OC-VTP 获取。|
|**2025-11-25**|[Self-Identifying Internal Model-Based Online Optimization](http://arxiv.org/abs/2511.20411)|null|本文提出了一种结合控制理论和系统辨识思想构建的新颖在线优化算法。我们算法的基础是一种利用在线问题内部模型的基于控制的设计。由于这种内部模型的先验知识在实践中可能不可用，我们引入了一个能够实时学习该模型的辨识例程。该算法最初是针对二次在线问题设计的，但可以应用于一般问题。对于二次情况，我们刻画了其到最优解轨迹的渐近收敛性。我们将所提出的算法与现有方法进行了比较，并展示了辨识例程如何确保其对底层内部模型变化的适应性。数值结果还表明，该算法在非二次设定下也表现出强大的性能。|
|**2025-11-25**|[Soft Adaptive Policy Optimization](http://arxiv.org/abs/2511.20347)|null|强化学习 (RL) 在增强大型语言模型 (LLMs) 的推理能力方面扮演着越来越重要的角色，然而，稳定且高性能的策略优化仍然充满挑战。词元级重要性比通常表现出高方差，这种现象在专家混合模型中尤为突出，导致更新不稳定。现有的基于组的策略优化方法，例如 GSPO 和 GRPO，通过硬裁剪缓解了这个问题，但难以同时保持稳定性和有效的学习。我们提出了软自适应策略优化 (SAPO)，它用一个平滑的、温度控制的门取代了硬裁剪，能够自适应地衰减离策略更新，同时保留有用的学习信号。与 GSPO 和 GRPO 相比，SAPO 既具有序列一致性又具有词元自适应性。像 GSPO 一样，SAPO 保持了序列级的一致性，但其软门控形成了一个连续的信任区域，避免了 GSPO 中使用的脆弱硬裁剪范围。当一个序列包含少量高度离策略的词元时，GSPO 会抑制该序列的所有梯度，而 SAPO 仅选择性地降低这些“问题”词元的权重，并保留了接近在策略词元的学习信号，从而提高了样本效率。相对于 GRPO，SAPO 用平滑的、温度控制的缩放取代了硬词元级裁剪，从而实现更具信息量且更稳定的更新。在数学推理基准上的实验结果表明，SAPO 在可比较的训练预算下表现出更高的训练稳定性和更高的 Pass@1 性能。此外，我们采用 SAPO 训练了 Qwen3-VL 模型系列，证明 SAPO 在不同任务和不同模型尺寸上都能带来持续的性能提升。总而言之，SAPO 为 LLM 的强化学习训练提供了一种更可靠、可扩展且有效的优化策略。|
|**2025-11-25**|[NNGPT: Rethinking AutoML with Large Language Models](http://arxiv.org/abs/2511.20333)|null|构建自我改进的AI系统仍然是AI领域的一个根本性挑战。我们提出了NNGPT，这是一个开源框架，它将大语言模型（LLM）转变为一个用于神经网络开发（主要针对计算机视觉）的自我改进的AutoML引擎。与以往框架不同，NNGPT通过生成新模型来扩展神经网络数据集，从而实现基于生成、评估和自我改进闭环系统的LLM持续微调。它在一个统一的工作流程中整合了五个协同的基于LLM的流水线：零样本架构合成、超参数优化（HPO）、代码感知精度/提前停止预测、检索增强的范围封闭PyTorch模块合成（NN-RAG）以及强化学习。NNGPT构建在LEMUR数据集（一个具有可复现指标的审计语料库）之上，它从单个提示生成并验证网络架构、预处理代码和超参数，端到端地执行它们，并从结果中学习。PyTorch适配器使NNGPT与框架无关，实现了强大的性能：NN-RAG在1,289个目标上实现了73%的可执行性，3样本提示在常见数据集上提高了精度，基于哈希的去重节省了数百次运行。单样本预测与基于搜索的AutoML相媲美，减少了大量试验的需求。在LEMUR上的HPO实现了0.60的均方根误差（RMSE），优于Optuna（0.64），而代码感知预测器达到了0.14的均方根误差，皮尔逊相关系数r=0.78。该系统已生成超过5K个经过验证的模型，证明NNGPT是一个自主的AutoML引擎。论文接收后，代码、提示和检查点将公开发布，以实现可复现性并促进社区使用。|
|**2025-11-25**|[Improving Language Agents through BREW](http://arxiv.org/abs/2511.20297)|null|基于大型语言模型（LLM）的智能体正越来越多地应用于需要结构化推理、工具使用和环境适应的任务，例如数据操作、多步规划和计算机使用自动化。然而，尽管它们具有多功能性，当前用于模型权重优化方法（如PPO和GRPO）的训练范式因其高昂的策略收敛计算开销而仍然相对不切实际。此外，由此产生的智能体策略难以解释、适应或增量改进。为解决此问题，我们研究了创建和完善智能体从环境中获取的经验学习的结构化记忆，以此作为智能体优化的替代途径。我们引入了BREW（Bootstrapping expeRientially-learned Environmental knoWledge），一个通过知识库（KB）构建和完善来实现下游任务智能体优化的框架。在我们的方案中，我们引入了一种有效方法来划分智能体记忆，以实现更高效的检索和完善。BREW利用任务评估器和行为准则来获取洞察，同时利用状态空间搜索来确保其在自然语言中的噪声和非特异性下仍能保持鲁棒性。在真实世界、领域特定的基准测试（OSWorld、 $τ^2$ Bench和SpreadsheetBench）上的实验结果表明，BREW实现了任务精度10-20%的提升，API/工具调用减少10-15%（从而缩短执行时间），同时保持了与基础模型相当的计算效率。与以往将记忆视为静态上下文的工作不同，我们将知识库（KB）建立为一个模块化、可控的智能体优化基底——一个以透明、可解释和可扩展的方式塑造行为的明确杠杆。|
|**2025-11-25**|[HVAdam: A Full-Dimension Adaptive Optimizer](http://arxiv.org/abs/2511.20277)|null|自适应优化器如Adam在训练大语言模型和扩散模型等大规模模型方面取得了巨大成功。然而，它们在CNN等经典架构上的泛化性能往往不如SGD等非自适应方法。我们发现了造成这种性能差距的一个关键原因：预条件器中的自适应性，它限制了优化器适应多样化优化格局的能力。为了解决这个问题，我们提出了Anon（Adaptivity Non-restricted Optimizer with Novel convergence technique），一种具有连续可调自适应性的新型优化器，使其能够在SGD类和Adam类行为之间进行插值，甚至超越两者。为确保在整个自适应性范围内实现收敛，我们引入了增量延迟更新（IDU），这是一种比AMSGrad的硬性最大值跟踪策略更灵活的新颖机制，并增强了对梯度噪声的鲁棒性。我们在理论上建立了在凸和非凸设置下的收敛性保证。在经验上，Anon在代表性的图像分类、扩散和语言建模任务上持续优于最先进的优化器。这些结果表明，自适应性可以作为一个有价值的可调设计原则，而Anon提供了第一个统一且可靠的框架，能够弥合经典优化器和现代优化器之间的差距，并超越它们各自的优势。|
|**2025-11-25**|[Rectified Flow for Vision-Aided mmWave V2I Beam Prediction](http://arxiv.org/abs/2511.20265)|null|本文提出一种基于整流流的流匹配 (FM) 框架，用于车-基础设施 (V2I) 链路中的视觉辅助波束预测。该方法不建模离散波束索引序列，而是学习由基于常微分方程 (ODE) 的向量场控制的连续潜在流，从而实现平滑的波束轨迹和快速采样。终端流约束在有限步积分下强制执行全局一致性，从而稳定长期预测。所提出的基于 FM 的模型显著提高了相对于 RNN 和 LSTM 基线的 Top-K 准确率，接近基于大型语言模型的方法的性能，并在相同的 GPU 和 CPU 部署上分别实现了约 10 倍和 10^4 倍的推理速度提升。|
|**2025-11-25**|[Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning](http://arxiv.org/abs/2511.20196)|null|多模态大语言模型 (MLLM) 具备卓越的能力，但可能会无意中记忆隐私敏感信息。尽管现有的遗忘方法能够移除此类知识，但它们未能实现良性遗忘，因为它们经常会降低模型的通用图像理解性能。为此，我们提出了 Sculpted Memory Forgetting Adapter (SMFA)，它将遗忘限制在目标记忆区域，同时保持模型的整体能力。SMFA 首先微调模型，将敏感响应替换为拒绝，从而得到一个记忆遗忘适配器，然后应用一个保留锚点引导的掩蔽机制，以防止干扰无关知识和理解能力。为了系统地评估选择性 MLLM 遗忘，我们引入了 S-MLLMUn Bench，这是第一个旨在联合评估敏感知识的移除和通用视觉理解的保留的基准。大量实验表明，与现有方法不同，SMFA 实现了精确可控的遗忘，同时保持了模型基础的图像理解能力。|
|**2025-11-25**|[Harmonious Parameter Adaptation in Continual Visual Instruction Tuning for Safety-Aligned MLLMs](http://arxiv.org/abs/2511.20158)|null|尽管持续视觉指令微调（CVIT）在适应多模态大语言模型（MLLMs）方面展现出潜力，但现有研究主要关注未经安全对齐的模型。这一关键性疏忽忽略了真实世界中的MLLMs本质上需要此类机制来缓解潜在风险。在这项工作中，我们将重点转向针对安全对齐MLLMs的CVIT，并观察到在持续适应过程中，模型不仅遭受任务遗忘，而且其安全性也出现下降。在安全性与任务性能之间实现和谐平衡仍然是一个关键挑战。为此，我们提出了和谐参数适应（HPA），这是一个后训练框架，由基于侧重的参数划分、和谐平衡的参数选择和正交参数调整组成。具体而言，HPA根据参数对安全性或任务性能的侧重将其分为两类，并从平衡的角度选择侧重参数进行保留。此外，HPA对参数更新施加正交约束，以进一步缓解灾难性遗忘。在CVIT基准和安全评估数据集上进行的大量实验表明，HPA比现有基线能更好地保持高安全性并缓解遗忘。|
|**2025-11-21**|[QueryOcc: Query-based Self-Supervision for 3D Semantic Occupancy](http://arxiv.org/abs/2511.17221)|null|从图像中学习三维场景几何和语义是计算机视觉的核心挑战，也是自动驾驶的关键能力。由于大规模三维标注成本过高，近期工作探索直接从传感器数据进行自监督学习，无需手动标注。现有方法要么依赖二维渲染一致性（其中三维结构仅隐式体现），要么依赖从累积激光雷达点云获得的离散体素网格，这限制了空间精度和可扩展性。我们引入了QueryOcc，一个基于查询的自监督框架，它通过在相邻帧之间采样的独立四维时空查询直接学习连续三维语义占用。该框架支持来自视觉基础模型派生的伪点云或原始激光雷达数据的监督。为了在恒定内存下实现长距离监督和推理，我们引入了一种收缩场景表示，该表示保留了近场细节，同时平滑地压缩了远距离区域。QueryOcc在自监督Occ3D-nuScenes基准测试中，语义RayIoU超越了先前的基于相机的方法26%，同时运行速度达到11.6 FPS，这表明直接的四维查询监督能够实现强大的自监督占用学习。|
|**2025-11-21**|[FireScope: Wildfire Risk Prediction with a Chain-of-Thought Oracle](http://arxiv.org/abs/2511.17171)|null|预测野火风险是一个推理密集型空间问题，需要整合视觉、气候和地理因素来推断连续风险图。现有方法缺乏可靠泛化所需的因果推理和多模态理解能力。我们引入了FireScope-Bench，一个大规模数据集和基准，它将Sentinel-2影像和气候数据与美国各地专家定义的风险栅格以及欧洲的真实野火事件结合起来，用于跨大陆评估。在此数据集的基础上，我们提出了FireScope，一个基于VLM的推理到生成框架，它结合强化学习和视觉监督进行学习，以预测带有互补推理轨迹的风险栅格。当在美国进行训练并在欧洲进行测试时，FireScope取得了显著的性能提升，同时专家反馈和自动化分析证实其推理轨迹是忠实且语义上有意义的。我们的研究结果表明，推理能够为栅格预测模型提供基础，从而提高了泛化能力和可解释性。据我们所知，这是第一个能够(1)证明基于语言的推理可以提高视觉生成的泛化能力，(2)提出一种可应用于跨大陆的高分辨率野火风险模型，以及(3)促进对多模态火灾风险模型鲁棒跨大陆泛化能力进行系统研究的框架。我们相信FireScope-Bench有潜力为推动推理驱动、可解释和可泛化的空间建模奠定基础。数据和源代码将公开发布。|
|**2025-11-21**|[Sparse Reasoning is Enough: Biological-Inspired Framework for Video Anomaly Detection with Large Pre-trained Models](http://arxiv.org/abs/2511.17094)|null|视频异常检测（VAD）在安全监控、自动驾驶和工业监测等现实世界应用中发挥着至关重要的作用。大型预训练模型的最新进展，通过利用丰富的先验知识和通用推理能力，为免训练VAD带来了新机遇。然而，现有研究通常依赖于密集帧级推理，导致高计算成本和延迟。这提出了一个基本问题：在VAD系统中使用强大的预训练模型时，密集推理是否真正必要？为此，我们提出了ReCoVAD，一个受人类神经系统双重反射和意识通路启发的新颖框架，通过实现选择性帧处理来减少冗余计算。ReCoVAD包含两条核心通路：(i) 反射通路，它使用轻量级基于CLIP的模块将视觉特征与原型提示融合并生成决策向量，这些向量查询过去帧和异常分数的动态记忆以实现快速响应；(ii) 意识通路，它采用中等规模视觉-语言模型为新颖帧生成文本事件描述和精炼的异常分数。它持续更新记忆和原型提示，同时一个集成的大型语言模型定期审查累积的描述，以识别未见的异常、纠正错误并完善原型。大量实验表明，ReCoVAD实现了最先进的免训练性能，同时在UCF-Crime和XD-Violence数据集上，仅处理了以往方法所用帧数的28.55%和16.04%，证明了稀疏推理足以实现有效的基于大模型的VAD。|
|**2025-11-21**|[Parametric Retrieval-Augmented Generation using Latent Routing of LoRA Adapters](http://arxiv.org/abs/2511.17044)|null|参数化检索增强生成（PRAG）是一种新颖的RAG范式，它通过使用LoRA适配器对文档进行参数化，将外部知识直接集成到大型语言模型（LLM）中，与传统RAG方法相比，证明了推理成本的降低。然而，当前的PRAG方法采用一对一的文档编码方案，即为每个文档使用一个专门的LoRA适配器。这种方案引入了两个主要限制：首先，由于单个LoRA适配器的训练数据集有限，导致数据稀缺；其次，它在推理过程中产生高昂的开销，需要为每个候选段落将LLM权重与新的LoRA适配器合并，这在计算上是低效的。为了克服这些挑战，我们提出了一种新颖的PRAG段落编码范式，该范式利用潜在路由编码过程（Poly-PRAG）。在离线编码阶段，我们将一组文档的编码视为一个多任务学习过程，其中每个段落都被分配一个唯一的任务标识符。通过采用路由函数，我们使用一小组潜在的LoRA适配器来编码整个段落空间。在在线推理阶段，这个路由函数根据输入查询选择性地激活一部分潜在专家。我们对Poly-PRAG在多个知识密集型自然语言处理（NLP）任务中进行了全面的评估。我们广泛的实验证明了所提方法的有效性，在四个不同的数据集上取得了最先进的结果。|
|**2025-11-21**|[MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays](http://arxiv.org/abs/2511.17043)|null|胸部X射线摄影仍然是胸部诊断最广泛使用的影像学检查方式之一，然而，不断增加的影像量和放射科医生工作量持续挑战着及时判读。在这项工作中，我们探讨了使用医学影像基础模型MedImageInsight，对胸部X射线片进行正常和异常类别的自动化二分类。我们评估了两种方法：（1）对MedImageInsight进行微调以实现端到端分类；（2）将该模型用作特征提取器，用于结合传统机器学习分类器的迁移学习流程。实验结合使用了ChestX-ray14数据集和来自合作医院的真实世界临床数据。经过微调的分类器取得了最高性能，ROC-AUC值为0.888，并且与迁移学习模型相比具有更优的校准性，表现出与CheXNet等已有架构相当的性能。这些结果突出了医学影像基础模型在减少特定任务训练需求的同时保持诊断可靠性的有效性。该系统旨在集成到基于网络的和医院PACS工作流程中，以支持分诊并减轻放射科医生的负担。未来的工作将把模型扩展到多标签病理分类，以在临床环境中提供初步诊断判读。|
|**2025-11-21**|[CLLMRec: LLM-powered Cognitive-Aware Concept Recommendation via Semantic Alignment and Prerequisite Knowledge Distillation](http://arxiv.org/abs/2511.17041)|null|慕课（大规模开放在线课程）的发展给个性化学习带来了重大挑战，其中概念推荐至关重要。现有方法通常依赖异构信息网络或知识图谱来捕获概念关系，并结合知识追踪模型来评估学习者的认知状态。然而，这些方法因其对高质量结构化知识图谱的依赖而面临显著局限性，而这类知识图谱在真实教育场景中通常稀缺。为了应对这一根本挑战，本文提出CLLMRec，一个新颖的框架，它通过语义对齐和前置知识蒸馏这两个协同技术支柱来利用大语言模型。语义对齐组件通过编码学习者和概念的非结构化文本描述来构建统一的表示空间。前置知识蒸馏范式采用教师-学生架构，其中一个大型教师大语言模型（作为先验知识感知组件实现）从其内化的世界知识中提取概念前置关系，并将其蒸馏为软标签，以训练一个高效的学生排序器。在此基础上，我们的框架融入了一个精细排序机制，通过深度知识追踪明确建模学习者的实时认知状态，确保推荐既结构合理又认知适宜。在两个真实世界慕课数据集上进行的广泛实验表明，CLLMRec在多个评估指标上显著优于现有基线方法，验证了其在不依赖显式结构先验的情况下生成真正认知感知和个性化概念推荐的有效性。|
|**2025-11-21**|[ARQUSUMM: Argument-aware Quantitative Summarization of Online Conversations](http://arxiv.org/abs/2511.16985)|null|在公共讨论平台（例如Reddit）上，在线对话变得越来越普遍。随着争议性话题的日益增多，期望能够总结的不仅是多样的论点，还有它们的推理依据和论证理由。早期文本摘要研究侧重于捕捉源文档中的一般性显著信息，却忽视了在线对话的论证性质。近期对话摘要研究尽管考虑了句子间的论证关系，但未能阐明句子内部更深层次的论证结构以进行摘要。在本文中，我们提出了一项新颖的论证感知量化摘要任务，旨在揭示对话中论点的“主张-理由”结构，并用量化指标衡量论证强度。我们进一步提出了ARQUSUMM，一个用于解决该任务的新颖框架。为了揭示句子内部的潜在论证结构，ARQUSUMM利用根植于论证理论的大型语言模型（LLM）少样本学习能力，以识别句子中的命题及其“主张-理由”关系。对于量化摘要，ARQUSUMM采用论证结构感知的聚类算法来聚合论点并量化它们的支持度。实验表明，ARQUSUMM优于现有的对话和量化摘要模型，并能生成对用户更有帮助、文本质量高且量化准确性强的论证结构摘要。|
|**2025-11-21**|[Predicting Talent Breakout Rate using Twitter and TV data](http://arxiv.org/abs/2511.16905)|null|在广告领域，早期识别潜力人才至关重要。在本文中，我们定义了“人才爆发”的概念，并提出了一种在日本人才成名之前对其进行检测的方法。本研究的主要关注点是确定结合Twitter和电视数据在预测社交数据时间相关变化方面的有效性。尽管传统时间序列模型在许多应用中以其鲁棒性而闻名，但神经网络模型在各种领域（例如自然语言处理、计算机视觉、强化学习）的成功持续激发了时间序列社区将新技术应用于实践的兴趣。因此，为了找到最佳建模方法，我们实验了传统方法、神经网络方法和集成学习方法。我们观察到，基于标准回归指标，集成学习方法优于传统模型和神经网络模型。然而，通过利用人才爆发的概念，我们能够评估模型的真实预测能力，在此方面，神经网络在精确率和召回率上优于传统方法和集成学习方法。|
|**2025-11-21**|[EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards](http://arxiv.org/abs/2511.16672)|null|大型多模态模型（LMM）的近期进展使其具备了令人印象深刻的推理和感知能力，然而，大多数现有训练流程仍依赖人工标注数据或外部验证的奖励模型，这限制了它们的自主性和可扩展性。在这项工作中，我们致力于以纯无监督方式（不依赖任何标注数据或奖励蒸馏）提升LMM的推理能力。为此，我们提出了一个名为 EvoLMM 的自演进框架，该框架从一个单一的主干模型中实例化出两个合作代理：一个生成多样化、基于图像问题的“提议者”（Proposer），和一个通过内部一致性解决这些问题的“解决者”（Solver），其中学习通过持续的自奖励过程进行。这种动态反馈在不依赖真实标签或人类判断的情况下，鼓励了信息丰富查询的生成和结构化推理的完善。当使用流行的 Qwen2.5-VL 作为基础模型时，我们的 EvoLMM 仅使用原始训练图像，便在包括 ChartQA、MathVista 和 MathVision 在内的多模态数学推理基准上取得了高达约3%的持续增益。我们希望我们这种简单而有效的方法能作为坚实基线，促进未来在全无监督自改进LMM方面的研究。我们的代码和模型可在 https://github.com/mbzuai-oryx/EvoLMM 获取。|
|**2025-11-20**|[EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards](http://arxiv.org/abs/2511.16672)|null|大型多模态模型（LMM）的近期进展使其具备了令人印象深刻的推理和感知能力，然而大多数现有训练流程仍依赖于人工筛选数据或外部验证的奖励模型，这限制了它们的自主性和可扩展性。在这项工作中，我们致力于以纯粹无监督的方式（无需任何标注数据或奖励蒸馏）提升LMM的推理能力。为此，我们提出了一个名为EvoLMM的自演化框架，它从单一骨干模型中实例化出两个协作代理：一个提问者（Proposer），负责生成多样化的、基于图像的问题；一个解决者（Solver），通过内部一致性来解决这些问题，其中学习通过持续的自我奖励过程进行。这种动态反馈促进了信息性查询的生成和结构化推理的完善，而无需依赖真实标签或人类判断。当使用流行的Qwen2.5-VL作为基础模型时，我们的EvoLMM仅使用原始训练图像，在ChartQA、MathVista和MathVision等多模态数学推理基准上取得了高达约3%的持续提升。我们希望我们这种简单而有效的方法能作为一个坚实基线，促进未来在完全无监督方式下LMM自改进方面的研究。我们的代码和模型可在https://github.com/mbzuai-oryx/EvoLMM获取。|
|**2025-11-20**|[Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter](http://arxiv.org/abs/2511.16665)|null|具备强大推理能力的大语言模型(LLM)的出现标志着一个重要里程碑，为复杂问题解决开辟了新领域。然而，训练这些通常采用强化学习(RL)的推理模型面临关键效率瓶颈：RL训练期间的响应生成呈现持续的长尾分布，其中少数极长的响应占据了大部分执行时间，浪费了资源并增加了成本。为此，我们提出了TLT，一个通过整合自适应推测解码来无损加速推理RL训练的系统。在RL中应用推测解码具有挑战性，原因在于动态工作负载、不断演进的目标模型以及草稿模型训练开销。TLT通过两个协同组件克服了这些障碍：(1) 自适应草稿模型（Adaptive Drafter），一个轻量级草稿模型，在长尾生成期间利用空闲GPU持续训练，以无额外成本保持与目标模型的对齐；以及(2) 自适应策略执行引擎（Adaptive Rollout Engine），它维护一个内存高效的预捕获CUDAGraphs池，并自适应地为每个输入批次选择合适的SD策略。评估表明，TLT相较于现有最先进系统实现了超过1.7倍的端到端RL训练加速，保持了模型精度，并生成了一个高质量的草稿模型作为免费副产品，适用于高效部署。代码已发布在https://github.com/mit-han-lab/fastrl。|
|**2025-11-20**|[Broad stochastic configuration residual learning system for norm-convergent universal approximation](http://arxiv.org/abs/2511.16550)|null|泛逼近是神经网络学习算法的基础。然而，某些网络通过证明迭代误差依概率测度收敛而非更严格的范数收敛来建立其泛逼近性质，这使得随机学习网络的泛逼近性质对随机参数选择高度敏感。宽余学习系统（BRLS）作为随机学习模型的一个成员，也面临着这个问题。我们从理论上证明了其泛逼近性质的局限性，即如果随机参数选择不当且收敛速度满足特定条件，迭代误差将不满足范数收敛。为了解决这个问题，我们提出了宽随机配置余学习系统（BSCRLS）算法，该算法在BRLS框架的基础上，引入了一种新颖的监督机制来自适应地约束随机参数的范围设置。此外，我们基于更严格的范数收敛证明了BSCRLS的泛逼近定理。我们提出了三种增量式BSCRLS算法版本，以满足各种网络更新的应用需求。我们在公开可用数据集上进行了太阳能电池板灰尘检测实验，并与13种深度和宽学习算法进行了比较。实验结果揭示了BSCRLS算法的有效性和优越性。|
|**2025-11-20**|[Contrastive vision-language learning with paraphrasing and negation](http://arxiv.org/abs/2511.16527)|null|对比式视觉-语言模型仍然是图像和文本检索的主流方法。对比语言-图像预训练 (CLIP) 以对比方式训练两个神经网络，以在共享潜在空间中对齐它们的图像和文本嵌入。最近评估CLIP在否定或释义文本上的结果显示其性能喜忧参半，因为否定在词汇变化极小的情况下彻底改变了含义，而释义可以创建具有相同预期含义但文本表达截然不同的内容。这对抗改进视觉-语言模型的评估结果和对齐构成重大挑战。为了解决这一挑战，本文评估了释义和否定的组合，提出了一种新的CLIP对比损失函数以同时考虑释义和否定，并将由LLM生成的包含原始、释义和否定文本描述的三元组训练数据应用于类CLIP训练模型。这种被称为SemCLIP的方法被证明能够将释义描述移向原始图像嵌入，同时将否定描述在嵌入空间中推得更远。实验结果表明，SemCLIP能够保持CLIP的性能，同时显著增加了与否定描述的距离。在CC-Neg基准测试中，使用“原始描述优于否定描述”的图像检索准确率指标，SemCLIP将准确率从68.1%提高到78.1%。尽管在Sugarcrepe++基准测试中与CLIP相比结果喜忧参半，但SemCLIP的性能通常优于用否定描述训练的模型。这种对否定的鲁棒性扩展到下游零样本分类任务，其中在Sugarcrepe++上预训练的SemCLIP在所有测试的下游任务上都优于CLIP。这些结果表明SemCLIP能够实现对语义转换的显著鲁棒性。|
|**2025-11-20**|[NLP Datasets for Idiom and Figurative Language Tasks](http://arxiv.org/abs/2511.16345)|null|习语和比喻性语言在口语和书面语中占很大一部分。随着社交媒体的兴起，这种非正式语言对于人们和大型语言模型（LLMs）的训练者来说都变得更容易观察。尽管大规模语料库的优势似乎是解决所有机器学习（ML）和自然语言处理（NLP）问题的方案，但习语和比喻性语言仍然是LLMs难以掌握的。微调方法被证明是最佳的，但更好、更大的数据集可以进一步缩小这一差距。本文提出的数据集提供了一个解决方案，同时提供了多样化的类别，可在此基础上构建新模型和开发新方法。我们使用了一系列最近的习语和比喻性语言数据集来获取一个合并的习语列表，该列表用于从大型语料库中检索上下文序列。我们创建了一个大规模的潜在习语和比喻性语言表达数据集以及两个额外的人工标注的明确习语和比喻性语言表达数据集，以通过习语识别（检测）任务来评估预训练语言模型处理比喻意义的基线能力。所得数据集经过后处理，以实现模型无关的训练兼容性，并用于训练，最终在槽位标注和序列标注任务上进行了评估。|
|**2025-11-20**|[Q-MLLM: Vector Quantization for Robust Multimodal Large Language Model Security](http://arxiv.org/abs/2511.16229)|null|多模态大型语言模型（MLLM）在跨模态理解方面展现出令人印象深刻的能力，但尽管存在强大的文本安全机制，它们仍然容易受到通过视觉输入发起的对抗性攻击。这些漏洞源于两个核心弱点：视觉表示的连续性（这允许基于梯度的攻击）以及文本安全机制向视觉内容的不充分迁移。我们引入了Q-MLLM，这是一种新颖的架构，它融合了两级向量量化，以创建一个离散瓶颈来对抗对抗性攻击，同时保留了多模态推理能力。通过在像素块和语义级别对视觉表示进行离散化，Q-MLLM阻断了攻击路径并弥合了跨模态安全对齐的鸿沟。我们的两阶段训练方法确保了鲁棒学习，同时保持了模型实用性。实验表明，Q-MLLM在防御越狱攻击和有害图像攻击方面的成功率显著优于现有方法。值得注意的是，除一个有争议的案例外，Q-MLLM实现了对越狱攻击完美的防御成功率（100%），同时在多个实用性基准上保持了有竞争力的性能，且推理开销极小。这项工作确立了向量量化作为安全多模态AI系统的一种有效防御机制，无需昂贵的安全特定微调或检测开销。代码可在https://github.com/Amadeuszhao/QMLLM获取。|
|**2025-11-20**|[Video2Layout: Recall and Reconstruct Metric-Grounded Cognitive Map for Spatial Reasoning](http://arxiv.org/abs/2511.16160)|null|空间智能是多模态大语言模型（MLLMs）的一个关键前沿，使其能够理解物理世界。现有研究借鉴人类感知机制，试图通过从多帧视觉输入中构建基于网格的认知地图来形成连贯的空间理解。然而，当前基于网格的地图方法依赖于离散化的栅格表示，这限制了模型在细粒度空间推理方面的能力。为了克服这一限制，我们提出了Video2Layout，一个用于从视频中重建基于度量的空间布局的框架。该框架采用连续的物体边界坐标来量化物体间的物理距离和物体尺寸。这赋予了模型定量空间计算能力，有效缓解了自然语言描述空间关系时固有的模糊性。具体而言，我们的方法包括两个核心阶段。首先，在监督微调阶段，我们从AI2THOR模拟器构建了一个高质量数据集，这使得模型能够学习从视觉输入到精确边界坐标的映射。随后，一个强化微调阶段进一步增强了模型的真实世界泛化能力。为了系统地评估认知地图准确性与图像数量之间的相关性，以及图像输入数量如何影响空间推理准确性，我们引入了QVS-Bench，这是一个旨在分析相关机制的诊断基准。在QVS-Bench和主流空间推理基准上进行评估，我们的模型V2LO-7B相较于在网格地图上训练的模型实现了平均4.92%的提升，验证了我们方法的优越性。我们的代码可在https://github.com/ybrrraway/Video2Layout获取。|
|**2025-11-20**|[Operon: Incremental Construction of Ragged Data via Named Dimensions](http://arxiv.org/abs/2511.16080)|null|现代数据处理工作流经常遇到不规则数据：即在自然语言处理、科学测量和自主人工智能代理等领域自然出现的、包含变长元素的集合。现有工作流引擎缺乏对跟踪不规则数据固有的形状和依赖关系的原生支持，这迫使用户手动管理复杂的索引和依赖关系记录工作。我们提出了Operon，一个基于Rust的工作流引擎，它通过一种新颖的、带有显式依赖关系的命名维度形式化方法解决了这些挑战。Operon提供了一种领域特定语言，用户可以在其中声明带有维度标注的管道，这些标注经过静态验证以确保正确性，而运行时系统则随着数据形状在执行过程中逐步被发现而动态调度任务。我们形式化了用于推理部分形状的数学基础，并证明Operon的增量构建算法保证在并行设置中确定性和合流的执行。该系统对部分已知状态的显式建模实现了健壮的持久化和恢复机制，而其每个任务的多队列架构在异构任务类型之间实现了高效的并行性。经验评估表明，Operon在将基线开销减少14.94倍的同时，在工作负载扩展时保持近乎线性的端到端输出速率，使其特别适用于机器学习应用中的大规模数据生成管道。|
|**2025-11-20**|[Learning Tractable Distributions Of Language Model Continuations](http://arxiv.org/abs/2511.16054)|null|受控语言生成根据序列级约束（例如，句法、风格或安全性）来调节文本。这些约束可能依赖于未来词元，这使得直接条件化自回归语言模型（LM）通常是难以处理的。先前工作使用可处理的替代模型，如隐马尔可夫模型（HMM），来近似后续序列的分布并在解码时调整模型的下一个词元对数几率。然而，我们发现这些替代模型通常上下文感知能力较弱，从而降低了查询质量。我们提出了前瞻学习（LTLA），这是一种混合方法，它将用于丰富前缀编码的相同基础语言模型与一个计算精确后续序列概率的固定且可处理的替代模型配对。在添加神经上下文时会出现两个效率陷阱：(i) 天真地用每个候选的下一个词元重新评分前缀需要在每个步骤中遍历整个词汇表，以及 (ii) 为每个前缀预测新的替代模型参数，虽然在单个步骤中是可处理的，但会强制为每个新前缀重新计算未来概率并消除重用。LTLA通过使用单次批量HMM更新来同时考虑所有下一个词元候选，并通过仅将替代模型的潜在状态先验条件化到LM的隐藏表示上，同时保持替代模型解码器固定，从而避免了这两个问题，因此计算可以在不同前缀之间重用。经验上，LTLA比无条件HMM获得了更高的条件似然，近似了独立HMM无法编码视觉上下文的视觉-语言模型的后续分布，并在受控生成任务上以可比的流畅性提高了约束满足度，同时推理开销最小。|
|**2025-11-20**|[Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning](http://arxiv.org/abs/2511.16043)|**[link](https://github.com/aiming-lab/Agent0)**|通常通过强化学习（RL）进行训练的大语言模型（LLM）智能体，受限于对人工标注数据的依赖，这限制了其可扩展性，并将人工智能束缚于人类知识。现有的自演化框架提供了一种替代方案，但通常受限于模型固有的能力和单轮交互，这阻碍了涉及工具使用或动态推理的复杂课程的开发。我们引入了Agent0，这是一个完全自主的框架，它通过多步协同演化和无缝工具集成，无需外部数据即可演化出高性能智能体。Agent0在两个均由相同基础大语言模型初始化的智能体之间建立了一种共生竞争机制：一个课程智能体负责提出越来越具有挑战性的前沿任务，另一个执行器智能体则学习解决这些任务。我们集成了外部工具以增强执行器的问题解决能力；这种能力的提升反过来促使课程智能体构建更复杂、更具工具意识的任务。通过这种迭代过程，Agent0建立了一个自我强化的循环，持续生成高质量的课程。经验上，Agent0显著提升了推理能力，将Qwen3-8B-Base模型在数学推理方面提升了18%，在通用推理基准上提升了24%。代码可在https://github.com/aiming-lab/Agent0获取。|
|**2025-11-18**|[Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge](http://arxiv.org/abs/2511.14744)|null|自2010年代初期以来，深度学习的兴起改变了计算机视觉和自然语言处理等领域，并强烈影响了生物医学研究。具体到药物发现，一个关键转折点——类似于视觉领域的“ImageNet时刻”——在2015年到来，当时深度神经网络在Tox21数据挑战赛中超越了传统方法。这一里程碑加速了深度学习在整个制药行业的采用，如今大多数主要公司已将这些方法整合到其研究管线中。Tox21挑战赛结束后，其数据集被纳入了几个已建立的基准，如MoleculeNet和Open Graph Benchmark。然而，在这些整合过程中，数据集被修改，标签被插补或生成，导致跨研究的可比性丧失。因此，生物活性和毒性预测方法在过去十年中改进的程度仍不清楚。为此，我们引入了一个可复现的排行榜，托管在Hugging Face上，使用原始的Tox21挑战赛数据集，并提供了一组基线和代表性方法。排行榜的当前版本表明，原始Tox21获胜者——基于集成的DeepTox方法——以及2017年引入的基于描述符的自归一化神经网络，持续保持竞争力并位列毒性预测顶尖方法之列，使得过去十年中毒性预测是否取得了实质性进展仍不清楚。作为这项工作的一部分，我们通过对Hugging Face Spaces的标准API调用，使所有基线和评估模型可公开访问以进行推理。|
|**2025-11-18**|[Seer: Online Context Learning for Fast Synchronous LLM Reinforcement Learning](http://arxiv.org/abs/2511.14617)|null|强化学习（RL）对于推动现代大型语言模型（LLMs）的发展至关重要，然而现有的同步强化学习系统面临严重的性能瓶颈。占据端到端迭代时间主要部分的rollout阶段，由于固有的工作负载不平衡，存在显著的尾部延迟和资源利用率低下问题。我们提出了Seer，一种新颖的在线上下文学习系统，它通过利用共享相同提示的请求之间在输出长度和生成模式上以前被忽视的相似性来解决这些挑战。Seer引入了三种关键技术：用于动态负载均衡的分段式rollout、上下文感知调度以及自适应分组推测解码。这些机制共同作用，在rollout期间大幅减少了尾部延迟并提高了资源效率。在生产级强化学习工作负载上的评估表明，与最先进的同步强化学习系统相比，Seer将端到端rollout吞吐量提高了74%至97%，并将尾部延迟降低了75%至93%，显著加速了RL训练迭代。|
|**2025-11-18**|[Full Atom Peptide Design via Riemannian Euclidean Bayesian Flow Networks](http://arxiv.org/abs/2511.14516)|null|扩散模型和流匹配模型最近已成为肽结合物设计有前景的方法。尽管取得了进展，这些模型仍然面临两大挑战。首先，离散残基类型的类别采样将其连续参数坍缩为独热编码，而连续变量（例如原子位置）在整个生成过程中平滑演变。这种不匹配扰乱了更新动力学并导致次优性能。其次，当前模型假设侧链扭转角服从单峰分布，这与侧链旋转异构态固有的多峰性相冲突，并限制了预测准确性。为了解决这些局限性，我们引入了PepBFN，这是首个用于全原子肽设计的贝叶斯流网络，它直接在完全连续空间中对参数分布进行建模。具体而言，PepBFN通过学习离散残基类型的连续参数分布来对其进行建模，从而实现了与其他连续结构参数的联合平滑贝叶斯更新。它进一步采用了一种新颖的基于高斯混合的贝叶斯流来捕获多峰侧链旋转异构态，以及一种基于矩阵费雪的黎曼流来直接建模SO(3)流形上的残基方向。总之，这些参数分布通过贝叶斯更新逐步细化，产生了平滑且连贯的肽生成。在侧链堆积、逆向折叠和结合物设计任务上的实验证明了PepBFN在计算肽设计中的强大潜力。|
|**2025-11-18**|[ArchMap: Arch-Flattening and Knowledge-Guided Vision Language Model for Tooth Counting and Structured Dental Understanding](http://arxiv.org/abs/2511.14336)|null|口腔内3D扫描的结构化理解对数字化正畸至关重要。然而，现有深度学习方法严重依赖模态特定训练、大规模标注数据集和受控扫描条件，这限制了其跨设备的泛化能力，并阻碍了在真实临床工作流程中的部署。此外，原始口腔网格在牙弓姿态上表现出显著差异，存在由于咬合或牙齿接触导致的不完整几何形状，并缺乏纹理线索，这使得统一的语义解释极具挑战性。为解决这些局限性，我们提出了ArchMap，一个用于鲁棒结构化牙科理解的免训练知识引导框架。ArchMap首先引入了一个几何感知牙弓展平模块，将原始3D网格标准化为空间对齐、保持连续性的多视图投影。然后，我们构建了一个牙科知识库（DKB），其中编码了分层牙齿本体、牙列阶段策略和临床语义，以约束符号推理空间。我们在1060例正畸前/后病例中验证了ArchMap，证明其在牙齿计数、解剖分区、牙列阶段分类以及识别诸如拥挤、缺失牙、修复体和龋齿等临床状况方面表现出鲁棒性能。与监督学习流程和提示式VLM基线相比，ArchMap在稀疏或易受伪影影响的条件下取得了更高的准确性、减少了语义漂移和卓越的稳定性。作为一个完全免训练的系统，ArchMap表明，将几何归一化与本体引导的多模态推理相结合，为现代数字化正畸中3D口腔内扫描的结构化分析提供了一种实用且可扩展的解决方案。|
|**2025-11-18**|[Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](http://arxiv.org/abs/2511.14249)|null|电影自动配音模型能根据给定脚本生成生动语音，在确保与无声视频口型同步的同时，通过简短的音色提示复制说话者的音色。现有方法模拟了一种简化的工作流程，即演员未经准备直接配音，这忽略了导演与演员之间关键的互动。相比之下，真实的配音工作流程涉及动态协作：导演积极与演员互动，引导他们在表演前内化语境线索，特别是情感。为解决此问题，我们提出了一种新的检索增强型导演-演员互动学习方案，旨在实现真实的电影配音，该方案被称为Authentic-Dubber，包含三种新颖机制：(1) 我们构建了一个多模态参考素材库，以模拟导演提供的学习素材。值得注意的是，我们整合了大型语言模型（LLMs），以实现对多模态信号中情感表达的深度理解。(2) 为模拟演员在配音过程中如何高效、全面地内化导演提供的素材，我们提出了一种基于情感相似度的检索增强策略。该策略检索与目标无声视频对齐的最相关的多模态信息。(3) 我们开发了一种渐进式图基语音生成方法，该方法逐步整合检索到的多模态情感知识，从而模拟演员最终的配音过程。上述机制使Authentic-Dubber能够忠实地复现真实的配音工作流程，并在情感表现力方面实现全面提升。在V2C动画基准数据集上的主观和客观评估均验证了其有效性。代码和演示可在https://github.com/AI-S2-Lab/Authentic-Dubber获取。|
|**2025-11-18**|[DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home](http://arxiv.org/abs/2511.14227)|null|物联网设备操作推荐是指根据用户情境，例如历史操作、环境信息和设备状态，为用户生成个性化的设备操作。这项任务对于提升用户满意度和企业利润至关重要。现有推荐模型难以处理复杂的操作逻辑、多样的用户偏好，并且对次优建议敏感，这限制了它们在物联网设备操作中的适用性。为了解决这些问题，我们提出了DevPiolt，一种基于大语言模型（LLM）的物联网设备操作推荐模型。具体而言，我们首先通过持续预训练和多任务微调，为LLM注入物联网操作的基础领域知识。接着，我们采用直接偏好优化以使微调后的LLM与特定的用户偏好对齐。最后，我们设计了一种基于置信度的曝光控制机制，以避免低质量推荐带来的负面用户体验。大量实验表明，DevPiolt在所有数据集上均显著优于基线模型，在所有指标上平均提升了69.5%。DevPiolt已在小米智能家居（Xiaomi Home）应用中实际部署了一个季度，为25.5万用户提供日常操作推荐。在线实验结果表明，独立访客设备覆盖率提升了21.6%，页面浏览接受率提升了29.1%。|
|**2025-11-18**|[Online Data Curation for Object Detection via Marginal Contributions to Dataset-level Average Precision](http://arxiv.org/abs/2511.14197)|null|在规模法则下，高质量数据已成为进步的主要驱动力，精选数据集通常以更低的成本表现优于大得多的未筛选数据集。在线数据筛选通过根据模型不断演变的状态动态选择训练样本，扩展了这一思想。尽管在分类和多模态学习中有效，但由于其结构复杂性和领域鸿沟，现有的在线采样策略很少能扩展到目标检测。我们引入了DetGain，这是一种专门用于目标检测的在线数据筛选方法，它根据每张图像的预测质量，估计其对数据集级别平均精度 (AP) 的边际扰动。通过建模全局分数分布，DetGain有效地估计全局AP变化并计算师生贡献差距，从而在每次迭代中选择信息丰富的样本。该方法与架构无关且侵入性最小，从而能够直接集成到各种目标检测架构中。在COCO数据集上使用多个代表性检测器进行的实验显示出准确性的一致改进。DetGain在低质量数据下也表现出强大的鲁棒性，并且可以与知识蒸馏技术有效结合以进一步提高性能，突显了其作为数据高效目标检测的通用且互补策略的潜力。|
|**2025-11-17**|[TaoSearchEmb: A Multi-Objective Reinforcement Learning Framework for Dense Retrieval in Taobao Search](http://arxiv.org/abs/2511.13885)|null|稠密检索作为电商搜索引擎的核心组件，通过预训练嵌入模型将用户查询和商品映射到统一语义空间，以实现大规模实时语义检索。尽管大语言模型的快速发展正逐渐取代传统BERT架构用于嵌入，但其训练范式仍遵循类BERT的监督微调和难负样本挖掘策略。这种方法依赖于复杂的离线难负样本构建流程，限制了模型迭代效率，并阻碍了语义表示能力的演进潜力。此外，现有多任务学习框架在同时优化语义相关性和非相关性目标时面临跷跷板效应。在本文中，我们提出了Retrieval-GRPO，一个基于多目标强化学习的稠密检索框架，旨在解决这些挑战。该方法通过在训练过程中动态检索每个查询的Top-K候选商品，消除了离线难负样本构建，同时引入一个相关性LLM作为奖励模型以生成实时反馈。具体来说，检索模型通过强化学习动态优化嵌入表示，其奖励信号结合了LLM生成的相关性分数、商品质量分数和多路排他性指标，以实现多目标用户偏好对齐和实时纠错。这种机制不仅消除了对难负样本的依赖，而且通过协同多目标优化缓解了跷跷板效应，显著增强了模型对复杂长尾查询的语义泛化能力。大量的离线和在线实验验证了Retrieval-GRPO的有效性，并且该系统已在中国最大的电商平台部署。|
|**2025-11-17**|[Beat the long tail: Distribution-Aware Speculative Decoding for RL Training](http://arxiv.org/abs/2511.13841)|null|强化学习(RL)后训练对于对齐大型语言模型(LLM)已变得至关重要，然而其效率日益受到rollout阶段的限制，在该阶段长轨迹是逐个token生成的。我们识别出一个主要瓶颈：rollout长度的长尾分布，其中一小部分长生成主导了实际运行时间；同时我们也发现了一个互补的机遇：历史rollout的可用性，它们揭示了跨训练周期的稳定prompt级别模式。受这些观察结果的启发，我们提出了DAS，一个分布感知推测解码框架，它在不改变模型输出的情况下加速了RL rollout。DAS整合了两个关键思想：一个使用增量维护的后缀树从近期rollout构建的自适应、非参数草稿器，以及一个长度感知的推测策略，该策略将更激进的草稿预算分配给主导总完成时间的长轨迹。这种设计利用rollout历史来维持接受率，同时平衡解码过程中的基本成本和token级别成本。在数学和代码推理任务上的实验表明，DAS将rollout时间缩短了高达50%，同时保持了相同的训练曲线，这证明了分布感知推测解码可以在不损害学习质量的情况下显著加速RL后训练。|
|**2025-11-17**|[UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity](http://arxiv.org/abs/2511.13714)|**[link](https://github.com/yujunwei04/UnSAMv2)**|Segment Anything模型（SAM）系列已成为广泛采用的视觉基础模型，但其控制分割粒度的能力仍然有限。用户通常需要通过添加更多提示或从预生成的掩码中选择来手动精细化结果，以达到期望的细节水平。这个过程可能模棱两可，因为相同的提示可能对应多个合理的掩码，并且收集跨所有粒度的密集标注成本过高，使得监督式解决方案不可行。为解决这一局限性，我们引入了UnSAMv2，它无需人工标注即可实现任意粒度的分割。UnSAMv2通过发现丰富的掩码-粒度对并引入一种新颖的粒度控制嵌入，扩展了UnSAM的分而治之策略，从而能够实现对分割尺度的精确、连续控制。值得注意的是，UnSAMv2仅利用6K未标注图像和0.02%的额外参数，就大幅增强了SAM-2，在交互式、全图像和视频分割任务中实现了任意粒度的分割。在超过11个基准测试中进行评估，UnSAMv2将NoC90（5.69 $\rightarrow$ 4.75）、1-IoU（58.0 $\rightarrow$ 73.1）和AR1000（49.6 $\rightarrow$ 68.3）均有所提升，表明少量未标注数据结合粒度感知的自监督学习方法可以释放视觉基础模型的潜力。|
|**2025-11-14**|[Drone Swarm Energy Management](http://arxiv.org/abs/2511.11557)|**[link](https://github.com/pkasyanov/Drone-Swarm-Energy-Management)**|本文提出了一种在不确定性下运行的无人机蜂群系统决策分析框架，该框架基于部分可观测马尔可夫决策过程 (POMDP) 与深度确定性策略梯度 (DDPG) 强化学习的集成。所提出的方法使得无人机 (UAVs) 在一个认知AI平台内实现自适应控制和协作行为，其中每个智能体从动态环境状态中学习最佳的能源管理和导航策略。我们通过采用源自贝叶斯滤波的信念状态表示来扩展标准DDPG架构，从而在部分可观测环境中实现鲁棒决策。在本文中，对于高斯情况，我们数值比较了源自DDPG的策略性能与原始连续问题的离散化版本的最优策略。仿真结果表明，与基线方法相比，基于POMDP-DDPG的蜂群控制模型显著提高了任务成功率和能源效率。所开发的框架支持跨多个智能体的分布式学习和决策协调，为可扩展的认知蜂群自主性奠定了基础。本研究成果有助于智能多智能体系统能源感知控制算法的进步，并可应用于安全、环境监测和基础设施检查等场景。|
|**2025-11-14**|[Scalable Policy Evaluation with Video World Models](http://arxiv.org/abs/2511.11520)|**[link](https://github.com/jettbrains/-L-)**|训练用于机器人操作的通用策略已展现出巨大潜力，因为它们能够在多样化场景中实现语言条件控制的多任务行为。然而，评估这些策略仍然困难，因为真实世界测试昂贵、耗时且劳动密集。此外，在物理机器人上部署未经验证的策略需要频繁的环境重置并存在安全风险。手动创建并填充用于机器人操作的模拟环境资产未能解决这些问题，这主要是由于所需的巨大工程量以及在物理和渲染方面通常存在的显著虚实鸿沟。在本文中，我们探索使用动作条件视频生成模型作为一种可扩展的方法来学习用于策略评估的世界模型。我们演示了如何将动作条件整合到现有的预训练视频生成模型中。这使得在预训练阶段能够利用互联网规模的野外在线视频，并减轻了对大规模视频-动作对数据的需求，而这些数据对于机器人操作而言收集成本高昂。我们的论文研究了数据集多样性、预训练权重以及所提出的评估流程的常见失败案例的影响。我们的实验表明，在包括策略排名以及实际策略值与预测策略值之间相关性在内的各种指标下，这些模型为在无需真实世界交互的情况下评估策略提供了一种有前景的方法。|
|**2025-11-14**|[BOFA: Bridge-Layer Orthogonal Low-Rank Fusion for CLIP-Based Class-Incremental Learning](http://arxiv.org/abs/2511.11421)|null|类别增量学习（CIL）旨在持续学习新类别而不遗忘先前获得的知识。CLIP等视觉-语言模型通过多模态监督提供强大的可迁移表示，使其在CIL中具有广阔前景。然而，将CLIP应用于CIL带来两大挑战：(1) 适应下游任务通常需要额外的可学习模块，这增加了模型复杂性并使其更容易遗忘；(2) 尽管多模态表示提供了互补优势，但现有方法尚未充分发挥其在有效整合视觉和文本模态方面的潜力。为了解决这些问题，我们提出了BOFA（桥接层正交融合自适应），一个新颖的CIL框架。BOFA将所有模型自适应完全限制在CLIP现有的跨模态桥接层中，从而不增加额外的参数或推理成本。为了防止该层中的遗忘，它利用了正交低秩融合，这是一种将参数更新限制在一个低秩“安全子空间”中的机制，该子空间在数学上被构建为与过去任务特征正交。这确保了稳定的知识积累而无需数据重放。此外，BOFA采用了一种跨模态混合原型，该原型协同稳定的文本原型与源自我们稳定自适应桥接层的视觉对应物，从而增强了分类性能。在标准基准上进行的大量实验表明，与现有方法相比，BOFA实现了卓越的准确性和效率。|
|**2025-11-14**|[MOON Embedding: Multimodal Representation Learning for E-commerce Search Advertising](http://arxiv.org/abs/2511.11305)|null|我们介绍MOON，这是一套用于电子商务应用中多模态表示学习的全面、可持续的迭代实践。MOON已全面部署在淘宝搜索广告系统的所有阶段，包括召回、相关性、排序等。在点击率（CTR）预测任务上，性能提升尤为显著，实现了整体线上CTR提升20.00%。在过去三年中，该项目在CTR预测任务上带来了最大幅度的改进，并经历了五次全面迭代。在MOON的探索和迭代过程中，我们积累了宝贵的见解和实践经验，我们相信这些将惠及研究社区。MOON包含一个“预训练、后训练和应用”的三阶段训练范式，允许将多模态表示与下游任务有效集成。值得注意的是，为了弥合多模态表示学习目标与下游训练目标之间的不一致性，我们定义了“交换率”，以量化中间指标的改进能多有效地转化为下游收益。通过这项分析，我们将基于图像的搜索召回识别为一个关键的中间指标，指导多模态模型的优化。经过三年和五次迭代，MOON沿四个关键维度发展：数据处理、训练策略、模型架构和下游应用。通过迭代改进获得的经验和见解也将进行分享。作为我们对电子商务领域规模效应探索的一部分，我们进一步对支配多模态表示学习的扩展定律进行系统研究，考察了训练token的数量、负样本和用户行为序列的长度等多个因素。|
|**2025-11-14**|[Rethinking Autoregressive Models for Lossless Image Compression via Hierarchical Parallelism and Progressive Adaptation](http://arxiv.org/abs/2511.10991)|null|自回归（AR）模型作为学习型无损图像压缩的理论性能基准，常因其过高的计算成本而被认为不切实际。本研究重新思考了这一范式，引入了一个基于层次并行性和渐进式适应的框架，重新确立了纯自回归作为一种性能卓越且实用的解决方案。我们的方法体现在层次并行自回归卷积网络（HPAC）中，这是一个超轻量级预训练模型，利用层次分解结构和内容感知卷积门控来有效捕获空间依赖性。我们为提高实用性引入了两个关键优化：缓存选择推理（CSI），通过消除冗余计算来加速编码；以及自适应焦点编码（AFC），有效地将框架扩展到高位深图像。在此高效基础之上，我们的渐进式适应策略通过空间感知速率引导渐进式微调（SARP-FT）实现。这种实例级策略通过优化在通过估计信息密度选择的、逐渐增大的空间连续区域上的低秩适配器，为每张测试图像微调模型。在多样化数据集（自然、卫星、医学）上的实验验证了我们的方法实现了新的最先进压缩性能。值得注意的是，我们的方法在学习型无损压缩领域设定了新基准，表明精心设计的AR框架可以在参数量小且编码速度具有竞争力的情况下，比现有方法提供显著增益。|
|**2025-11-14**|[Preserving Cross-Modal Consistency for CLIP-based Class-Incremental Learning](http://arxiv.org/abs/2511.10974)|null|类增量学习（CIL）使模型能够从序列任务中持续学习新类别，而不遗忘先前习得的知识。尽管CLIP等视觉-语言模型的最新进展在跨领域泛化方面表现出强大能力，但将其扩展到持续学习设置仍然具有挑战性。特别是，为新引入的类别学习任务特定的软提示通常会导致严重的分类器偏差，因为在缺少先前数据时，文本原型会对近期类别过拟合。在本文中，我们提出了DMC，一个简单而有效的两阶段框架，用于基于CLIP的CIL，它解耦了视觉编码器的适应性学习和文本软提示的优化。每个阶段在另一个阶段冻结的情况下进行训练，允许一种模态作为另一种模态的稳定语义锚点，以保持跨模态对齐。此外，当前基于CLIP的CIL方法通常存储类别高斯统计量用于生成式回放，但它们忽略了当视觉编码器随时间更新时产生的分布漂移。为了解决这个问题，我们引入了DMC-OT，它是DMC的增强版本，引入了最优传输引导的校准策略，以校准演进编码器之间的记忆统计量，以及一个任务特定的提示设计，以增强任务间的可分离性。在CIFAR-100、Imagenet-R、CUB-200和UCF-101上进行的广泛实验证明，DMC和DMC-OT都达到了最先进的性能，其中DMC-OT进一步将准确率平均提高了1.80%。|
|**2025-11-14**|[LEMUR: Large scale End-to-end MUltimodal Recommendation](http://arxiv.org/abs/2511.10962)|null|传统的基于ID的推荐系统常常面临冷启动和泛化挑战。多模态推荐系统利用文本和视觉数据，为缓解这些问题提供了一个有前景的解决方案。然而，现有的工业方法通常采用两阶段训练范式：首先预训练一个多模态模型，然后将其冻结的表征应用于训练推荐模型。这种解耦的框架存在多模态学习目标与推荐目标之间未对齐以及无法动态适应新数据的问题。为解决这些局限性，我们提出了LEMUR，这是第一个从原始数据端到端训练的大规模多模态推荐系统。通过联合优化多模态和推荐两个组件，LEMUR确保了与下游目标更紧密的对齐，同时实现了实时参数更新。从用户历史构建多模态序列表征通常涉及过高的计算成本。为缓解这一瓶颈，我们提出了一种新颖的记忆库机制，能够在整个训练过程中增量式地累积历史多模态表征。在抖音搜索上线一个月后，LEMUR实现了查询变化率衰减降低0.843%，QAUC提升0.81%。此外，LEMUR在抖音广告的多个关键离线指标上也取得了显著提升。我们的结果验证了端到端多模态推荐在真实世界工业场景中的优越性。|
|**2025-11-14**|[Short-Window Sliding Learning for Real-Time Violence Detection via LLM-based Auto-Labeling](http://arxiv.org/abs/2511.10866)|null|本文提出了一种用于闭路电视录像中实时暴力检测的短窗口滑动学习框架。与传统的长视频训练方法不同，所提出的方法将视频分成1-2秒的短片段，并应用基于大型语言模型（LLM）的自动字幕标注来构建细粒度数据集。每个短片段都充分利用所有帧以保持时间连续性，从而实现对快速暴力事件的精确识别。实验表明，所提出的方法在RWF-2000数据集上达到了95.25%的准确率，并在长视频（UCF-Crime：83.25%）上显著提高了性能，证实了其在智能监控系统中的强大泛化能力和实时适用性。|
|**2025-11-13**|[AgentEvolver: Towards Efficient Self-Evolving Agent System](http://arxiv.org/abs/2511.10395)|**[link](https://github.com/modelscope/AgentEvolver)**|由大型语言模型（LLM）驱动的自主智能体，通过推理、使用工具和在多样化环境中执行复杂任务，有潜力显著提升人类生产力。然而，当前开发此类智能体的方法仍然成本高昂且效率低下，因为它们通常需要手动构建的任务数据集以及需要大量随机探索的强化学习（RL）流程。这些局限性导致过高的数据构建成本、低探索效率和差的样本利用率。为了解决这些挑战，我们提出了AgentEvolver，一个自进化智能体系统，它利用LLM的语义理解和推理能力来驱动自主智能体学习。AgentEvolver引入了三个协同机制：(i) 自提问，它能够在新环境中实现好奇心驱动的任务生成，减少对手工制作数据集的依赖；(ii) 自导航，它通过经验复用和混合策略指导来提高探索效率；以及(iii) 自归因，它通过根据贡献度为轨迹状态和动作分配差异化奖励来提高样本效率。通过将这些机制整合到一个统一的框架中，AgentEvolver能够实现智能体能力的可扩展、经济高效和持续改进。初步实验表明，与传统的基于RL的基线相比，AgentEvolver实现了更高效的探索、更好的样本利用率和更快的适应。|
|**2025-11-13**|[SUGAR: Learning Skeleton Representation with Visual-Motion Knowledge for Action Recognition](http://arxiv.org/abs/2511.10091)|null|大语言模型（LLM）蕴含着丰富的隐式知识和强大的迁移能力。在本文中，我们探索将LLM与人体骨架结合，以执行动作分类和描述。然而，当把LLM视作识别器时，会产生两个问题：1）LLM如何理解骨架？2）LLM如何区分不同动作？为了解决这些问题，我们引入了一种新颖的范式，名为SUGAR（用视觉-运动知识学习骨架表示以进行动作识别）。在我们的流程中，我们首先利用现成的大规模视频模型作为知识库，生成与动作相关的视觉和运动信息。接着，我们提出通过这些先验知识监督骨架学习，以产生离散表示。最后，我们使用保持不变预训练权重的LLM来理解这些表示，并生成所需的动作目标和描述。值得注意的是，我们提出了一种时间查询投影（TQP）模块，用于连续建模长序列的骨架信号。在多个基于骨架的动作分类基准上的实验证明了我们SUGAR方法的有效性。此外，零样本场景下的实验表明，SUGAR比基于线性的方法更具通用性。|
|**2025-11-06**|[DMA: Online RAG Alignment with Human Feedback](http://arxiv.org/abs/2511.04880)|null|检索增强生成 (RAG) 系统通常依赖静态检索，这限制了其对不断变化的意图和内容漂移的适应性。我们引入了动态记忆对齐 (DMA)，这是一个在线学习框架，它系统地整合了多粒度人类反馈，以在交互式环境中对齐排序。DMA 将文档级、列表级和响应级信号组织成一个连贯的学习流程：包括用于点式和列表式排序器的监督训练、由响应级偏好驱动的策略优化，以及将知识蒸馏到轻量级评分器中以实现低延迟服务。在本文中，“记忆”指代模型的“工作记忆”，即大型语言模型 (LLM) 用于上下文学习 (ICL) 的整个可见上下文。我们采用了一种模拟实际部署的双轨评估协议：(i) 大规模在线 A/B 消融实验以分离每个反馈源的效用，以及 (ii) 在知识密集型基准上的少样本离线测试。在线方面，为期数月的工业部署进一步显示了用户参与度的显著提升。离线方面，DMA 保持了有竞争力的基础检索能力，同时在会话式问答 (TriviaQA, HotpotQA) 上取得了显著提升。综合来看，这些结果将 DMA 定位为一种在 RAG 中实现反馈驱动的实时适应的原则性方法，且不牺牲基线能力。|
|**2025-11-05**|[SCALE: Upscaled Continual Learning of Large Language Models](http://arxiv.org/abs/2511.03270)|null|我们重新审视大语言模型的持续预训练，并认为当前进展更多取决于扩展正确的结构，而非仅仅扩展参数。我们引入了SCALE，这是一种宽度扩展架构，它在冻结所有预训练参数的同时，将轻量级扩展插入到线性模块中。这保留了残差和注意力拓扑结构，并在不干扰基础模型原始功能的情况下增加了容量。SCALE遵循两个原则：持久保留（Persistent Preservation），通过保留导向初始化和冻结预训练权重来维持基础模型的行为；以及协同适应（Collaborative Adaptation），选择性地训练一部分扩展组件，以最小的干扰获取新知识。我们将这些思想实例化为SCALE-Preserve（保留优先）、SCALE-Adapt（适应优先）以及SCALE-Route，一个在保留头和适应头之间执行词元级路由的可选路由扩展。在一个受控的合成传记基准测试中，SCALE减轻了深度扩展中观察到的严重遗忘，同时仍能获取新知识。在韩语语料库上的持续预训练中，SCALE变体在英语评估中实现了更少的遗忘，并在韩语基准测试中取得了有竞争力的提升，这些变体提供了最佳的整体稳定性-可塑性权衡。随附分析阐明了保留何时能被证明成立，以及与标准持续学习设置相比，保留与适应之间的相互作用为何能稳定优化过程。|
|**2025-11-04**|[An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks](http://arxiv.org/abs/2511.02356)|null|大语言模型（LLM）作为面向公众的网络服务和API的广泛部署，使其安全性成为网络生态系统的核心关注点。越狱攻击作为对LLM的重大威胁之一，最近吸引了广泛研究。在本文中，我们揭示了一种能有效规避当前防御策略的越狱策略。该策略能够从失败或部分成功的攻击尝试中提取有价值的信息，并包含从攻击交互中进行自我演化的能力，从而产生足够的策略多样性和适应性。受持续学习和模块化设计原则的启发，我们提出了ASTRA，一个越狱框架，能够自主发现、检索和演化攻击策略，以实现更高效和自适应的攻击。为了实现这种自主演化，我们设计了一个闭环的“攻击-评估-提炼-重用”核心机制，该机制不仅生成攻击提示，还能从每一次交互中自动提炼和泛化可重用的攻击策略。为了系统地积累和应用这些攻击知识，我们引入了一个三层策略库，根据策略的性能得分将其分为有效、有前景和无效三类。该策略库不仅为攻击生成提供精确指导，还具有出色的可扩展性和可迁移性。我们在黑盒设置下进行了广泛实验，结果表明ASTRA实现了82.7%的平均攻击成功率（ASR），显著优于基线。|
|**2025-11-04**|[Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models](http://arxiv.org/abs/2511.01831)|null|视觉-语言模型（VLMs）在新任务上进行顺序微调时会面临灾难性遗忘，导致在先前学习到的基础能力和任务特定能力上性能下降。尽管多任务学习可以缓解遗忘，但它需要同时访问所有数据集，并带来与任务数量呈线性关系的计算开销。在这项工作中，我们提出了一种基于路由的方法，该方法能够在集成新任务的同时，保留预训练期间获得的基础知识。我们使用 InternVL-2 模型（2B 和 8B 参数）评估了我们的方法，并证明了路由通过在 ChartQA、MMBench 和 DocVQA 等通用基准测试上保持性能来保留模型的基础能力，同时提高了在专用任务上的准确性。重要的是，我们的方法无需同时访问所有任务的数据即可实现这一点，从而避免了与传统多任务学习相关的巨大计算和数据开销。我们进一步进行了广泛的消融研究，以评估基于路由学习的可扩展性和鲁棒性，结果表明该方法能够应对不断增长的任务数量，并且在新任务在语义上相关时表现尤为出色。最后，我们展示了路由机制能够实现语言和视觉能力之间卓越的跨模态迁移，使得在一个模态中学习到的知识能够提升在另一个能力上的表现，这是现有持续学习方法无法实现的。|
|**2025-11-03**|[HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA](http://arxiv.org/abs/2511.01463)|null|指令微调数据的扩展使得基础语言模型在多样化的下游任务中展现出改进的指令遵循能力和卓越性能。语义丰富的3D人体运动正逐步与这些基础模型集成，以增强多模态理解和跨模态生成能力。然而，人体运动与文本之间的模态鸿沟引发了关于在此集成过程中灾难性遗忘的未解决担忧。此外，开发能够保持异构下游任务泛化能力的自回归兼容姿态表示，仍然是一个关键技术障碍。为解决这些问题，我们提出了人体运动-视觉-语言模型（HMVLM），这是一个基于专家混合低秩自适应（MoE LoRA）策略的统一框架。该框架利用门控网络根据输入提示动态分配LoRA专家权重，从而实现多任务的同步微调。为缓解指令微调过程中的灾难性遗忘，我们引入了一种新颖的零专家，用于保留通用语言任务的预训练参数。对于姿态表示，我们通过将人体划分为不同的关节组来实现身体部位特定的分词，从而增强表示的空间分辨率。实验表明，我们的方法有效缓解了指令微调过程中的知识遗忘，并在多样化的人体运动下游任务中取得了显著性能。|
|**2025-11-03**|[Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions](http://arxiv.org/abs/2511.01284)|null|基础模型（FMs）已成为医学图像分析领域的一种变革性范式，有望为广泛的临床任务和成像模态提供可泛化、任务无关的解决方案。它们从大规模数据中学习可迁移表示的能力，有潜力解决传统任务专用模型的局限性。然而，基础模型在真实世界临床实践中的适应性仍受限于关键挑战，包括域偏移、高质量标注数据可用性有限、巨大的计算需求以及严格的隐私要求。本综述对基础模型适应医学成像特定需求的策略进行了全面评估。我们考察了监督微调、领域特定预训练、参数高效微调、自监督学习、混合方法以及多模态或跨模态框架等方法。对于每种方法，我们评估了报告的性能增益、临床适用性和局限性，同时识别了先前综述常忽略的权衡和悬而未决的挑战。除了这些已建立的技术之外，我们还强调了旨在解决当前不足的新兴方向。这些方向包括实现动态部署的持续学习、保护敏感数据的联邦学习和隐私保护方法、提高数据效率的混合自监督学习、将合成数据生成与人工验证相结合的以数据为中心的流程，以及评估真实世界临床变异性下鲁棒泛化能力的系统基准测试。通过概述这些策略和相关的研究空白，本综述为开发适应性强、值得信赖且临床整合的基础模型提供了路线图，这些模型能够满足真实世界医学成像的需求。|
|**2025-11-02**|[Aligning LLM agents with human learning and adjustment behavior: a dual agent approach](http://arxiv.org/abs/2511.00993)|null|有效建模人类出行者如何从与交通系统的互动中学习并调整其出行行为对系统评估和规划至关重要。然而，这项任务也很困难，因为这种行为涉及复杂的认知和决策。最近的研究已开始利用大语言模型（LLM）智能体来完成这项任务。在此基础上，我们引入一种新颖的双智能体框架，能够实现LLM智能体和人类出行者之间关于学习和适应行为的持续学习和对齐，通过在线数据流进行。我们的方法涉及一组LLM出行者智能体，配备记忆系统和可学习的人格，它们充当人类出行者的模拟器。为确保行为对齐，我们引入一个LLM校准智能体，它利用LLM的推理和分析能力来训练这些出行者智能体的人格。协同工作，这个双智能体系统旨在追踪并对齐出行者的潜在决策机制，并生成真实、自适应的模拟。利用来自一项日常路线选择实验的真实世界数据集，我们展示了我们的方法在个体行为对齐和聚合模拟精度两方面都显著优于现有基于LLM的方法。此外，我们证明了我们的方法超越了简单的行为模仿，能够捕捉潜在学习过程的演变，这是一种更深层次的对齐，有助于实现鲁棒的泛化。总之，我们的框架提供了一种新方法，用于创建自适应且行为真实的智能体以模拟出行者的学习和适应，这将有益于交通模拟和政策分析。|
|**2025-11-04**|[A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios](http://arxiv.org/abs/2511.00130)|null|大型语言模型（LLM）的卓越能力通常需要针对特定应用进行定制，这要求整合新知识或习得新技能。尽管完全微调是一种强大的适应方法，但其计算成本高昂，并可能导致通用推理能力的下降，这种现象被称为灾难性遗忘。存在一系列替代技术，每种技术都有其自身的权衡。上下文学习（ICL）速度快但受限于上下文长度，而参数高效微调（PEFT）方法（如低秩适应（LoRA））通过最小化参数变化提供了一种折衷方案。然而，灾难性遗忘的挑战依然存在，这引发了关于特定任务最佳适应策略的疑问。本文对数据稀缺场景下的监督微调（SFT）、LoRA和ICL进行了比较分析。我们发现LoRA提供了最有效的平衡，在成功灌输新技能的同时，对基础模型的通用知识影响最小。相比之下，SFT虽然在技能习得方面表现出色，但极易受到灾难性遗忘的影响。ICL在整合事实知识方面有效，但难以处理复杂技能。我们的研究结果为选择LLM适应策略提供了一个实用的框架。我们强调了技能习得与知识整合之间的关键区别，并阐明了任务特定性能与通用能力保留之间的权衡。|
|**2025-10-30**|[GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation](http://arxiv.org/abs/2511.00097)|null|图增量学习（GIL）通过序列知识获取持续更新图模型，近来引起了广泛关注。然而，现有的GIL方法专注于单一领域内的任务增量和类别增量场景。随着图基础模型（GFMs）的发展，旨在跨多个图领域更新模型的图领域增量学习（Domain-IL）已变得至关重要，但在现有文献中仍未被探索。本文中，我们提出了基于知识解耦与保持的图领域增量学习（GraphKeeper），以从嵌入偏移和决策边界偏差的角度解决Domain-IL场景中的灾难性遗忘问题。具体而言，为了防止跨增量图领域的嵌入偏移和混淆，我们首先提出了领域特异性参数高效微调，并结合域内和域间解耦目标。随后，为了保持稳定的决策边界，我们引入了无偏差知识保持以持续适应增量领域。此外，对于领域不可观测的图，我们执行了领域感知分布判别以获得精确的嵌入。大量实验表明，所提出的GraphKeeper相较于次优方法取得了6.5%~16.6%的提升，实现了最先进的结果，且遗忘程度可忽略不计。此外，我们展示了GraphKeeper可以与各种代表性GFM无缝集成，突出了其广泛的应用潜力。|
|**2025-10-31**|[Adapting Large Language Models to Emerging Cybersecurity using Retrieval Augmented Generation](http://arxiv.org/abs/2510.27080)|null|安全应用越来越依赖大型语言模型（LLM）进行网络威胁检测；然而，它们的非透明推理过程常限制信任度，尤其是在需要领域特定网络安全知识的决策中。由于安全威胁迅速演变，LLM不仅必须回忆历史事件，还需适应新兴漏洞和攻击模式。检索增强生成（RAG）已在通用LLM应用中展现出有效性，但其在网络安全领域的潜力仍未得到充分探索。在这项工作中，我们引入了一个基于RAG的框架，旨在对网络安全数据进行情境化，并提高LLM在知识保留和时间推理方面的准确性。利用外部数据集和Llama-3-8B-Instruct模型，我们评估了基线RAG、一种优化的混合检索方法，并针对多个性能指标进行了比较分析。我们的发现凸显了混合检索在增强LLM用于网络安全任务的适应性和可靠性方面的潜力。|
|**2025-10-30**|[From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning](http://arxiv.org/abs/2510.26336)|null|大语言模型（LLMs）擅长通用任务，但在经济学和心理学等需要深刻、有原则理解的专业领域表现不佳。为此，我们引入了ACER（自动化课程增强方案），它能将通用模型转化为领域专家，同时不牺牲其广泛能力。ACER首先通过为一个主题生成目录，然后以布鲁姆分类法为指导创建问答（QA）对，从而合成全面、教科书式的课程。这确保了系统的主题覆盖和逐步增加的难度。所合成的语料库用于采用交错课程安排的持续预训练，使学习在内容和认知维度上保持一致。使用Llama 3.2（1B和3B）进行的实验表明，在MMLU的专业子集上取得了显著提升。在微观经济学等基线模型表现不佳的挑战性领域，ACER将准确率提高了5个百分点。在所有目标领域，我们观察到宏观平均提高了3个百分点。值得注意的是，ACER不仅防止了灾难性遗忘，而且促进了积极的跨领域知识迁移，将非目标领域的性能提高了0.7个百分点。除了MMLU，ACER还使ARC和GPQA等知识密集型基准测试的性能提升了2个以上的绝对百分点，同时在通用推理任务上保持了稳定的性能。我们的结果表明，ACER为弥合LLM中关键的领域鸿沟提供了一种可扩展且有效的方案。|
|**2025-10-30**|[Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections](http://arxiv.org/abs/2510.26328)|null|在大型语言模型中实现持续学习仍然是一个尚未解决的关键研究挑战。在最近的一项公告中，一家前沿大型语言模型公司通过引入Agent Skills朝此方向迈出了一步，Agent Skills是一个基于存储在简单Markdown文件中的指令赋予代理新知识的框架。尽管Agent Skills可以是一个非常有用的工具，但我们发现它们在根本上是不安全的，因为它们使得极其简单的提示注入成为可能。我们演示了如何将恶意指令隐藏在长的Agent Skill文件和引用的脚本中，以窃取敏感数据，例如内部文件或密码。重要的是，我们展示了如何绕过一个流行的编码代理的系统级防护措施：一个带有“不再询问”选项的良性、特定任务的批准可能会蔓延到密切相关但有害的行为。总之，我们得出结论，尽管持续的研究努力和模型能力的扩展，前沿大型语言模型在现实场景中仍然容易受到非常简单的提示注入攻击。我们的代码可在 https://github.com/aisa-group/promptinject-agent-skills 获取。|
|**2025-10-29**|[Continual Low-Rank Adapters for LLM-based Generative Recommender Systems](http://arxiv.org/abs/2510.25093)|null|大语言模型（LLMs）在推荐系统中取得了强大性能，但随着用户、物品和用户偏好随时间演变，它们在持续学习方面面临挑战。现有的基于LoRA的持续学习方法主要侧重于保持在先前任务上的性能，但这忽略了推荐系统的独特本质：目标并非预测过去的偏好，当当前兴趣发生显著变化时，过时的偏好甚至会损害性能。为解决此问题，我们提出了PESO（Proximally rEgularized Single evolving lOra），一种在推荐系统中针对LoRA的持续适应方法。PESO引入了一种近端正则化器，将当前适配器锚定到其最近的冻结状态，使模型能够灵活地平衡适应性和保留性，并更好地捕获最近的用户行为。理论上，我们表明这种近端设计在LoRA子空间中提供了数据感知、方向性的指导。经验上，PESO始终优于现有的基于LoRA的持续学习方法。|
|**2025-10-26**|[Agentsway -- Software Development Methodology for AI Agents-based Teams](http://arxiv.org/abs/2510.23664)|null|智能体AI的兴起正在从根本上改变软件的设计、开发和维护方式。传统的软件开发方法论，如敏捷、看板、ShapeUp等，最初是为以人为中心的团队设计的，在自主AI智能体参与规划、编码、测试和持续学习的环境中，这些方法论越来越不足。为了弥补这一方法论空白，我们提出了“Agentsway”，这是一种新颖的软件开发框架，专为AI智能体作为一流协作者运行的生态系统而设计。Agentsway引入了一个结构化的生命周期，该生命周期以人类编排为中心，并实现了专业化AI智能体之间的隐私保护协作。该框架定义了规划、提示、编码、测试和微调智能体的不同角色，每个角色都促进了贯穿整个开发过程的迭代改进和自适应学习。通过整合经过微调的大型语言模型，这些模型在整个开发周期中利用来自不同智能体的输出和反馈，并将其作为回顾性学习过程的一部分，Agentsway增强了贯穿整个软件开发生命周期的领域特定推理和可解释的决策制定。通过协调使用多个经过微调的大型语言模型和高级推理模型，负责任的AI原则进一步嵌入到各个智能体中，从而确保决策制定做到平衡、透明和负责。这项工作通过形式化以智能体为中心的协作、整合隐私设计原则以及定义可衡量的生产力和信任指标，推动了软件工程的发展。Agentsway代表了迈向下一代AI原生、自我改进软件开发方法论的基础性一步。据我们所知，这是首次引入明确为基于AI智能体的软件工程团队设计的专用方法论的研究工作。|
|**2025-10-27**|[ISA-Bench: Benchmarking Instruction Sensitivity for Large Audio Language Models](http://arxiv.org/abs/2510.23558)|null|大型音频语言模型 (LALMs) 将声学感知与大型语言模型 (LLMs) 相结合，用于从音频中提取和理解多样化信息，引起了学术界和工业界的广泛关注。然而，现有的LALMs对指令的措辞方式高度敏感，这影响了 (i) 指令遵循率 和 (ii) 任务性能。然而，目前还没有任何基准能够系统且全面地评估这种敏感性。我们引入了ISA-Bench，这是一个动态基准，用于评估LALMs的指令敏感性，评估维度包括：指令描述、输出格式和任务构成。我们使用ISA-Bench评估了近期开源和专有的LALMs，在受控的指令变体下，分析了它们的遵循度和准确性。实验结果表明，即使是最先进的LALMs也存在显著的指令敏感性，导致其在基本的音频理解任务上性能下降。为了缓解这个问题，我们在一个专门构建的复杂指令变体数据集上对Qwen2-Audio进行了微调，取得了指令遵循性能的显著提升。然而，这也导致了不容忽视的灾难性遗忘：即模型在接触新的指令风格时，会失去一些之前掌握的任务能力。我们的基准为评估和改进LALMs的指令敏感性提供了一个标准化基础，强调了在实际应用中实现指令鲁棒的音频理解的重要性。|
|**2025-10-27**|[AQCat25: Unlocking spin-aware, high-fidelity machine learning potentials for heterogeneous catalysis](http://arxiv.org/abs/2510.22938)|null|大规模数据集使得高精度的机器学习原子间势（MLIPs）能够用于通用多相催化建模。然而，由于基础训练数据中存在空白，这些势能所能处理的范围存在一些局限性。为了扩展这些能力，我们引入了AQCat25，这是一个包含1350万个密度泛函理论（DFT）单点计算的补充数据集，旨在改善对自旋极化和/或更高保真度至关重要的系统的处理。我们还研究了将AQCat25等新数据集与更广泛的Open Catalyst 2020 (OC20) 数据集整合的方法，以创建自旋感知模型，同时不牺牲泛化能力。我们发现，直接在AQCat25上微调通用模型会导致对原始数据集知识的灾难性遗忘。相反，联合训练策略被证明能有效提高在新数据上的准确性，同时不牺牲通用性能。这种联合方法带来了一个挑战，因为模型必须从一个包含混合保真度计算和混合物理（自旋极化与非极化）的数据集中学习。我们表明，通过使用特征级线性调制（FiLM）等方法，显式地将模型基于系统特定的元数据进行条件化，可以成功解决这一挑战并进一步提高模型准确性。最终，我们的工作建立了一个有效的协议，用于弥合DFT保真度领域，以提升催化领域基础模型的预测能力。|
|**2025-10-28**|[Robust Uncertainty Quantification for Self-Evolving Large Language Models via Continual Domain Pretraining](http://arxiv.org/abs/2510.22931)|null|持续学习 (CL) 对于使自演化大型语言模型 (LLM) 在知识快速增长的情况下进行适应并保持有效性至关重要。然而，尽管其重要性，鲜有研究关注在持续学习下为LLM建立统计可靠性保证，尤其是在持续域预训练 (CDP) 环境中。保形预测 (CP) 已在为LLM提供正确性保证方面显示出潜力，但它在CDP中面临重大挑战：测试数据通常来源于未知或变化的域分布，在此情况下，CP可能无法再提供有效的保证。此外，当需要高覆盖率时，CP可能会为无法回答的查询生成过大的预测集，从而降低信息量。为解决这些挑战，我们引入了一种自适应拒绝和非可交换的保形预测框架。我们的方法首先使用基于Transformer的聚类来估计测试集中跨域问题的分布，然后相应地重新加权或重新采样校准数据。在此基础上，自适应拒绝保形预测允许LLM在其置信度或能力发生显著变化时选择性地拒绝回答。大量实验表明，我们的框架提高了在CDP场景下CP的有效性和可靠性。我们的代码可在以下网址获取：https://anonymous.4open.science/r/CPCL-8C12/|
|**2025-10-26**|[Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks](http://arxiv.org/abs/2510.22628)|null|本文介绍了一种名为Sentra-Guard的实时模块化防御系统，该系统用于检测并缓解针对大型语言模型（LLM）的越狱和提示注入攻击。该框架采用混合架构，结合了基于FAISS索引的SBERT嵌入表示（用于捕获提示的语义含义）和微调的Transformer分类器（专门用于区分良性与对抗性语言输入的机器学习模型）。它能够识别直接和混淆攻击向量中的对抗性提示。一项核心创新是分类器-检索器融合模块，该模块动态计算上下文感知风险分数，以根据提示的内容和上下文估计其对抗性的可能性。该框架通过一个语言无关的预处理层确保了多语言弹性，此组件自动将非英语提示翻译成英语进行语义评估，从而实现跨越100多种语言的一致检测。该系统包含一个人在回路（HITL）反馈循环，其中自动化系统做出的决策由人类专家进行审查，以在对抗性压力下实现持续学习和快速适应。Sentra-Guard维护一个不断演进的良性和恶意提示双标签知识库，从而提高了检测可靠性并减少了误报。评估结果显示，检测率为99.96%（AUC = 1.00，F1 = 1.00），攻击成功率（ASR）仅为0.004%。这优于LlamaGuard-2（1.3%）和OpenAI Moderation（3.7%）等领先基线。与黑盒方法不同，Sentra-Guard是透明的、可微调的，并兼容各种LLM后端。其模块化设计支持在商业和开源环境中进行可扩展部署。该系统确立了对抗性LLM防御领域的新最先进水平。|
|**2025-10-26**|[OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models](http://arxiv.org/abs/2510.22535)|null|多模态大语言模型（MLLMs）的进步加剧了对数据隐私的担忧，使得机器遗忘（MU），即有选择地移除已学习信息，成为一项关键需求。然而，现有针对MLLMs的MU基准受限于图像多样性不足、潜在不准确性和评估场景不充分，未能捕捉真实世界应用的复杂性。为了促进MLLMs遗忘技术的发展并缓解上述局限性，我们引入了OFFSIDE，一个基于足球转会谣言评估MLLMs中错误信息遗忘的新颖基准。这个手动整理的数据集包含80名球员的15.68K条记录，提供了一个综合框架，包含四个测试集以评估遗忘效果、泛化能力、实用性和鲁棒性。OFFSIDE支持选择性遗忘和纠正性再学习等高级设置，以及关键的单模态遗忘（仅遗忘文本数据）。我们对多种基线模型的广泛评估揭示了关键发现：（1）单模态方法（擦除基于文本的知识）在多模态谣言上失效；（2）遗忘效果主要由灾难性遗忘驱动；（3）所有方法都难以处理“视觉谣言”（谣言出现在图像中）；（4）已遗忘的谣言可以轻易恢复；（5）所有方法都容易受到提示攻击。这些结果揭示了当前方法的显著脆弱性，强调了对更鲁棒的多模态遗忘解决方案的需求。代码可在https://github.com/zh121800/OFFSIDE获取。|
|**2025-10-23**|[Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning](http://arxiv.org/abs/2510.21885)|null|大语言模型在良性数据上进行微调时，通常会失去之前对齐的安全行为，这是一种被称为灾难性遗忘的现象。先前工作表明，添加随机安全示例可以缓解这种影响，但目前尚不清楚哪些示例最有效。我们提出了一种行为感知采样框架，该框架根据两个互补因素选择安全示例：指令-响应行为（例如，拒绝与服从）和跨危害类别的语义多样性。系统评估表明，这种方法显著减少了有害输出，同时保持了有用性，仅使用了0.5%的额外训练数据就实现了有害性降低高达41%。这些结果凸显了目标数据选择如何能够提高大规模微调的安全性与效率。|
|**2025-10-24**|[PLAN: Proactive Low-Rank Allocation for Continual Learning](http://arxiv.org/abs/2510.21188)|null|持续学习（CL）要求模型在持续适应新任务的同时不遗忘以往知识。在这项工作中，我们提出了主动低秩分配（PLAN），这是一个将低秩适应（LoRA）扩展的框架，旨在实现持续学习设置中大型预训练模型的高效且抗干扰的微调。PLAN通过为每个任务引入正交基向量，并通过基于扰动的策略对其进行优化，从而主动管理任务特定子空间的分配，该策略旨在最大程度地减少与先前学习参数的冲突。此外，PLAN还整合了一种新颖的选择机制，该机制识别并分配对干扰敏感度最小的基向量，从而降低了损害以往知识的风险，同时保持对新任务的有效适应。在标准CL基准测试上的实验结果表明，PLAN始终优于现有方法，为使用基础模型的持续学习建立了新的最先进水平。|
|**2025-10-24**|[Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models](http://arxiv.org/abs/2510.21175)|null|预训练视觉-语言模型（VLMs），如CLIP，展现出卓越的零样本泛化能力，使其无需额外的任务特定训练即可部署到广泛的现实世界任务中。然而，在实际部署场景中，随着环境的变化或新类别的出现，这些模型不可避免地会面临分布偏移和新任务。在这种背景下，静态的零样本能力是不足的，并且对允许模型随着时间进行适应同时避免灾难性遗忘的持续学习方法的需求日益增长。我们引入了NuSA-CL（用于持续学习的零空间适应），这是一个旨在解决这一挑战的轻量级、无内存的持续学习框架。NuSA-CL采用低秩适应，并将任务特定的权重更新限制在模型当前参数的近似零空间内。这种策略最大限度地减少了对先前习得知识的干扰，有效地保留了原始模型的零样本能力。与依赖于重放缓冲区或昂贵蒸馏的方法不同，NuSA-CL施加了最小的计算和内存开销，使其在资源受限的现实世界持续学习环境中具有部署的实用性。实验表明，我们的框架不仅有效保留了零样本迁移能力，而且在持续学习基准上取得了极具竞争力的表现。这些结果将NuSA-CL定位为在现实世界应用中持续进化的零样本VLM的一种实用且可扩展的解决方案。|
|**2025-10-23**|[RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging](http://arxiv.org/abs/2510.20479)|null|我们揭示了大语言模型（LLM）的内部表征可作为所学知识的可靠代理，并提出了RECALL，一个新颖的、表征感知的模型合并框架，用于无需访问历史数据的持续学习。RECALL通过聚类的典型样本上的层级隐藏表征计算模型间相似性，并执行自适应的、分层的参数融合以对齐模型间的知识。这种设计使得在浅层中保留域通用特征，同时在深层中实现任务特定适应。与以往需要任务标签或带来性能权衡的方法不同，RECALL实现了无缝的多领域集成和强大的抗灾难性遗忘能力。跨越五个自然语言处理（NLP）任务和多个持续学习场景的大量实验表明，RECALL在知识保留和泛化方面均优于基线，为不断发展的大语言模型提供了一种可扩展且无需数据的解决方案。|
|**2025-10-22**|[LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation](http://arxiv.org/abs/2510.19988)|null|尽管大语言模型（LLM）具有广泛的适用性，但它们对概率推理的依赖使其容易出现错误，例如生成事实中的幻觉以及自然语言理解（NLU）任务中输出结构的不一致。相比之下，符号NLU系统提供基于精心策划的词典、语义资源以及句法和语义解释规则的可解释理解，它们生成的关系表示可用于精确推理和规划，以及增量可调试学习。然而，符号NLU系统在覆盖范围上往往比LLM更受限，并且需要稀缺的知识表示和语言学技能才能扩展和维护。本文探索了一种混合方法，该方法将LLM的广泛覆盖语言处理与符号NLU生成结构化关系表示的能力相结合，以期兼具两种方法的优点。我们使用LLM进行复述和文本简化以提供广泛覆盖，并将其作为信息来源以更自动化地填补知识空白。我们使用符号NLU生成可用于推理和增量学习的表示。我们通过从常识科学文本中提取和解释数量及因果定律的任务，以及仅使用符号方法和仅使用LLM的管道来评估这种方法。我们的结果表明，我们的混合方法显著优于仅使用符号方法的管道。|
|**2025-10-22**|[GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters](http://arxiv.org/abs/2510.19778)|null|稀疏微调技术通过仅调整模型参数的稀疏子集，使大型语言模型（LLMs）适应下游任务。然而，稀疏适应的有效性取决于最优选择待微调的模型参数。在这项工作中，我们引入了一种新颖的稀疏微调技术，命名为GaLLoP：基于梯度的低幅度参数稀疏学习，它仅微调那些在下游任务上具有最大梯度幅度和最小预训练幅度的模型参数，直观上优先考虑那些与任务高度相关但对预训练知识干扰最小的参数。我们以LLaMA3 8B和Gemma 2B作为基础模型的实验表明，GaLLoP持续改进或媲美通过使用其他领先的参数高效微调技术（包括LoRA、DoRA和SAFT）获得的分布内以及分布外性能。我们的分析表明，GaLLoP减轻了灾难性遗忘和任务数据的记忆化，因为重要的预训练参数保持不变，并相对于其他微调技术稳定了性能，在大多数随机种子下均能稳健泛化。|
|**2025-10-22**|[Conditions for Catastrophic Forgetting in Multilingual Translation](http://arxiv.org/abs/2510.19546)|null|多语言基础模型在特定语言上进行微调时，通常会导致灾难性遗忘，从而降低模型在微调中未见语言上的性能。尽管这种现象已被广泛记录，但现有文献关于遗忘何时发生的结果却零散不一。为解决这种模糊性，我们以机器翻译作为试验平台，进行了一项系统的实证研究，旨在识别在多语言微调中触发灾难性遗忘的条件。通过针对不同模型架构、数据规模和微调方法的受控实验，我们发现模型与数据规模之间的相对比例是遗忘的主要决定因素。此外，我们证明模型的指令遵循能力对于保留多语言知识而言更为关键，而非其架构。与假设相反，参数高效微调在缓解遗忘方面并未比全量微调展现出明显的优势。最后，我们表明跨语言对齐可以缓解遗忘，同时促进对未见目标语言的正向迁移。|
|**2025-10-22**|[KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints](http://arxiv.org/abs/2510.19316)|null|大规模多模态模型在其预训练权重中编码了大量的事实知识。然而，其知识是静态且有限的，无法跟上现实世界的发展，这阻碍了持续的知识获取。因此，有效的知识注入变得至关重要，涉及两个目标：知识适应（注入新知识）和知识保留（保存旧知识）。现有方法往往难以学习新知识并遭受灾难性遗忘。为解决这一问题，我们提出了 KORE，一种知识导向的增强与约束的协同方法，用于将新知识注入大规模多模态模型同时保留旧知识。与一般的文本或图像数据增强不同，KORE 自动将单个知识项转化为结构化和全面的知识，以确保模型准确学习新知识，从而实现精确适应。同时，KORE 将先前的知识存储在 LMM 线性层激活的协方差矩阵中，并通过将原始权重投影到该矩阵的零空间来初始化适配器，定义了一个最小化对先前知识干扰的微调方向，从而实现了强大的保留能力。在包括 LLaVA-v1.5-7B、LLaVA-v1.5-13B 和 Qwen2.5-VL-7B 在内的各种大规模多模态模型上进行的广泛实验表明，KORE 实现了卓越的新知识注入性能并有效缓解了灾难性遗忘。|
|**2025-10-21**|[Prior-informed optimization of treatment recommendation via bandit algorithms trained on large language model-processed historical records](http://arxiv.org/abs/2510.19014)|null|当前医疗实践依赖于标准化的治疗框架和经验性方法，这些方法忽视了个体患者差异，从而导致次优的健康结果。我们开发了一个综合系统，该系统整合了大语言模型（LLMs）、条件表格生成对抗网络（CTGAN）、T-学习器反事实模型以及上下文多臂老虎机方法，以提供定制化的、数据驱动的临床建议。该方法利用LLMs将非结构化医疗叙述处理成结构化数据集（准确率达93.2%），使用CTGANs生成逼真的合成患者数据（通过双样本验证准确率为55%），部署T-学习器预测患者特定的治疗反应（准确率达84.3%），并整合了先验信息驱动的上下文多臂老虎机，通过有效平衡新可能性的探索与现有知识的利用来增强在线治疗选择。在III期结肠癌数据集上的测试表明，我们的KernelUCB方法在5,000轮中获得了0.60-0.61的平均奖励分数，超越了其他参考方法。这个综合系统克服了在线学习环境中的冷启动限制，提高了计算效率，并构成了迈向适应特定患者特征的个性化医疗的显著进展。|
|**2025-10-21**|[Bayesian Low-Rank Factorization for Robust Model Adaptation](http://arxiv.org/abs/2510.18723)|null|大型语音基础模型在许多领域取得了强大的性能，但它们通常需要进行适应性调整以处理本地需求，例如语码转换（即说话者在同一话语中混合使用多种语言）。直接微调这些模型有过拟合目标域并覆盖基础模型广泛能力的风险。为了解决这一挑战，我们探索了用于语音基础模型的贝叶斯因子化适配器，该适配器将先验设置为接近零，以实现更稀疏的适应矩阵，从而在适应特定领域的同时保留通用性能。我们将我们的方法应用于 Whisper 模型，并在不同的多语言语码转换场景中进行了评估。我们的结果表明，该方法仅导致最小的适应损失，同时显著减少了基础模型的灾难性遗忘。与 LoRA 相比，我们的方法实现了 54% 的回溯增益，而新域上的性能仅下降了 4%。这些发现强调了贝叶斯适应在微调语音基础模型时不牺牲泛化能力的有效性。|
|**2025-10-21**|[A Compositional Paradigm for Foundation Models: Towards Smarter Robotic Agents](http://arxiv.org/abs/2510.18608)|null|基础模型的诞生在从语言到视觉再到机器人控制等广泛任务中带来了前所未有的成果。这些模型能够处理海量数据，并能提取和发展出丰富的表征，这些表征可应用于不同领域和模态。然而，它们在不从头开始重新训练整个模型的情况下，适应动态的现实世界场景时仍然存在问题。在这项工作中，我们提出了持续学习和组合性原则的应用，以促进开发更灵活、高效和智能的人工智能解决方案。|
|**2025-10-22**|[PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of Multi-turn Exploits](http://arxiv.org/abs/2510.17947)|null|大型语言模型（LLMs）正以惊人的速度发展。随着智能体工作流的出现，多轮对话已成为LLM完成长而复杂任务的事实上的交互模式。尽管LLM的能力持续提升，但它们仍然越来越容易受到越狱攻击，尤其是在多轮场景中，恶意意图可以通过对话巧妙地植入以产生恶意结果。虽然单轮攻击已被广泛探索，但适应性、效率和有效性仍然是其多轮对应物的关键挑战。为了解决这些不足，我们提出了PLAGUE，一个受终身学习智能体启发的新颖即插即用框架，用于设计多轮攻击。PLAGUE将多轮攻击的生命周期分解为三个精心设计的阶段（启动器、规划器和终结器），这使得对多轮攻击家族能够进行系统性且信息丰富的探索。评估结果表明，使用PLAGUE设计的红队智能体实现了最先进的越狱结果，在更少或相当的查询预算下，将主流模型的攻击成功率（ASR）提高了30%以上。特别是，PLAGUE使得OpenAI的o3上（基于StrongReject）的ASR达到81.4%，在Claude的Opus 4.1上达到67.3%，这两款模型在安全文献中被认为对越狱具有高度抵抗力。我们的工作提供了工具和见解，以理解计划初始化、上下文优化和终身学习在构建多轮攻击中的重要性，从而进行全面的模型漏洞评估。|
|**2025-10-20**|[PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of Multi-turn Exploits](http://arxiv.org/abs/2510.17947)|null|大语言模型 (LLM) 正以惊人的速度不断发展。随着智能体工作流的出现，多轮对话已成为与LLM交互以完成漫长而复杂任务的事实标准模式。尽管LLM的能力持续提升，但它们也越来越容易受到越狱攻击，尤其是在多轮场景中，恶意意图可以通过对话巧妙地注入，从而产生有害结果。虽然单轮攻击已得到广泛探索，但其多轮对应攻击的适应性、效率和有效性仍是主要挑战。为了弥补这些不足，我们提出了PLAGUE，一个受终身学习智能体启发、用于设计多轮攻击的新颖即插即用框架。PLAGUE将多轮攻击的生命周期分解为三个精心设计的阶段（引导阶段、规划阶段和完成阶段），从而能够对多轮攻击家族进行系统化且信息丰富的探索。评估结果表明，使用PLAGUE设计的红队智能体取得了最先进的越狱结果，在更少或相当的查询预算下，将主流模型的攻击成功率 (ASR) 提高了30%以上。特别地，PLAGUE使得对OpenAI的o3模型和Claude的Opus 4.1模型（这两种模型在安全文献中被认为对越狱具有高度抵抗力）的ASR（基于StrongReject指标）分别达到81.4%和67.3%。我们的工作提供了工具和见解，以理解计划初始化、上下文优化和终身学习在构建多轮攻击以进行全面模型漏洞评估方面的重要性。|
|**2025-10-20**|[Efficient Toxicity Detection in Gaming Chats: A Comparative Study of Embeddings, Fine-Tuned Transformers and LLMs](http://arxiv.org/abs/2510.17924)|null|本文对在线游戏聊天中自动有害内容检测的自然语言处理（NLP）方法进行了全面的比较分析。对带有嵌入的传统机器学习模型、采用零样本和少样本提示的大型语言模型（LLMs）、微调的Transformer模型以及检索增强生成（RAG）方法进行了评估。评估框架从分类准确率、处理速度和计算成本三个关键维度进行评估。本文提出了一种混合审核系统架构，该架构通过自动化检测优化人工审核员的工作量，并融入了持续学习机制。实验结果表明，不同方法之间存在显著的性能差异，其中微调后的DistilBERT在准确率-成本权衡方面实现了最优表现。这些发现为在动态在线游戏环境中部署经济高效、高效率的内容审核系统提供了经验证据。|
|**2025-10-20**|[Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models](http://arxiv.org/abs/2510.17705)|null|大语言模型（LLMs）具备出色的泛化能力，但在多任务适应方面存在困难，尤其是在平衡知识保留与任务特定专业化方面。传统的微调方法面临灾难性遗忘和大量的资源消耗，而现有的参数高效方法在复杂多任务场景中表现不佳。为了解决这个问题，我们提出了上下文注意力调制（CAM），这是一种新颖的机制，能够动态调制LLMs中自注意力模块的表示。CAM在增强任务特定特征的同时保留了通用知识，从而促进了更有效和高效的适应。为了实现有效的多任务适应，我们将CAM整合到我们的混合上下文注意力调制（HyCAM）框架中，该框架结合了一个共享的、全参数的CAM模块与多个专门的、轻量级的CAM模块，并通过动态路由策略进行增强，以实现自适应的知识融合。在异构任务上进行的广泛实验，包括问答、代码生成和逻辑推理，表明我们的方法显著优于现有方法，平均性能提升了3.65%。实现的代码和数据已公开，以便于复现，网址为https://github.com/Applied-Machine-Learning-Lab/HyCAM。|
|**2025-10-20**|[MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems](http://arxiv.org/abs/2510.17281)|null|扩大数据、参数和测试时计算一直是改进大型语言模型系统（LLMsys）的主流方法，但由于高质量数据逐渐枯竭以及更多计算资源消耗带来的边际收益递减，它们的上限几乎已达到。受人类和传统人工智能系统从实践中学习能力的启发，为LLMsys构建记忆和持续学习框架已成为近期文献中一个重要且热门的研究方向。然而，现有的大型语言模型记忆基准往往侧重于评估系统在具有长篇输入的同质阅读理解任务上的表现，而非测试其在服务时间内从累积的用户反馈中学习的能力。因此，我们提出了一个用户反馈模拟框架和一个涵盖多个领域、语言和任务类型的全面基准，以评估LLMsys的持续学习能力。实验表明，最先进基线的有效性和效率远不能令人满意，我们希望该基准能为未来关于大型语言模型记忆和优化算法的研究铺平道路。|
|**2025-10-19**|[Online Learning Defense against Iterative Jailbreak Attacks via Prompt Optimization](http://arxiv.org/abs/2510.17006)|null|利用模型之前的响应来指导每次新迭代的迭代越狱方法，即反复重写并输入提示到大型语言模型 (LLMs) 以诱导有害输出，已被证明是一种高效的攻击策略。尽管这是一种针对LLMs及其安全机制的有效攻击策略，但现有防御措施未能主动打破这种动态试错循环。在本研究中，我们提出了一种新颖的框架，能够通过在线学习动态更新其防御策略，以响应迭代越狱方法中的每个新提示。利用有害越狱生成提示与典型无害提示之间的区别，我们引入了一种基于强化学习的方法，该方法优化提示以确保对无害任务给出适当响应，同时明确拒绝有害提示。此外，为了抑制在攻击过程中探索的狭窄范围的部分输入重写所导致的过拟合，我们引入了过去方向梯度阻尼 (PDGD)。在三个LLMs上进行的实验表明，我们的方法在对抗五种迭代越狱方法方面显著优于五种现有防御方法。此外，我们的结果表明，我们的提示优化策略同时提高了无害任务的响应质量。|
|**2025-10-18**|[RAVEN: Robust Advertisement Video Violation Temporal Grounding via Reinforcement Reasoning](http://arxiv.org/abs/2510.16455)|null|广告视频违规检测对于确保平台合规性至关重要，但现有方法在精确时间定位、噪声标注和有限泛化能力方面面临挑战。我们提出了RAVEN，这是一种新颖的框架，它将课程强化学习与多模态大语言模型（MLLMs）相结合，以增强违规检测的推理和认知能力。RAVEN采用渐进式训练策略，结合了精确标注和粗略标注数据，并利用群组相对策略优化（GRPO）来发展出涌现的推理能力，而无需显式的推理标注。多层级复杂的奖励机制确保了精确的时间定位和一致的类别预测。在工业数据集和公共基准上的实验表明，RAVEN在违规类别准确性和时间区间定位方面取得了卓越的性能。我们还设计了一个流水线将RAVEN部署到在线广告服务中，在线A/B测试进一步验证了其实用性，并在精确率和召回率方面取得了显著提升。RAVEN还展示出强大的泛化能力，缓解了与监督微调相关的灾难性遗忘问题。|
|**2025-10-17**|[PolySkill: Learning Generalizable Skills Through Polymorphic Abstraction](http://arxiv.org/abs/2510.15863)|null|大语言模型（LLMs）正超越静态用途，开始赋能能够在与外部环境交互过程中持续学习的智能体。例如，智能体可以在浏览网页或切换新工具时学习可复用技能。然而，现有的技能学习方法往往会创建过度专注于单一网站且难以泛化的技能。我们引入了PolySkill，这是一个新框架，使智能体能够学习可泛化和可组合的技能。其核心思想受软件工程中多态性的启发，即将技能的抽象目标（它完成什么）与其具体实现（它如何执行）解耦。实验表明，我们的方法（1）在已知网站上将技能复用率提高了1.7倍，（2）在Mind2Web上将成功率提高了9.4%，在未知网站上提高了13.9%，同时将步骤减少了20%以上。（3）在没有指定任务的自我探索设置中，我们的框架提高了提出任务的质量，并使智能体能够学习适用于不同站点的泛化技能。通过使智能体能够识别和完善自身目标，PolySkill增强了智能体学习更优课程的能力，从而相比基线方法获得了更具泛化性的技能。这项工作为构建能够在自适应环境中持续学习的智能体提供了一条实用路径。我们的研究结果表明，将技能的目标与其执行分离是迈向开发能够在开放网络中持续学习和泛化的自主智能体的一个关键步骤。|
|**2025-10-17**|[Paper2Web: Let's Make Your Paper Alive!](http://arxiv.org/abs/2510.15842)|null|学术项目网站在清晰呈现核心内容并实现直观导航和交互时，能更有效地传播研究成果。然而，当前的方法，如大型语言模型（LLM）直接生成、模板或直接HTML转换，难以生成布局感知且具有交互性的网站，并且缺乏针对此任务的全面评估套件。在本文中，我们引入了Paper2Web，这是一个用于评估学术网页生成的基准数据集和多维度评估框架。它整合了基于规则的指标，如连通性、完整性，以及经过人工验证的“LLM即法官”评估方法（涵盖交互性、美观性和信息量），以及PaperQuiz，用于衡量论文级知识保留度。我们进一步提出了PWAgent，这是一个自主流程，能将科学论文转换为交互式且富含多媒体的学术主页。该代理通过旨在增强强调、平衡和呈现质量的MCP工具，迭代地优化内容和布局。我们的实验表明，PWAgent在保持低成本的同时，始终以显著优势优于基于模板的网页和arXiv/alphaXiv版本等端到端基线，并在学术网页生成领域达到了帕累托前沿。|
|**2025-10-15**|[VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models](http://arxiv.org/abs/2510.13808)|null|大规模视觉-语言模型（VLM）在通用视觉推理任务中表现出色，但当应用于与预训练数据存在显著分布偏移的新领域时，其性能会急剧下降。现有的域适应方法通常微调VLM的不同组件，但这却常导致有限的域特定特征学习或对先前能力的灾难性遗忘。为解决这些问题，我们引入了视觉上下文探测（VisCoP），它通过一组紧凑的可学习视觉探针来增强VLM的视觉编码器。这些探针实现了高效的域特定适应，同时对预训练参数的修改最小。我们在三种具有挑战性的域适应设置上评估了VisCoP：跨视角（从外视角到自我视角）、跨模态（从RGB到深度）和跨任务（从人类理解到机器人控制）。实验表明，VisCoP始终优于现有的适应策略，在目标域上实现了卓越的性能，同时有效保留了源域知识。|
|**2025-10-16**|[ReMindRAG: Low-Cost LLM-Guided Knowledge Graph Traversal for Efficient RAG](http://arxiv.org/abs/2510.13193)|null|知识图谱（KGs）凭借其结构化表示能力，为增强检索增强生成（RAG）系统提供了有前景的途径，从而促成了KG-RAG系统的发展。然而，现有方法往往难以在系统有效性和成本效率之间实现有效协同，导致要么性能不尽如人意，要么LLM提示词和推理时间过长。为此，本文提出了REMINDRAG，它采用LLM引导的图遍历，该遍历具有节点探索、节点利用，以及最重要的是记忆回放功能，以提高系统有效性和成本效率。具体而言，REMINDRAG将遍历经验记忆在知识图谱的边嵌入中，这类似于LLM在其参数中“记忆”世界知识的方式，但以一种免训练的方式实现。我们从理论和实验上证实了REMINDRAG的有效性，证明了其在各种基准数据集和LLM骨干网络上优于现有基线方法。我们的代码可在https://github.com/kilgrims/ReMindRAG获取。|
|**2025-10-14**|[OPLoRA: Orthogonal Projection LoRA Prevents Catastrophic Forgetting during Parameter-Efficient Fine-Tuning](http://arxiv.org/abs/2510.13003)|null|低秩适配（LoRA）实现了大语言模型的高效微调，但当学习到的更新干扰到编码了重要预训练知识的主导奇异方向时，会存在灾难性遗忘问题。我们提出正交投影LoRA (OPLoRA)，这是一种有理论基础的方法，旨在通过双边正交投影防止这种干扰。通过SVD分解冻结权重，OPLoRA使用投影 $P_L = I - U_k U_k^\top$和$P_R = I - V_k V_k^\top$将LoRA更新限制在完全位于前k个奇异子空间的正交补空间内。我们证明这种构造精确地保留了前k个奇异三元组，为知识保留提供了数学保证。为了量化子空间干扰，我们引入了$\rho_k$ ，一个衡量更新与主导方向对齐程度的指标。在常识推理、数学和代码生成任务上的广泛实验证明，OPLoRA在LLaMA-2 7B和Qwen2.5 7B模型上显著减少了遗忘，同时保持了有竞争力的任务特定性能，确立了正交投影作为参数高效微调中知识保留的有效机制。|
|**2025-10-14**|[CoRA: Covariate-Aware Adaptation of Time Series Foundation Models](http://arxiv.org/abs/2510.12681)|null|时间序列基础模型（TSFM）凭借其模型容量、可扩展性和零样本泛化能力展现出显著影响。然而，由于变量间依赖关系的异质性以及主干网络在大规模多变量数据集上的可扩展性问题，大多数TSFM通常在单变量时间序列上进行预训练。这一局限性使得它们在现实世界的预测任务中无法感知来自多样化协变量的关键信息。为了进一步提升TSFM的性能，我们提出了一种通用的协变量感知适应（CoRA）框架。它利用基础模型的预训练主干网络，同时有效整合来自时间序列、语言和图像等不同模态的外部协变量，以提高预测质量。在技术上，CoRA在适应过程中保持了初始化等效性和参数一致性。在将基础模型的预留主干网络作为冻结的特征提取器后，经验证明来自基础模型的输出嵌入比原始数据更具信息量。此外，CoRA采用一种新颖的格兰杰因果嵌入（GCE）来自动评估协变量相对于目标变量的因果可预测性。我们将这些加权嵌入与零初始化条件注入机制相结合，避免了预训练基础模型的灾难性遗忘，并逐步整合外部信息。大量实验表明，TSFM的CoRA在全量或少量样本训练下，超越了最先进的协变量感知深度预测器，并在协变量感知预测上实现了31.1%的MSE降低。与其他适应方法相比，CoRA对各种先进TSFM表现出强大的兼容性，并将协变量的范围扩展到其他模态，为TSFM的应用提供了一个实用的范式。|
|**2025-10-14**|[MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant](http://arxiv.org/abs/2510.12245)|null|将分子图结构与大语言模型（LLMs）有效整合是药物发现中的一个关键挑战。大多数现有的多模态对齐方法通常通过同时微调LLM或添加静态适配器来处理这些结构。然而，这些方法有两个主要局限性：（1）它们优化了所有分子输入共享的参数空间，限制了模型捕获实例特定结构特征的能力；（2）为分子任务微调LLM可能导致灾难性遗忘，损害其通用推理能力。在本文中，我们没有采用静态的面向任务的适配，而是提出了一种针对每个分子即时进行的实例特定参数空间对齐方法。为此，我们引入了分子感知低秩适配（MoRA），它为每个输入分子图生成一组独特的低秩适配权重。这些权重随后被动态注入到一个冻结的LLM中，使模型能够根据每个分子输入的结构调整其推理，同时保留了LLM的核心知识。大量实验表明，在化学反应预测和分子描述生成等关键分子任务上，MoRA的实例特定动态适配优于静态适配的基线方法，包括在反应预测精确匹配方面相对提高了14.1%，以及在量子性质预测方面错误率降低了22%。代码可在https://github.com/jk-sounds/MoRA获取。|
|**2025-10-13**|[ $How^{2}$: How to learn from procedural How-to questions](http://arxiv.org/abs/2510.11144)|null|智能体在面对规划问题时，可以利用“如何做”问题的答案来减少不确定性并填补知识空白，从而帮助其解决当前和未来的任务。然而，这类问题开放式的特性——“我如何做X？”的有效答案范围从可执行动作到X的子目标的高级描述——使得AI智能体难以提出，也使AI专家难以回答，从而难以支持高效规划。我们引入了$How^{2}$，一个记忆智能体框架，它使智能体能够提出“如何做”问题、存储答案，并在交互式环境中重复利用它们进行终身学习。我们在Plancraft（一个Minecraft合成环境，智能体必须通过操纵库存物品来完成装配任务）中评估了我们的方法。通过使用在不同抽象级别（从可执行动作序列到高级子目标描述）提供答案的教师模型，我们表明终身学习智能体从抽象且与当前状态解耦的答案中获益最大。$How^{2}$ 为基于大型语言模型（LLM）的智能体提供了一种通过在交互式环境中提问来随时间提高其规划能力的方法。|
|**2025-10-11**|[ADEPT: Continual Pretraining via Adaptive Expansion and Dynamic Decoupled Tuning](http://arxiv.org/abs/2510.10071)|null|传统用于大语言模型 (LLM) 领域适应的持续预训练 (CPT) 通常面临灾难性遗忘和有限领域容量的问题。现有策略采用层扩展，引入额外的可训练参数以适应新知识。然而，统一的扩展和更新仍然纠缠了通用学习和领域学习，损害了其有效性。我们的初步研究表明，LLM 表现出功能特化，其中层和单元差异化地编码了对通用领域至关重要的能力，这表明参数扩展和优化应是功能感知的。我们因此提出了 ADEPT，即用于持续预训练的自适应扩展和动态解耦微调，这是一个用于领域适应性 CPT 的两阶段框架。ADEPT 首先执行通用能力引导的选择性层扩展，复制对通用领域最不重要的层，以增加表示能力，同时最大限度地减少对通用知识的干扰。然后它应用自适应单元级解耦微调，根据其通用领域重要性解耦扩展层内的参数单元，并分配不对称的学习率以平衡知识注入和保留。在数学和医学基准上的实验表明，ADEPT 在通用领域和目标领域分别比全参数 CPT 性能高出 5.76% 和 5.58%，而仅需调整 15% 的参数，且训练时间不到 50%。消融研究、理论分析和扩展调查进一步证明了目标性扩展和解耦优化的必要性，为高效且鲁棒的领域适应性 CPT 提供了新原则。我们的代码已在 https://github.com/PuppyKnightUniversity/ADEPT 开源。|
|**2025-10-11**|[MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](http://arxiv.org/abs/2510.08540)|**[link](https://github.com/PhoenixZ810/MM-HELIX)**|尽管当前多模态大语言模型（MLLMs）在数学和逻辑等推理任务中已展现出熟练能力，但它们进行长链式反思性推理的能力（这是解决复杂现实世界问题的先决条件）仍未得到充分探索。在这项工作中，我们首先进行了一项广泛的实证研究以评估这种能力。利用精心设计的数据合成引擎，我们构建了多模态基准MM-HELIX，该基准包含1,260个样本，这些样本来自42个需要迭代思维和回溯的挑战性合成任务。在该基准上的实证结果表明，现有MLLMs在长链式反思性推理方面表现出显著的性能不足。为了解决这一局限性，我们生成了后训练数据，并进一步探索了利用此类数据的学习范式。我们首先开发了“步骤启发式响应生成”管道，以创建MM-HELIX-100K，这是一个包含10万条高质量反思性推理轨迹的大规模数据集，用于指令微调阶段。考虑到标准强化学习由于稀疏奖励信号以及在监督微调后出现的灾难性遗忘，在复杂任务上表现不佳，我们提出了自适应混合策略优化（AHPO），这是一种新颖的训练策略，它将离线监督和在线优化动态统一到一个阶段。这种策略使模型能够在奖励稀疏时从专家数据中学习，并在熟练后进行独立探索。将其应用于Qwen2.5-VL-7B基线模型时，我们的方法在MM-HELIX基准上实现了18.6%的准确率提升，并在通用数学和逻辑任务上平均性能提升5.7%，展现出强大的泛化能力。我们的工作表明，MLLMs中的反思性推理可以被有效地学习和泛化，为开发更强大的MLLMs铺平了道路。|
|**2025-10-09**|[MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](http://arxiv.org/abs/2510.08540)|**[link](https://github.com/PhoenixZ810/MM-HELIX)**|当前多模态大语言模型（MLLMs）已在数学和逻辑等推理任务中展现出熟练能力，但其长链反思性推理能力（解决复杂现实世界问题的先决条件）仍未得到充分探索。在这项工作中，我们首先进行了一项广泛的实证研究来评估这种能力。我们利用精心设计的数据合成引擎，构建了MM-HELIX，这是一个多模态基准，包含1,260个样本，涵盖42个需要迭代思维和回溯的挑战性合成任务。该基准上的实证结果表明，现有MLLMs在长链反思性推理方面存在显著的性能缺陷。为了解决这一局限性，我们生成了训练后数据，并进一步探索了利用此类数据的学习范式。我们首先开发了“步进式响应生成”流程，创建了MM-HELIX-100K，一个包含10万条高质量反思性推理轨迹的大规模数据集，用于指令微调阶段。鉴于标准强化学习由于稀疏奖励信号和监督微调后的灾难性遗忘而在复杂任务上失败，我们提出了自适应混合策略优化（AHPO），这是一种新颖的训练策略，它动态地将离线监督和在线优化统一到一个阶段。该策略使模型能够在奖励稀疏时从专家数据中学习，并在熟练后进行独立探索。当应用于Qwen2.5-VL-7B基线模型时，我们的方法在MM-HELIX基准上取得了18.6%的准确率提升，并在一般数学和逻辑任务上平均性能提升5.7%，展现出强大的泛化能力。我们的工作表明，MLLMs中的反思性推理可以被有效地学习和泛化，为开发更强大的MLLMs铺平了道路。|
|**2025-10-09**|[DACIP-RC: Domain Adaptive Continual Instruction Pre-Training via Reading Comprehension on Business Conversations](http://arxiv.org/abs/2510.08152)|null|大型语言模型（LLMs）的快速发展使其能够在现实世界的工业场景中应用于各种自然语言处理任务。然而，大规模LLMs的高推理成本使其部署不切实际，因此需要使用更小的模型。尽管效率更高，但更小的LLMs在不同领域中缺乏稳健的零样本指令遵循能力，限制了它们对动态用户需求的适应性。传统的微调方法通过引入灾难性遗忘加剧了这个问题，降低了模型对未见任务的泛化能力。在本文中，我们提出了通过阅读理解的领域自适应持续指令预训练（DACIP-RC），这是一种持续预训练技术，旨在增强更小LLMs在商业对话任务中的领域适应性。与依赖下一词元预测的传统预训练方法不同，DACIP-RC通过对对话记录进行阅读理解来生成多样化的任务指令和响应，从而实现更好的指令泛化。我们的实证评估表明，DACIP-RC显著提高了在广泛商业对话任务中的零样本泛化能力，包括会议摘要、行动项生成和通话目的识别。据我们所知，这是首次将指令预训练应用于商业对话数据的工作，为行业如何利用专有数据集进行领域适应提供了见解。|
|**2025-10-09**|[Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks](http://arxiv.org/abs/2510.08002)|**[link](https://github.com/KnowledgeXLab/MUSE)**|大型语言模型已在多个领域展现出卓越能力，但将其部署为AI智能体以执行真实世界的长周期任务时，仍然存在重大挑战。现有的LLM智能体面临一个关键局限：它们是运行时静态的，无法从经验中学习，缺乏积累知识和持续在工作中改进的能力。为解决这一挑战，我们提出了MUSE，这是一种新颖的智能体框架，引入了一种经验驱动的、自进化的系统，其核心是一个分层记忆模块。MUSE组织了不同层次的经验，并利用这些经验来规划和执行跨多个应用的长周期任务。在每次子任务执行后，智能体自主地反思其轨迹，将原始轨迹转换为结构化经验，并将其重新整合到记忆模块中。这种机制使得智能体能够超越其静态的预训练参数进行进化，促进了持续学习和自我进化。我们在长周期生产力基准TAC上评估了MUSE，它仅使用轻量级的Gemini-2.5 Flash模型就以显著优势取得了新的SOTA性能。充分的实验表明，随着智能体自主积累经验，它展现出越来越卓越的任务完成能力，以及强大的持续学习和自我进化能力。此外，MUSE积累的经验表现出强大的泛化能力，使其能够在新任务上实现零样本改进。MUSE为能够实现真实世界生产力任务自动化的AI智能体建立了一个新范式。|
|**2025-10-08**|[OpenJAI-v1.0: An Open Thai Large Language Model](http://arxiv.org/abs/2510.06847)|null|我们推出了OpenJAI-v1.0，一个基于Qwen3-14B模型开发的开源泰语和英语大型语言模型。我们的工作致力于通过精心整理的数据，在指令遵循、长文本理解和工具使用这三个关键用例中提升其在实际任务上的性能。评估结果表明，OpenJAI-v1.0提升了其基础模型的能力，并在多样化的基准测试中超越了其他领先的开源泰语模型，同时避免了灾难性遗忘。OpenJAI-v1.0已公开发布，作为泰语AI社区的又一个替代性自然语言处理资源。|
|**2025-10-08**|[Distilling Lightweight Language Models for C/C++ Vulnerabilities](http://arxiv.org/abs/2510.06645)|null|现代软件系统日益增长的复杂性加剧了安全漏洞的普遍性，带来了严重的安全泄露和巨大的经济损失风险。因此，鲁棒的代码漏洞检测对软件安全至关重要。尽管大型语言模型（LLM）在自然语言处理方面表现出卓越的能力，但它们在自动化代码漏洞检测方面的潜力仍未得到充分探索。本文提出了FineSec，一个通过知识蒸馏技术利用大型语言模型（LLM）以实现在C/C++代码库中高效准确地识别漏洞的新颖框架。FineSec利用知识蒸馏将大型教师模型的专业知识转移到紧凑型学生模型中，以最小的计算成本实现高精度。通过将数据准备、训练、评估和持续学习整合到一个统一的、单任务工作流程中，FineSec提供了一种精简的方法。在C/C++代码库上的广泛评估证明了FineSec在识别复杂漏洞和逻辑缺陷方面优于基础模型和更大的LLM，将其确立为一种针对实际软件安全的实用且可扩展的解决方案。为了便于复现，数据集、源代码和实验结果已在以下网址公开提供：https://github.com/yangxiaoxuan123/FineSec_detect。|
|**2025-10-06**|[Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization](http://arxiv.org/abs/2510.06274)|null|最近的进展将人工智能前沿从模式识别任务推向了需要一步一步、系统2式推理的问题，尤其是在大型语言模型方面。然而，与泛化和分布外（OoD）评估概念已被很好地形式化的学习不同，推理能力尚无清晰一致的定义或衡量标准。我们提出了复杂性分布外（Complexity OoD）泛化，作为定义和衡量推理的框架和问题设置。当模型在测试实例上保持性能，且其所需最小解的复杂性，无论是表征性的（更丰富的解结构）还是计算性的（更多的推理步骤/程序长度），都超出了所有训练样本的复杂性时，它就展现出复杂性OoD泛化。我们通过解描述柯尔莫哥洛夫复杂性和操作性代理（例如，对象/关系计数；推理步骤计数）来形式化复杂性，阐明了复杂性OoD与长度和组合性OoD的区别。这一视角统一了学习和推理：许多在低复杂性下可通过系统1式处理解决的案例，在复杂性压力下变得像系统2，而系统2可以被视为对解结构的泛化。我们将这一视角转化为实践，并提出了在整个堆栈中操作复杂性OoD的建议：将复杂性纳入基准和评估指标设计，重新思考监督以针对解的轨迹，寻求和设计用于复杂性OoD泛化的归纳偏置，解决学习推理的溢出效应，如虚假捷径、语义鲁棒性、灾难性遗忘和分步校准。由于仅靠数据规模化无法解决复杂性OoD，迈向鲁棒推理的进展将需要明确建模和根据复杂性分配计算的架构和训练机制。|
|**2025-10-06**|[Draft, Verify, and Improve: Toward Training-Aware Speculative Decoding](http://arxiv.org/abs/2510.05421)|null|自回归 (AR) 解码是大型语言模型的一个主要延迟瓶颈。推测解码 (SD) 通过让一个草稿器提出多token块，并由一个验证器接受或拒绝，从而加速AR。然而，许多SD系统需要大量的离线训练或额外的组件。这些选择增加了数据/计算成本，并可能在分布漂移下产生脆弱的草稿器。我们引入了“撰写、验证与改进 (DVI)”，这是一个训练感知型自推测框架，它结合了推理和持续在线学习。我们将一个大型语言模型划分为一个草稿器和一个验证器，在生成过程中，验证器的接受/拒绝决策被转换为监督信号，并用于更新草稿器头部。一个简单的KL $\rightarrow$ RL调度通过在线蒸馏引导校准，然后添加了带有在策略策略梯度项的奖励掩码交叉熵，从而保持了无损的单模型部署。在Spec-Bench上，DVI实现了2.16倍的实际运行时间加速，与EAGLE-2等最先进的方法相当，同时训练数据量少几个数量级，并且消融实验表明DVI优于仅使用KL的在线蒸馏。DVI表明，训练感知型自推测可以在最小的训练开销下，提供最先进的无损加速。|
|**2025-10-08**|[AutoDAN-Reasoning: Enhancing Strategies Exploration based Jailbreak Attacks with Test-Time Scaling](http://arxiv.org/abs/2510.05379)|null|大型语言模型（LLM）越狱方面的最新进展，例如AutoDAN-Turbo，已经展示了自动化策略发现的强大能力。AutoDAN-Turbo采用终身学习代理从零开始构建了一个丰富的攻击策略库。尽管AutoDAN-Turbo高效，但其测试时生成过程涉及采样一个策略并生成单个对应的攻击提示，这可能未能充分利用所学策略库的潜力。在本文中，我们提出通过测试时扩展来进一步提高AutoDAN-Turbo的攻击性能。我们引入了两种不同的扩展方法：N选最优和束搜索。N选最优方法从采样的策略中生成N个候选攻击提示，并根据评分模型选择最有效的一个。束搜索方法通过探索库中策略的组合进行更详尽的搜索，以发现更强大和协同的攻击向量。实验表明，所提出的方法显著提升了性能，其中束搜索在Llama-3.1-70B-Instruct上将攻击成功率提高了多达15.6个百分点，并且与原始方法相比，在高度鲁棒的GPT-o4-mini上实现了近60%的相对提升。|
|**2025-10-06**|[AutoDAN-Reasoning: Enhancing Strategies Exploration based Jailbreak Attacks with Test-Time Scaling](http://arxiv.org/abs/2510.05379)|null|大型语言模型（LLMs）越狱领域的近期进展，例如AutoDAN-Turbo，已展示了自动化策略发现的强大能力。AutoDAN-Turbo采用终身学习智能体从零开始构建了一个丰富的攻击策略库。尽管非常有效，其测试时生成过程涉及采样一个策略并生成一个对应的攻击提示，这可能未能充分利用所学策略库的潜力。在本文中，我们提出通过测试时扩展来进一步提升AutoDAN-Turbo的攻击性能。我们引入了两种不同的扩展方法：N中选优和束搜索。N中选优方法从一个采样的策略中生成N个候选攻击提示，并基于一个评分模型选择最有效的一个。束搜索方法通过探索库中策略的组合进行更彻底的搜索，以发现更强大和协同的攻击向量。实验结果表明，所提出的方法显著提升了性能，其中束搜索在Llama-3.1-70B-Instruct上将攻击成功率提高了高达15.6个百分点，并相比于原始方法，在高度鲁棒的GPT-o4-mini上实现了近60%的相对改进。|
|**2025-10-06**|[Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners](http://arxiv.org/abs/2510.04454)|null|大语言模型 (LLMs) 展现出强大的推理能力，这种能力常常通过思维链 (CoT) 提示和强化学习 (RL) 得到增强。尽管强化学习算法能显著提升推理能力，但它们难以扩展推理边界，因为它们从自身的推理轨迹中学习，而非获取外部知识。有监督微调 (SFT) 提供了互补的优势，但通常需要大规模数据并存在过拟合的风险。最近结合SFT和RL的尝试面临三个主要挑战：数据效率低下、算法特定设计和灾难性遗忘。我们提出了一个即插即用框架，通过为SFT选择有挑战性的示例，将SFT动态地整合到RL中。这种方法减少了SFT的数据需求，并且对RL或SFT算法的选择保持无关性。为了缓解在SFT过程中RL习得技能的灾难性遗忘，我们选择高熵词元进行损失计算，并冻结被识别为对RL至关重要的参数。我们的方法取得了最先进 (SoTA) 的推理性能，仅使用了之前SoTA所用SFT数据的1.5%和RL数据的20.4%，为推理后训练中SFT与RL的结合提供了一种高效且即插即用的解决方案。|
|**2025-10-05**|[Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to Improve LLM Agents Adaptation](http://arxiv.org/abs/2510.04373)|null|大语言模型（LLM）智能体在序列决策任务中表现良好，但在不熟悉领域改进它们通常需要昂贵的在线交互或在大型专家数据集上进行微调。这些策略对于闭源模型不切实际，对于开源模型成本高昂，且存在灾难性遗忘的风险。离线轨迹提供可复用知识，但基于演示的方法面临挑战，因为原始轨迹过长、嘈杂且与特定任务绑定。我们提出了即时情景反馈提示器（JEF Hinter），一个智能体系统，它将离线轨迹提炼成紧凑、上下文感知的提示。一种缩放机制突出长轨迹中的关键步骤，捕捉策略和陷阱。与现有方法不同，JEF Hinter利用成功和失败的轨迹，即使只有失败数据可用也能提取指导，同时支持并行化的提示生成和基准无关的提示。在推理时，一个检索器为当前状态选择相关提示，提供具有透明性和可追溯性的有针对性指导。在MiniWoB++、WorkArena-L1和WebArena-Lite上的实验表明，JEF Hinter持续优于强大的基线，包括基于人工和基于文档的提示。|
|**2025-10-05**|[AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents](http://arxiv.org/abs/2510.04257)|null|基于大规模视觉语言模型（LVLM）构建的多模态智能体正越来越多地部署在开放世界环境中，但它们仍然极易受到提示注入的攻击，特别是通过视觉输入进行的注入。我们引入了AgentTypo，这是一个黑盒红队框架，它通过将优化后的文本嵌入到网页图像中，实现自适应排版提示注入。我们的自动排版提示注入（ATPI）算法通过替换字幕生成器来最大化提示重构，同时通过隐身损失最小化人类可检测性，并利用树结构Parzen估计器指导文本位置、大小和颜色的黑盒优化。为进一步增强攻击强度，我们开发了AgentTypo-pro，这是一个多LLM系统，它利用评估反馈迭代优化注入提示，并检索成功的历史案例以实现持续学习。有效的提示被抽象为通用策略并存储在策略库中，从而实现渐进式知识积累并在未来的攻击中重用。在分类广告、购物和Reddit场景的VWA-Adv基准上进行的实验表明，AgentTypo显著优于AgentAttack等最新的基于图像的攻击。在GPT-4o智能体上，我们仅基于图像的攻击将成功率从0.23提高到0.45，并且在GPT-4V、GPT-4o-mini、Gemini 1.5 Pro和Claude 3 Opus上取得了持续一致的结果。在图像+文本设置中，AgentTypo达到了0.68的攻击成功率（ASR），也优于最新的基线。我们的研究结果表明，AgentTypo对多模态智能体构成了实际而强大的威胁，并凸显了对有效防御的迫切需求。|
|**2025-10-03**|[A $1000\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps](http://arxiv.org/abs/2510.02716)|null|源于各种应用的网格地图路径规划已引起广泛关注。A*、Dijkstra及其变体等现有方法适用于小规模地图，但由于搜索时间和内存消耗过高，无法解决大规模地图问题。最近，大语言模型（LLMs）在路径规划中展现出卓越性能，但仍存在空间错觉和规划性能不佳的问题。在所有工作中，LLM-A* \cite{meng2024llm} 利用LLM生成一系列路点，然后使用A*规划相邻路点之间的路径。通过这种方式，构建了完整的路径。然而，LLM-A*对于大规模地图仍然存在计算时间过高的问题。为了弥补这一空白，我们对LLM-A*进行了深入研究，发现了其瓶颈，导致性能受限。因此，我们设计了一种创新的LLM增强算法，简称为iLLM-A*。iLLM-A*包含3个精心设计的机制，包括对A*的优化、一种用于LLM生成高质量路点的增量学习方法，以及为A*路径规划选择合适路点的方法。最后，在各种网格地图上的综合评估表明，与LLM-A*相比，iLLM-A* 1) 平均实现超过1000倍的加速，在极端情况下最高可达2349.5倍的加速，2) 节省高达58.6%的内存开销，3) 实现了显著更短的路径长度和更低的路径长度标准差。|
|**2025-10-01**|[Energy-Regularized Sequential Model Editing on Hyperspheres](http://arxiv.org/abs/2510.01172)|null|大语言模型（LLMs）需要持续更新以保持与不断演变的现实世界知识对齐。模型编辑提供了一种重训练的轻量级替代方案，但顺序编辑常常会破坏表征的稳定性并导致灾难性遗忘。在这项工作中，我们旨在更好地理解和缓解由顺序编辑引起的性能下降。我们假设超球面均匀性（一种保持神经元权重在超球面上均匀分布的特性）有助于模型保持稳定、保留先验知识，同时适应新的更新。我们使用超球面能量（HE）来量化编辑过程中的神经元均匀性，并检查其与编辑性能的相关性。跨广泛使用的编辑方法的经验研究揭示了HE动态与编辑性能之间的强烈相关性，其中编辑失败始终与高HE波动同时发生。我们进一步从理论上证明，HE动态对预训练知识的退化施加了一个下界，强调了HE稳定性对知识保留至关重要的原因。受这些见解的启发，我们提出了SPHERE（用于超球面能量正则化编辑的稀疏投影），这是一种HE驱动的正则化策略，它能稳定神经元权重分布，最终保留先验知识，同时实现可靠的顺序更新。具体而言，SPHERE识别出一个与预训练权重矩阵的主要超球面方向互补的稀疏空间，并将新知识投影到该空间，从而减弱对主要方向的扰动。在LLaMA3（8B）和Qwen2.5（7B）上进行的大量实验表明，SPHERE在编辑能力上平均优于最佳基线16.41%，同时最忠实地保留了模型的整体性能，从而为实现可靠的大规模知识编辑提供了一条原则性的路径。|
|**2025-10-02**|[Are Time Series Foundation Models Susceptible to Catastrophic Forgetting?](http://arxiv.org/abs/2510.00809)|null|时序基础模型（TSFMs）在多样化的预测任务中展现出前景广阔的零样本泛化能力。然而，它们对持续适应的鲁棒性仍未得到充分探索。在这项工作中，我们研究了TSFMs在多个数据集上进行顺序微调时遭受灾难性遗忘的程度。我们使用旨在具有不同程度周期性结构的合成数据集，衡量了模型对新数据的适应能力与对先验知识的保留能力之间的权衡。我们的实验表明，尽管微调提高了在新任务上的性能，但它常常导致在先前学习过的任务上性能显著下降，这揭示了一个根本性的稳定性-可塑性困境。|
|**2025-09-30**|[TTT3R: 3D Reconstruction as Test-Time Training](http://arxiv.org/abs/2509.26645)|null|现代循环神经网络因其线性时间复杂度，已成为三维重建领域具有竞争力的架构。然而，当其应用于超出训练上下文长度的场景时，性能会显著下降，暴露出有限的长度泛化能力。在这项工作中，我们从测试时间训练的视角重新审视三维重建基础模型，将其设计视为一个在线学习问题。基于这一视角，我们利用记忆状态与新传入观测之间的对齐置信度，推导出一个用于记忆更新的闭式学习率，以在保留历史信息和适应新观测之间取得平衡。这种名为TTT3R的免训练干预措施，显著提升了长度泛化能力，在全球姿态估计方面实现了相对于基线2倍的改进，同时以20 FPS的速度运行，仅需6 GB GPU显存即可处理数千张图像。代码可在https://rover-xingyu.github.io/TTT3R获取。|
|**2025-09-29**|[Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection](http://arxiv.org/abs/2509.25502)|null|多模态大语言模型（MLLM）因其丰富的世界知识、常识推理能力和潜在的可解释性，在检测AI生成图像方面受到越来越多的关注。然而，天真地应用这些MLLM进行检测往往会导致次优性能。我们认为这种失败的根源在于一个根本性的不匹配：MLLM在真正“看到”伪造品之前就被要求对其进行推理。首先，它们并没有真正“看到”：现有MLLM的视觉编码器主要针对语义导向的识别进行优化，而非对低级信号的感知，这使得它们对细微的伪造痕迹不敏感。在无法获取可靠感知证据的情况下，模型将其判断基于不完整和有限的视觉观察。其次，用于检测的现有微调数据通常使用狭窄的指令式格式，这与预训练中看到的多样化、异构分布截然不同。在缺乏有意义视觉线索的情况下，模型因此利用这些语言捷径，导致预训练知识的灾难性遗忘（甚至包括基本的对话能力）。作为回应，我们倡导一种新范式：先“看到”再推理。我们提出MLLM应首先训练感知伪影——增强其对伪影的视觉感知能力——以便随后的推理基于实际观察。因此，我们提出了Forensic-Chat，一个用于假图像检测的具有泛化性、可解释性且仍具会话能力（支持多轮对话）的助手。我们还提出了ExplainFake-Bench，一个专门用于从五个关键方面评估MLLM在图像取证方面可解释性的基准。大量实验表明其在泛化性和真正可靠的可解释性方面的优越性。|
|**2025-09-29**|[Understanding the Dilemma of Unlearning for Large Language Models](http://arxiv.org/abs/2509.24675)|null|遗忘旨在从大语言模型（LLMs）中移除特定知识，但其有效性仍存在争议。一方面，“被遗忘的”知识常可通过轻度微调等干预措施恢复；另一方面，遗忘可能导致灾难性遗忘，从而损害通用能力。尽管对遗忘方法进行了积极探索，但由于追踪大语言模型复杂架构中知识的难度，对其机制的可解释性分析却十分稀缺。我们通过提出unPact来解决这一空白，unPact是一个通过提示归因和贡献追踪实现遗忘的可解释框架。通常，它量化每个提示词元对输出的影响，从而能够进行遗忘前后的比较，以揭示发生了哪些变化。跨越六种主流遗忘方法、三种大语言模型和三个基准测试，我们发现：(1) 遗忘似乎通过扰乱对提示中关键词的关注而生效；(2) 许多知识并未真正被擦除，只需在提示中强调这些关键词即可恢复，而无需修改模型的权重；(3) 灾难性遗忘源于对所有词元的无差别惩罚。综合来看，我们的结果揭示了一个遗忘困境：现有方法往往要么不足（知识可通过关键词强调来恢复），要么过度破坏性（通用性能因灾难性遗忘而崩溃），这仍然与可靠的遗忘存在差距。|
|**2025-09-29**|[ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning](http://arxiv.org/abs/2509.24219)|null|通过强化学习（RL）或模仿学习（IL）训练的机器人通常对新任务适应缓慢，而近期的大型语言模型（LLMs）和视觉-语言模型（VLMs）则预示着从少量数据中进行知识丰富的规划。然而，将LLMs/VLMs部署到运动规划中面临两个主要障碍：(i) 符号规划很少基于场景几何和物体物理特性进行落地，以及 (ii) 对于相同的提示，模型输出可能不同，从而损害了执行的可靠性。我们提出了ViReSkill，这是一个将视觉落地式重规划与用于积累和重用的技能记忆相结合的框架。当发生故障时，重规划器会基于当前场景生成一个新的动作序列，并根据观察到的状态进行调整。成功时，执行的规划被存储为可重用技能，并在未来的遇到中重放，无需额外调用LLMs/VLMs。这种反馈循环实现了自主持续学习：每次尝试都会立即扩展技能集并稳定后续的执行。我们在LIBERO和RLBench等模拟器以及物理机器人上评估了ViReSkill。在所有设置中，它在任务成功率方面始终优于传统基线，展示了强大的模拟到现实泛化能力。|
|**2025-09-28**|[EWC-Guided Diffusion Replay for Exemplar-Free Continual Learning in Medical Imaging](http://arxiv.org/abs/2509.23906)|null|医学影像基础模型必须随时间推移进行适应，然而，由于隐私限制和成本，完全再训练通常受到阻碍。我们提出了一个持续学习框架，该框架通过结合类别条件扩散回放与弹性权重整合（Elastic Weight Consolidation，EWC）来避免存储患者样本。使用紧凑的Vision Transformer骨干网络，我们在八项MedMNIST v2任务和CheXpert数据集上进行了评估。在CheXpert数据集上，我们的方法达到了0.851的AUROC，相对于DER++，遗忘减少了30%以上，并且接近联合训练（0.869 AUROC）的性能，同时保持了高效和隐私保护。分析将遗忘与两个可测量的因素联系起来：回放的保真度和费雪加权参数漂移，强调了回放扩散和突触稳定性的互补作用。结果表明了一条实用的途径，可实现临床影像模型的可扩展、隐私感知的持续适应。|
|**2025-09-28**|[Dynamic Orthogonal Continual Fine-tuning for Mitigating Catastrophic Forgettings](http://arxiv.org/abs/2509.23893)|null|灾难性遗忘仍然是大型语言模型（LLMs）持续学习中的一个关键挑战，即模型在无法访问过去数据集的情况下，对新的序列数据进行微调时，难以保持在历史任务上的性能。在本文中，我们首先揭示了微调过程中函数方向的漂移是现有基于正则化的方法在长期LLM持续学习中失效的一个关键原因。为了解决这个问题，我们提出了一种新颖的方法——动态正交持续（DOC）微调，它跟踪这些函数方向的漂移并在微调过程中动态更新它们。此外，通过调整新任务参数的梯度使其与跟踪到的历史函数方向正交，我们的方法减轻了新旧任务之间的干扰。在各种LLM持续学习基准上进行的大量实验表明，这种方法优于现有方法，有效减少了灾难性遗忘，并为LLM的持续微调提供了一个鲁棒的工具。我们的代码可在 https://github.com/meloxxxxxx/DOC 获取。|
|**2025-09-28**|[How LLMs Learn to Reason: A Complex Network Perspective](http://arxiv.org/abs/2509.23629)|null|使用可验证奖励强化学习（RLVR）训练大语言模型展现出一系列独特且令人费解的行为，这些行为目前尚不清楚，包括两阶段学习曲线、V形响应长度轨迹以及明显的灾难性遗忘脆弱性。在这项工作中，我们提出这些看似不同的现象可以用一个统一的理论来解释：模型的推理过程映射为语义复杂网络的自组织，其拓扑结构持续稀疏，平均度数固定在接近二。这种拓扑结构为遗忘和学习施加了一个基本机制：它首先将系统驱动到最大受挫状态，在此状态下形成“技能孤岛”，发生缓慢学习并诱发遗忘；然后进入一个急剧增长阶段，新技能被“固定”上去，这是由网络前沿的相变式学习所驱动的。借助该理论，我们提出了退火RLVR（Annealed-RLVR），这是一种原则性算法，它在最大受挫点引入基于SFT的“加热”步骤，以解决竞争瓶颈并增强模型的推理能力。在一个15亿参数模型上的实验表明，该方法在分布内和分布外基准测试中均优于标准RLVR。通过将RLVR从黑盒优化重塑为可预测的结构自组织过程，我们的工作为工程化未来人工智能系统的新兴推理能力提供了新的物理直觉。|
|**2025-09-28**|[On the Shelf Life of Fine-Tuned LLM Judges: Future Proofing, Backward Compatibility, and Question Generalization](http://arxiv.org/abs/2509.23542)|null|大语言模型作为评判范式被广泛应用于评估自由文本模型响应以及用于模型对齐和微调的奖励建模。近来，相较于直接提示前沿模型作为裁判，使用裁判专用数据微调裁判模型已成为一种更受青睐的选择，因为前者在模型尺寸较小的情况下能实现更好的性能，同时对常见偏差更具鲁棒性。然而，标准评估忽略了微调裁判模型在实际部署方面的几个实际问题。在本文中，我们识别并形式化了影响这些裁判模型“保质期”的三个方面：未来适应性（即今天的生成器模型响应上微调的裁判模型，在未来模型或过去模型的响应上的表现如何）和向后兼容性，以及问题泛化能力（即裁判模型在测试时对未见问题的泛化能力如何）。我们在一个统一的框架下，在数学领域研究了这三个方面，该框架具有不同的训练和测试分布、三种基于SFT和DPO的微调算法以及三种不同的基础模型。实验表明，未来适应性对大多数模型来说是具有挑战性的，而向后兼容性相对容易，其中DPO训练的模型持续提升性能。我们进一步发现，持续学习为新旧响应分布之间的变化提供了更平衡的适应，相比于仅在更强或更弱的响应上进行训练。此外，所有模型都观察到当从训练期间见过的问题转移到未见过的问题时，性能会发生一定程度的下降，这表明当前的裁判模型未能完全泛化到未见过的问题。这些发现为在不断变化的生成器面前开发和部署裁判模型提供了实际考量方面的见解。|
|**2025-09-27**|[Dual-Space Smoothness for Robust and Balanced LLM Unlearning](http://arxiv.org/abs/2509.23362)|**[link](https://github.com/Tsuzukii/PRISM)**|随着大语言模型的快速发展，机器遗忘应运而生，旨在解决用户隐私、版权侵犯和整体安全性日益增长的担忧。然而，最先进的（SOTA）遗忘方法常常面临灾难性遗忘和指标不平衡的问题，例如通过过度优化一个目标（如遗忘有效性、效用保持或隐私保护）而牺牲其他目标。此外，表征空间或参数空间中的微小扰动可能被重学习攻击和越狱攻击利用。为解决这些挑战，我们提出了PRISM，一个统一的框架，它在表征空间和参数空间中强制执行双空间平滑性，以提高鲁棒性并平衡遗忘指标。PRISM包含两个平滑优化阶段：(i)一个表征空间阶段，采用鲁棒训练的探测器以防御越狱攻击；(ii)一个参数空间阶段，解耦保留-遗忘梯度冲突，减少不平衡，并平滑参数空间以缓解重学习攻击。在WMDP和MUSE数据集上，涵盖对话和连续文本设置的大量实验表明，PRISM在多种攻击下均优于SOTA基线，同时在关键指标之间实现了更好的平衡。|
|**2025-09-27**|[Exploring LLM-based Frameworks for Fault Diagnosis](http://arxiv.org/abs/2509.23113)|null|基于大语言模型（LLM）的系统为传感器丰富的工业环境中的自主健康监测带来了新的机遇。本研究探索了LLM直接从传感器数据中检测和分类故障的潜力，同时通过自然语言推理生成内在可解释的输出。我们系统地评估了LLM系统架构（单LLM与多LLM）、输入表示（原始数据与描述性统计数据）以及上下文窗口大小如何影响诊断性能。我们的研究结果表明，当提供汇总的统计输入时，LLM系统表现最有效；并且与单LLM系统相比，使用专门提示的多个LLM系统在故障分类方面提供了改进的灵敏度。尽管LLM可以为其决策生成详细且人类可读的理由，但我们观察到它们在持续学习环境中随时间适应能力的局限性，在重复的故障周期中经常难以校准预测。这些见解指出了基于LLM的系统作为复杂环境中透明、自适应诊断工具的潜力与当前局限。|
|**2025-09-26**|[Hierarchical Representation Matching for CLIP-based Class-Incremental Learning](http://arxiv.org/abs/2509.22645)|null|类增量学习（CIL）旨在使模型具备持续适应不断演进的数据流的能力。预训练视觉-语言模型（例如CLIP）的最新进展为此任务提供了强大基础。然而，现有方法通常依赖于“一张[类别]的照片”等简单模板，这忽略了视觉概念的层级性。例如，“猫”与“汽车”的识别依赖于粗粒度线索，而区分“猫”与“狮子”则需要细粒度细节。同样，CLIP中当前的特征映射仅依赖于最后一层的表示，忽略了早期层中包含的层级信息。在这项工作中，我们为基于CLIP的CIL引入了层级表示匹配（HERMAN）方法。我们的方法利用大型语言模型（LLMs）递归生成判别性文本描述符，从而通过显式层级线索扩充语义空间。这些描述符被匹配到语义层级的不同级别，并根据任务特定要求进行自适应路由，从而在增量任务中实现精确判别并缓解灾难性遗忘。在多个基准上进行的大量实验表明，我们的方法持续达到了最先进的性能。|
|**2025-09-26**|[We Think, Therefore We Align LLMs to Helpful, Harmless and Honest Before They Go Wrong](http://arxiv.org/abs/2509.22510)|null|大型语言模型（LLM）在有益性、无害性和诚实性（HHH）等多个目标上的对齐对于其安全可靠的部署至关重要。先前的工作使用引导向量——注入到隐藏状态中的小型控制信号——来指导LLM的输出，通常通过一对一（1-to-1）Transformer解码器实现。在这种设置下，优化单一对齐目标可能会无意中覆盖为其他目标学习到的表示，从而导致灾难性遗忘。最近的方法通过一对多（1-to-N）Transformer解码器扩展了引导向量。虽然这缓解了灾难性遗忘，但朴素的多分支设计独立优化每个目标，这可能导致推理碎片化——HHH目标之间的输出可能变得不一致。我们提出了自适应多分支引导（AMBS），这是一个两阶段的1-to-N框架，用于统一高效的多目标对齐。在第一阶段，Transformer层的注意力后隐藏状态被计算一次以形成共享表示。在第二阶段，该表示被克隆到并行分支中，并通过策略-参考机制进行引导，从而在保持跨目标一致性的同时实现目标特定控制。在Alpaca、BeaverTails和TruthfulQA上的经验评估表明，AMBS在多个7B LLM骨干模型上持续改进了HHH对齐。例如，在DeepSeek-7B上，与朴素的1-to-N基线相比，AMBS将平均对齐分数提高了32.4%，并将不安全输出减少了11.0%，同时与最先进的方法保持竞争力。|
|**2025-09-26**|[Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting](http://arxiv.org/abs/2509.22195)|null|将视觉语言模型（VLM）在机器人远程操作数据上进行微调以创建视觉语言动作（VLA）模型，是训练通用策略的一个有前景的范式，但它面临一个根本性权衡：学习生成动作通常会削弱VLM的基础推理和多模态理解能力，从而阻碍其泛化到新颖场景、指令遵循和语义理解。我们认为这种灾难性遗忘是由于VLM的互联网规模预训练语料库与机器人微调数据之间存在分布不匹配。受此观察启发，我们引入了VLM2VLA：一种VLA训练范式，它首先通过自然语言表示低级动作，在数据层面解决这种不匹配。这种对齐使得仅使用低秩适应（LoRA）来训练VLA成为可能，从而最大限度地减少对VLM主干的修改并避免灾难性遗忘。因此，VLM可以在机器人远程操作数据上进行微调，而无需从根本上改变底层架构，也无需在互联网规模的VLM数据集上进行昂贵的联合训练。通过大量的视觉问答（VQA）研究和超过800次真实世界机器人实验，我们证明VLM2VLA保留了VLM的核心能力，实现了对需要开放世界语义推理和多语言指令遵循的新颖任务的零样本泛化。|
|**2025-09-26**|[ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation](http://arxiv.org/abs/2509.21730)|null|随着大语言模型（LLMs）日益融入日常生活，对不仅能够响应、还能主动提供个性化服务的AI助手的需求日益增长。尽管近期进展分别推动了主动性和个性化的发展，但它们的结合仍未得到充分探索。为弥补这一差距，我们引入了ProPerSim，这是一个新的任务与模拟框架，用于开发能够在真实的家庭场景中提供及时、个性化推荐的助手。在我们的模拟环境中，一个具有丰富人设的用户代理与助手交互，并根据每条建议与其偏好和情境的契合度提供评分。助手的目标是利用这些评分进行学习和适应，以随着时间推移获得更高的分数。基于ProPerSim，我们提出了ProPerAssistant，这是一个结合检索增强、偏好对齐的助手，能够通过用户反馈持续学习和适应。在32种不同人设上的实验表明，ProPerAssistant调整其策略并稳步提升用户满意度，突显了将主动性和个性化结合起来的巨大潜力。|
|**2025-09-24**|[A co-evolving agentic AI system for medical imaging analysis](http://arxiv.org/abs/2509.20279)|**[link](https://github.com/zhihuanglab/TissueLab)**|智能体AI在医疗保健和生物医学研究领域正迅速发展。然而，在医学图像分析中，由于缺乏强大的生态系统、不足的工具集以及实时交互式专家反馈的缺失，其性能和应用仍受限制。本文我们介绍“TissueLab”，一个协同进化的智能体AI系统，它允许研究人员直接提问，自动规划并生成可解释的工作流，并进行实时分析，专家可以在其中可视化中间结果并对其进行优化。TissueLab整合了病理学、放射学和空间组学领域的工具工厂。通过标准化各种工具的输入、输出和功能，该系统能够确定何时以及如何调用它们以解决研究和临床问题。在涉及具有临床意义的量化（为分期、预后和治疗计划提供信息）的各种任务中，与端到端视觉-语言模型（VLM）以及GPT-5等其他智能体AI系统相比，TissueLab均实现了最先进的性能。此外，TissueLab不断向临床医生学习，演化出改进的分类器和更有效的决策策略。通过主动学习，它能在数分钟内在新疾病背景下提供准确结果，而无需大规模数据集或冗长的再训练。作为可持续的开源生态系统发布，TissueLab旨在加速医学成像领域的计算研究和转化应用，同时为下一代医疗AI奠定基础。|
|**2025-09-24**|[CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks](http://arxiv.org/abs/2509.19855)|null|智能移动应用日益增长的需求使得多智能体协作结合基于Transformer的大型语言模型（LLMs）在移动边缘计算（MEC）网络中变得至关重要。然而，在此类环境中训练LLMs仍面临挑战，原因在于计算量大、高端到端延迟以及模型泛化能力有限。我们引入了CollaPipe，这是一种混合分布式学习框架，它集成了协作流水线并行与联邦聚合，以支持自演进智能网络。在CollaPipe中，编码器部分被自适应地划分为可变大小的段并部署在移动设备上用于流水线并行训练，而解码器则部署在边缘服务器上以处理生成任务。接着我们通过联邦聚合执行全局模型更新。为了提高训练效率，我们提出了一个联合优化问题，该问题自适应地分配模型段、微批次、带宽和传输功率。我们推导并利用了一个闭式收敛界来设计一个基于Lyapunov优化的动态段调度和资源分配（DSSDA）算法，确保了长期约束下的系统稳定性。在使用Transformer和BERT模型进行下游任务的广泛实验表明，CollaPipe将计算效率提高了高达15.09%，将端到端延迟降低了至少48.98%，并将单设备内存使用量削减了一半以上，从而在异构和动态通信环境中实现了在线学习。|
|**2025-09-23**|[Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](http://arxiv.org/abs/2509.18942)|**[link](https://github.com/zzm-black/DEAL-Continuous-Low-Rank-Fine-Tuning)**|大语言模型（LLMs）的最新进展强调了微调（FT）技术在使LLMs适应特定任务方面的关键作用，尤其是在从头开始重新训练计算上不可行时。微调使LLMs能够利用任务或领域特定数据，生成更有效地满足目标应用需求的模型。然而，传统微调方法通常存在灾难性遗忘和次优数据效率的问题，限制了它们的实际应用性。为解决这些挑战，本文提出了DEAL，一个将低秩适应（LoRA）与持续微调策略相结合的新颖框架。通过引入知识保留和自适应参数更新模块，该框架缓解了现有微调方法的局限性，同时在隐私保护设置中保持了效率。在15个不同数据集上进行的实验表明，DEAL始终优于基线方法，在任务准确性和资源效率方面取得了显著提升。这些发现证明了我们方法在通过提高任务性能同时提升资源效率来推动LLMs持续适应方面的潜力。|
|**2025-09-24**|[COLT: Enhancing Video Large Language Models with Continual Tool Usage](http://arxiv.org/abs/2509.18754)|null|大语言模型（LLMs）的成功显著推动了视频理解的研究。为了利用训练有素的专家模型（即工具）的优势，视频大语言模型优先探索工具使用能力。现有方法要么提示闭源大语言模型，要么采用指令微调范式进行工具使用微调。然而，这些方法假设存在一个固定的工具库，并且难以泛化到工具数据不断演进和涌入的真实世界环境。为此，我们提出通过持续工具使用（简称COLT）来增强开源视频大语言模型，使其在连续的工具流中自动获取工具使用能力，而不会遭受对过去学习工具的“灾难性遗忘”。具体来说，我们的COLT集成了一个可学习的工具码本作为工具专用记忆系统。然后，根据用户指令与码本中工具特征之间的相似性，动态选择相关工具。为了释放视频大语言模型的工具使用潜力，我们收集了一个以视频为中心的工具使用指令微调数据集VideoToolBench。在先前的视频大语言模型基准和工具使用专用VideoToolBench数据集上进行的大量实验证明了我们提出的COLT的最先进性能。|
|**2025-09-23**|[COLT: Enhancing Video Large Language Models with Continual Tool Usage](http://arxiv.org/abs/2509.18754)|null|大语言模型（LLMs）的成功显著推动了视频理解研究。为了利用训练有素的专家模型（即工具）的优势，视频大语言模型优先探索工具使用能力。现有方法要么提示闭源大语言模型，要么采用指令微调范式进行工具使用微调。然而，这些方法假设存在一个固定的工具库，难以泛化到工具数据不断演变和涌入的真实世界环境。为此，我们提出通过持续工具使用能力（简称COLT）来增强开源视频大语言模型，使其能够在连续的工具流中自动获取工具使用能力，而不会遭受对过去学习工具的“灾难性遗忘”。具体而言，我们的COLT引入了一个可学习的工具码本作为特定于工具的记忆系统。然后，根据用户指令与码本中工具特征之间的相似性动态选择相关工具。为了释放视频大语言模型的工具使用潜力，我们收集了一个以视频为中心的工具使用指令微调数据集VideoToolBench。在之前的视频大语言模型基准和特定于工具使用的VideoToolBench数据集上进行的大量实验证明了我们提出的COLT具有最先进的性能。|
|**2025-09-25**|[Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills](http://arxiv.org/abs/2509.18597)|**[link](https://github.com/Ghiara/LYRA)**|基于大型语言模型（LLMs）的机器人操作代码生成近期展现出潜力，能将人类指令直接转化为可执行代码，但现有方法仍存在噪声，受限于固定的基元和有限的上下文窗口，并且难以应对长周期任务。尽管已探索闭环反馈，但纠正后的知识通常以不当格式存储，限制了泛化能力并导致灾难性遗忘，这突显了学习可复用技能的必要性。此外，仅依赖LLM指导的方法在极长周期场景中经常失败，原因在于LLM在机器人领域推理能力有限，而此类问题对人类而言通常很容易识别。为解决这些挑战，我们提出了一种人机协作框架，该框架将纠正编码为可复用技能，并由外部记忆和带有提示机制的检索增强生成（Retrieval-Augmented Generation, RAG）支持以实现动态复用。在Ravens、Franka Kitchen和MetaWorld以及真实世界环境中的实验表明，我们的框架实现了0.93的成功率（比基线高出多达27%），并在纠正轮次中效率提高了42%。它能鲁棒地解决极长周期任务，例如“建造房屋”，这需要对20多个基元进行规划。|
|**2025-09-23**|[Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills](http://arxiv.org/abs/2509.18597)|**[link](https://github.com/Ghiara/LYRA)**|基于大型语言模型（LLMs）的机器人操作代码生成最近通过将人类指令直接转换为可执行代码而展现出潜力，但现有方法仍然存在噪声，受限于固定的基元和有限的上下文窗口，并且难以处理长程任务。尽管已探索闭环反馈，但纠正后的知识通常以不当格式存储，限制了泛化能力并导致灾难性遗忘，这突出了学习可重用技能的必要性。此外，仅依赖LLM指导的方法在超长程场景中经常失败，原因在于LLM在机器人领域推理能力的局限性，而这些问题对人类来说通常很容易识别。为应对这些挑战，我们提出了一种人机协作（human-in-the-loop）框架，该框架将纠正编码为可重用技能，并由外部记忆以及带有提示机制的检索增强生成（Retrieval-Augmented Generation）提供支持以实现动态重用。在Ravens、Franka Kitchen和MetaWorld以及真实世界环境中的实验表明，我们的框架实现了0.93的成功率（比基线高出27%），并在纠正轮次中实现了42%的效率提升。它能够稳健地解决超长程任务，例如“建造房屋”，这需要对20多个基元进行规划。|
|**2025-09-22**|[AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning](http://arxiv.org/abs/2509.17348)|null|持续学习（CL）对于在动态的现实世界环境中部署大型语言模型（LLMs）至关重要，且无需昂贵的再训练。最近基于模型合并的方法引起了广泛关注，但它们在学习新知识和防止遗忘之间的权衡管理上仍面临挑战，这主要源于次优的合并次数和合并频率。在本文中，我们提出了一种新颖的持续学习框架——自适应迭代模型合并（AimMerging），它利用来自训练轨迹的学习和遗忘信号来动态监测模型的训练状态。在动态监测的指导下，训练轨迹引导的合并控制器自适应地确定迭代融合的时机和频率，而基于排练的知识融合模块则计算合并权重并执行融合。在三个不同模型尺寸（从770M到13B）的CL基准上进行的全面实验表明，AimMerging相较于现有最先进方法取得了显著的性能提升，在FWT和BWT上分别实现了80%和59%的平均相对提升。源代码已提供以供复现。|
|**2025-09-21**|[LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization](http://arxiv.org/abs/2509.17183)|null|对齐在大型语言模型（LLMs）中发挥着关键作用，使其与人类在特定任务/领域的偏好保持一致。传统的对齐方法面临灾难性遗忘问题，即模型在适应新偏好或领域时会丢失先前获得的知识。我们引入了LifeAlign，一个用于终身对齐的新颖框架，它使LLMs能够在顺序学习任务中保持一致的人类偏好对齐，而不会遗忘先前学到的知识。我们的方法包含两项关键创新。首先，我们提出了一种聚焦式偏好优化策略，该策略使LLMs与新偏好对齐，同时防止先前任务中获得的知识受到侵蚀。其次，我们开发了一种从短期到长期的记忆巩固机制，该机制利用内在降维将去噪的短期偏好表示融合到稳定的长期记忆中，从而实现跨多样化领域的对齐模式的高效存储和检索。我们在涵盖不同领域和偏好类型的多个顺序对齐任务中评估了LifeAlign。实验结果表明，与现有终身学习方法相比，我们的方法在保持偏好对齐质量和知识保留方面均取得了卓越的性能。代码和数据集将在GitHub上发布。|
|**2025-09-21**|[MCTS-EP: Empowering Embodied Planning with Online Preference Optimization](http://arxiv.org/abs/2509.17116)|null|本文介绍了MCTS-EP，一个结合大语言模型（LLM）与蒙特卡洛树搜索（MCTS）来训练具身智能体的在线学习框架。MCTS-EP集成了三个关键组件：用于偏好数据收集的MCTS引导探索、高效的多模态推理机制，以及基于偏好优化的迭代训练流程。我们理论上证明了当损失函数为强凸时，MCTS-EP实现了优于传统在线策略算法的性能界限，并展示了它可以被表述为GAIL的一种搜索增强变体。MCTS-EP在多个基准测试中取得了最先进的性能。在ALFWorld中，它对于文本任务和视觉任务分别达到了92%和87%的成功率。在WebShop中，它达到了0.81的平均奖励。MTCS-EP还将视觉ALFWorld中的平均交互步数从18.7/19.5步减少到10.2/9.9步。代码可在以下网址获取：https://github.com/xuhang-2/Embodied-Agent-Planning|
|**2025-09-23**|[K-DeCore: Facilitating Knowledge Transfer in Continual Structured Knowledge Reasoning via Knowledge Decoupling](http://arxiv.org/abs/2509.16929)|null|持续结构化知识推理（CSKR）专注于训练模型处理顺序任务，其中每个任务都涉及将自然语言问题转化为基于结构化知识的结构化查询。现有通用持续学习方法在应用于此任务时面临显著挑战，包括对异构结构化知识的泛化能力差以及随着任务增加而参数增长导致的推理效率低下。为解决这些局限性，我们提出了一种新颖的CSKR框架K-DeCore，它在固定数量的可调参数下运行。与现有方法不同，K-DeCore引入了一种知识解耦机制，将推理过程解耦为任务特定和任务无关阶段，有效弥合了不同任务之间的差距。在此基础上，K-DeCore集成了一种用于不同阶段的双视角记忆巩固机制，并引入了一种结构引导的伪数据合成策略，以进一步增强模型的泛化能力。在四个基准数据集上进行的大量实验证明，利用各种骨干大型语言模型，K-DeCore在多项指标上均优于现有持续学习方法。|
|**2025-09-21**|[AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software](http://arxiv.org/abs/2509.16861)|null|护栏对于大型语言模型（LLM）驱动的软件的安全部署至关重要。与具有有限、预定义输入-输出空间、本质上限制不安全行为的传统基于规则的系统不同，LLM实现了开放式、智能的交互——这为通过用户输入发起的越狱攻击打开了大门。护栏作为保护层，在不安全的提示到达LLM之前对其进行过滤。然而，先前的研究表明，即使是面对GPT-4o等高级模型，越狱攻击的成功率仍然超过70%。尽管LlamaGuard等护栏报告的准确率高达95%，但我们的初步分析显示，当面对未见攻击时，它们的性能会急剧下降——低至12%。这凸显了一个日益增长的软件工程挑战：如何构建一个能够动态适应新出现的威胁的部署后护栏？为解决此问题，我们提出了AdaptiveGuard，这是一种自适应护栏，它将新型越狱攻击检测为分布外（OOD）输入，并通过持续学习框架学习防御这些攻击。通过经验评估，AdaptiveGuard实现了96%的OOD检测准确率，仅用两个更新步骤即可适应新攻击，并在适应后在分布内数据上保持超过85%的F1分数，优于其他基线。这些结果表明，AdaptiveGuard是一种能够在部署后响应新出现的越狱策略而演变的护栏。我们已在https://github.com/awsm-research/AdaptiveGuard发布了我们的AdaptiveGuard和所研究的数据集，以支持进一步的研究。|
|**2025-09-19**|[Towards Robust Visual Continual Learning with Multi-Prototype Supervision](http://arxiv.org/abs/2509.16011)|null|语言引导监督利用来自预训练语言模型 (PLM) 的冻结语义目标，已成为视觉持续学习 (CL) 的一个有前景的范式。然而，依赖单一目标引入了两个关键限制：1) 语义模糊性，即多义类别名称会导致冲突的视觉表示；2) 类内视觉多样性，即单一原型无法捕捉类内丰富的视觉外观多样性。为此，我们提出了 MuproCL，一个用多个上下文感知原型取代单一目标的新颖框架。具体而言，我们采用一个轻量级大型语言模型 (LLM) 代理来执行类别消歧和视觉模态扩展，以生成一组鲁棒的语义原型。LogSumExp 聚合机制允许视觉模型对于给定图像自适应地与最相关的原型对齐。在各种持续学习 (CL) 基线上进行的大量实验表明，MuproCL 持续提升了性能和鲁棒性，为语言引导的持续学习开辟了一条更有效的路径。|
|**2025-09-19**|[UNIV: Unified Foundation Model for Infrared and Visible Modalities](http://arxiv.org/abs/2509.15642)|null|联合RGB可见光与红外感知的需求迅速增长，尤其是在各种天气条件下实现鲁棒性能。尽管用于RGB可见光和红外数据的预训练模型在各自领域表现出色，但在多模态场景（如配备两种传感器的自动驾驶汽车）中它们往往表现不佳。为解决这一挑战，我们提出了一种受生物学启发，用于红外和可见光模态的统一基础模型（UNIV），该模型具有两项关键创新。首先，我们引入了逐块跨模态对比学习（PCCL），这是一种注意力引导的蒸馏框架，它模仿视网膜水平细胞的侧向抑制，能够在实现有效跨模态特征对齐的同时，与任何基于Transformer的架构兼容。其次，我们的双知识保持机制模拟了视网膜双极细胞的信号路由——结合LoRA适配器（增加2%参数）与同步蒸馏以防止灾难性遗忘，从而复刻了视网膜的明视（视锥细胞驱动）和暗视（视杆细胞驱动）功能。为支持跨模态学习，我们引入了MVIP数据集，这是迄今为止最全面的可见光-红外基准，它包含98,992对精确对齐的图像，涵盖多种场景。大量实验证明，UNIV在红外任务上表现优越（语义分割mIoU提升1.7，目标检测mAP提升0.7），同时在可见光RGB任务上保持了99%以上的基线性能。我们的代码可在https://github.com/fangyuanmao/UNIV获取。|
|**2025-09-18**|[The Energy-Efficient Hierarchical Neural Network with Fast FPGA-Based Incremental Learning](http://arxiv.org/abs/2509.15097)|null|深度学习日益增长的计算和能源需求，特别是在基础模型和大语言模型（LLM）等大规模架构中，对可持续性构成了严峻挑战。传统的基于梯度的训练方法效率低下，需要大量的迭代更新和高功耗。为解决这些局限性，我们提出了一种混合框架，将分层分解与基于FPGA的直接方程求解和增量学习相结合。我们的方法将神经网络分为两个功能层级：较低层通过FPGA上的单步方程求解进行优化，以实现高效且可并行化的特征提取；而较高层则采用自适应增量学习，以支持持续更新而无需完全重新训练。在此基础上，我们引入了复合LLM框架，该框架明确地在两个层级中部署了LLM模块。较低层LLM以最小的能源开销处理可重用表示学习，而较高层LLM则通过能源感知更新执行自适应决策。这种集成设计增强了可扩展性，减少了冗余计算，并符合可持续AI的原则。理论分析和架构见解表明，我们的方法显著降低了计算成本，同时保持了高模型性能，使其非常适合在能源受限环境中进行边缘部署和实时适应。|
|**2025-09-18**|[Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models](http://arxiv.org/abs/2509.15076)|null|空气污染仍然是对公众健康和环境可持续性构成严重威胁，然而传统监测系统常受限于有限的空间覆盖和可及性。本文提出一种人工智能驱动的代理，该代理利用天空图像预测环境空气污染水平，并使用生成式建模合成逼真的污染场景可视化。我们的方法将统计纹理分析与监督学习相结合进行污染分类，并利用视觉-语言模型（VLM）引导的图像生成来产生可解释的空气质量状况表示。生成的视觉效果模拟不同程度的污染，为面向用户的界面提供基础，从而提高透明度并支持知情的环境决策。这些输出可以无缝集成到旨在增强态势感知并鼓励基于实时预测的行为响应的智能应用中。我们使用城市天空图像数据集验证了我们的方法，并证明了其在污染水平估计和语义一致的视觉合成方面的有效性。系统设计还进一步融合了以人为中心的用户体验原则，以确保空气质量预测的可及性、清晰度和公众参与度。为支持可扩展和节能的部署，未来的迭代将整合一种绿色CNN架构，该架构通过基于FPGA的增量学习得到增强，从而实现在边缘平台上的实时推理。|
|**2025-09-18**|[Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification](http://arxiv.org/abs/2509.14958)|null|3D数字内容的快速增长要求针对开放世界场景的可扩展识别系统。然而，现有的3D类别增量学习方法在极端数据稀缺下，由于几何不对齐和纹理偏置，表现不佳。尽管最近的方法将3D数据与2D基础模型（例如CLIP）相结合，但它们存在由纹理偏置投影和几何-纹理线索不加区分的融合导致的语义模糊问题，从而导致不稳定的决策原型和灾难性遗忘。为解决这些问题，我们提出了跨模态几何校正（CMGR）框架，该框架通过利用CLIP的层次空间语义来增强3D几何保真度。具体而言，我们引入了一个结构感知几何校正模块，通过注意力驱动的几何融合，将3D部件结构与CLIP的中间空间先验进行分层对齐。此外，一个纹理放大模块合成最小但具有区分性的纹理，以抑制噪声并增强跨模态一致性。为进一步稳定增量原型，我们采用一个基类-新类判别器来隔离几何变异。大量实验表明，我们的方法显著改善了3D小样本类别增量学习，在跨域和域内设置中均实现了卓越的几何一致性和对纹理偏置的鲁棒性。|
|**2025-09-18**|[Cross-Modal Knowledge Distillation for Speech Large Language Models](http://arxiv.org/abs/2509.14930)|null|在这项工作中，我们首次系统性评估了语音大语言模型中的灾难性遗忘和模态不一致性，结果表明，引入语音能力即使在输入仍为文本时，也会损害知识和推理能力，并且当查询为语音时，性能会进一步下降。为了解决这些挑战，我们提出了一个跨模态知识蒸馏框架，该框架利用文本到文本和语音到文本两种通道，将知识从基于文本的教师模型迁移到语音大语言模型。在对话和音频理解任务上进行的广泛实验验证了我们方法在保留文本知识、改善跨模态对齐以及增强基于语音交互中的推理能力方面的有效性。|
|**2025-09-18**|[Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications](http://arxiv.org/abs/2509.14921)|null|CLIP等基础模型在多种视觉任务中展现了卓越的零样本和少样本迁移能力。然而，当针对人脸识别（FR）、形态攻击检测（MAD）和演示攻击检测（PAD）等高度专业化的生物识别任务进行微调时，这些模型可能会出现过度专业化，从而失去其基础优势之一——跨领域泛化能力。在这项工作中，我们通过评估三个针对FR、MAD和PAD任务微调的CLIP模型实例，系统地量化了这些权衡。我们评估了每个经过适应的模型以及原始的CLIP基线模型在14个通用视觉数据集上的零样本和线性探测协议下的性能，同时也在常见的FR、MAD和PAD基准测试中进行了评估。我们的结果表明，微调模型存在过度专业化问题，尤其是在针对复杂的人脸识别任务进行微调时。此外，我们的结果指出，任务复杂性和分类头设计（多类别FR与二元类别MAD和PAD）与灾难性遗忘的程度相关。采用ViT-L骨干网络的FRoundation模型在大型FR基准测试IJB-C上优于其他方法，实现了高达58.52%的改进。然而，它在ImageNetV2上经历了显著的性能下降，仅达到51.63%，而基线CLIP模型达到了69.84%。此外，较大的CLIP架构始终比小型变体保留了更多的模型原始泛化能力，表明增加模型容量可能有助于减轻过度专业化。|
|**2025-09-18**|[OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning](http://arxiv.org/abs/2509.14803)|null|在在线学习环境中，学生通常缺乏个性化的同伴互动，而这种互动在支持认知发展和学习投入方面起着关键作用。尽管之前的研究已经利用大语言模型（LLMs）为学生模拟交互式动态学习环境，但这些互动仍然局限于对话交流，缺乏对学习者个性化学习和认知状态的洞察和适应。结果是，学生与AI学习伙伴进行讨论的兴趣不高，并且他们难以从这些互动中获得启发。为了解决这一挑战，我们提出了OnlineMate，一个由LLMs驱动并整合了心智理论（ToM）的多智能体学习伙伴系统。OnlineMate能够模拟同伴般的智能体角色，在协作讨论中适应学习者的认知状态，并推断他们的心理状态，例如误解、困惑或动机。通过整合心智理论能力，该系统可以动态调整其交互策略，以支持高阶思维和认知的发展。在模拟学习场景中的实验结果表明，OnlineMate有效地促进了深度学习和讨论，同时增强了在线教育环境中的认知投入。|
|**2025-09-18**|[AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](http://arxiv.org/abs/2509.14647)|null|随着大语言模型（LLMs）在自动化复杂多智能体工作流中的日益普及，组织面临着来自错误、涌现行为和系统性故障的日益增长的风险，而这些是当前评估方法未能捕捉到的。我们提出了AgentCompass，这是首个专门为智能体工作流的部署后监控和调试设计的评估框架。AgentCompass通过一个结构化的多阶段分析管道模拟专家调试员的推理过程，包括：错误识别和分类、主题聚类、定量评分和策略性总结。该框架通过一个双记忆系统——情景记忆和语义记忆——得到进一步增强，从而实现了跨执行的持续学习。通过与设计伙伴的合作，我们展示了该框架在真实世界部署中的实用性，并在公开可用的TRAIL基准上确立了其有效性。AgentCompass在关键指标上取得了最先进的结果，同时揭示了人工标注中遗漏的关键问题，强调了其作为一种强大且以开发者为中心的工具，在生产环境中对智能体系统进行可靠监控和改进的作用。|
|**2025-09-17**|[CL $^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](http://arxiv.org/abs/2509.13672)|null|自动化写作辅助在不同学术领域日益增长的需求，凸显了对能够跨学科适应的鲁棒中文语法纠错（CGEC）系统的需求。然而，现有的CGEC研究很大程度上缺乏用于多学科的学术写作的专用基准，忽视了持续学习（CL）作为处理领域特定语言变异和防止灾难性遗忘的一种有前景的解决方案。为了填补这一关键空白，我们引入了CL$^2$GEC，这是首个用于中文文献语法纠错的持续学习基准，旨在评估跨多个学术领域的自适应CGEC。我们的基准包含10,000个人工标注的句子，涵盖10个学科，每个学科都展现出独特的语言风格和错误模式。CL$^2$ GEC专注于在持续学习设置下评估语法纠错，模拟顺序暴露于不同的学术学科，以反映真实的编辑动态。我们在顺序微调、参数高效适应和四种代表性CL算法下评估了大型语言模型，使用了标准GEC指标和适应任务级别变化的持续学习指标。实验结果表明，基于正则化的方法比基于回放或朴素顺序的方法能更有效地缓解遗忘。我们的基准为未来在跨不同学术领域的自适应语法纠错研究提供了坚实的基础。|
|**2025-09-10**|[A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](http://arxiv.org/abs/2509.09727)|null|问答 (QA) 在金融教育中扮演核心角色，然而现有的大型语言模型 (LLM) 方法往往未能捕捉到解决金融问题所需的细致入微且专业化的推理。金融领域要求多步定量推理、熟悉领域特定术语以及理解现实世界情景。我们提出了一个多智能体框架，该框架利用基于角色的提示 (role-based prompting) 来提高在领域特定问答 (QA) 上的性能。我们的框架包含一个基础生成器 (Base Generator)、一个证据检索器 (Evidence Retriever) 和一个专家评审员智能体 (Expert Reviewer)，它们通过单次迭代 (single-pass iteration) 协同工作以生成一个精炼的答案。我们使用来自在线学习平台 Study.com 的 3,532 个专家设计的金融教育问题对我们的框架进行了评估。我们利用检索增强生成 (RAG) 从 6 本金融教科书中获取上下文证据，并为领域专家评审员设计了提示策略。我们的实验表明，基于批判的精炼 (critique-based refinement) 将答案准确率相较于零样本思维链 (zero-shot Chain-of-Thought) 基线提高了 6.6-8.3%，其中 Gemini-2.0-Flash 取得了最高性能。此外，我们的方法使 GPT-4o-mini 能够达到与经过金融领域微调的 FinGPT-mt_Llama3-8B_LoRA 模型相当的性能。我们的结果展示了一种提升金融问答 (QA) 的成本效益方法，并为多智能体金融大型语言模型 (LLM) 系统的进一步研究提供了见解。|
|**2025-09-10**|[Ubiquitous Intelligence Via Wireless Network-Driven LLMs Evolution](http://arxiv.org/abs/2509.08400)|null|我们引入泛在智能作为一种范式，其中大语言模型(LLMs)在无线网络驱动的生态系统中演进。与静态模型部署不同，这种方法通过网络和LLMs之间的协同，实现了可扩展和持续的智能提升。无线网络支持系统编排的终身学习，而LLMs则推动了更具适应性和响应性的下一代网络发展。这种协同演进凸显了向自我完善系统的转变，在多样化和资源受限的环境中持续提升能力。|
|**2025-08-06**|[Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting](http://arxiv.org/abs/2508.04227)|null|视觉-语言模型（VLM）通过利用大规模预训练，在各种多模态任务中取得了令人印象深刻的性能。然而，使其能够从非平稳数据中持续学习仍然是一个重大挑战，因为它们的跨模态对齐和泛化能力特别容易受到灾难性遗忘的影响。与传统单模态持续学习（CL）不同，VLM面临独特的挑战，例如跨模态特征漂移、由于共享架构引起的参数干扰以及零样本能力侵蚀。本综述首次对VLM持续学习（VLM-CL）进行了专注且系统的回顾。我们首先识别了导致VLM-CL性能下降的三种核心失效模式。在此基础上，我们提出了一种挑战驱动的分类法，将解决方案映射到其目标问题上：(1) 多模态回放策略通过显式或隐式记忆机制解决跨模态漂移；(2) 跨模态正则化在更新期间保持模态对齐；以及(3) 参数高效适应通过模块化或低秩更新缓解参数干扰。我们进一步分析了当前的评估协议、数据集和指标，强调需要更好的基准来捕捉VLM特有的遗忘和组合泛化能力。最后，我们概述了开放问题和未来方向，包括持续预训练和组合零样本学习。本综述旨在为开发终身视觉-语言系统的研究人员提供全面且诊断性的参考。所有资源均可在：https://github.com/YuyangSunshine/Awesome-Continual-learning-of-Vision-Language-Models 获取。|
|**2025-10-28**|[CalFuse: Multi-Modal Continual Learning via Feature Calibration and Parameter Fusion](http://arxiv.org/abs/2503.18672)|null|随着多模态数据在大规模视觉识别系统中的普及，使模型能够从不断演变的数据流中持续获取知识，同时保留先前信息，已变得越来越关键。类别持续学习 (CCL) 通过在不重新访问历史数据的情况下增量地整合新类别知识来解决这一挑战，这使其对现实世界的大数据应用至关重要。尽管传统的CCL方法仅依赖视觉特征，但视觉-语言模型 (VLM)（如CLIP）的最新进展通过利用预训练的多模态知识，为CCL展示了巨大潜力。然而，现有方法在缓解灾难性遗忘的同时保持VLM的跨模态泛化能力方面面临挑战。为解决这些局限性，我们提出了CalFuse，一个将特征校准与参数融合相结合的框架，以实现在持续学习场景中有效进行多模态知识整合。CalFuse引入了一种动态特征校准机制，该机制自适应地平衡原始CLIP视觉表示与特定任务特征，从而保留了模型固有的跨模态泛化能力，同时适应新类别。同时，一种基于QR分解的参数融合策略逐步将新获取的知识与历史任务参数相结合，在学习新类别表示和在顺序任务中保留先前知识之间保持平衡。在基准数据集上进行的广泛实验验证了我们方法在大规模多模态持续学习设置中的有效性，在平均准确性和最终任务保留方面均表现出优于现有最先进方法的性能。|
|**2025-02-27**|[When Continue Learning Meets Multimodal Large Language Model: A Survey](http://arxiv.org/abs/2503.01887)|null|人工智能的最新进展促成了多模态大语言模型（MLLM）的发展。然而，使这些预训练模型高效适应动态数据分布和各种任务仍然是一个挑战。针对特定任务微调MLLM经常导致模型先验知识领域的性能下降，这个问题被称为“灾难性遗忘”。尽管这个问题在持续学习（CL）社区已得到充分研究，但它为MLLM带来了新的挑战。本综述论文作为MLLM持续学习领域的首篇此类综述，对该领域的440篇研究论文进行了概述和分析。本综述分为四个部分。首先，它讨论了MLLM的最新研究，涵盖了模型创新、基准测试以及在各个领域的应用。其次，它对持续学习的最新研究进行了分类和概述，分为三个部分：非大语言模型单模态持续学习（Non-LLM Unimodal CL）、非大语言模型多模态持续学习（Non-LLM Multimodal CL）以及大语言模型中的持续学习（CL in LLM）。第三部分详细分析了MLLM持续学习研究的现状，包括基准评估、架构创新以及理论和实证研究的总结。最后，本文讨论了MLLM中持续学习的挑战和未来方向，旨在启发该领域的未来研究和发展。本综述连接了多模态大模型持续学习的基础概念、理论见解、方法创新和实际应用，提供了对该领域研究进展和挑战的全面理解，旨在启发该领域的研究人员并促进相关技术的进步。|
|**2025-01-13**|[Lifelong Learning of Large Language Model based Agents: A Roadmap](http://arxiv.org/abs/2501.07278)|null|终身学习，也称为持续学习或增量学习，是推进通用人工智能（AGI）的关键组成部分，它使系统能够在动态环境中持续适应。尽管大型语言模型（LLM）在自然语言处理方面表现出令人印象深刻的能力，但现有的LLM智能体通常为静态系统设计，缺乏随时间适应以应对新挑战的能力。本综述首次系统地总结了将终身学习融入基于LLM的智能体中的潜在技术。我们将这些智能体的核心组件分为三个模块：用于多模态输入集成的感知模块、用于存储和检索演进知识的记忆模块，以及用于与动态环境进行基础交互的行动模块。我们强调这些支柱如何共同实现持续适应、缓解灾难性遗忘并提高长期性能。本综述为致力于开发LLM智能体终身学习能力的研究人员和从业者提供了一份路线图，其中包含了对新兴趋势、评估指标和应用场景的见解。相关文献和资源可在https://github.com/qianlima-lab/awesome-lifelong-llm-agent获取。|
|**2025-08-13**|[Improving Multimodal Large Language Models Using Continual Learning](http://arxiv.org/abs/2410.19925)|null|生成式大型语言模型（LLM）展现出令人印象深刻的能力，通过将预训练视觉模型整合到原始LLM中，可以进一步增强这些能力，从而创建多模态LLM（MLLM）。然而，与原始LLM相比，这种整合往往会显著降低其在自然语言理解和生成任务上的性能。本研究使用LLaVA多模态大模型探讨了这个问题，将这种整合视为一个持续学习问题。我们评估了五种持续学习方法以减轻遗忘，并确定了一种在增强视觉理解的同时最大限度地减少语言性能损失的技术。我们的方法将语言性能下降相较于LLaVA方案降低了高达15%，同时保持了高多模态准确性。我们还通过在连续的视觉-语言任务上进行持续学习，证明了我们方法的鲁棒性，有效地保留了语言技能，同时获得了新的多模态能力。项目网页：https://shikhar-srivastava.github.io/cl-for-improving-mllms|
|**2024-10-23**|[RE-tune: Incremental Fine Tuning of Biomedical Vision-Language Models for Multi-label Chest X-ray Classification](http://arxiv.org/abs/2410.17827)|null|本文引入RE-tune，一种新颖的方法，用于在增量学习场景中对预训练的多模态生物医学视觉-语言模型（VLMs）进行微调，以实现多标签胸部疾病诊断。RE-tune冻结骨干网络，仅在VLM的图像和文本编码器之上训练简单的适配器。通过为疾病设计正向和负向文本提示，我们利用大型语言模型的能力来引导训练轨迹。我们在三种现实的增量学习场景中评估了RE-tune：类别增量、标签增量和数据增量。我们的结果表明，生物医学VLM是天然的持续学习器，并能防止灾难性遗忘。RE-tune不仅实现了准确的多标签分类结果，而且优先考虑患者隐私，并通过卓越的计算效率脱颖而出，使其非常适合在现实世界的医疗环境中广泛采用。|
|**2025-11-13**|[Caption, Create, Continue: Continual Learning with Pre-trained Generative Vision-Language Models](http://arxiv.org/abs/2409.17806)|null|持续学习（CL）使模型能够适应不断演变的数据流而不会出现灾难性遗忘，这是真实世界AI系统的一项基本要求。然而，当前方法通常依赖于大型回放缓冲区或大量标注的数据集，这由于存储、隐私和成本限制而变得不切实际。我们提出CLTS（通过文本-图像协同的持续学习），这是一种新颖的类增量框架，可以在不存储真实任务数据的情况下减轻遗忘。CLTS利用预训练的视觉-语言模型，其中BLIP（自举语言-图像预训练）用于字幕生成，稳定扩散用于样本生成。每个任务由一个专用的任务头处理，而一个任务路由器学习使用生成的数据将输入分配给正确的任务头。在三个基准数据集上，CLTS将平均任务准确率提高了高达54%，并且与四种近期持续学习基线相比，实现了63倍的内存效率提升，证明了更好的保留能力和适应性。CLTS通过整合生成式文本-图像增强，为可扩展的持续学习引入了一个新颖的视角。|
|**2024-06-10**|[Towards Lifelong Learning of Large Language Models: A Survey](http://arxiv.org/abs/2406.06391)|null|随着大型语言模型（LLMs）的应用范围扩展到各个领域，这些模型适应数据、任务和用户偏好持续变化的能力变得至关重要。传统的训练方法依赖于静态数据集，在应对真实世界信息的动态性方面越来越不足。终身学习，也称为持续学习或增量学习，通过使LLMs在其运行生命周期中持续自适应地学习，整合新知识同时保留先前学习的信息并防止灾难性遗忘，从而解决了这一挑战。本综述深入探讨了终身学习的复杂领域，将策略分为两大类：内部知识和外部知识。内部知识包括持续预训练和持续微调，它们各自在各种场景中增强了LLMs的适应性。外部知识包括基于检索和基于工具的终身学习，它们利用外部数据源和计算工具来扩展模型的能力，而无需修改核心参数。本综述的主要贡献在于：(1) 引入了一种新颖的分类法，将终身学习的广泛文献归类为12种场景；(2) 识别了所有终身学习场景中的通用技术，并将现有文献分类到每个场景内的各种技术组中；(3) 突出了模型扩展和数据选择等新兴技术，这些技术在LLM前时代探索较少。通过对这些组及其各自类别的详细审查，本综述旨在增强LLMs在实际应用中的适应性、可靠性和整体性能。|
|**2024-11-29**|[Recent Advances of Foundation Language Models-based Continual Learning: A Survey](http://arxiv.org/abs/2405.18653)|null|最近，基础语言模型（LMs）在自然语言处理（NLP）和计算机视觉（CV）领域取得了显著成就。与传统神经网络模型不同，基础语言模型通过在包含大量参数的广泛无监督数据集上进行预训练，获取了丰富的常识知识，从而获得了强大的迁移学习能力。然而，由于灾难性遗忘，它们仍无法模拟人类般的持续学习。因此，各种基于持续学习（CL）的方法学已被开发出来，以改进语言模型，使其能够在不遗忘先前知识的情况下适应新任务。然而，目前仍缺乏对现有方法的系统分类及其性能比较，这正是本综述旨在填补的空白。我们深入回顾、总结并分类了应用于基础语言模型（如预训练语言模型（PLMs）、大语言模型（LLMs）和视觉-语言模型（VLMs））的基于持续学习的方法的现有文献。我们将这些研究分为离线持续学习（offline CL）和在线持续学习（online CL），其中包括传统方法、参数高效方法、指令微调方法和持续预训练方法。离线持续学习包括域增量学习、任务增量学习和类增量学习，而在线持续学习则细分为硬任务边界和模糊任务边界设置。此外，我们概述了持续学习研究中常用的数据集和评估指标，并详细分析了基于语言模型的持续学习所面临的挑战和未来的工作。|
|**2024-03-18**|[CoLeCLIP: Open-Domain Continual Learning via Joint Task Prompt and Vocabulary Learning](http://arxiv.org/abs/2403.10245)|**[link](https://github.com/YukunLi99/CoLeCLIP)**|本文探讨了开放域中视觉-语言模型（VLM）的持续学习（CL）问题，其中模型需要对来自包含新类别、不同已知和未知域的数据流进行持续更新和推理。这种能力对于开放环境中的多种应用至关重要，例如AI助手、自动驾驶系统和机器人技术。当前CL研究大多关注具有已知类别的单一域中的闭集场景。像CLIP这样的大型预训练VLM已展示出卓越的零样本识别能力，并且最近的一些研究利用这种能力来缓解CL中的灾难性遗忘，但它们关注的是单一域数据集上的闭集CL。大型VLM的开放域CL挑战性显著更大，原因在于1) 数据集之间存在较大的类别相关性和域差距，以及2) 除了从新适应的数据集中学到的知识外，预训练VLM中零样本知识的遗忘。在这项工作中，我们引入了一种新颖方法，命名为CoLeCLIP，它学习一个基于CLIP的开放域CL模型。它通过联合学习一组任务提示和跨域类别词汇来解决这些挑战。在11个域数据集上的广泛实验表明，CoLeCLIP在任务增量和类别增量学习设置下均优于开放域CL的最先进方法。|
|**2023-12-05**|[Investigating the Catastrophic Forgetting in Multimodal Large Language Models](http://arxiv.org/abs/2309.10313)|null|继GPT4成功之后，多模态大型语言模型（MLLM）研究的兴趣激增。这类研究侧重于通过微调预训练的大型语言模型（LLM）和视觉模型来开发通用型LLM。然而，灾难性遗忘——一种臭名昭著的现象，即微调后的模型未能保持与预训练模型相似的性能——仍然是多模态大型语言模型（MLLM）中固有的问题。在本文中，我们引入了EMT（Evaluating MulTimodality）来评估MLLM中的灾难性遗忘，方法是将每个MLLM视为一个图像分类器。我们首先应用EMT评估了几个开源的微调MLLM，发现几乎所有被评估的MLLM在标准图像分类任务上都未能保持与其视觉编码器相同的性能水平。此外，我们对一个MLLM LLaVA进行持续微调，并利用EMT在整个微调过程中评估其性能。有趣的是，我们的结果表明，在图像数据集上进行早期阶段的微调，通过增强文本和视觉特征的对齐，可以提高在其他图像数据集上的性能。然而，随着微调的进行，MLLM开始出现幻觉，导致泛化能力显著下降，即使图像编码器保持冻结状态也是如此。我们的结果表明，MLLM在标准图像分类任务上尚未展现出与其视觉模型相当的性能，并且当前的MLLM微调程序仍有改进空间。|

## Transformer

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-12-19**|[Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting](http://arxiv.org/abs/2512.17696)|null|The modeling of high-dimensional spatio-temporal processes presents a fundamental dichotomy between the probabilistic rigor of classical geostatistics and the flexible, high-capacity representations of deep learning. While Gaussian processes offer theoretical consistency and exact uncertainty quantification, their prohibitive computational scaling renders them impractical for massive sensor networks. Conversely, modern transformer architectures excel at sequence modeling but inherently lack a geometric inductive bias, treating spatial sensors as permutation-invariant tokens without a native understanding of distance. In this work, we propose a spatially-informed transformer, a hybrid architecture that injects a geostatistical inductive bias directly into the self-attention mechanism via a learnable covariance kernel. By formally decomposing the attention structure into a stationary physical prior and a non-stationary data-driven residual, we impose a soft topological constraint that favors spatially proximal interactions while retaining the capacity to model complex dynamics. We demonstrate the phenomenon of ``Deep Variography'', where the network successfully recovers the true spatial decay parameters of the underlying process end-to-end via backpropagation. Extensive experiments on synthetic Gaussian random fields and real-world traffic benchmarks confirm that our method outperforms state-of-the-art graph neural networks. Furthermore, rigorous statistical validation confirms that the proposed method delivers not only superior predictive accuracy but also well-calibrated probabilistic forecasts, effectively bridging the gap between physics-aware modeling and data-driven learning.|
|**2025-12-19**|[Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study](http://arxiv.org/abs/2512.17477)|null|Inconel 625等高温合金的时效变形，尤其是蠕变，是航空航天和能源系统中使用的部件长期可靠性的关键因素。尽管Inconel 625表现出优异的抗蠕变性能，但在ANSYS等工具中进行的有限元蠕变模拟仍然计算成本高昂，单次10,000小时的运行通常需要数十分钟。本研究提出了基于深度学习的代理模型，以提供此类模拟的快速准确替代方案。在ANSYS中，使用诺顿定律在50至150 MPa的单轴应力和700至1000 °C的温度下生成了蠕变应变数据，并利用该时间序列数据集训练了两种架构：一种是用于不确定性感知和生成预测的BiLSTM变分自编码器，另一种是采用自注意力机制捕获长程时间行为的BiLSTM Transformer混合模型。两种模型都充当代理预测器，其中BiLSTM-VAE提供概率输出，而BiLSTM-Transformer提供高确定性精度。性能使用均方根误差（RMSE）、平均绝对误差（MAE）和决定系数（R^2）进行评估。结果表明，BiLSTM-VAE提供了稳定可靠的蠕变应变预测，而BiLSTM-Transformer在整个时间范围内实现了高精度。延迟测试表明显著加速：虽然每个ANSYS模拟在给定应力-温度条件下需要30到40分钟，但代理模型在数秒内即可生成预测。所提出的框架实现了设计优化和结构健康监测的快速蠕变评估，并为高温合金应用提供了可扩展的解决方案。|
|**2025-12-19**|[Linear Attention for Joint Power Optimization and User-Centric Clustering in Cell-Free Networks](http://arxiv.org/abs/2512.17466)|null|在以用户为中心的无蜂窝大规模MIMO系统中，最佳AP聚类和功率分配至关重要。现有的深度学习模型在处理动态网络配置时缺乏灵活性。此外，许多方法忽略导频污染，并存在高计算复杂度。在本文中，我们提出了一种轻量级Transformer模型，通过仅根据用户设备和AP的空间坐标联合预测AP聚类和功率，从而克服了这些局限性。我们的模型对用户负载的架构是无关的，无需信道估计开销即可同时处理聚类和功率分配，并通过在导频复用约束内将用户分配给AP来消除导频污染。我们还引入了一种定制的线性注意力机制，以有效地捕获用户-AP交互，并实现随着用户数量增加的线性可扩展性。数值结果证实了该模型在最大化最小频谱效率和提供接近最优性能方面的有效性，同时确保了在动态场景中的适应性和可扩展性。|
|**2025-12-19**|[A Systematic Reproducibility Study of BSARec for Sequential Recommendation](http://arxiv.org/abs/2512.17442)|null|In sequential recommendation (SR), the self-attention mechanism of Transformer-based models acts as a low-pass filter, limiting their ability to capture high-frequency signals that reflect short-term user interests. To overcome this, BSARec augments the Transformer encoder with a frequency layer that rescales high-frequency components using the Fourier transform. However, the overall effectiveness of BSARec and the roles of its individual components have yet to be systematically validated. We reproduce BSARec and show that it outperforms other SR methods on some datasets. To empirically assess whether BSARec improves performance on high-frequency signals, we propose a metric to quantify user history frequency and evaluate SR methods across different user groups. We compare digital signal processing (DSP) techniques and find that the discrete wavelet transform (DWT) offer only slight improvements over Fourier transforms, and DSP methods provide no clear advantage over simple residual connections. Finally, we explore padding strategies and find that non-constant padding significantly improves recommendation performance, whereas constant padding hinders the frequency rescaler's ability to capture high-frequency signals.|
|**2025-12-19**|[EMAG: Self-Rectifying Diffusion Sampling with Exponential Moving Average Guidance](http://arxiv.org/abs/2512.17303)|null|In diffusion and flow-matching generative models, guidance techniques are widely used to improve sample quality and consistency. Classifier-free guidance (CFG) is the de facto choice in modern systems and achieves this by contrasting conditional and unconditional samples. Recent work explores contrasting negative samples at inference using a weaker model, via strong/weak model pairs, attention-based masking, stochastic block dropping, or perturbations to the self-attention energy landscape. While these strategies refine the generation quality, they still lack reliable control over the granularity or difficulty of the negative samples, and target-layer selection is often fixed. We propose Exponential Moving Average Guidance (EMAG), a training-free mechanism that modifies attention at inference time in diffusion transformers, with a statistics-based, adaptive layer-selection rule. Unlike prior methods, EMAG produces harder, semantically faithful negatives (fine-grained degradations), surfacing difficult failure modes, enabling the denoiser to refine subtle artifacts, boosting the quality and human preference score (HPS) by +0.46 over CFG. We further demonstrate that EMAG naturally composes with advanced guidance techniques, such as APG and CADS, further improving HPS.|
|**2025-12-19**|[Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces](http://arxiv.org/abs/2512.17149)|null|This study investigates the task of dwell time prediction and proposes a Transformer framework based on interaction behavior modeling. The method first represents user interaction sequences on the interface by integrating dwell duration, click frequency, scrolling behavior, and contextual features, which are mapped into a unified latent space through embedding and positional encoding. On this basis, a multi-head self-attention mechanism is employed to capture long-range dependencies, while a feed-forward network performs deep nonlinear transformations to model the dynamic patterns of dwell time. Multiple comparative experiments are conducted with BILSTM, DRFormer, FedFormer, and iTransformer as baselines under the same conditions. The results show that the proposed method achieves the best performance in terms of MSE, RMSE, MAPE, and RMAE, and more accurately captures the complex patterns in interaction behavior. In addition, sensitivity experiments are carried out on hyperparameters and environments to examine the impact of the number of attention heads, sequence window length, and device environment on prediction performance, which further demonstrates the robustness and adaptability of the method. Overall, this study provides a new solution for dwell time prediction from both theoretical and methodological perspectives and verifies its effectiveness in multiple aspects.|
|**2025-12-18**|[DVGT: Driving Visual Geometry Transformer](http://arxiv.org/abs/2512.16919)|null|Perceiving and reconstructing 3D scene geometry from visual inputs is crucial for autonomous driving. However, there still lacks a driving-targeted dense geometry perception model that can adapt to different scenarios and camera configurations. To bridge this gap, we propose a Driving Visual Geometry Transformer (DVGT), which reconstructs a global dense 3D point map from a sequence of unposed multi-view visual inputs. We first extract visual features for each image using a DINO backbone, and employ alternating intra-view local attention, cross-view spatial attention, and cross-frame temporal attention to infer geometric relations across images. We then use multiple heads to decode a global point map in the ego coordinate of the first frame and the ego poses for each frame. Unlike conventional methods that rely on precise camera parameters, DVGT is free of explicit 3D geometric priors, enabling flexible processing of arbitrary camera configurations. DVGT directly predicts metric-scaled geometry from image sequences, eliminating the need for post-alignment with external sensors. Trained on a large mixture of driving datasets including nuScenes, OpenScene, Waymo, KITTI, and DDAD, DVGT significantly outperforms existing models on various scenarios. Code is available at https://github.com/wzzheng/DVGT.|
|**2025-12-18**|[CLARiTy: A Vision Transformer for Multi-Label Classification and Weakly-Supervised Localization of Chest X-ray Pathologies](http://arxiv.org/abs/2512.16700)|null|The interpretation of chest X-rays (CXRs) poses significant challenges, particularly in achieving accurate multi-label pathology classification and spatial localization. These tasks demand different levels of annotation granularity but are frequently constrained by the scarcity of region-level (dense) annotations. We introduce CLARiTy (Class Localizing and Attention Refining Image Transformer), a vision transformer-based model for joint multi-label classification and weakly-supervised localization of thoracic pathologies. CLARiTy employs multiple class-specific tokens to generate discriminative attention maps, and a SegmentCAM module for foreground segmentation and background suppression using explicit anatomical priors. Trained on image-level labels from the NIH ChestX-ray14 dataset, it leverages distillation from a ConvNeXtV2 teacher for efficiency. Evaluated on the official NIH split, the CLARiTy-S-16-512 (a configuration of CLARiTy), achieves competitive classification performance across 14 pathologies, and state-of-the-art weakly-supervised localization performance on 8 pathologies, outperforming prior methods by 50.7%. In particular, pronounced gains occur for small pathologies like nodules and masses. The lower-resolution variant of CLARiTy, CLARiTy-S-16-224, offers high efficiency while decisively surpassing baselines, thereby having the potential for use in low-resource settings. An ablation study confirms contributions of SegmentCAM, DINO pretraining, orthogonal class token loss, and attention pooling. CLARiTy advances beyond CNN-ViT hybrids by harnessing ViT self-attention for global context and class-specific localization, refined through convolutional background suppression for precise, noise-reduced heatmaps.|
|**2025-12-19**|[DeContext as Defense: Safe Image Editing in Diffusion Transformers](http://arxiv.org/abs/2512.16625)|null|In-context diffusion models allow users to modify images with remarkable ease and realism. However, the same power raises serious privacy concerns: personal images can be easily manipulated for identity impersonation, misinformation, or other malicious uses, all without the owner's consent. While prior work has explored input perturbations to protect against misuse in personalized text-to-image generation, the robustness of modern, large-scale in-context DiT-based models remains largely unexamined. In this paper, we propose DeContext, a new method to safeguard input images from unauthorized in-context editing. Our key insight is that contextual information from the source image propagates to the output primarily through multimodal attention layers. By injecting small, targeted perturbations that weaken these cross-attention pathways, DeContext breaks this flow, effectively decouples the link between input and output. This simple defense is both efficient and robust. We further show that early denoising steps and specific transformer blocks dominate context propagation, which allows us to concentrate perturbations where they matter most. Experiments on Flux Kontext and Step1X-Edit show that DeContext consistently blocks unwanted image edits while preserving visual quality. These results highlight the effectiveness of attention-based perturbations as a powerful defense against image manipulation. Code is available at https://github.com/LinghuiiShen/DeContext.|
|**2025-12-18**|[DeContext as Defense: Safe Image Editing in Diffusion Transformers](http://arxiv.org/abs/2512.16625)|null|In-context diffusion models allow users to modify images with remarkable ease and realism. However, the same power raises serious privacy concerns: personal images can be easily manipulated for identity impersonation, misinformation, or other malicious uses, all without the owner's consent. While prior work has explored input perturbations to protect against misuse in personalized text-to-image generation, the robustness of modern, large-scale in-context DiT-based models remains largely unexamined. In this paper, we propose DeContext, a new method to safeguard input images from unauthorized in-context editing. Our key insight is that contextual information from the source image propagates to the output primarily through multimodal attention layers. By injecting small, targeted perturbations that weaken these cross-attention pathways, DeContext breaks this flow, effectively decouples the link between input and output. This simple defense is both efficient and robust. We further show that early denoising steps and specific transformer blocks dominate context propagation, which allows us to concentrate perturbations where they matter most. Experiments on Flux Kontext and Step1X-Edit show that DeContext consistently blocks unwanted image edits while preserving visual quality. These results highlight the effectiveness of attention-based perturbations as a powerful defense against image manipulation.|
|**2025-12-18**|[Trainable Log-linear Sparse Attention for Efficient Diffusion Transformers](http://arxiv.org/abs/2512.16615)|null|Diffusion Transformers (DiTs) set the state of the art in visual generation, yet their quadratic self-attention cost fundamentally limits scaling to long token sequences. Recent Top-K sparse attention approaches reduce the computation of DiTs by compressing tokens into block-wise representation and selecting a small set of relevant key blocks, but still suffer from (i) quadratic selection cost on compressed tokens and (ii) increasing K required to maintain model quality as sequences grow. We identify that their inefficiency is due to the single-level design, as a single coarse level is insufficient to represent the global structure. In this paper, we introduce Log-linear Sparse Attention (LLSA), a trainable sparse attention mechanism for extremely long token sequences that reduces both selection and attention costs from quadratic to log-linear complexity by utilizing a hierarchical structure. LLSA performs hierarchical Top-K selection, progressively adopting sparse Top-K selection with the indices found at the previous level, and introduces a Hierarchical KV Enrichment mechanism that preserves global context while using fewer tokens of different granularity during attention computation. To support efficient training, we develop a high-performance GPU implementation that uses only sparse indices for both the forward and backward passes, eliminating the need for dense attention masks. We evaluate LLSA on high-resolution pixel-space image generation without using patchification and VAE encoding. LLSA accelerates attention inference by 28.27x and DiT training by 6.09x on 256x256 pixel token sequences, while maintaining generation quality. The results demonstrate that LLSA offers a promising direction for training long-sequence DiTs efficiently. Code is available at: https://github.com/SingleZombie/LLSA|
|**2025-12-18**|[In-Context Multi-Operator Learning with DeepOSets](http://arxiv.org/abs/2512.16074)|null|In-context Learning (ICL) is the remarkable capability displayed by some machine learning models to learn from examples in a prompt, without any further weight updates. ICL had originally been thought to emerge from the self-attention mechanism in autoregressive transformer architectures. DeepOSets is a non-autoregressive, non-attention based neural architecture that combines set learning via the DeepSets architecture with operator learning via Deep Operator Networks (DeepONets). In a previous study, DeepOSets was shown to display ICL capabilities in supervised learning problems. In this paper, we show that the DeepOSets architecture, with the appropriate modifications, is a multi-operator in-context learner that can recover the solution operator of a new PDE, not seen during training, from example pairs of parameter and solution placed in a user prompt, without any weight updates. Furthermore, we show that DeepOSets is a universal uniform approximator over a class of continuous operators, which we believe is the first result of its kind in the literature of scientific machine learning. This means that a single DeepOSets architecture exists that approximates in-context any continuous operator in the class to any fixed desired degree accuracy, given an appropriate number of examples in the prompt. Experiments with Poisson and reaction-diffusion forward and inverse boundary-value problems demonstrate the ability of the proposed model to use in-context examples to predict accurately the solutions corresponding to parameter queries for PDEs not seen during training.|
|**2025-12-17**|[Lyapunov-based Adaptive Transformer (LyAT) for Control of Stochastic Nonlinear Systems](http://arxiv.org/abs/2512.15996)|**[link](https://github.com/saia-akbari/Lyapunov-based-Adaptive-Transformer_LyAT_for-Control-of-Stochastic-Nonlinear-Systems)**|This paper presents a novel Lyapunov-based Adaptive Transformer (LyAT) controller for stochastic nonlinear systems. While transformers have shown promise in various control applications due to sequential modeling through self-attention mechanisms, they have not been used within adaptive control architectures that provide stability guarantees. Existing transformer-based approaches for control rely on offline training with fixed weights, resulting in open-loop implementations that lack real-time adaptation capabilities and stability assurances. To address these limitations, a continuous LyAT controller is developed that adaptively estimates drift and diffusion uncertainties in stochastic dynamical systems without requiring offline pre-training. A key innovation is the analytically derived adaptation law constructed from a Lyapunov-based stability analysis, which enables real-time weight updates while guaranteeing probabilistic uniform ultimate boundedness of tracking and parameter estimation errors. Experimental validation on a quadrotor demonstrates the performance of the developed controller.|
|**2025-12-17**|[Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models](http://arxiv.org/abs/2512.15973)|null|We propose Dynamic Rank Reinforcement Learning (DR-RL), a novel framework that adaptively optimizes the low-rank factorization of Multi-Head Self-Attention (MHSA) in Large Language Models (LLMs) through the integration of reinforcement learning and online matrix perturbation theory. While traditional low-rank approximations often rely on static rank assumptions--limiting their flexibility across diverse input contexts--our method dynamically selects ranks based on real-time sequence dynamics, layer-specific sensitivities, and hardware constraints. The core innovation lies in an RL agent that formulates rank selection as a sequential policy optimization problem, where the reward function strictly balances attention fidelity against computational latency. Crucially, we employ online matrix perturbation bounds to enable incremental rank updates, thereby avoiding the prohibitive cost of full decomposition during inference. Furthermore, the integration of a lightweight Transformer-based policy network and batched Singular Value Decomposition (SVD) operations ensures scalable deployment on modern GPU architectures. Experiments demonstrate that DR-RL maintains downstream accuracy statistically equivalent to full-rank attention while significantly reducing Floating Point Operations (FLOPs), particularly in long-sequence regimes (L > 4096). This work bridges the gap between adaptive efficiency and theoretical rigor in MHSA, offering a principled, mathematically grounded alternative to heuristic rank reduction techniques in resource-constrained deep learning. Source code and experiment logs are available at: https://github.com/canererden/DR_RL_Project|
|**2025-12-17**|[Multi-Modal Semantic Communication](http://arxiv.org/abs/2512.15691)|**[link](https://github.com/2sqr10minus1/Multi-SemComm)**|Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.|
|**2025-12-17**|[DeX-Portrait: Disentangled and Expressive Portrait Animation via Explicit and Latent Motion Representations](http://arxiv.org/abs/2512.15524)|null|Portrait animation from a single source image and a driving video is a long-standing problem. Recent approaches tend to adopt diffusion-based image/video generation models for realistic and expressive animation. However, none of these diffusion models realizes high-fidelity disentangled control between the head pose and facial expression, hindering applications like expression-only or pose-only editing and animation. To address this, we propose DeX-Portrait, a novel approach capable of generating expressive portrait animation driven by disentangled pose and expression signals. Specifically, we represent the pose as an explicit global transformation and the expression as an implicit latent code. First, we design a powerful motion trainer to learn both pose and expression encoders for extracting precise and decomposed driving signals. Then we propose to inject the pose transformation into the diffusion model through a dual-branch conditioning mechanism, and the expression latent through cross attention. Finally, we design a progressive hybrid classifier-free guidance for more faithful identity consistency. Experiments show that our method outperforms state-of-the-art baselines on both animation quality and disentangled controllability.|
|**2025-12-17**|[Attention in Motion: Secure Platooning via Transformer-based Misbehavior Detection](http://arxiv.org/abs/2512.15503)|null|Vehicular platooning promises transformative improvements in transportation efficiency and safety through the coordination of multi-vehicle formations enabled by Vehicle-to-Everything (V2X) communication. However, the distributed nature of platoon coordination creates security vulnerabilities, allowing authenticated vehicles to inject falsified kinematic data, compromise operational stability, and pose a threat to passenger safety. Traditional misbehaviour detection approaches, which rely on plausibility checks and statistical methods, suffer from high False Positive (FP) rates and cannot capture the complex temporal dependencies inherent in multi-vehicle coordination dynamics. We present Attention In Motion (AIMformer), a transformer-based framework specifically tailored for real-time misbehaviour detection in vehicular platoons with edge deployment capabilities. AIMformer leverages multi-head self-attention mechanisms to simultaneously capture intra-vehicle temporal dynamics and inter-vehicle spatial correlations. It incorporates global positional encoding with vehicle-specific temporal offsets to handle join/exit maneuvers. We propose a Precision-Focused (BCE) loss function that penalizes FPs to meet the requirements of safety-critical vehicular systems. Extensive evaluation across 4 platoon controllers, multiple attack vectors, and diverse mobility scenarios demonstrates superior performance ( $\geq$ 0.93) compared to state-of-the-art baseline architectures. A comprehensive deployment analysis utilizing TensorFlow Lite (TFLite), Open Neural Network Exchange (ONNX), and TensorRT achieves sub-millisecond inference latency, making it suitable for real-time operation on resource-constrained edge platforms. Hence, validating AIMformer is viable for both in-vehicle and roadside infrastructure deployment.|
|**2025-12-12**|[EditMGT: Unleashing Potentials of Masked Generative Transformers in Image Editing](http://arxiv.org/abs/2512.11715)|**[link](https://github.com/weichow23/EditMGT)**|Recent advances in diffusion models (DMs) have achieved exceptional visual quality in image editing tasks. However, the global denoising dynamics of DMs inherently conflate local editing targets with the full-image context, leading to unintended modifications in non-target regions. In this paper, we shift our attention beyond DMs and turn to Masked Generative Transformers (MGTs) as an alternative approach to tackle this challenge. By predicting multiple masked tokens rather than holistic refinement, MGTs exhibit a localized decoding paradigm that endows them with the inherent capacity to explicitly preserve non-relevant regions during the editing process. Building upon this insight, we introduce the first MGT-based image editing framework, termed EditMGT. We first demonstrate that MGT's cross-attention maps provide informative localization signals for localizing edit-relevant regions and devise a multi-layer attention consolidation scheme that refines these maps to achieve fine-grained and precise localization. On top of these adaptive localization results, we introduce region-hold sampling, which restricts token flipping within low-attention areas to suppress spurious edits, thereby confining modifications to the intended target regions and preserving the integrity of surrounding non-target areas. To train EditMGT, we construct CrispEdit-2M, a high-resolution dataset spanning seven diverse editing categories. Without introducing additional parameters, we adapt a pre-trained text-to-image MGT into an image editing model through attention injection. Extensive experiments across four standard benchmarks demonstrate that, with fewer than 1B parameters, our model achieves similarity performance while enabling 6 times faster editing. Moreover, it delivers comparable or superior editing quality, with improvements of 3.6% and 17.6% on style change and style transfer tasks, respectively.|
|**2025-12-12**|[RadarFuseNet: Complex-Valued Attention-Based Fusion of IQ Time- and Frequency-Domain Radar Features for Classification Tasks](http://arxiv.org/abs/2512.11537)|null|毫米波(mmWave)雷达已成为一种紧凑而强大的传感模式，用于利用机器学习技术的高级感知任务。它在视觉传感器无法获取可靠信息的场景中特别有效，例如检测被遮挡物体或区分室内环境中不同表面材料。由于毫米波雷达信号的非线性特性，基于深度学习的方法非常适合从同相和正交(IQ)数据中提取相关信息。然而，当前基于IQ信号的被遮挡物体和材料分类最先进技术仍有巨大的改进潜力。在本文中，我们提出了一种双向交叉注意力融合网络，该网络结合了通过不同复值卷积神经网络(CNN)获得的IQ信号和FFT变换后的雷达特征。与独立的复值CNN相比，所提出的方法实现了改进的性能和鲁棒性。我们在训练期间使用的相同传感器到表面距离处收集的样本上，实现了99.92%的近乎完美的材料分类精度；在先前未见过的距离处测量的样本上，精度提高到67.38%，证明了在不同测量条件下泛化能力的提高。此外，被遮挡物体分类的精度从使用独立的复值CNN的91.99%提高到使用我们提出的方法的94.20%。|
|**2025-12-12**|[Task-Specific Sparse Feature Masks for Molecular Toxicity Prediction with Chemical Language Models](http://arxiv.org/abs/2512.11412)|null|Reliable in silico molecular toxicity prediction is a cornerstone of modern drug discovery, offering a scalable alternative to experimental screening. However, the black-box nature of state-of-the-art models remains a significant barrier to adoption, as high-stakes safety decisions demand verifiable structural insights alongside predictive performance. To address this, we propose a novel multi-task learning (MTL) framework designed to jointly enhance accuracy and interpretability. Our architecture integrates a shared chemical language model with task-specific attention modules. By imposing an L1 sparsity penalty on these modules, the framework is constrained to focus on a minimal set of salient molecular fragments for each distinct toxicity endpoint. The resulting framework is trained end-to-end and is readily adaptable to various transformer-based backbones. Evaluated on the ClinTox, SIDER, and Tox21 benchmark datasets, our approach consistently outperforms both single-task and standard MTL baselines. Crucially, the sparse attention weights provide chemically intuitive visualizations that reveal the specific fragments influencing predictions, thereby enhancing insight into the model's decision-making process.|
|**2025-12-12**|[Do We Need Reformer for Vision? An Experimental Comparison with Vision Transformers](http://arxiv.org/abs/2512.11260)|null|Transformers have recently demonstrated strong performance in computer vision, with Vision Transformers (ViTs) leveraging self-attention to capture both low-level and high-level image features. However, standard ViTs remain computationally expensive, since global self-attention scales quadratically with the number of tokens, which limits their practicality for high-resolution inputs and resource-constrained settings.   In this work, we investigate the Reformer architecture as an alternative vision backbone. By combining patch-based tokenization with locality-sensitive hashing (LSH) attention, our model approximates global self-attention while reducing its theoretical time complexity from $\mathcal{O}(n^2)$ to $\mathcal{O}(n \log n)$ in the sequence length $n$ . We evaluate the proposed Reformer-based vision model on CIFAR-10 to assess its behavior on small-scale datasets, on ImageNet-100 to study its accuracy--efficiency trade-off in a more realistic setting, and on a high-resolution medical imaging dataset to evaluate the model under longer token sequences.   While the Reformer achieves higher accuracy on CIFAR-10 compared to our ViT-style baseline, the ViT model consistently outperforms the Reformer in our experiments in terms of practical efficiency and end-to-end computation time across the larger and higher-resolution settings. These results suggest that, despite the theoretical advantages of LSH-based attention, meaningful computation gains require sequence lengths substantially longer than those produced by typical high-resolution images.|
|**2025-12-12**|[FAIR: Focused Attention Is All You Need for Generative Recommendation](http://arxiv.org/abs/2512.11254)|null|Recently, transformer-based generative recommendation has garnered significant attention for user behavior modeling. However, it often requires discretizing items into multi-code representations (e.g., typically four code tokens or more), which sharply increases the length of the original item sequence. This expansion poses challenges to transformer-based models for modeling user behavior sequences with inherent noises, since they tend to overallocate attention to irrelevant or noisy context. To mitigate this issue, we propose FAIR, the first generative recommendation framework with focused attention, which enhances attention scores to relevant context while suppressing those to irrelevant ones. Specifically, we propose (1) a focused attention mechanism integrated into the standard Transformer, which learns two separate sets of Q and K attention weights and computes their difference as the final attention scores to eliminate attention noise while focusing on relevant contexts; (2) a noise-robustness objective, which encourages the model to maintain stable attention patterns under stochastic perturbations, preventing undesirable shifts toward irrelevant context due to noise; and (3) a mutual information maximization objective, which guides the model to identify contexts that are most informative for next-item prediction. We validate the effectiveness of FAIR on four public benchmarks, demonstrating its superior performance compared to existing methods.|
|**2025-12-11**|[Network and Compiler Optimizations for Efficient Linear Algebra Kernels in Private Transformer Inference](http://arxiv.org/abs/2512.11135)|null|Large language model (LLM) based services are primarily structured as client-server interactions, with clients sending queries directly to cloud providers that host LLMs. This approach currently compromises data privacy as all queries must be processed in the cloud and in the clear. Fully Homomorphic Encryption (FHE) is a solution to this data privacy issue by enabling computations directly upon encrypted queries. However, running encrypted transformer inference is challenging as programmers must map standard kernels to the constrained instruction set provided by FHE. In this work, we explore implementations of linear algebra kernels needed for transformer inference in FHE and understand how network optimization can help mitigate FHE costs while remaining performant.   We leverage the Orion PyTorch to FHE framework to benchmark several linear algebra kernels in order to profile two linear transformation methods, packed row and BSGS, and find that BSGS outperforms packed row methods by up to $13.7 \times$ at transformer-level scales. We also incorporate network-level pruning strategies that reduce FHE runtimes of feed forward layers by up to $11.46\times$. Furthermore, we extend Orion to include ciphertext-ciphertext matrix-matrix products, a key component in the self-attention blocks. Finally, we perform a roofline analysis of FHE primitives and encrypted linear transformations and find that (SIMD encoded) implementations are memory-bound with primitives having roughly $0.1$ integer operations per byte of DRAM traffic. These findings illustrate the need for exploring alternative encoding schemes and models of computation within CKKS to unlock scalable private transformer inference. We conduct all experiments using the Orion framework which can be found at: https://github.com/baahl-nyu/orion.|
|**2025-12-11**|[Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration](http://arxiv.org/abs/2512.10954)|null|In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rather than limited to just the patches within an image. This enables images to be jointly denoised at inference time, learning both intra and inter-image correspondence. We observe a clear scaling effect - larger group sizes yield stronger cross-sample attention and better generation quality. Furthermore, we introduce a qualitative measure to capture this behavior and show that its strength closely correlates with FID. Built on standard diffusion transformers, our GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256. Our work reveals cross-sample inference as an effective, previously unexplored mechanism for generative modeling.|
|**2025-12-11**|[Template-Free Retrosynthesis with Graph-Prior Augmented Transformers](http://arxiv.org/abs/2512.10770)|null|Retrosynthesis reaction prediction seeks to infer plausible reactant molecules for a given product and is a central problem in computer-aided organic synthesis. Despite recent progress, many existing models still fall short of the accuracy and robustness required for practical deployment. This work studies a template-free, Transformer-based framework that eliminates reliance on handcrafted reaction templates or additional chemical rule engines. The model injects molecular graph information into the attention mechanism to jointly exploit \SMILES\ sequences and structural cues, and further applies a paired data augmentation strategy to enhance training diversity and scale. On the USPTO-50K benchmark, our proposed approach achieves state-of-the-art performance among template-free methods and substantially outperforming a vanilla Transformer baseline.|
|**2025-12-11**|[Sliding Window Attention Adaptation](http://arxiv.org/abs/2512.10411)|**[link](https://github.com/yuyijiong/sliding-window-attention-adaptation)**|The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving "sink" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at https://github.com/yuyijiong/sliding-window-attention-adaptation|
|**2025-12-11**|[Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation](http://arxiv.org/abs/2512.10353)|null|Weakly supervised semantic segmentation offers a label-efficient solution to train segmentation models for volumetric medical imaging. However, existing approaches often rely on 2D encoders that neglect the inherent volumetric nature of the data. We propose TranSamba, a hybrid Transformer-Mamba architecture designed to capture 3D context for weakly supervised volumetric medical segmentation. TranSamba augments a standard Vision Transformer backbone with Cross-Plane Mamba blocks, which leverage the linear complexity of state space models for efficient information exchange across neighboring slices. The information exchange enhances the pairwise self-attention within slices computed by the Transformer blocks, directly contributing to the attention maps for object localization. TranSamba achieves effective volumetric modeling with time complexity that scales linearly with the input volume depth and maintains constant memory usage for batch processing. Extensive experiments on three datasets demonstrate that TranSamba establishes new state-of-the-art performance, consistently outperforming existing methods across diverse modalities and pathologies. Our source code and trained models are openly accessible at: https://github.com/YihengLyu/TranSamba.|
|**2025-12-10**|[DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting](http://arxiv.org/abs/2512.10051)|null|Time series forecasting requires models that can efficiently capture complex temporal dependencies, especially in large-scale and high-dimensional settings. While Transformer-based architectures excel at modeling long-range dependencies, their quadratic computational complexity poses limitations on scalability and adaptability. To overcome these challenges, we introduce DB2-TransF, a novel Transformer-inspired architecture that replaces the self-attention mechanism with a learnable Daubechies wavelet coefficient layer. This wavelet-based module efficiently captures multi-scale local and global patterns and enhances the modeling of correlations across multiple time series for the time series forecasting task. Extensive experiments on 13 standard forecasting benchmarks demonstrate that DB2-TransF achieves comparable or superior predictive accuracy to conventional Transformers, while substantially reducing memory usage for the time series forecasting task. The obtained experimental results position DB2-TransF as a scalable and resource-efficient framework for advanced time series forecasting. Our code is available at https://github.com/SteadySurfdom/DB2-TransF|
|**2025-12-10**|[Composing Concepts from Images and Videos via Concept-prompt Binding](http://arxiv.org/abs/2512.09824)|**[link](https://github.com/refkxh/BiCo)**|Visual concept composition, which aims to integrate different elements from images and videos into a single, coherent visual output, still falls short in accurately extracting complex concepts from visual inputs and flexibly combining concepts from both images and videos. We introduce Bind & Compose, a one-shot method that enables flexible visual concept composition by binding visual concepts with corresponding prompt tokens and composing the target prompt with bound tokens from various sources. It adopts a hierarchical binder structure for cross-attention conditioning in Diffusion Transformers to encode visual concepts into corresponding prompt tokens for accurate decomposition of complex visual concepts. To improve concept-token binding accuracy, we design a Diversify-and-Absorb Mechanism that uses an extra absorbent token to eliminate the impact of concept-irrelevant details when training with diversified prompts. To enhance the compatibility between image and video concepts, we present a Temporal Disentanglement Strategy that decouples the training process of video concepts into two stages with a dual-branch binder structure for temporal modeling. Evaluations demonstrate that our method achieves superior concept consistency, prompt fidelity, and motion quality over existing approaches, opening up new possibilities for visual creativity.|
|**2025-12-10**|[DynaIP: Dynamic Image Prompt Adapter for Scalable Zero-shot Personalized Text-to-Image Generation](http://arxiv.org/abs/2512.09814)|null|Personalized Text-to-Image (PT2I) generation aims to produce customized images based on reference images. A prominent interest pertains to the integration of an image prompt adapter to facilitate zero-shot PT2I without test-time fine-tuning. However, current methods grapple with three fundamental challenges: 1. the elusive equilibrium between Concept Preservation (CP) and Prompt Following (PF), 2. the difficulty in retaining fine-grained concept details in reference images, and 3. the restricted scalability to extend to multi-subject personalization. To tackle these challenges, we present Dynamic Image Prompt Adapter (DynaIP), a cutting-edge plugin to enhance the fine-grained concept fidelity, CP-PF balance, and subject scalability of SOTA T2I multimodal diffusion transformers (MM-DiT) for PT2I generation. Our key finding is that MM-DiT inherently exhibit decoupling learning behavior when injecting reference image features into its dual branches via cross attentions. Based on this, we design an innovative Dynamic Decoupling Strategy that removes the interference of concept-agnostic information during inference, significantly enhancing the CP-PF balance and further bolstering the scalability of multi-subject compositions. Moreover, we identify the visual encoder as a key factor affecting fine-grained CP and reveal that the hierarchical features of commonly used CLIP can capture visual information at diverse granularity levels. Therefore, we introduce a novel Hierarchical Mixture-of-Experts Feature Fusion Module to fully leverage the hierarchical features of CLIP, remarkably elevating the fine-grained concept fidelity while also providing flexible control of visual granularity. Extensive experiments across single- and multi-subject PT2I tasks verify that our DynaIP outperforms existing approaches, marking a notable advancement in the field of PT2l generation.|
|**2025-12-10**|[CS3D: An Efficient Facial Expression Recognition via Event Vision](http://arxiv.org/abs/2512.09592)|null|Responsive and accurate facial expression recognition is crucial to human-robot interaction for daily service robots. Nowadays, event cameras are becoming more widely adopted as they surpass RGB cameras in capturing facial expression changes due to their high temporal resolution, low latency, computational efficiency, and robustness in low-light conditions. Despite these advantages, event-based approaches still encounter practical challenges, particularly in adopting mainstream deep learning models. Traditional deep learning methods for facial expression analysis are energy-intensive, making them difficult to deploy on edge computing devices and thereby increasing costs, especially for high-frequency, dynamic, event vision-based approaches. To address this challenging issue, we proposed the CS3D framework by decomposing the Convolutional 3D method to reduce the computational complexity and energy consumption. Additionally, by utilizing soft spiking neurons and a spatial-temporal attention mechanism, the ability to retain information is enhanced, thus improving the accuracy of facial expression detection. Experimental results indicate that our proposed CS3D method attains higher accuracy on multiple datasets compared to architectures such as the RNN, Transformer, and C3D, while the energy consumption of the CS3D method is just 21.97\% of the original C3D required on the same device.|
|**2025-12-10**|[Hands-on Evaluation of Visual Transformers for Object Recognition and Detection](http://arxiv.org/abs/2512.09579)|null|Convolutional Neural Networks (CNNs) for computer vision sometimes struggle with understanding images in a global context, as they mainly focus on local patterns. On the other hand, Vision Transformers (ViTs), inspired by models originally created for language processing, use self-attention mechanisms, which allow them to understand relationships across the entire image. In this paper, we compare different types of ViTs (pure, hierarchical, and hybrid) against traditional CNN models across various tasks, including object recognition, detection, and medical image classification. We conduct thorough tests on standard datasets like ImageNet for image classification and COCO for object detection. Additionally, we apply these models to medical imaging using the ChestX-ray14 dataset. We find that hybrid and hierarchical transformers, especially Swin and CvT, offer a strong balance between accuracy and computational resources. Furthermore, by experimenting with data augmentation techniques on medical images, we discover significant performance improvements, particularly with the Swin Transformer model. Overall, our results indicate that Vision Transformers are competitive and, in many cases, outperform traditional CNNs, especially in scenarios requiring the understanding of global visual contexts like medical imaging.|
|**2025-12-10**|[Transformers for Tabular Data: A Training Perspective of Self-Attention via Optimal Transport](http://arxiv.org/abs/2512.09530)|null|This thesis examines self-attention training through the lens of Optimal Transport (OT) and develops an OT-based alternative for tabular classification. The study tracks intermediate projections of the self-attention layer during training and evaluates their evolution using discrete OT metrics, including Wasserstein distance, Monge gap, optimality, and efficiency. Experiments are conducted on classification tasks with two and three classes, as well as on a biomedical dataset.   Results indicate that the final self-attention mapping often approximates the OT optimal coupling, yet the training trajectory remains inefficient. Pretraining the MLP section on synthetic data partially improves convergence but is sensitive to their initialization. To address these limitations, an OT-based algorithm is introduced: it generates class-specific dummy Gaussian distributions, computes an OT alignment with the data, and trains an MLP to generalize this mapping. The method achieves accuracy comparable to Transformers while reducing computational cost and scaling more efficiently under standardized inputs, though its performance depends on careful dummy-geometry design. All experiments and implementations are conducted in R.|
|**2025-12-04**|[Semantic-Guided Two-Stage GAN for Face Inpainting with Hybrid Perceptual Encoding](http://arxiv.org/abs/2512.05039)|null|人脸图像修复旨在恢复人脸图像中缺失或损坏的区域，同时保留身份信息、结构一致性和逼真的图像质量，这是一项专为照片修复创建的任务。尽管深度生成模型最近取得了许多进展，但现有方法在处理大面积不规则掩码时仍面临挑战，由于采用直接像素级合成方法并对人脸先验知识利用不足，这些方法常常在掩码区域边缘产生模糊纹理、语义不一致或不自然的脸部结构。为解决上述挑战，本文提出了一种新颖的架构，通过语义引导的分层合成来实现。我们的方法首先采用一种基于语义组织和合成信息的方法，然后进行纹理细化。这一过程在我们创建细节图像之前，能清楚地洞察脸部结构。在第一阶段，我们融合了两种技术：一种是利用卷积神经网络（CNN）关注局部特征，另一种是利用视觉Transformer关注全局特征。这有助于我们创建清晰详细的语义布局。在第二阶段，我们使用多模态纹理生成器，通过引入不同尺度的信息来细化这些布局，确保整体的连贯性和一致性。该架构通过动态注意力机制，无需针对特定掩码进行训练，即可自然地处理任意掩码配置。在CelebA-HQ和FFHQ两个数据集上的实验表明，我们的模型优于其他最先进的方法，在LPIPS、PSNR和SSIM等指标上均有所改进。在具有挑战性的大面积修复场景中，它能产生视觉上引人注目的结果，并具有更好的语义保留能力。|
|**2025-12-04**|[Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence](http://arxiv.org/abs/2512.04619)|null|本文引入了HeFT（头-频率追踪器），这是一个零样本点追踪框架，它利用了预训练视频扩散模型的视觉先验。为了更好地理解它们如何编码时空信息，我们分析了视频扩散Transformer (VDiT) 的内部表示。我们的分析揭示，注意力头充当最小功能单元，对匹配、语义理解和位置编码具有独特的专业化分工。此外，我们发现VDiT特征中的低频分量对于建立对应关系至关重要，而高频分量则倾向于引入噪声。基于这些见解，我们提出了一种头-频率感知特征选择策略，该策略联合选择最具信息量的注意力头和低频分量，以增强追踪性能。具体而言，我们的方法通过单步去噪提取判别性特征，应用特征选择，并采用结合前向-后向一致性检查的软argmax定位来估计对应关系。在TAP-Vid基准测试上的大量实验表明，HeFT实现了最先进的零样本追踪性能，接近监督方法的准确性，同时消除了对标注训练数据的需求。我们的工作进一步凸显了视频扩散模型作为强大基础模型在广泛下游任务中的潜力，为统一的视觉基础模型铺平了道路。|
|**2025-12-04**|[UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers](http://arxiv.org/abs/2512.04504)|null|近期的图像扩散Transformer实现了高保真生成，但难以生成超出这些尺寸的图像，存在内容重复和质量下降的问题。在这项工作中，我们提出了UltraImage，一个解决了这两个问题的系统化框架。通过对位置嵌入进行频率分析，我们发现重复现象源于主导频率的周期性，其周期与训练分辨率一致。我们引入了一种递归主导频率校正，以在推断后将其限制在一个周期内。此外，我们发现质量下降源于稀释的注意力，因此提出了熵引导的自适应注意力集中机制，该机制为局部注意力分配更高的聚焦因子以锐化细节，为全局注意力模式分配更低的聚焦因子以保持结构一致性。实验表明，UltraImage在Qwen-Image和Flux（约4K）上，跨三个生成场景始终优于现有方法，减少了重复并提高了视觉保真度。此外，UltraImage能够在1328p的训练分辨率下，无需低分辨率引导，生成高达6K*6K的图像，展示了其极强的外推能力。项目页面可在\href{https://thu-ml.github.io/ultraimage.github.io/}{https://thu-ml.github.io/ultraimage.github.io/}访问。|
|**2025-12-04**|[Shift-Window Meets Dual Attention: A Multi-Model Architecture for Specular Highlight Removal](http://arxiv.org/abs/2512.04496)|null|实际环境中不可避免的镜面反射高光严重损害视觉性能，从而降低任务的有效性和效率。尽管存在大量方法侧重于从卷积神经网络模型中获取局部信息或从Transformer模型中获取全局信息，但单一类型模型在局部细粒度细节和全局长程依赖之间陷入了建模困境，从而对不同尺度的镜面反射高光去除效果不佳。因此，为了适应所有尺度的镜面反射高光，我们提出了一种多模型架构用于镜面反射高光去除（MM-SHR），该架构能有效捕获高光区域的细粒度特征并建模高光区域与无高光区域之间的长程依赖关系。具体而言，我们在MM-SHR的浅层使用卷积操作提取局部细节，并在深层利用注意力机制捕获全局特征，从而确保了操作效率和去除精度。为了在不损害计算复杂度的前提下建模长程依赖关系，我们采用了一种从粗到精的方式，并提出了全向注意力集成块（OAIBlock）和自适应区域感知混合域双注意力卷积网络（HDDAConv），它们利用原始特征上的全向像素移位和窗口划分操作以实现镜面反射高光去除。大量实验结果在三个基准任务和六种表面材料上表明MM-SHR在镜面反射高光去除的准确性和效率方面均优于现有最先进方法。实施代码将在https://github.com/Htcicv/MM-SHR公开。|
|**2025-12-03**|[DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision](http://arxiv.org/abs/2512.04314)|null|视觉Transformer面临一个根本局限：标准自注意力联合处理空间和通道维度，导致表示纠缠，从而阻碍了对结构和语义依赖的独立建模。这个问题在高光谱成像中尤为突出，从卫星高光谱遥感，到红外病理成像，其中通道捕获独特的生物物理或生物化学线索。我们提出了DisentangleFormer，这是一种通过原则性的空间-通道解耦实现鲁棒多通道视觉表示的架构。受去相关表示学习的信息论原理启发，我们的并行设计实现了对结构和语义线索的独立建模，同时最小化了空间流和通道流之间的冗余。我们的设计集成了三个核心组件：(1) 并行解耦：独立处理空间-token流和通道-token流，实现了跨空间和光谱维度的去相关特征学习；(2) 挤压Token增强器：一个自适应校准模块，动态融合空间流和通道流；以及 (3) 多尺度FFN：通过多尺度局部上下文补充全局注意力，以捕获细粒度的结构和语义依赖。在高光谱基准上进行的大量实验表明，DisentangleFormer实现了最先进的性能，在Indian Pine、Pavia University和Houston数据集、大型BigEarthNet遥感数据集以及一个红外病理数据集上持续优于现有模型。此外，它在ImageNet上保持了有竞争力的精度，同时将浮点运算次数（FLOPs）的计算成本降低了17.8%。代码将在论文接受后公开。|
|**2025-12-03**|[Look Around and Pay Attention: Multi-camera Point Tracking Reimagined with Transformers](http://arxiv.org/abs/2512.04213)|**[link](https://github.com/ostadabbas/Look-Around-and-Pay-Attention-LAPA-)**|本文提出了LAPA（环顾并关注），一种新颖的端到端基于Transformer的架构，用于多相机点跟踪，它整合了基于外观的匹配与几何约束。传统流程将检测、关联和跟踪解耦，导致在复杂场景中出现误差传播和时间不一致性。LAPA通过利用注意力机制在视图和时间维度上联合推理来解决这些局限性，通过一个辅以几何先验的跨视图注意力机制建立软对应关系。我们不依赖于经典三角测量，而是通过注意力加权聚合构建3D点表示，内在地适应了不确定性和部分观测。时间一致性进一步通过一个建模长程依赖关系的Transformer解码器来保持，在长时间遮挡下仍能保持身份。在挑战性数据集上进行的广泛实验，包括我们新创建的TAPVid-3D全景和PointOdyssey的多相机（MC）版本，表明我们的统一方法显著优于现有方法，在TAPVid-3D-MC上取得了37.5%的APD，在PointOdyssey-MC上取得了90.3%的APD，尤其在复杂运动和遮挡场景中表现出色。代码可在https://github.com/ostadabbas/Look-Around-and-Pay-Attention-LAPA-获取。|
|**2025-12-03**|[MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction](http://arxiv.org/abs/2512.03939)|null|近期有状态循环神经网络在静态三维重建方面取得了显著进展，但仍易受运动引起的伪影影响，其中非刚性区域会破坏空间记忆和图像特征之间的注意力传播。通过分析状态和图像token更新机制的内部行为，我们发现聚合跨层的自注意力图会揭示一个一致的模式：动态区域自然地被降权，暴露出预训练Transformer已编码但从未明确使用的一个隐式运动线索。受此观察启发，我们引入了一个免训练框架MUT3R，该框架在推理过程中应用注意力派生的运动线索，以抑制Transformer早期层中的动态内容。我们的注意力级门控模块在其伪影通过特征层级传播之前，抑制了动态区域的影响。值得注意的是，我们不重新训练或微调模型；我们让预训练Transformer诊断其自身的运动线索并进行自我纠正。这种早期调节稳定了流式场景中的几何推理，并在多个动态基准上改进了时间一致性和相机姿态鲁棒性，为运动感知流式重建提供了一条简单且免训练的途径。|
|**2025-12-03**|[Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence](http://arxiv.org/abs/2512.03905)|**[link](https://github.com/Sunnycookies/FRESCO-v2)**|文生图扩散模型取得的显著成功，推动了对其在视频应用中潜力的广泛研究。零样本技术旨在无需额外模型训练即可将图像扩散模型应用于视频。近期方法主要侧重于将帧间对应性整合到注意力机制中。然而，用于识别有效特征进行注意的软约束是不足的，这可能导致时间不一致性。在本文中，我们提出了FRESCO，它将帧内对应性与帧间对应性相结合，以形成一个更鲁棒的时空约束。这种增强确保了帧之间语义相似内容的一致性转换。我们的方法超越了注意力引导，显式地优化特征，实现了与输入视频的高度时空一致性，显著增强了处理后视频的视觉连贯性。我们在视频到视频翻译和文本引导的视频编辑这两个零样本任务上验证了FRESCO的适应性。全面实验证明了我们框架在生成高质量、连贯视频方面的有效性，突显了相对于当前零样本方法的显著进步。|
|**2025-12-03**|[Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy](http://arxiv.org/abs/2512.03883)|null|越来越多的证据支持对接受全程新辅助治疗（TNT）后在重新分期时显示临床完全缓解（cCR）的直肠癌患者进行观察等待（WW）监测。然而，在WW期间从随访内窥镜图像中客观准确地早期检测局部复发（LR）的方法对于管理护理和预防远处转移至关重要。因此，我们开发了一种带有双交叉注意力机制的孪生Swin Transformer（SSDCA），用于结合重新分期和随访时的纵向内窥镜图像，并区分cCR和LR。SSDCA利用预训练的Swin Transformer提取领域无关特征，并增强对成像变化的鲁棒性。实现了双交叉注意力机制，以强调来自两次扫描的特征，无需图像的任何空间对齐即可预测响应。SSDCA以及基于Swin的基线模型使用来自135名患者的图像对进行训练，并在一个包含来自62名患者的图像对的保留集上进行评估。SSDCA产生了最佳的平衡准确率（81.76% ± 0.04）、敏感性（90.07% ± 0.08）和特异性（72.86% ± 0.05）。鲁棒性分析显示，无论是否存在血液、粪便、毛细血管扩张和较差图像质量等伪影，模型性能均保持稳定。提取特征的UMAP聚类显示，使用SSDCA时，簇间分离度最大（1.45 ± 0.18），簇内离散度最小（1.07 ± 0.19），证实了判别性表示学习能力。|
|**2025-12-04**|[CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond](http://arxiv.org/abs/2512.03767)|null|无线系统面向AI原生6G及未来网络的基本设计，是由不断增长的移动数据流量需求、极致频谱效率和跨多样化服务场景的适应性所驱动的。为克服基于反馈的多输入多输出（MIMO）传输所带来的局限性，我们提出了一种新颖的频率域相关感知无反馈MIMO传输与资源分配（CaFTRA）框架，该框架专为全解耦无线接入网络（FD-RAN）设计，以满足AI原生6G及后续演进的新兴需求。通过利用人工智能（AI），CaFTRA仅基于用户地理位置预测信道状态信息（CSI），从而有效消除了实时上行反馈。我们引入了一种可学习查询驱动的Transformer网络，用于从用户地理位置映射CSI，该网络利用多头注意力和可学习查询嵌入来准确捕获资源块（RBs）之间的频率域相关性，从而显著提高了CSI预测的精度。一旦基站（BS）采用无反馈传输，由于消除了频繁的上行反馈，其下行传输覆盖范围可以显著扩展。为了在这种广覆盖场景下实现高效的资源调度，我们应用了一种低复杂度的基于多对一匹配理论的算法，用于高效的多基站关联和多RB资源分配，该算法被证明能在有限迭代内收敛到稳定匹配。仿真结果表明，相较于5G，CaFTRA实现了稳定匹配收敛，并在频谱效率和用户公平性方面获得了显著提升，突显了其对6G标准化工作的潜在价值。|
|**2025-12-02**|[TEXTRIX: Latent Attribute Grid for Native Texture Generation and Beyond](http://arxiv.org/abs/2512.02993)|null|现有的3D纹理生成方法通常依赖多视图融合，但常受视图间不一致性和复杂表面覆盖不完整性阻碍，限制了生成内容的保真度和完整性。为了克服这些挑战，我们引入了TEXTRIX，这是一个原生3D属性生成框架，用于高保真纹理合成和精确3D部件分割等下游应用。我们的方法构建了一个潜在3D属性网格，并利用配备稀疏注意力机制的扩散Transformer，实现了3D模型在体素空间中的直接着色，从根本上避免了多视图融合的局限性。基于这种原生表示，该框架通过训练相同的架构来预测网格上的语义属性，自然地扩展到高精度3D分割。大量实验表明，该方法在这两项任务上均达到了最先进的性能，生成了无缝、高保真的纹理以及具有精确边界的准确3D部件分割。|
|**2025-12-02**|[GraphFusion3D: Dynamic Graph Attention Convolution with Adaptive Cross-Modal Transformer for 3D Object Detection](http://arxiv.org/abs/2512.02991)|null|尽管3D目标检测取得了显著进展，但点云由于数据稀疏、结构不完整和语义信息有限，其挑战性依然存在。捕获远距离对象之间的上下文关系带来了额外的困难。为解决这些挑战，我们提出了GraphFusion3D，一个结合多模态融合与先进特征学习的统一框架。我们的方法引入了自适应跨模态Transformer (ACMT)，它自适应地将图像特征整合到点表示中，以丰富几何和语义信息。对于候选区域细化，我们引入了图推理模块 (GRM)，这是一种新颖的机制，通过建模邻域关系同时捕获局部几何结构和全局语义上下文。该模块采用多尺度图注意力，动态地加权候选区域之间的空间邻近性和特征相似性。我们进一步采用了一个级联解码器，通过多阶段预测逐步细化检测结果。在SUN RGB-D (70.6% AP $_{25}$和51.2% AP$_{50}$) 和ScanNetV2 (75.1% AP$_{25}$和60.8% AP$_{50}$ ) 上的大量实验表明，相较于现有方法，我们取得了显著的性能提升。|
|**2025-12-02**|[AutoNeural: Co-Designing Vision-Language Models for NPU Inference](http://arxiv.org/abs/2512.02924)|null|尽管神经网络处理器（NPU）为边缘AI提供了高理论效率，但为GPU量身定制的最先进视觉-语言模型（VLM）在这些基板上往往表现不佳。我们将这种硬件-模型不匹配归因于两个主要因素：视觉Transformer (ViT) 的量化脆弱性，以及自回归注意力机制的I/O密集型特性，后者未能充分利用NPU的高算术吞吐量。为弥合这一差距，我们提出了AutoNeural，这是一种为纯整数推理协同设计的NPU原生VLM架构。我们将标准ViT编码器替换为利用深度可分离卷积的MobileNetV5风格主干网络，这确保了有界激活分布，以实现稳定的INT4/8/16量化。与之相辅相成，我们的语言主干网络将状态空间模型（SSM）原理与Transformer层相结合，采用高效的门控卷积以实现线性时间复杂度。这种混合设计消除了生成过程中键值缓存带来的沉重内存I/O开销。我们的方法实现了显著的效率提升，与传统基线相比，将视觉编码器的量化误差降低多达7倍，端到端延迟降低14倍。AutoNeural还提供了比基线快3倍的解码速度和4倍更长的上下文窗口。我们通过在Qualcomm SA8295P SoC上的真实汽车案例研究验证了这些改进，展示了其在座舱应用中的实时性能。我们的结果强调，专门针对NPU约束重新思考模型拓扑结构是实现强大多模态边缘智能的先决条件。|
|**2025-12-02**|[Modeling and Inverse Identification of Interfacial Heat Conduction in Finite Layer and Semi-Infinite Substrate Systems via a Physics-Guided Neural Framework](http://arxiv.org/abs/2512.02618)|null|半导体器件中的热传递主要由芯片与衬底组件决定，其中有限芯片层内产生的热量会耗散到具有高得多的热物理特性的半无限衬底中。这种不匹配会产生陡峭的界面温度梯度，使得瞬态热响应对界面高度敏感。传统数值求解器需要过多的离散化才能解析这些动力学，而物理信息神经网络（PINNs）在材料界面附近经常表现出不稳定的收敛性和物理一致性的丧失。为解决这些挑战，我们引入了HeatTransFormer，这是一种用于界面主导扩散问题的物理引导Transformer架构。该框架集成了物理信息的时空采样、模拟解析扩散解的基于拉普拉斯的激活函数以及支持双向时空耦合的无掩码注意力机制。这些组件使模型能够解析陡峭的梯度、保持物理一致性，并在PINNs通常失败的地方保持稳定。当应用于有限层和半无限衬底配置时，HeatTransFormer在界面处产生连贯的温度场。结合物理约束的逆向策略，它进一步实现了仅使用外部测量同时可靠地识别三个未知热学特性。总而言之，这项工作表明物理引导的Transformer架构为界面主导热系统中的正向和逆向建模提供了一个统一的框架。|
|**2025-12-02**|[Predictive Beamforming in Low-Altitude Wireless Networks: A Cross-Attention Approach](http://arxiv.org/abs/2512.02563)|null|精确波束预测对于维持动态低空无线网络中的可靠链路和高频谱效率至关重要。然而，现有方法往往未能捕捉异构传感模态之间的深度关联，限制了它们在复杂三维环境中的适应性。为克服这些挑战，我们提出了一种基于交叉注意力融合机制的多模态预测波束成形方法，该方法联合利用了视觉和结构化传感器数据。所提出的模型利用卷积神经网络（CNN）从视觉图像中学习多尺度空间特征层次结构，并利用Transformer编码器捕捉传感器数据内部的跨维度依赖关系。随后，引入了一个交叉注意力融合模块以整合两种模态之间的互补信息，从而生成统一且具有判别性的表示，用于精确波束预测。通过在真实世界数据集上进行的实验评估，我们的方法达到了 79.7% 的 Top-1 准确率和 99.3% 的 Top-3 准确率，在 Top-1 到 Top-5 指标上超过 3D ResNet-Transformer 基线 4.4%-23.2%。这些结果验证了多模态交叉注意力融合对于动态低空无线网络中的智能波束选择是有效的。|
|**2025-12-02**|[Deep Learning-Based Joint Uplink-Downlink CSI Acquisition for Next-Generation Upper Mid-Band Systems](http://arxiv.org/abs/2512.02557)|null|在新一代无线通信系统中，新划分的上限中频段（也称为频段3，FR3）引起了广泛关注，凸显了对下行（DL）传输设计的需求，而这根本上依赖于精确的CSI。然而，FR3系统中的CSI获取面临重大挑战：天线数量增加和传输带宽更宽，使得传统估计方法引入了过高的训练开销，因为每次探测仅捕获不完整的空间-频率观测，而更高的载波频率导致更快的信道时间变化。为解决这些挑战，我们提出了一种新颖的CSI获取框架，该框架在FR3 TDD大规模MIMO系统中集成了CSI反馈、上行（UL）和DL信道估计以及信道预测。具体而言，我们首先开发了联合上行和下行信道估计网络（JUDCEN），用于基于SRS和CSI-RS融合不完整的观测。通过利用通过初始UL估计和量化反馈辅助的DL估计获得的初步UL和DL估计特征的互补特性，它实现了空间域中的完整CSI重建。为减轻反馈过程中的性能下降，我们提出了Transformer-MLP CSI反馈网络（TMCFN），采用基于MLP的模块联合利用角度域和延迟域特征。在重建的完整CSI基础上，我们进一步开发了基于Mamba的信道预测网络（MCPN），该网络利用选择性状态空间模型（SSM）机制捕获角度-延迟域中的长程时间动态，以进行未来的CSI预测。仿真结果表明，所提出的框架在CSI获取精度和传输频谱效率两方面都始终优于基准，且计算复杂度更低。|
|**2025-12-02**|[Quantum-Based Self-Attention Mechanism for Hardware-Aware Differentiable Quantum Architecture Search](http://arxiv.org/abs/2512.02476)|null|NISQ时代变分算法参数化量子电路的自动化设计面临一个根本局限，因为传统的、可微分的架构搜索依赖于经典模型，这些模型无法充分表示硬件噪声下的量子门相互作用。我们引入了基于量子的自注意力可微量子架构搜索（QBSA-DQAS），这是一个元学习框架，其特点是基于量子的自注意力机制和硬件感知多目标搜索。该框架采用两阶段量子自注意力模块，通过参数化量子电路映射架构参数来计算上下文依赖关系，用量子导出的注意力分数替换经典相似性度量，然后应用逐位置量子变换进行特征丰富。架构搜索由一个任务无关的多目标函数引导，该函数联合优化带噪声的表达能力和成功试验概率（PST）。搜索后优化阶段应用门交换、融合和消除来降低电路复杂度。实验验证表明，在VQE任务和大规模无线传感器网络上性能卓越。对于H $_2$ 上的VQE，QBSA-DQAS实现了0.9的准确率，而标准DQAS为0.89。搜索后优化将发现的电路复杂度在门数量上降低了高达44%，在深度上降低了47%，且不降低准确率。该框架在三种分子和五种IBM量子硬件噪声模型下均保持鲁棒性能。对于WSN路由，发现的电路相较于QAOA实现了8.6%的能量降低，相较于经典贪婪方法实现了40.7%的能量降低，从而确立了量子原生架构搜索对于NISQ应用的有效性。|
|**2025-12-02**|[TabGRU: An Enhanced Design for Urban Rainfall Intensity Estimation Using Commercial Microwave Links](http://arxiv.org/abs/2512.02465)|null|面对全球城市化加速和极端天气事件日益频繁的挑战，高分辨率城市降雨监测对于建设有韧性的智慧城市至关重要。商用微波链路（CMLs）是一种新兴数据源，在此任务中展现出巨大潜力。尽管传统的CML降雨反演依赖于基于物理的模型，但这些模型在处理信号噪声和非线性衰减等现实世界复杂性时常面临困难。为解决这些局限性，本文提出了一种新颖的混合深度学习架构，其基于Transformer和双向门控循环单元（BiGRU），并将其命名为TabGRU。这种设计协同捕获了CML信号数据中的长期依赖性和局部序列特征。该模型通过可学习的位置嵌入和注意力池化机制得到进一步增强，以提高其动态特征提取和泛化能力。该模型在瑞典哥德堡的一个公共基准数据集（2015年6月至9月）上进行了验证。评估使用了来自两个雨量计（Torp和Barl）的12个子链路，测试期为8月22日至31日，覆盖了大约10个独立的降雨事件。所提出的TabGRU模型展现出持续的优势，优于深度学习基线，并在Torp站点（0.91）和Barl站点（0.96）均获得了高决定系数（R2）。此外，与基于物理的方法相比，TabGRU保持了更高的准确性，并且在缓解PL模型在峰值降雨事件中观察到的显著高估问题方面特别有效。这项评估证实，TabGRU模型能够有效克服传统方法的局限性，为测试条件下基于CML的城市降雨监测提供了一个鲁棒而准确的解决方案。|
|**2025-12-02**|[The brain-AI convergence: Predictive and generative world models for general-purpose computation](http://arxiv.org/abs/2512.02419)|null|基于注意力的Transformer通用人工智能系统在近期取得的进展，为我们理解新皮层和小脑如何在相对统一的电路架构下产生多种功能并最终形成人类智能，提供了一个潜在的视角。本文对大脑和人工智能进行了跨领域比较，超越了对视觉处理的传统关注，并采纳了新兴的基于世界模型的计算视角。在此，我们识别出基于注意力的新皮层和非注意力的小脑中共享的计算机制：两者都从过去的输入中预测未来的世界事件，并通过预测误差学习构建内部世界模型。这些预测性世界模型被重新利用于表面上不同的功能——感知处理中的理解和运动处理中的生成——从而使大脑能够实现多领域能力和类人自适应智能。值得注意的是，基于注意力的AI也独立地趋同于类似的学习范式和基于世界模型的计算。我们得出结论，生物和人工系统中的这些共享机制构成了实现包括高级智能在内的多种功能的核心计算基础，尽管它们具有相对统一的电路结构。我们的理论见解弥合了神经科学与人工智能之间的鸿沟，增进了我们对智能计算本质的理解。|
|**2025-12-02**|[ESACT: An End-to-End Sparse Accelerator for Compute-Intensive Transformers via Local Similarity](http://arxiv.org/abs/2512.02403)|null|Transformer模型，由QKV生成、注意力计算和FFNs组成，因其出色的性能已成为各个领域的主流模型。然而，其高计算成本阻碍了高效的硬件部署。稀疏性提供了一个有前景的解决方案，但大多数现有加速器只利用注意力中的行内稀疏性，很少考虑行间稀疏性。利用行间稀疏性的方法通常依赖于昂贵的全局相似度估计，这降低了稀疏性的加速效益，并且通常只将稀疏性应用于Transformer的一个或两个组件。通过对注意力分布和计算流的仔细分析，我们观察到局部相似度可以在较低的计算开销下实现端到端稀疏加速。受此观察启发，我们提出了ESACT，一个用于计算密集型Transformer的端到端稀疏加速器。ESACT的核心是基于局部相似度的稀疏性预测（SPLS）机制，该机制利用HLog量化在QK生成之前准确预测局部注意力稀疏性，从而在所有Transformer组件中实现高效稀疏性。为支持高效的硬件实现，我们引入了三项架构创新。在26个基准测试上的实验结果表明，SPLS将总计算量减少了52.03%，且精度损失小于1%。ESACT实现了3.29 TOPS/W的端到端能效，并分别将注意力层能效比最先进的注意力加速器SpAtten和Sanger提高了2.95倍和2.26倍。|
|**2025-11-28**|[AnyTalker: Scaling Multi-Person Talking Video Generation with Interactivity Refinement](http://arxiv.org/abs/2511.23475)|**[link](https://github.com/HKUST-C4G/AnyTalker)**|最近，多人视频生成开始崭露头角。尽管一些初步工作探索了音频驱动的多人说话视频生成，但它们常面临挑战，原因在于多样化多人数据收集的高成本以及驱动多个身份实现连贯互动的困难。为解决这些挑战，我们提出了AnyTalker，一个具有可扩展多流处理架构的多人生成框架。具体而言，我们通过一种新颖的身份感知注意力机制扩展了扩散Transformer的注意力块，该机制迭代处理身份-音频对，允许可驱动身份的任意扩展。此外，训练多人生成模型需要大量多人数据。我们提出的训练流程仅依赖单人视频来学习多人说话模式，并仅用少量真实多人视频片段来细化互动性。此外，我们贡献了一个专门的度量指标和数据集，旨在评估所生成多人视频的自然度和互动性。大量实验表明，AnyTalker在唇部同步、视觉质量和自然互动性方面表现卓越，在数据成本和身份可扩展性之间取得了良好的平衡。|
|**2025-11-28**|[Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models](http://arxiv.org/abs/2511.23319)|null|本工作探索了构建“会记忆的机器”的挑战，将长期记忆定义为高效超长上下文建模问题。我们认为这需要三个关键特性：稀疏性、随机访问灵活性和长度泛化能力。为解决超长上下文建模问题，我们利用了分层稀疏注意力（HSA），这是一种满足所有这三个特性的新颖注意力机制。我们将HSA集成到Transformer中以构建HSA-UltraLong，它是一个80亿参数的MoE模型，在超过8万亿个token上进行训练，并通过在不同任务上使用域内和域外上下文长度进行严格评估，以证明其处理超长上下文的能力。结果表明，我们的模型在域内长度上与全注意力基线表现相当，同时在大多数上下文内检索任务中实现了超过90%的准确率，上下文长度高达16M。本报告概述了我们的实验见解和开放问题，为超长上下文建模领域的未来研究奠定了基础。|
|**2025-11-28**|[Refinements of the Eigenstate Thermalization Hypothesis under Local Rotational Invariance via Free Probability](http://arxiv.org/abs/2511.23217)|null|本征态热化假说（ETH）被发展成为一个框架，用于理解统计力学原理如何在孤立量子多体系统的长时间极限下涌现。此后，ETH将注意力转向了能量本征基中物理可观测量的矩阵元研究。在这项工作中，我们回顾了最近导致完整ETH表述的进展，完整ETH是原始ETH猜想的推广，它考虑了多点关联函数。我们利用自由概率论的工具，探究了局部旋转不变性的含义，该特性源于哈密顿量微扰引起的随机基变换下可观测量的统计不变性。这种方法使我们能够做出定量预测，并推导出矩阵元关联的次主导修正的解析表征，从而完善了ETH猜想。此外，我们的分析将随机基变换下矩阵元的统计特性与通常在处理集合单个实例时考虑的能量窗口上的经验平均联系起来。我们通过与不可积Floquet系统中的数值模拟进行比较，验证了我们的解析预测。|
|**2025-11-28**|[db-SP: Accelerating Sparse Attention for Visual Generative Models with Dual-Balanced Sequence Parallelism](http://arxiv.org/abs/2511.23113)|null|通过序列并行扩展扩散变换器（DiT）推理对于降低视觉生成中的延迟至关重要，但当应用于采用块级稀疏注意力的模型时，其性能受到工作负载不平衡的严重阻碍。当序列并行沿头部维度（如Ulysses中）或块维度（如Ring Attention中）应用时，这种不平衡源于注意力头之间固有的稀疏性变化以及稀疏掩码内密集块的不规则分布。在本文中，我们形式化了一个稀疏不平衡比率来量化这种不平衡，并提出了db-SP，一种解决这一挑战的稀疏性感知序列并行技术。db-SP包含一种双层分区方法，在头部和块两个层面实现了近乎完美的工作负载平衡，且开销可忽略不计。此外，为了处理跨去噪步骤和层不断演变的稀疏模式，db-SP在运行时动态确定头部和块维度的并行度。实验结果表明，db-SP平均而言比最先进的序列并行方法实现了端到端1.25倍的加速和注意力特定1.40倍的加速。代码可在https://github.com/thu-nics/db-SP获取。|
|**2025-11-28**|[Pooling Attention: Evaluating Pretrained Transformer Embeddings for Deception Classification](http://arxiv.org/abs/2511.22977)|null|本文研究了虚假新闻检测作为Transformer表示的下游评估任务，对仅编码器和仅解码器的预训练模型（BERT、GPT-2、Transformer-XL）进行了基准测试，将它们作为冻结嵌入器与轻量级分类器结合使用。通过比较池化与填充、神经网络头与线性头的受控预处理，结果表明上下文自注意力编码始终能有效迁移。BERT嵌入结合逻辑回归在LIAR数据集划分上优于神经网络基线，而对序列长度和聚合的分析揭示了对截断的鲁棒性以及简单最大池化或平均池化的优势。这项工作将基于注意力的词元编码器定位为真实性任务的鲁棒的、以架构为中心的基础，将Transformer的贡献与分类器复杂性隔离开来。|
|**2025-11-28**|[One-to-All Animation: Alignment-Free Character Animation and Image Pose Transfe](http://arxiv.org/abs/2511.22940)|null|扩散模型的最新进展已大幅提升了姿态驱动的角色动画。然而，现有方法局限于空间对齐且骨骼结构匹配的参考姿态对。处理参考姿态不对齐问题仍未解决。为解决此问题，我们提出了One-to-All Animation，这是一个用于高保真角色动画和图像姿态迁移的统一框架，适用于任意布局的参考。首先，为处理空间未对齐的参考，我们将训练重新表述为一个自监督的图像外绘任务，该任务将多样布局的参考转换为统一的遮挡输入格式。其次，为处理部分可见的参考，我们设计了一个参考提取器用于全面的身份特征提取。此外，我们集成了混合参考融合注意力机制，以处理不同的分辨率和动态序列长度。最后，从生成质量的角度来看，我们引入了身份鲁棒的姿态控制，该控制将外观与骨骼结构解耦以减轻姿态过拟合，并提出了一种令牌替换策略用于连贯的长视频生成。大量实验表明，我们的方法优于现有方法。代码和模型将发布于https://github.com/ssj9596/One-to-All-Animation。|
|**2025-11-28**|[Scalable Diffusion Transformer for Conditional 4D fMRI Synthesis](http://arxiv.org/abs/2511.22870)|null|由于跨受试者/采集的高维异构BOLD动态以及缺乏神经科学基础的验证，生成以认知任务为条件的全脑4D fMRI序列仍然具有挑战性。我们引入了首个用于体素级4D fMRI条件生成的扩散Transformer，它结合了3D VQ-GAN潜在压缩与CNN-Transformer骨干网络，并通过AdaLN-Zero和交叉注意力实现强大的任务条件作用。在HCP任务fMRI上，我们的模型再现了任务诱发的激活图，保留了真实数据中观察到的任务间表征结构（RSA），实现了完美的条件特异性，并使ROI时间序列与典型血流动力学响应对齐。性能随规模可预测地提升，任务诱发图相关性达到0.83，RSA达到0.98，在所有指标上持续超越U-Net基线。通过结合潜在扩散与可扩展的骨干网络和强大的条件作用，这项工作为条件4D fMRI合成建立了实用的路径，为虚拟实验、跨站点协调以及下游神经影像模型的有原则增强等未来应用铺平了道路。|
|**2025-11-27**|[Intelligent Neural Networks: From Layered Architectures to Graph-Organized Intelligence](http://arxiv.org/abs/2511.22813)|null|生物神经元展现出卓越的智能：它们维持内部状态，选择性地与其他神经元通信，并自组织成复杂图结构而非僵化的分层结构。如果人工智能也能源于类似的智能计算单元呢？我们引入了智能神经网络（INN），这是一种范式转变，其中神经元是具有内部记忆和习得通信模式的一等实体，以全连接图而非顺序层组织。每个智能神经元结合了选择性状态空间动力学（知道何时激活）和基于注意力的路由（知道向谁发送信号），通过图结构交互实现涌现计算。在标准Text8字符建模基准上，INN实现了1.705比特每字符（BPC），显著优于可比的Transformer（2.055 BPC），并媲美高度优化的LSTM基线。关键的是，在相同的训练协议下，参数匹配的堆叠Mamba模块基线未能收敛（>3.4 BPC），这表明INN的图拓扑结构提供了必要的训练稳定性。消融研究证实了这一点：移除神经元间通信会导致性能下降或不稳定，证明了习得神经路由的价值。这项工作表明，以神经元为中心并采用图组织的设计不仅仅是受生物学启发，它在计算上也是有效的，为模块化、可解释、可扩展的神经网络架构开辟了新方向。|
|**2025-11-27**|[LC4-DViT: Land-cover Creation for Land-cover Classification with Deformable Vision Transformer](http://arxiv.org/abs/2511.22812)|null|土地覆盖是生态系统服务、水文调节、减少灾害风险以及基于证据的土地规划的基础；因此，及时、准确的土地覆盖地图对于环境保护至关重要。基于遥感的土地覆盖分类为获取此类地图提供了可扩展的途径，但其受限于稀缺和不平衡的标注，以及高分辨率场景中的几何畸变。我们提出了LC4-DViT（Land-cover Creation for Land-cover Classification with Deformable Vision Transformer），这是一个将生成式数据创建与变形感知视觉Transformer相结合的框架。一个文本引导的扩散模型利用GPT-4o生成的场景描述和超分辨率样本来合成类别平衡、高保真度的训练图像，而DViT则将DCNv4可变形卷积骨干网络与视觉Transformer编码器相结合，共同捕捉细粒度几何特征和全局上下文。在航空影像数据集（AID）的八个类别——海滩、桥梁、沙漠、森林、山脉、池塘、港口和河流——上，DViT取得了0.9572的总体准确度、0.9576的宏F1分数和0.9510的Cohen's Kappa系数，相比标准ViT基线（0.9274的总体准确度、0.9300的宏F1和0.9169的Kappa系数）有所提升，并优于ResNet50、MobileNetV2和FlashInternImage。在SIRI-WHU数据集的一个三类别子集（港口、池塘、河流）上进行的跨数据集实验取得了0.9333的总体准确度、0.9316的宏F1和0.8989的Kappa系数，表明了良好的可迁移性。一个使用GPT-4o对Grad-CAM热力图进行评分的基于大语言模型的判别器进一步表明，DViT的注意力与具有水文意义的结构对齐最佳。这些结果表明，描述驱动的生成式增强与变形感知Transformer相结合，是高分辨率土地覆盖制图的一种有前途的方法。|
|**2025-11-27**|[TransCoder: A Neural-Enhancement Framework for Channel Codes](http://arxiv.org/abs/2511.22539)|**[link](https://github.com/smeshk/TransCoder)**|噪声信道上的可靠通信需要设计专门的纠错码（ECC），以适应特定的系统要求。最近，基于神经网络的译码器已成为提高ECC可靠性的有前景的工具，但其高计算复杂度阻碍了它们的潜在实际部署。在本文中，我们采取了一种不同的方法，设计了一种采用Transformer架构的神经传输方案，以提高现有ECC的可靠性。我们将这种方法命名为TransCoder，暗示了其功能和架构。TransCoder作为一个旨在增强性能的码自适应神经模块运行，可以灵活地在发射端、接收端或两者同时实现。该框架采用迭代译码过程，其中来自信道的噪声信息和来自传统ECC译码器的更新都由一个神经译码器模块处理，该模块利用块注意力机制来提高效率。通过对各种传统编码（LDPC、BCH、Polar和Turbo）在广泛信道条件下进行大量仿真，我们证明TransCoder显著提高了块差错率（BLER）性能，同时保持了与传统译码器相当的计算复杂度。值得注意的是，我们的方法对于较长编码（码块长度 >64）和较低码率特别有效，而现有神经译码器在这些场景下通常表现不佳（尽管它们具有强大的计算复杂度）。结果表明，TransCoder是资源受限无线设备之间可靠通信的一个有前景的实用解决方案。|
|**2025-11-26**|[Visualizing LLM Latent Space Geometry Through Dimensionality Reduction](http://arxiv.org/abs/2511.21594)|null|大型语言模型（LLMs）在许多自然语言任务中取得了最先进的结果，但其内部机制仍然难以解释。在这项工作中，我们通过降维技术，提取、处理并可视化了基于Transformer的语言模型中的潜在状态几何结构。我们在Transformer块内的多个点捕获了层级激活，并通过主成分分析（PCA）和均匀流形逼近（UMAP）实现了系统分析。我们在GPT-2和LLaMa模型上进行了实验，揭示了潜在空间中有趣的几何模式。值得注意的是，我们发现在中间层中，注意力（attention）和多层感知机（MLP）组件的输出之间存在明显的分离，据我们所知，这是以往工作中未曾记录的模式。我们还表征了序列初始位置潜在状态的高范数，并可视化了潜在状态的层级演变。此外，我们展示了GPT-2位置嵌入的高维螺旋结构、LLaMa中序列级的几何模式，并对重复的token序列进行了实验。我们的目标是支持对Transformer内部机制的系统分析，以促进进一步可复现的解释性研究。我们的代码已在https://github.com/Vainateya/Feature_Geometry_Visualization开源。|
|**2025-11-26**|[Mechanistic Interpretability for Transformer-based Time Series Classification](http://arxiv.org/abs/2511.21514)|null|基于Transformer的模型已成为各种机器学习任务（包括时间序列分类）中的最先进工具，然而它们的复杂性使得理解其内部决策过程变得具有挑战性。现有的可解释性方法通常侧重于输入-输出归因，使得内部机制在很大程度上不透明。本文通过将各种机制可解释性技术——激活修补、注意力显著性和稀疏自编码器——从自然语言处理（NLP）领域借鉴并应用于专门为时间序列分类设计的Transformer架构，解决了这一空白。我们系统地探究了单个注意力头和时间步的内部因果作用，揭示了这些模型内部的因果结构。通过在基准时间序列数据集上进行实验，我们构建了因果图，阐明了信息如何在内部传播，并突出了推动正确分类的关键注意力头和时间位置。此外，我们展示了稀疏自编码器在揭示可解释的潜在特征方面的潜力。我们的研究结果为Transformer可解释性提供了方法论贡献，并为时间序列分类任务中支撑Transformer性能的功能机制提供了新颖见解。|
|**2025-11-26**|[Frequency-Aware Token Reduction for Efficient Vision Transformer](http://arxiv.org/abs/2511.21477)|null|视觉Transformer在各种计算机视觉任务中表现出卓越性能，但其关于token长度的二次计算复杂度仍然是一个重大挑战。为此，token缩减方法已得到广泛探索。然而，现有方法常常忽略自注意力机制的频率特性，例如秩坍塌和过平滑现象。在本文中，我们提出了一种频率感知的token缩减策略，通过缓解秩坍塌来提高计算效率并同时保持性能。我们的方法将token划分为高频token和低频token。高频token被选择性地保留，而低频token被聚合成一个紧凑的直流token，以保留必要的低频分量。通过大量的实验和分析，我们证明我们的方法在显著提高准确性的同时，降低了计算开销并缓解了秩坍塌和过平滑现象。此外，我们分析了先前方法，揭示了它们隐含的频率特性和局限性。|
|**2025-11-26**|[SAM Guided Semantic and Motion Changed Region Mining for Remote Sensing Change Captioning](http://arxiv.org/abs/2511.21420)|null|遥感变化描述是一项新兴且热门的研究任务，旨在用自然语言描述在不同时间捕获的两幅遥感图像之间发生变化的目标内容。现有方法通常采用卷积神经网络（CNN）/Transformer模型从给定图像中提取视觉表示，或结合辅助任务以提高最终结果，但这些方法普遍存在区域感知能力弱和时间对齐性有限的问题。为了解决这些问题，本文探索使用SAM（Segment Anything Model）基础模型来提取区域级表示，并将感兴趣区域知识注入描述框架中。具体而言，我们采用一个CNN/Transformer模型提取全局级视觉特征，利用SAM基础模型划分语义级和运动级变化区域，并利用专门构建的知识图谱提供关于感兴趣对象的信息。这些异构信息源随后通过交叉注意力机制进行融合，并使用Transformer解码器生成观测到的变化的最终自然语言描述。大量的实验结果表明，我们的方法在多个广泛使用的基准数据集上实现了最先进的性能。本文的源代码将发布在https://github.com/Event-AHU/SAM_ChangeCaptioning|
|**2025-11-26**|[Subjective Depth and Timescale Transformers: Learning Where and When to Compute](http://arxiv.org/abs/2511.21408)|null|标准Transformer（TF）架构中刚性、统一的计算分配会限制其效率和可扩展性，尤其对于大规模模型和长序列而言。为解决此问题，我们引入了主观深度Transformer（SDT）和主观时间尺度Transformer（STT）这两种不同的架构，它们利用贝叶斯惊喜信号动态路由计算，学习在仅解码器Transformer中何处以及何时进行计算。SDT通过交替的决策层和动态层增强仅解码器堆栈：决策层计算完整的块“后验”和轻量级“先验”，而动态层则基于贝叶斯惊喜（预期和非预期变化）采用固定容量的Top-K路由，同时保持静态计算图。STT将这种条件计算扩展到时间域：一个转换网络预测残差更新，形成时间“变化假设”，该假设指示路由器为每个token动态执行或绕过TF块，并管理KV缓存贡献。两种架构在训练过程中都表现出从新颖性驱动到预测驱动门控的预期转变，这表明它们与基于惊喜的原则相符。尽管在降低的容量下运行，它们为条件计算的计算-精度权衡提供了初步见解。所提出的架构建立了一个灵活的效率框架，在每个计算跳过层内将自注意力计算量减少75%，KV缓存需求减少50%，为更高效的模型铺平了道路。|
|**2025-11-26**|[Controlling changes to attention logits](http://arxiv.org/abs/2511.21377)|null|在训练Transformer模型时，神经网络权重的稳定性至关重要。查询（query）和键（key）权重尤其成问题，因为它们在没有任何干预的情况下倾向于变得很大。对查询和键应用归一化，即所谓的“QK归一化（QK norm）”，在实践中解决了稳定性问题，但并非总是适用。例如，QK归一化与多潜在注意力（Multi Latent Attention, MLA）不兼容，因为QK归一化在推理过程中需要查询和键的完全实例化，而MLA中没有这样做。在本文中，我们提出控制logit的变化对稳定性很重要。我们表明，通过为查询和键权重分配与参数相关的学习率，这些变化是可控的。我们发现，我们廉价的干预措施使我们能够提高网络的基准学习率，在MLA设置下优于其他方法，并在使用多头注意力（Multi-head Attention）时达到与QK归一化相当的性能。|
|**2025-11-26**|[HTTM: Head-wise Temporal Token Merging for Faster VGGT](http://arxiv.org/abs/2511.21317)|null|视觉几何基础Transformer (VGGT) 在3D场景重建方面取得了重大飞跃，因为它是首个在一次前向传播中直接联合推断所有关键3D属性（相机姿态、深度和密集几何）的模型。然而，这种联合推断机制需要全局注意力层对来自所有视角的tokens执行所有-到-所有（all-to-all）的注意力计算。对于具有长序列输入的大型场景重建，这会导致显著的延迟瓶颈。在本文中，我们提出逐头时间合并 (HTTM)，这是一种免训练的3D token合并方法，用于加速VGGT。现有的合并技术在不同注意力头之间统一合并tokens，导致在层的输出中产生相同的tokens，这阻碍了模型的表示能力。HTTM通过以多头粒度合并tokens来解决这个问题，这在头部拼接后保持了特征tokens的唯一性。此外，这使得HTTM能够利用在头部层面观察到的空间局部性和时间对应性，与现有方法相比，以更低的合并成本实现更高的合并比率。因此，HTTM在基于GPU的推理中实现了高达7倍的加速，同时性能下降可忽略不计。|
|**2025-11-26**|[CaliTex: Geometry-Calibrated Attention for View-Coherent 3D Texture Generation](http://arxiv.org/abs/2511.21309)|null|尽管扩散模型带来了重大进展，但当前的3D纹理生成系统仍受限于跨视角不一致性——从一个视角看似乎令人信服的纹理，在其他视角下往往无法对齐。我们发现这个问题源于注意力模糊性，其中非结构化的全局注意力不加区分地应用于不同的token和模态，导致几何混淆和不稳定的外观-结构耦合。为解决此问题，我们引入了CaliTex，这是一个几何校准注意力的框架，它显式地将注意力与3D结构对齐。它引入了两个模块：部件对齐注意力，用于强制语义匹配部件之间的空间对齐；以及条件路由注意力，通过几何条件路径路由外观信息以保持空间保真度。结合两阶段扩散transformer，CaliTex使几何一致性成为网络的固有行为，而非优化的副产品。经验上，CaliTex生成无缝且视角一致的纹理，并优于开源和商业基线。|
|**2025-11-26**|[Discovery and recovery of crystalline materials with property-conditioned transformers](http://arxiv.org/abs/2511.21299)|**[link](https://github.com/C-Bone-UCL/CrystaLLM-pi)**|生成模型最近在加速新型功能材料的设计与发现方面展现出巨大潜力。条件生成通过实现逆向设计增强了这一能力，即在生成过程中可以请求特定的期望性能。然而，基于Transformer方法中的条件设置，尤其受限于离散分词方案以及在微调过程中灾难性遗忘的风险。本工作引入了CrystaLLM-π（属性注入），这是一个将连续属性表示直接集成到Transformer注意力机制中的条件自回归框架。提出了两种架构：属性-键-值（PKV）前缀注意力（Prefix attention）和PKV残差注意力（Residual attention）。这些方法绕过了低效的序列级分词，并保留了从以晶体学信息文件（CIFs）作为文本输入进行无监督预训练中获得的基础知识。我们通过系统性鲁棒性研究证实了这些机制的有效性，并在两项不同的任务中评估了该框架的通用性。首先，在结构恢复任务中，模型处理高维、异构的X射线衍射图，实现了与专业模型相媲美的结构准确性，并展示了在实验结构恢复和多晶型物区分方面的应用。其次，在材料发现任务中，模型在专门的光伏数据集上进行微调，以生成经密度泛函理论（DFT）验证的新颖、稳定候选材料。它隐式地学习针对高光伏效率的最佳带隙区域，展示了映射复杂结构-性能关系的能力。CrystaLLM-π为逆向材料设计提供了一个统一、灵活且计算高效的框架。|
|**2025-11-26**|[LLaVA-UHD v3: Progressive Visual Compression for Efficient Native-Resolution Encoding in MLLMs](http://arxiv.org/abs/2511.21150)|**[link](https://github.com/thunlp/LLaVA-UHD)**|视觉编码后接令牌凝聚已成为多模态大语言模型（MLLM）的标准架构范式。许多近期MLLM越来越倾向于采用全局原生分辨率视觉编码而非基于切片的方法。为探究这一趋势，我们系统地比较了它们在视觉语言理解和注意力模式上的行为，结果表明全局编码虽能提升整体能力，但代价是更大的计算开销。为解决此问题，我们提出了LLaVA-UHD v3，这是一个以我们提出的渐进式视觉压缩（PVC）方法为核心的MLLM，该方法可无缝集成到标准Vision Transformer (ViT) 中，以实现高效的原生分辨率编码。PVC方法包含两个关键模块：(i) 精炼的图像块嵌入，其支持灵活的图像块尺寸缩放以实现细粒度视觉建模；(ii) 窗口式令牌压缩，其分层部署在ViT层中以逐步聚合局部令牌表示。在这两个模块的共同调节下，一个广泛预训练的ViT可以被重构为一个高效的架构，同时在很大程度上保留了泛化能力。经广泛基准测试评估，在相同的MLLM架构下开发时，这种经过转换的ViT（命名为ViT-UHD）展现出与MoonViT相媲美的性能，同时将TTFT（首令牌生成时间）减少2.4倍。基于ViT-UHD，LLaVA-UHD v3也实现了与Qwen2-VL相媲美的性能，同时进一步将TTFT减少1.9倍。我们将发布所有代码和检查点，以支持未来关于高效MLLM的研究。|
|**2025-11-25**|[MSTN: Fast and Efficient Multivariate Time Series Model](http://arxiv.org/abs/2511.20577)|null|现实世界的时间序列数据高度非平稳，其动态复杂且跨越多个时间尺度，涵盖从快速、短期变化到缓慢、长期趋势。大多数现有模型依赖于固定尺度结构先验，例如基于块的标记化、固定频率变换或冻结的主干架构。这通常会导致时间动态的过度正则化，限制了它们自适应建模时间变化全谱的能力，并损害了它们在不可预测、突发、高幅度事件上的性能。为了解决这个问题，我们引入了多尺度时间网络（MSTN），这是一种基于分层多尺度和序列建模原理的新颖深度学习架构。MSTN框架整合了：(i) 一个多尺度卷积编码器，用于构建局部模式的分层特征金字塔；(ii) 一个用于长程时间依赖的序列建模组件，我们通过BiLSTM和Transformer变体对其进行了实证验证，为未来的架构改进奠定了灵活的基础；以及 (iii) 一个门控融合机制，其通过挤压-激励（SE）和多头时间注意力（MHTA）增强，实现动态、上下文感知的特征整合。这种设计使MSTN能够在统一框架内自适应地建模从毫秒级到长程依赖的时间模式。跨时间序列长周期预测、插补、分类和泛化性研究的广泛评估表明，MSTN实现了具有竞争力的最先进（SOTA）性能，相比包括EMTSF、LLM4TS、HiMTM、TIME-LLM、MTST、SOFTS、iTransformer、TimesNet和PatchTST在内的现有方法均有所改进。总而言之，MSTN在32个基准数据集中的24个上建立了新的SOTA性能，证明了其在各种时间任务中的一致性能。|
|**2025-11-25**|[HBridge: H-Shape Bridging of Heterogeneous Experts for Unified Multimodal Understanding and Generation](http://arxiv.org/abs/2511.20520)|null|近期统一模型将理解专家（例如大语言模型）与生成专家（例如扩散模型）进行整合，取得了强大的多模态性能。然而，BAGEL和LMFusion等近期先进方法遵循Transformer混合（MoT）范式，采用对称设计将一个专家映射到另一个专家，以方便初始化和融合，但这由于固有的模态差异而仍然是次优的。在这项工作中，我们提出了HBridge，一种不对称的H形架构，它能够使异构专家最佳地利用其各自模态领域中的预训练先验知识。与以往通过共享注意力直接连接专家之间所有层的密集融合策略不同，HBridge选择性地连接中间层，减少了超过40%的注意力共享，这提高了效率并增强了生成质量。浅层和深层（它们捕获模态特定的表示）被解耦，而中间层桥接促进了语义对齐。为了进一步加强跨模态一致性，我们引入了语义重建token，它们明确地指导生成专家重建目标图像的视觉语义token。在多个基准上进行的大量实验证明了HBridge的有效性和卓越性能，为统一多模态生成建立了一个新范式。|
|**2025-11-25**|[3D Motion Perception of Binocular Vision Target with PID-CNN](http://arxiv.org/abs/2511.20332)|null|本文训练了一个感知双目视觉目标三维运动信息的网络，该网络能提供实时三维坐标、速度和加速度，并具有基本的时空感知能力。从PID的角度理解了神经网络拟合非线性问题的能力。将单层神经网络视为利用二阶差分方程和一个非线性函数来描述一个局部问题。多层网络通过多个这样的组合，逐步将原始表示转换为所需表示。分析了一些用于设计神经网络的参考原则。设计了一个相对较小的PID卷积神经网络，总计17层，41.3万个参数。通过拼接和池化实现了一种简单而实用的特征重用方法。该网络使用模拟的随机运动球体数据集进行训练和测试，实验结果表明，其预测精度接近输入图像分辨率所能表示的上限。分析了实验结果和误差，以及现有不足和可能的改进方向。最后，讨论了高维卷积在提高计算效率和特征空间利用率方面的优势，以及利用PID信息实现记忆和注意力机制的潜在优势。|
|**2025-11-25**|[IrisNet: Infrared Image Status Awareness Meta Decoder for Infrared Small Targets Detection](http://arxiv.org/abs/2511.20319)|null|红外小目标检测（IRSTD）面临着严峻挑战，这主要是由于低信噪比、复杂背景以及缺乏可辨识的目标特征。尽管基于深度学习的编解码器框架推动了该领域的发展，但其静态模式学习在多样化场景（例如昼夜变化、空域/海域/地面领域）中存在模式漂移问题，从而限制了鲁棒性。为解决此问题，我们提出了IrisNet，这是一种新颖的元学习框架，能够根据输入的红外图像状态动态地调整检测策略。我们的方法通过一个图像到解码器的Transformer建立了红外图像特征与整个解码器参数之间的动态映射。更具体地说，我们将参数化解码器表示为一个结构化二维张量，保留了层次化的层间相关性，并使Transformer能够通过自注意力建模层间依赖关系，同时通过交叉注意力生成自适应解码模式。为了进一步增强红外图像的感知能力，我们融合了高频分量以补充目标位置和场景边缘信息。在NUDT-SIRST、NUAA-SIRST和IRSTD-1K数据集上的实验证明了我们IrisNet的优越性，实现了最先进的性能。|
|**2025-11-25**|[V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs](http://arxiv.org/abs/2511.20223)|**[link](https://github.com/Summu77/V-Attack)**|对抗性攻击已从简单地扰乱传统任务专用模型的预测演变为更复杂的目标，即在大型视觉语言模型（LVLMs）上操纵图像语义。然而，现有方法在可控性方面存在困难，并且未能精确操纵图像中特定概念的语义。我们将此限制归因于对抗性攻击通常在其上操作的补丁-标记表示中的语义纠缠：视觉编码器中自注意力机制聚合的全局上下文支配着单个补丁特征，使其成为精确局部语义操纵的不可靠手段。我们的系统性研究揭示了一个关键见解：在Transformer注意力块内计算的值特征（V）可作为更精确的操纵手段。我们表明，V抑制了全局上下文通道，使其能够保留高熵、解耦的局部语义信息。基于这一发现，我们提出了V-Attack，一种专为精确局部语义攻击设计的新颖方法。V-Attack以值特征为目标，并引入了两个核心组件：（1）一个自值增强模块，用于提炼V固有的语义丰富性；（2）一个文本引导的值操纵模块，该模块利用文本提示来定位源概念并将其优化至目标概念。通过绕过纠缠的补丁特征，V-Attack实现了高效的语义控制。在包括LLaVA、InternVL、DeepseekVL和GPT-4o在内的各种LVLMs上进行的大量实验表明，V-Attack将攻击成功率比最先进的方法平均提高了36%，揭示了现代视觉语言理解中的关键漏洞。我们的代码和数据可在https://github.com/Summu77/V-Attack获取。|
|**2025-11-25**|[In-Context Compositional Learning via Sparse Coding Transformer](http://arxiv.org/abs/2511.20194)|null|Transformer架构在语言、视觉和多模态任务中取得了显著成功，并且人们对它们解决上下文合成学习任务的需求日益增长。在这些任务中，模型通过从上下文示例中推断组合规则来解决目标问题，这些上下文示例由底层规则构建的基本组件构成。然而，其中一些任务对Transformer模型来说仍然具有挑战性，因为它们并非天生设计用于处理组合任务，并且提供有限的结构归纳偏置。在这项工作中，受稀疏编码原理启发，我们提出了一种注意力机制的重新表述，以增强其处理组合任务的能力。在稀疏编码中，数据被表示为字典原子的稀疏组合，其系数捕获了数据的组合规则。具体而言，我们将注意力块重新解释为通过投影到两组学习到的字典原子（一个编码字典和一个解码字典）来将输入映射到输出。编码字典将输入分解为一组系数，这些系数代表输入的组合结构。为了增强结构化表示，我们对这些系数施加稀疏性。然后，稀疏系数用于线性组合解码字典原子以生成输出。此外，为了辅助组合泛化任务，我们提出将目标问题的系数估计为从上下文示例中获得的系数的线性组合。我们验证了我们方法在S-RAVEN和RAVEN数据集上的有效性。对于某些组合泛化任务，即使标准Transformer模型失败时，我们的方法也能保持性能，这归因于其学习和应用组合规则的能力。|
|**2025-11-25**|[Hybrid Convolution and Frequency State Space Network for Image Compression](http://arxiv.org/abs/2511.20151)|null|学习图像压缩（LIC）最近受益于基于 Transformer 和基于状态空间模型（SSM）的架构。卷积神经网络（CNN）能有效捕获局部高频细节，而 Transformer 和 SSM 则提供强大的长距离建模能力，但可能导致结构信息丢失或忽略对压缩至关重要的频率特性。在这项工作中，我们提出了 HCFSSNet，一个用于 LIC 的混合卷积与频率状态空间网络。HCFSSNet 使用 CNN 提取局部高频结构，并引入了一个视觉频率状态空间（VFSS）块来建模长距离低频信息。VFSS 块结合了一个全向邻域状态空间（VONSS）模块（该模块水平、垂直和对角线扫描特征），以及一个自适应频率调制模块（AFMM），AFMM 对离散余弦变换频率分量应用内容自适应加权，以实现更高效的比特分配。为了进一步减少熵模型中的冗余，我们将 AFMM 与 Swin Transformer 集成，形成频率 Swin Transformer 注意力模块（FSTAM），用于频率感知的辅助信息建模。在 Kodak、Tecnick 和 CLIC 专业验证数据集上的实验表明，HCFSSNet 实现了与 MambaIC 等近期基于 SSM 的编码器相比具有竞争力的码率失真性能，同时使用了显著更少的参数。在 Kodak、Tecnick 和 CLIC 数据集上，HCFSSNet 相对于 VTM 基准，BD 率分别降低了 18.06%、24.56% 和 22.44%，为未来的学习图像压缩系统提供了一种高效且可解释的混合架构。|
|**2025-11-25**|[ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction](http://arxiv.org/abs/2511.20020)|null|预测行人穿越意图对于自动驾驶车辆预防与行人相关的碰撞事故至关重要。然而，有效提取和整合不同类型数据中的互补线索仍然是主要挑战之一。本文提出了一种注意力引导的跨模态交互Transformer（ACIT），用于行人穿越意图预测。ACIT利用六种视觉和运动模态，将其分为三对交互对：(1) 全局语义地图和全局光流，(2) 局部RGB图像和局部光流，以及 (3) 自车速度和行人边界框。在每对视觉交互对中，双路径注意力机制通过模态内自注意力增强主要模态中的显著区域，并通过光流引导注意力促进与辅助模态（即光流）的深度交互。在运动交互对中，采用跨模态注意力来建模跨模态动态，从而实现互补运动特征的有效提取。除了成对交互之外，一个多模态特征融合模块在每个时间步进一步促进跨模态交互。此外，引入了一个基于Transformer的时间特征聚合模块来捕获序列依赖性。实验结果表明，ACIT优于现有最先进方法，在JAADbeh和JAADall数据集上分别实现了70%和89%的准确率。本文还进行了广泛的消融研究，以探究ACIT不同模块的贡献。|
|**2025-11-25**|[Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments](http://arxiv.org/abs/2511.20011)|null|行人过街意图预测对于自动驾驶车辆提高行人安全性、减少交通事故至关重要。然而，由于影响行人行为的因素众多，在城市环境中准确预测行人意图仍然具有挑战性。在本文中，我们提出了一种多上下文融合Transformer（MFT），它利用行人行为上下文、环境上下文、行人定位上下文和车辆运动上下文这四个关键维度上的多样化数值上下文属性，以实现准确的行人意图预测。MFT采用渐进式融合策略，其中相互的上下文内注意力（mutual intra-context attention）促进每个上下文内部的相互作用，从而促进特征序列融合并生成一个上下文令牌作为上下文特有的表示。随后是相互的上下文间注意力（mutual cross-context attention），它将不同上下文的特征与一个全局CLS令牌进行整合，该令牌作为紧凑的多上下文表示。最后，引导式上下文内注意力（guided intra-context attention）通过定向交互细化每个上下文内的上下文令牌，而引导式上下文间注意力（guided cross-context attention）则通过引导式信息传播加强全局CLS令牌以促进多上下文融合，从而实现更深入、更高效的集成。实验结果验证了MFT优于现有先进方法的性能，在JAADbeh、JAADall和PIE数据集上分别达到了73%、93%和90%的准确率。此外，还进行了广泛的消融研究，以探究网络架构的有效性和不同输入上下文的贡献。我们的代码已开源：https://github.com/ZhongHang0307/Multi-Context-Fusion-Transformer。|
|**2025-11-25**|[Pedestrian Crossing Intention Prediction Using Multimodal Fusion Network](http://arxiv.org/abs/2511.20008)|null|行人过街意图预测对于自动驾驶车辆（AVs）在城市环境中的部署至关重要。理想的预测为AVs提供关键的环境线索，从而降低与行人相关的碰撞风险。然而，由于行人行为的多样性及其对多种上下文因素的依赖，该预测任务具有挑战性。本文提出了一种多模态融合网络，该网络利用来自视觉和运动分支的七种模态特征，旨在有效提取和整合不同模态之间的互补线索。具体而言，运动和视觉特征使用多个基于Transformer的提取模块从原始输入中提取。深度引导注意力模块利用深度信息，通过全面的空间特征交互，引导注意力转向另一模态中的显著区域。为了考虑不同模态和帧的变异重要性，设计了模态注意力和时间注意力，以选择性地强调信息丰富的模态并有效捕获时间依赖性。在JAAD数据集上进行的广泛实验验证了所提出网络的有效性，并实现了优于基线方法的性能。|
|**2025-11-21**|[Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?](http://arxiv.org/abs/2511.17400)|null|视觉Transformer ( $\text{ViT}$) 已成为视觉基础模型的骨干，然而，它们在多通道领域（如细胞涂色或卫星图像）中的优化仍未得到充分探索。这些领域中的一个主要挑战是捕获通道间的交互，因为每个通道都携带着不同的信息。尽管现有工作通过在标记化过程中独立处理每个通道来显示出有效性，但这种方法自然会在注意力块中引入一个主要的计算瓶颈——通道间的比较导致注意力呈二次增长，从而产生过多的浮点运算 ($\text{FLOPs}$) 和高昂的训练成本。在这项工作中，我们将重点从有效性转移到跨通道注意力中被忽视的效率挑战，并提出问题：“是否有必要建模所有通道交互？”受稀疏专家混合模型 ($\text{MoE}$) 理念的启发，我们提出了MoE-ViT，这是一种用于$\text{ViT}$中多通道图像的专家混合架构，该架构将每个通道视为一个专家，并采用轻量级路由器为每个图像块选择最相关的专家进行注意力计算。在真实世界数据集 JUMP-CP 和 So2Sat 上的概念验证实验表明，$\text{MoE-ViT}$ 在不牺牲性能的同时，在某些情况下甚至提升了性能，从而取得了显著的效率提升，使其成为多通道成像中一种实用且有吸引力的骨干。|
|**2025-11-21**|[Selective Rotary Position Embedding](http://arxiv.org/abs/2511.17388)|null|位置信息对语言建模至关重要。在Softmax Transformer中，旋转位置嵌入（RoPE）通过固定角度旋转来编码位置；而在线性Transformer中，顺序通过衰减过去的键值关联的依赖于输入（选择性）门控来处理。选择性通常被证明能提高语言相关任务的性能。受此启发，我们引入了选择性RoPE，这是一种依赖于输入的旋转嵌入机制，它泛化了RoPE，并能使线性Transformer和Softmax Transformer实现任意角度的旋转。我们表明，Softmax注意力已经在查询-键对上执行了这些旋转的一种隐藏形式，揭示了一种隐式的位置结构。我们进一步表明，在状态空间模型和门控线性Transformer中，实部负责遗忘，而虚部通过旋转编码位置。我们通过为门控Transformer配备选择性RoPE来验证我们的方法，证明了其依赖于输入的旋转提高了语言建模以及复制、状态跟踪和检索等困难序列任务的性能。|
|**2025-11-21**|[DSeq-JEPA: Discriminative Sequential Joint-Embedding Predictive Architecture](http://arxiv.org/abs/2511.17354)|**[link](https://github.com/SkyShunsuke/DSeq-JEPAProject)**|基于图像的联合嵌入预测架构（I-JEPA）通过从可见上下文预测掩蔽区域的潜在嵌入来学习视觉表征。然而，它统一且独立地对待所有区域，缺乏关于预测应该在哪里或以何种顺序进行的明确概念。受人类视觉感知的启发，人类视觉感知选择性地并按顺序从信息最丰富的区域部署注意力到次要区域，我们提出了DSeq-JEPA，一种判别性序列联合嵌入预测架构，它弥合了预测式和自回归式自监督学习，整合了JEPA风格的潜在预测与GPT风格的序列推理。具体而言，DSeq-JEPA (i) 首先基于Transformer派生的显著性图识别主要判别区域，强调视觉重要性的分布，然后 (ii) 按照这种判别顺序预测后续区域，逐步形成课程般的语义进展，从主要线索到次要线索——这是一种GPT风格的预训练形式。在各种任务中进行的广泛实验，包括图像分类（ImageNet）、细粒度视觉分类（iNaturalist21、CUB-200-2011、Stanford-Cars）、检测和分割（MS-COCO、ADE20K）以及低级推理任务（Clevr/Count、Clevr/Dist），都表明DSeq-JEPA始终专注于比I-JEPA变体更具判别性和泛化性的表征。项目页面：https://github.com/SkyShunsuke/DSeq-JEPA。|
|**2025-11-21**|[A Little More Like This: Text-to-Image Retrieval with Vision-Language Models Using Relevance Feedback](http://arxiv.org/abs/2511.17255)|null|大型视觉-语言模型（VLM）支持使用自然语言查询进行直观的视觉搜索。然而，提升其性能通常需要进行微调并扩展到更大的模型变体。在这项工作中，我们提出了一种受传统基于文本的搜索启发而用于在推理时提高检索性能的机制：相关性反馈。虽然相关性反馈可以作为微调的替代方案，但其模型无关的设计也使其能够与经过微调的VLM一起使用。具体来说，我们为基于VLM的检索引入并评估了四种反馈策略。首先，我们修订了经典的伪相关性反馈（PRF），它根据排名靠前的结果优化查询嵌入。为了解决其局限性，我们提出了生成式相关性反馈（GRF），它使用合成描述进行查询优化。此外，我们引入了注意力反馈摘要器（AFS），这是一种定制的基于Transformer的模型，它整合了来自相关项的多模态细粒度特征。最后，我们使用真值描述模拟显式反馈作为上限基线。在Flickr30k和COCO数据集上使用VLM骨干网络进行的实验表明，与无反馈检索相比，GRF、AFS和显式反馈在MRR@5指标上将小型VLM的检索性能提高了3-5%，大型VLM的检索性能提高了1-3%。此外，AFS与显式反馈类似，能够缓解查询漂移，并且在迭代式、多轮检索设置中比GRF更具鲁棒性。我们的研究结果表明，相关性反馈可以持续提升VLM的检索性能，并为交互式和自适应视觉搜索开辟了新的机会。|
|**2025-11-21**|[Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT Transformers](http://arxiv.org/abs/2511.17209)|null|我们介绍了SPECTRE，一个完全基于Transformer的体积计算机断层扫描（CT）基础模型。我们用于CT表示提取的自监督和跨模态预训练（SPECTRE）方法利用可扩展的3D视觉Transformer架构以及现代的自监督和视觉-语言预训练策略来学习通用CT表示。体积CT带来独特挑战，例如极端的token尺度、几何各向异性以及微弱或噪声化的临床监督，这些使得标准Transformer和对比学习方法无法直接有效应用。该框架联合优化一个用于高分辨率体积特征提取的局部Transformer和一个用于全扫描上下文建模的全局Transformer，使得大规模3D注意力计算变得可行。值得注意的是，SPECTRE专门在公开可用的CT数据集上进行训练，表明无需依赖私有数据即可实现高性能、可泛化的表示。预训练结合了DINO风格的自蒸馏与使用成对放射学报告的基于SigLIP的视觉-语言对齐，从而产生了既几何一致又临床有意义的特征。在多个CT基准测试中，SPECTRE在零样本和微调设置下始终优于先前的CT基础模型，将SPECTRE确立为一种可扩展、开放且完全基于Transformer的3D医学成像基础模型。|
|**2025-11-21**|[DReX: Pure Vision Fusion of Self-Supervised and Convolutional Representations for Image Complexity Prediction](http://arxiv.org/abs/2511.16991)|**[link](https://github.com/jskaza/DReX)**|视觉复杂度预测是计算机视觉中的一个基本问题，在图像压缩、检索和分类中都有应用。理解是什么让人们将图像感知为复杂，也是认知科学中一个长期存在的问题。最近的方法利用了结合视觉和语言表示的多模态模型，但语言信息对于此任务是否必要仍不清楚。我们提出了DReX（DINO-ResNet融合），这是一个纯视觉模型，它通过可学习的注意力机制融合自监督和卷积表示来预测图像复杂度。我们的架构将来自ResNet-50的多尺度分层特征与来自DINOv3 ViT-S/16的语义丰富表示相结合，使模型能够捕获低级纹理模式和高级语义结构。DReX在IC9600基准测试上取得了最先进的性能（皮尔逊相关系数r = 0.9581），超越了先前的方法——包括那些在多模态图像-文本数据上训练的方法——同时使用的可学习参数数量减少了约21.5倍。此外，DReX在多个数据集和评估指标上表现出强大的泛化能力，在皮尔逊和斯皮尔曼相关系数、均方根误差（RMSE）和平均绝对误差（MAE）方面均取得了优异结果。消融和注意力分析证实，DReX利用了两个主干网络的互补线索，其中DINOv3 [CLS] token增强了对视觉复杂度的敏感性。我们的研究结果表明，仅凭视觉特征就足以进行与人类感知一致的复杂度预测，并且当适当融合时，自监督Transformer和监督式深度卷积神经网络能为该任务提供互补和协同的增益。|
|**2025-11-20**|[ManifoldFormer: Geometric Deep Learning for Neural Dynamics on Riemannian Manifolds](http://arxiv.org/abs/2511.16828)|null|现有的脑电基础模型主要将神经信号视为欧几里得空间中的通用时间序列，忽略了将大脑活动限制在低维流形上的神经动力学的内在几何结构。这种模型假设与神经几何之间的根本不匹配限制了表示质量和跨受试者泛化能力。ManifoldFormer通过一种新颖的几何深度学习框架解决了这一局限性，该框架明确学习神经流形表示。该架构整合了三项关键创新：一个用于流形嵌入的黎曼VAE，它保留了几何结构；一个几何Transformer，具有直接在神经流形上操作的测地线感知注意力机制；以及一个利用神经ODE进行流形约束时间演化的动力学预测器。对四个公共数据集的广泛评估表明，其比最先进的方法有显著改进，准确率提高了4.6-4.8%，且Cohen's Kappa提高了6.2-10.2%，同时保持了鲁棒的跨受试者泛化能力。这种几何方法揭示了有意义的神经模式，与神经生理学原理一致，从而确立了几何约束对于有效的脑电基础模型至关重要。|
|**2025-11-20**|[TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding](http://arxiv.org/abs/2511.16595)|**[link](https://github.com/xiaomi-research/timeviper)**|我们引入了TimeViper，一种混合视觉-语言模型，旨在解决长视频理解的挑战。处理长视频既需要高效的模型架构，又需要有效处理扩展时间上下文的机制。为此，TimeViper采用了混合Mamba-Transformer骨干网络，它结合了状态空间模型的效率与注意力机制的表达能力。通过这种混合设计，我们揭示了视觉到文本信息聚合现象，即信息随着LLM深度的增加，逐渐从视觉token流向文本token，导致严重的视觉token冗余。受此观察的启发，我们提出了TransV，一个token信息传输模块，能够将视觉token传输并压缩为指令token，同时保持多模态理解能力。这种设计使TimeViper能够处理超过10,000帧的长达数小时的视频。在多个基准测试上的大量实验表明，TimeViper与最先进的模型具有竞争力，同时扩展了处理的帧数。我们进一步分析了Mamba层和Transformer层的注意力行为，为混合模型的可解释性提供了新见解。这项工作代表了在开发、解释和压缩混合Mamba-Transformer架构方面迈出的第一步。|
|**2025-11-20**|[ODE-ViT: Plug & Play Attention Layer from the Generalization of the ViT as an Ordinary Differential Equation](http://arxiv.org/abs/2511.16501)|null|近年来，越来越大的模型在计算机视觉（CV）任务中取得了优异的性能。然而，这些模型需要大量的计算资源和存储空间，并且其日益增长的复杂性限制了我们对其决策方式的理解。这些架构中的大多数都依赖于基于Transformer设计中的注意力机制。基于残差神经网络与常微分方程（ODE）之间的联系，我们引入了ODE-ViT，这是一种将Vision Transformer重新表述为ODE系统的模型，该系统满足适定且稳定动力学的条件。在CIFAR-10和CIFAR-100上的实验表明，ODE-ViT实现了稳定、可解释且具有竞争力的性能，参数量最多减少了一个数量级，在分类任务中超越了之前的基于ODE的Transformer方法。我们进一步提出了一种即插即用的师生框架，其中离散的ViT通过将教师模型的中间表示视为ODE的解来指导ODE-ViT的连续轨迹。与从头开始训练一个独立的ODE-ViT相比，这种策略将性能提高了10%以上。|
|**2025-11-20**|[Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](http://arxiv.org/abs/2511.16467)|null|我们采用一套新颖的电路发现和分析技术，研究了基于Transformer的语言模型中习语表达的处理。首先，通过改进的路径修补算法发现电路，我们发现习语处理表现出独特的计算模式。我们识别并研究了“习语注意力头”（即在不同习语中频繁激活的注意力头），以及由于早期处理而在习语词元之间增强的注意力，我们将其称为“增强接收”。我们分析了这些现象以及所发现电路的通用特征，将其作为Transformer平衡计算效率和鲁棒性的机制。最后，这些发现为Transformer如何处理非组合性语言提供了见解，并为理解更复杂语法结构的处理提供了途径。|
|**2025-11-20**|[LiSTAR: Ray-Centric World Models for 4D LiDAR Sequences in Autonomous Driving](http://arxiv.org/abs/2511.16049)|**[link](https://github.com/ocean-luna/LiSTAR)**|合成高保真和可控的4D激光雷达数据对于创建可扩展的自动驾驶仿真环境至关重要。这项任务本质上具有挑战性，原因在于传感器独特的球形几何结构、点云的时间稀疏性以及动态场景的复杂性。为了解决这些挑战，我们提出了LiSTAR，这是一种直接在传感器原生几何结构上操作的新颖生成式世界模型。LiSTAR引入了混合圆柱-球形（HCS）表示，通过减轻笛卡尔网格中常见的量化伪影来保持数据保真度。为了从稀疏的时间数据中捕捉复杂的动态，它利用了带有以射线为中心Transformer的时空注意力机制（START），该机制明确建模了沿着单个传感器射线的特征演变，以实现鲁棒的时间连贯性。此外，为了可控合成，我们提出了一种新颖的4D点云对齐体素布局用于条件生成，以及相应的离散掩码生成式START（MaskSTART）框架，该框架学习场景的紧凑、标记化表示，从而实现高效、高分辨率和布局引导的组合式生成。全面实验验证了LiSTAR在4D激光雷达重建、预测和条件生成方面的最先进性能，取得了显著的量化提升：将生成MMD大幅降低76%，将重建IoU提升32%，并将预测L1中位数降低50%。这种性能水平为创建真实可控的自动驾驶系统仿真提供了强大的新基础。项目链接：https://ocean-luna.github.io/LiSTAR.gitub.io。|
|**2025-11-20**|[AMS-KV: Adaptive KV Caching in Multi-Scale Visual Autoregressive Transformers](http://arxiv.org/abs/2511.16047)|null|视觉自回归建模 (VAR) 通过下一尺度预测已成为一种可扩展的图像生成范式。尽管大语言模型 (LLM) 中的键值 (KV) 缓存已被广泛研究，但下一尺度预测带来了独特的挑战，并且基于下一尺度的VAR Transformer模型的KV缓存设计在很大程度上仍未被探索。一个主要瓶颈是随着尺度数量的增加，KV内存过度增长，严重限制了可扩展性。我们的系统性研究揭示了：(1) 关注局部尺度中的token显著有助于提升生成质量；(2) 为最粗尺度（称为凝聚尺度）分配少量内存可以稳定多尺度图像生成；(3) 在缓存效率高的层中主要观察到更细尺度间的强KV相似性，而缓存需求大的层则表现出较弱的层级间相似性。基于这些观察，我们引入了AMS-KV，这是一种用于VAR模型中下一尺度预测的尺度自适应KV缓存策略。AMS-KV优先存储来自凝聚尺度和局部尺度的KV，保留最相关的token以维持生成质量。它通过层级间相似性分析识别缓存需求大的层，从而进一步优化KV缓存利用率和计算效率。与传统的基于下一尺度预测的VAR模型相比，AMS-KV将KV缓存使用量减少高达84.83%，并将自注意力延迟降低了60.48%。此外，当基线VAR-d30模型在批处理大小为128时遇到内存不足错误，AMS-KV能够稳定扩展到批处理大小256，并提升了吞吐量。|
|**2025-11-19**|[Breaking the Bottleneck with DiffuApriel: High-Throughput Diffusion LMs with Mamba Backbone](http://arxiv.org/abs/2511.15927)|null|基于扩散的语言模型最近已成为自回归生成的一种有前景的替代方案，然而，它们对Transformer骨干网络的依赖由于二次注意力和KV缓存开销而限制了推理效率。在这项工作中，我们引入了DiffuApriel，这是一种基于双向Mamba骨干网络的掩码扩散语言模型，它将扩散目标与线性时间序列建模相结合。DiffuApriel与基于Transformer的扩散模型性能相当，同时使用1.3B模型对于长序列实现了高达4.4倍的推理吞吐量提升。我们进一步提出了DiffuApriel-H，这是一种混合变体，它交错注意力层和Mamba层，通过平衡的全局和局部上下文建模提供了高达2.6倍的吞吐量提升。我们的结果表明，双向状态空间架构在掩码扩散语言模型中可作为强大的去噪器，为更快、内存高效的文本生成提供了一个实用且可扩展的基础。|
|**2025-11-19**|[Disagreement is Disappearing on U.S. Cable Debate Shows](http://arxiv.org/abs/2511.15774)|null|黄金时段有线新闻节目是美国媒体格局中极具影响力的一部分，收视率最高的评论节目每晚吸引数百万关注政治的观众。在政治两极分化日益加剧的时代，一个关键问题是这些广受关注的“辩论”节目是促进了真诚的讨论，还是已经演变为加深社会分歧的党派回音室。尽管这些节目声称播报相互竞争的观点，却缺乏大规模证据来量化主持人与嘉宾实际意见相左的频率。衡量这些交流是一个重大挑战，因为直播节目中存在说话者重叠、讽刺以及数十亿字的文本。为弥补这一空白，我们构建了首个涵盖美国有线电视评论节目的说话者区分的意见一致与分歧图谱。我们的研究汇集了2010年至2024年间福克斯新闻、MSNBC和CNN的24个旗舰节目中超过21,000集节目，将其分割成主持人与嘉宾的发言回合，并使用高精度大型语言模型分类器标注了213万个回合对。我们提出了三项发现：(1)黄金时段节目中意见分歧/辩论的比例呈现持续下降趋势，在2017年至2024年间下降了约三分之一；(2)节目中的挑战具有党派性和不对称性——保守派在福克斯新闻上很少受到反驳，自由派在MSNBC上也很少受到反驳，而CNN则趋向中点下降；(3)堕胎、枪支权利和移民等两极分化议题吸引的意见分歧最少。这项工作贡献了一个公共语料库、一个开源的立场分析流程，以及首个纵向证据，表明电视“辩论”正在偏离真诚的讨论。通过转变为党派肯定的平台，这些节目侵蚀了多元社会必不可少的跨领域分歧，从而加剧了情感两极分化。|
|**2025-11-19**|[A time for monsters: Organizational knowing after LLMs](http://arxiv.org/abs/2511.15762)|null|大语言模型（LLMs）通过动摇表征视角和基于实践的视角的认识论基础，正在重塑组织认知。我们将LLMs概念化为哈拉维式怪物，即那些既能颠覆既定范畴又能为探究开辟新可能性的混合型跨界实体。论文聚焦于作为知识根本驱动力的类比，审视LLMs如何通过大规模统计推断生成关联。通过分析LLMs在表面/深层类比和近域/远域维度上的运作，我们强调了它们扩展组织认知的能力以及它们所引入的认识论风险。基于此，我们识别出与此类认识论怪物共存的三个挑战：探究方式的转变、对对话式审查日益增长的需求以及主体性的重新分配。通过突出与LLMs共知的纠缠动态，本文将组织理论扩展到超越以人类为中心的认识论范畴，并呼吁在智能技术时代重新关注知识如何被创造、验证和付诸行动。|
|**2025-11-19**|[MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation](http://arxiv.org/abs/2511.15603)|null|医学图像分割通常采用逐点卷积分割头来预测密集标签，其中每个输出通道启发式地与特定类别绑定。这种僵硬的设计限制了特征共享和语义泛化能力。在这项工作中，我们提出了一种统一的解耦分割头，它使用共享的对象查询将多类别预测分离为类别无关的掩码预测和类别标签预测。此外，我们引入了一个全尺度感知可变形Transformer模块，它使得低分辨率编码器特征能够通过可变形注意力关注全分辨率编码器特征，从而实现内存高效和空间对齐的全尺度融合。我们提出的方法，命名为MaskMed，取得了最先进的性能，在AMOS 2022数据集上Dice系数超过nnUNet 2.0%，在BTCV数据集上Dice系数超过6.9%。|
|**2025-11-19**|[RS-CA-HSICT: A Residual and Spatial Channel Augmented CNN Transformer Framework for Monkeypox Detection](http://arxiv.org/abs/2511.15476)|null|本文提出了一种混合深度学习方法，即基于残差和空间学习的通道增强型集成CNN-Transformer架构（RS-CA-HSICT），该方法融合了CNN和Transformer的优势，以实现增强型猴痘检测。所提出的RS-CA-HSICT框架由一个HSICT模块、一个残差CNN模块、一个空间CNN块和一个通道增强（CA）模块组成，旨在增强多样化的特征空间、详细的病变信息和长距离依赖。新的HSICT模块首先集成了骨干CNN的抽象表示和定制化的ICT模块，以实现高效的多头注意力和具有同质（H）和结构（S）操作的结构化CNN层。定制化的ICT模块学习全局上下文交互和局部纹理提取。此外，H和S层通过减少噪声和建模复杂的形态学变化来学习空间同质性和精细结构细节。此外，逆残差学习缓解了梯度消失问题，阶段性分辨率降低确保了尺度不变性。此外，RS-CA-HSICT框架利用TL驱动的残差和空间CNN特征图来增强学习到的HSICT通道，从而获得增强的多尺度特征空间，能够捕获全局和局部结构线索、细微纹理和对比度变化。这些通道在增强之前，通过通道融合与注意力模块进行细化，该模块保留了判别性通道并抑制了冗余通道，从而实现了高效计算。最后，空间注意力机制优化了像素选择，以检测猴痘中细微模式和类内对比度变化。在Kaggle基准数据集和多样化猴痘数据集上的实验结果显示，分类准确率高达98.30%，F1分数达到98.13%，优于现有CNN和ViT模型。|
|**2025-11-18**|[FreeSwim: Revisiting Sliding-Window Attention Mechanisms for Training-Free Ultra-High-Resolution Video Generation](http://arxiv.org/abs/2511.14712)|**[link](https://github.com/WillWu111/FreeSwim)**|现代基于Transformer的视频生成器中注意力机制的二次时间复杂度和内存复杂度使得超高分辨率视频的端到端训练成本高昂。受此限制的启发，我们引入了一种免训练方法，该方法利用在其原始尺度上预训练的视频扩散Transformer来合成更高分辨率的视频，而无需任何额外的训练或调整。我们方法的核心是一种向内滑动窗口注意力机制，它源于一个关键观察：保持每个查询标记的训练尺度感受野对于保留视觉保真度和细节至关重要。然而，朴素的局部窗口注意力不幸地经常导致重复内容，并在生成结果中表现出缺乏全局连贯性。为了克服这一挑战，我们设计了一个双路径管道，通过一种新颖的交叉注意力覆盖策略来支持窗口注意力，使局部注意力产生的语义内容能够被另一个具有完整感受野的分支引导，从而确保整体一致性。此外，为了提高效率，我们为该分支引入了交叉注意力缓存策略，以避免频繁计算完整的3D注意力。大量实验表明，我们的方法以免训练范式生成具有细粒度视觉细节的超高分辨率视频，并具有高效率。同时，即使与基于训练的替代方案相比，它在VBenc上也实现了卓越的性能，并具有竞争力或更高的效率。代码可在以下网址获取：https://github.com/WillWu111/FreeSwim|
|**2025-11-18**|[Near-Lossless Model Compression Enables Longer Context Inference in DNA Large Language Models](http://arxiv.org/abs/2511.14694)|**[link](https://github.com/huthvincent/DNA-Large-Language-Models-Compression)**|在 F O C U S ( F e a t u r e - O r i e n t e d C o m p r e s s i o n f o r U l t r a - l o n g S e l f - a t t e n t i o n ) ) ，这是一个可以插入到预训练 D N A L L M 中的渐进式上下文压缩模块。 F O C U S 将基因组学中已有的 k - m e r 表示与可学习的分层压缩相结合：它以 k - m e r 粒度插入摘要令牌，并逐步压缩跨多个 T r a n s f o r m e r 层的注意力键和值激活，只保留跨窗口的摘要 K V 状态，同时丢弃普通令牌的 K V 。共享边界的窗口方案产生一个固定的跨窗口接口，以最小损失传播长程信息。我们在一个基于 E v o - 2 的 D N A L L M 上验证了 F O C U S ，该 L L M 在 G R C h 3 8 1 号染色体上进行了微调，采用自监督训练和随机压缩策略，以提高在不同压缩比下的鲁棒性。在保留的人类染色体上， F O C U S 实现了近乎无损的保真度：将 1 k b 上下文压缩成仅 1 0 个摘要令牌（约 1 0 0 倍）仅使平均每核苷酸概率偏移约 0 . 0 0 0 4 。与未压缩的基线相比， F O C U S 减少了 K V 缓存内存，并将有效推理扩展从 O ( N ^ 2 ) 转换为接近线性的 O ( N ) ，从而在商用 G P U 上实现约 1 0 0 倍长的推理窗口，同时保持近乎无损的保真度。|
|**2025-11-18**|[Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer](http://arxiv.org/abs/2511.14691)|null|注意力是大脑选择性地关注特定方面而忽略不相关方面的能力，这一生物学原理启发了现代Transformer模型中的注意力机制。Transformer模型如今支撑着诸如GPT之类的大语言模型，但其代价是巨大的训练和推理能耗，导致了巨大的碳足迹。大脑注意力源于神经回路，而Transformer注意力则依赖于点积相似性来对输入序列中的元素进行加权。神经拟态计算，尤其是脉冲神经网络（SNN），提供了一条受大脑启发实现节能智能的路径。尽管近期在基于注意力的脉冲Transformer方面有所研究，但其核心注意力层仍是非神经拟态的。当前的脉冲注意力机制(i)依赖于适用于浮点运算而非事件驱动脉冲的点积或逐元素相似性；(ii)保留了受冯·诺依曼瓶颈限制的注意力矩阵，从而限制了内存计算；并且(iii)仍然偏离了类脑计算。为了解决这些问题，我们提出了脉冲STDP Transformer（S $^{2}$TDPT），这是一种神经拟态Transformer，它通过脉冲时间依赖可塑性（STDP）实现自注意力，将查询-键关联嵌入到突触权重中。STDP是大脑中记忆和学习的核心机制，并在神经拟态设备中得到广泛研究，它自然地实现了内存计算并支持非冯·诺依曼硬件。在CIFAR-10和CIFAR-100数据集上，我们的模型仅用四个时间步便达到了94.35%和78.08%的准确率，在CIFAR-100上能耗为0.49毫焦，相较于标准ANN Transformer降低了88.47%的能耗。Grad-CAM结果表明，模型关注语义相关区域，增强了可解释性。总而言之，S$^{2}$ TDPT展示了生物启发式注意力如何能够产生节能、硬件友好且可解释的神经拟态模型。|
|**2025-11-18**|[M-CALLM: Multi-level Context Aware LLM Framework for Group Interaction Prediction](http://arxiv.org/abs/2511.14661)|null|本文探讨了大型语言模型如何利用多级上下文信息来预测协作式混合现实环境中的群体协作模式。我们证明，将个体行为档案、群体结构属性和时间动态编码为自然语言，能够使大型语言模型突破统计模型的性能上限。我们构建了M-CALLM，一个将多模态传感器流转换为用于基于大型语言模型的预测的分层上下文的框架，并在干预模式（实时预测）和模拟模式（自回归预测）下，评估了三种范式（零样本提示、少样本学习和有监督微调）与统计基线的对比。对16个群组（64名参与者，约25小时）的直接比较表明，上下文感知的LLM在对话预测方面达到了96%的准确率，比LSTM基线提高了3.2倍，同时保持了低于35毫秒的延迟。然而，模拟模式显示出脆弱性，由于级联错误导致83%的性能下降。深入分析模态特定性能表明，对话依赖于时间模式，接近度受益于群体结构（+6%），而共享注意力则完全失败（0%召回率），揭示了架构局限性。我们希望这项工作能够激发新思路，用于构建能够在语义推理能力和基本约束之间取得平衡的智能协作感知系统。|
|**2025-11-18**|[IMSE: Efficient U-Net-based Speech Enhancement using Inception Depthwise Convolution and Amplitude-Aware Linear Attention](http://arxiv.org/abs/2511.14515)|null|在资源受限设备上，实现轻量化设计与高性能之间的平衡仍然是语音增强（SE）任务面临的重大挑战。现有最先进的方法，例如MUSE，通过引入多路径增强泰勒（MET）变换器和可变形嵌入（DE），仅用0.51M参数便建立了强大的基线。然而，深入分析表明MUSE仍然存在效率瓶颈：MET模块依赖复杂的“近似-补偿”机制来缓解基于泰勒展开的注意力存在的局限性，而可变形嵌入的偏移量计算则引入了额外的计算负担。本文提出了IMSE，一个系统优化且超轻量级的网络。我们引入了两项核心创新：1）用幅度感知线性注意力（MALA）取代MET模块。MALA通过在注意力计算中明确保留查询向量的范数信息，从根本上纠正了线性注意力中的“忽略幅度”问题，无需辅助补偿分支即可实现高效的全局建模。2）用Inception深度卷积（IDConv）取代DE模块。IDConv借鉴了Inception概念，将大核操作分解为高效的并行分支（方形、水平和垂直条带），从而以极低的参数冗余捕获语谱图特征。在VoiceBank+DEMAND数据集上进行的大量实验表明，与MUSE基线相比，IMSE显著减少了16.8%的参数数量（从0.513M降至0.427M），同时在PESQ指标（3.373）上实现了与最先进水平媲美的具有竞争力的性能。这项研究为超轻量级语音增强中模型尺寸与语音质量之间的权衡设立了新的基准。|
|**2025-11-18**|[Parameter Aware Mamba Model for Multi-task Dense Prediction](http://arxiv.org/abs/2511.14503)|null|理解任务间的相互关系和交互对于多任务密集预测至关重要。现有方法主要利用卷积层和注意力机制来探索任务级别的交互。在这项工作中，我们提出了一种新颖的基于解码器的框架——参数感知Mamba模型（PAMM），专门为多任务学习设置中的密集预测而设计。不同于采用Transformer来建模整体任务关系的方法，PAMM利用状态空间模型丰富且可扩展的参数来增强任务互联性。它具有双状态空间参数专家，用于集成并设置任务特定的参数先验，从而捕获每个任务的内在属性。这种方法不仅促进了精确的多任务交互，而且通过结构化状态空间序列模型（S4）实现了任务先验的全局集成。此外，我们采用多方向希尔伯特扫描方法来构建多角度特征序列，从而增强了序列模型对二维数据的感知能力。在NYUD-v2和PASCAL-Context基准数据集上进行的大量实验证明了我们所提出方法的有效性。我们的代码可在https://github.com/CQC-gogopro/PAMM获取。|
|**2025-11-18**|[nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers](http://arxiv.org/abs/2511.14465)|null|机械可解释性研究需要可靠的工具来分析跨多样化架构的Transformer内部机制。当前方法面临一个根本性权衡：像TransformerLens这样的自定义实现确保了接口一致性，但需要为每种架构手动编码适配，这引入了与原始模型的数值不匹配；而通过NNsight直接访问HuggingFace则保留了精确行为，但缺乏跨模型的标准化。为弥合这一差距，我们开发了nnterp，一个基于NNsight的轻量级封装，它为Transformer分析提供统一接口，同时保留原始HuggingFace实现。通过自动化模块重命名和全面的验证测试，nnterp使研究人员能够一次编写干预代码，并将其部署到涵盖16个架构家族的50多种模型变体上。该库包含常见可解释性方法（如logit透镜、patchscope、激活引导）的内置实现，并为支持此功能的模型提供对注意力概率的直接访问。通过将验证测试与库一起打包，研究人员可以在本地验证与自定义模型的兼容性。nnterp弥合了机械可解释性工具在正确性和可用性之间的差距。|
|**2025-11-18**|[Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning](http://arxiv.org/abs/2511.14427)|null|有效的接触密集型操作要求机器人协同利用视觉、力觉和本体感受。然而，强化学习智能体在此类多传感器环境中难以学习，尤其是在传感器噪声和动态变化中。我们提出了多传感器动态预训练（MSDP），这是一种新颖的框架，用于学习专为面向任务的策略学习量身定制的富有表现力的多传感器表示。MSDP 基于掩码自编码，通过仅从传感器嵌入的子集重建多传感器观测来训练一个基于 Transformer 的编码器，从而实现跨模态预测和传感器融合。对于下游策略学习，我们引入了一种新颖的非对称架构，其中交叉注意力机制允许评论家从冻结的嵌入中提取动态的、任务特定的特征，而行动者则接收一个稳定的池化表示来指导其行动。我们的方法展示了在各种扰动（包括传感器噪声和物体动力学变化）下的加速学习和鲁棒性能。在模拟和真实世界中多个具有挑战性的接触密集型机器人操作任务中的评估展示了 MSDP 的有效性。我们的方法对扰动表现出强大的鲁棒性，并在真实机器人上仅需 6,000 次在线交互就实现了高成功率，为复杂的多传感器机器人控制提供了一个简单而强大的解决方案。|
|**2025-11-18**|[Attention Via Convolutional Nearest Neighbors](http://arxiv.org/abs/2511.14137)|null|卷积神经网络向Transformer的转变重塑了计算机视觉，然而这两种架构家族通常被视为根本上不同的。我们认为，卷积和自注意力，尽管表面上存在差异，但可以在单一的k近邻聚合框架内实现统一。关键的见解是，这两种操作都是邻居选择和聚合的特例；卷积通过空间邻近性选择邻居，而注意力通过特征相似性选择邻居，这表明它们存在于一个连续的谱系上。我们引入了卷积近邻 (ConvNN)，这是一个形式化了这种联系的统一框架。关键的是，ConvNN可以作为卷积层和注意力层的即插即用替代品，从而能够系统地探索这两个极端之间的中间谱系。我们在CIFAR-10和CIFAR-100分类任务上，通过两种互补架构验证了该框架的一致性：(1) VGG中的混合分支通过结合空间邻近性和特征相似性选择，提高了在两个CIFAR数据集上的准确性；(2) ViT中的ConvNN在两个数据集上均优于标准注意力和其他注意力变体。对k值和架构变体进行的大量消融实验表明，沿此谱系进行插值通过平衡局部和全局感受野提供了正则化益处。我们的工作提供了一个统一框架，消除了卷积和注意力之间表面上的区别，对设计更具原则性和可解释性的视觉架构具有启示意义。|
|**2025-11-18**|[GCA-ResUNet:Image segmentation in medical images using grouped coordinate attention](http://arxiv.org/abs/2511.14087)|null|医学图像分割通过支持临床诊断、术前规划和疾病监测，为计算机辅助诊断和治疗奠定基础。虽然U-Net风格的卷积神经网络因其带有跳跃连接的编码器-解码器结构而表现良好，但它们在捕获长距离依赖方面存在困难。基于Transformer的变体能够处理全局上下文，但通常需要大量的计算和大型训练数据集。本文提出了GCA-ResUNet，这是一种将分组坐标注意力（GCA）集成到ResNet-50残差块中的高效分割网络。GCA利用分组坐标建模共同编码跨通道和空间位置的全局依赖，从而强化特征表示和边界描绘，同时与自注意力相比，仅增加极小的参数和FLOP开销。在Synapse数据集上，GCA-ResUNet的Dice分数达到86.11%；在ACDC数据集上，其Dice分数达到92.64%，超越了多个最先进的基线，同时保持了快速推理和有利的计算效率。这些结果表明GCA提供了一种实用的方法，能够增强卷积架构的全局建模能力，从而实现高精度和资源高效的医学图像分割。|
|**2025-11-14**|[Multistability of Self-Attention Dynamics in Transformers](http://arxiv.org/abs/2511.11553)|null|在机器学习中，自注意力动力学是Transformer注意力机制的一种连续时间多智能体类模型。在本文中，我们展示了这种动力学与Oja流的多智能体版本相关，Oja流是一种计算矩阵主特征向量的动力系统，该矩阵对应于Transformer中的值矩阵。我们将“单头”自注意力系统的平衡点分为四类：共识、二分共识、聚类和多边形平衡点。前三类中的多个渐近稳定平衡点经常在自注意力动力学中并存。有趣的是，前两类中的平衡点总是与值矩阵的特征向量对齐，通常但不限于与主特征向量对齐。|
|**2025-11-14**|[Parameter-Efficient MoE LoRA for Few-Shot Multi-Style Editing](http://arxiv.org/abs/2511.11236)|null|近年来，图像编辑受到越来越多的关注。然而，通用图像编辑模型在面对新风格时，往往难以产生令人满意的结果。挑战在于如何仅使用有限的成对数据，有效地将通用图像编辑模型微调到新风格。为解决此问题，本文提出了一种新颖的小样本风格编辑框架。针对此任务，我们构建了一个包含五种不同风格的基准数据集。相应地，我们提出了一种参数高效的多风格专家混合低秩适应 (MoE LoRA)，其包含风格特定和风格共享路由机制，用于联合微调多种风格。风格特定路由确保不同风格之间互不干扰，而风格共享路由则自适应地分配共享的 MoE LoRA 以学习共同模式。我们的 MoE LoRA 通过一种新颖的度量指导方法，估计每个单秩组件的重要性分数，从而自动确定每一层的最佳秩。此外，我们探索了在 Transformer 中的扩散模型 (DiT) 中插入 LoRA 的最佳位置，并结合了对抗学习和流匹配来指导扩散训练过程。实验结果表明，我们提出的方法在显著减少 LoRA 参数的同时，优于现有最先进的方法。|
|**2025-11-14**|[Viper-F1: Fast and Fine-Grained Multimodal Understanding with Cross-Modal State-Space Modulation](http://arxiv.org/abs/2511.11177)|null|多模态大语言模型（MLLM）的最新进展在视觉-语言理解方面取得了显著进步，但其高计算成本限制了在机器人操作、个人助理和智能摄像头等资源受限场景中的部署。大多数现有方法依赖于基于Transformer的交叉注意力，其二次复杂度阻碍了效率。此外，小型视觉-语言模型往往难以精确捕获细粒度、任务相关的视觉区域，导致在细粒度推理任务上的性能下降，从而限制了它们在现实世界中的有效性。为了解决这些问题，我们引入了Viper-F1，一种混合状态空间视觉-语言模型，它用高效的液体状态空间动力学替代了注意力机制。为了进一步增强视觉基础，我们提出了一种令牌-网格相关模块，该模块计算文本令牌和图像块之间的轻量级相关性，并通过FiLM条件作用来调节状态空间动力学。这使得模型能够选择性地强调与文本提示相关的视觉区域，同时保持线性时间推理。在多个基准测试中的实验结果表明，Viper-F1实现了准确、细粒度的理解，并显著提高了效率。|
|**2025-11-14**|[LiteAttention: A Temporal Sparse Attention for Diffusion Transformers](http://arxiv.org/abs/2511.11062)|null|扩散Transformer，特别是用于视频生成时，能够实现卓越的质量，但其二次注意力复杂度导致了巨大的延迟。现有加速方法面临一个根本性权衡：在每个去噪步骤中动态估计稀疏注意力模式会带来高计算开销和估计误差，而静态稀疏模式在整个去噪过程中保持固定且往往次优。我们发现扩散注意力一个关键的结构特性，即其稀疏模式在去噪步骤之间表现出强大的时间连贯性。在步骤 $t$被认为不重要的块通常在步骤$t+δ$ 仍然不重要。利用这一观察结果，我们引入了LiteAttention，一种利用时间连贯性在去噪序列中实现演进式计算跳过的方法。通过尽早标记非必要块并向前传播跳过决策，LiteAttention消除了冗余注意力计算，无需重复分析开销，结合了动态方法的适应性与静态方法的效率。我们在FlashAttention之上实现了一个高度优化的LiteAttention核，并在生产级视频扩散模型上展示了显著的加速，同时质量没有下降。代码和实现细节将公开发布。|
|**2025-11-13**|[From Attention to Frequency: Integration of Vision Transformer and FFT-ReLU for Enhanced Image Deblurring](http://arxiv.org/abs/2511.10806)|null|图像去模糊在计算机视觉中至关重要，旨在从运动模糊或相机抖动引起的模糊图像中恢复清晰图像。尽管卷积神经网络（CNN）和视觉Transformer（ViT）等深度学习方法已推动该领域发展，但它们通常难以处理复杂或高分辨率的模糊以及巨大的计算需求。我们提出了一种新的双域架构，该架构将视觉Transformer与频域FFT-ReLU模块相结合，明确地连接了空间注意力建模和频率稀疏性。在这种结构中，ViT骨干网络捕捉局部和全局依赖，而FFT-ReLU组件强制执行频域稀疏性，以抑制模糊相关伪影并保留精细细节。在基准数据集上的大量实验表明，与最先进的模型相比，该架构在PSNR、SSIM和感知质量方面均表现优越。定量指标、定性比较和人类偏好评估都证实了其有效性，为实际图像恢复建立了一个实用且可推广的范式。|
|**2025-11-13**|[GFT: Graph Feature Tuning for Efficient Point Cloud Analysis](http://arxiv.org/abs/2511.10799)|**[link](https://github.com/manishdhakal/GFT)**|参数高效微调（PEFT）通过仅更新模型参数的一小部分，显著降低了计算和内存成本，从而使模型能够更快地适应新任务，且性能损失最小。先前的研究已经提出了专为点云数据设计的PEFT方法，因为通用方法表现次优。为了进一步减少可训练参数的数量，我们提出了一种点云专用的PEFT，命名为图特征微调（GFT），它使用轻量级图卷积网络从Transformer的初始分词输入中学习一个动态图，并通过跳跃连接和高效的交叉注意力模块将这些图特征传递到更深层。在目标分类和分割任务上的大量实验表明，GFT在相同领域内运行，性能媲美现有方法，同时减少了可训练参数。代码位于https://github.com/manishdhakal/GFT。|
|**2025-11-13**|[Rethinking Visual Information Processing in Multimodal LLMs](http://arxiv.org/abs/2511.10301)|null|尽管LLaVA架构在视觉-语言任务中取得了显著成功，但由于文本和视觉模态之间固有的不匹配，其设计天生难以有效整合视觉特征。我们从一个新颖的视角来解决这个问题，即大型语言模型（LLM）不仅充当语言模型，而且充当强大的视觉编码器。为此，我们提出了LLaViT——将大型语言模型扩展为视觉Transformer——它通过三个关键修改使LLM能够同时作为视觉编码器发挥作用：(1) 为视觉模态学习独立的QKV投影，(2) 在视觉token上启用双向注意力，以及(3) 整合全局和局部视觉表示。通过在各种LLM上进行广泛的受控实验，我们证明LLaViT在众多基准上显著优于基线LLaVA方法，甚至超越参数量是其两倍的模型，从而建立了一种更有效的视觉-语言建模方法。|
|**2025-11-13**|[Fractional neural attention for efficient multiscale sequence processing](http://arxiv.org/abs/2511.10208)|null|注意力机制是Transformer模型计算能力的基础，这些模型已在不同领域取得了显著成功。然而，理解和拓展自注意力背后的原理仍然是推动人工智能发展的一个关键挑战。我们从生物注意力的多尺度动力学和动力系统理论中汲取灵感，引入了分数神经注意力（FNA），这是一个基于原理、受神经科学启发的用于多尺度信息处理的框架。FNA通过由分数拉普拉斯算子控制的Lévy扩散来建模token间的交互，内在实现了跨多个尺度的短程和长程依赖。这种机制带来了更强的表达能力和更快的信息混合，提升了Transformer的基础能力。理论上，我们证明FNA的动力学由分数扩散方程控制，并且由此产生的注意力网络表现出更大的谱隙和更短的路径长度——这是计算效率增强的机制性标志。经验上，FNA即使在单层和单头配置下也能实现有竞争力的文本分类性能；它还在图像处理和神经机器翻译中提升了性能。最后，来自几何谐波的扩散映射算法能够对FNA权重进行降维，同时保留嵌入和隐藏状态的内在结构。综上，这些结果将FNA确立为连接自注意力、随机动力学和几何的基于原理的机制，为强大且受神经科学启发的AI提供了可解释、具有生物学基础的基石。|
|**2025-11-13**|[VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction](http://arxiv.org/abs/2511.10203)|null|多智能体轨迹预测对于在密集、交互式环境中运行的自主系统至关重要。现有方法往往未能同时捕捉智能体的长期目标及其细粒度社交互动，这导致多智能体未来轨迹不切实际。我们提出了VISTA，一种用于多智能体轨迹预测的递归式目标条件Transformer。VISTA结合了(i)一个交叉注意力融合模块，将长期意图与过去运动融合；(ii)一个社交令牌注意力机制，用于灵活建模智能体间的互动；以及(iii)成对注意力图，在推理时使社交影响力模式可解释。我们的模型将单智能体目标条件预测转化为一个连贯的多智能体预测框架。除了标准位移指标之外，我们评估了轨迹碰撞率作为衡量联合真实性的一种方法。在高密度MADRAS基准测试和SDD上，VISTA取得了最先进的精度并显著减少了碰撞。在MADRAS上，它将强基线的平均碰撞率从2.14%降低到0.03%；而在SDD上，它实现了零碰撞，同时改善了ADE、FDE和minFDE。这些结果表明VISTA生成了符合社交规范、目标感知且可解释的轨迹，使其在安全关键型自主系统中具有广阔的应用前景。|
|**2025-11-14**|[FreDFT: Frequency Domain Fusion Transformer for Visible-Infrared Object Detection](http://arxiv.org/abs/2511.10046)|null|可见光-红外目标检测因其在低光照、雾天和雨天条件下的检测性能而获得了足够的关注。然而，由不同传感器捕获的可见光和红外模态在复杂场景中存在信息不平衡问题，这可能导致跨模态融合不足，从而降低检测性能。此外，大多数现有方法在空间域中使用Transformer来捕获互补特征，而忽略了开发频域Transformer来挖掘互补信息的优势。为了解决这些不足，我们提出了一种用于可见光-红外目标检测的频域融合Transformer，称为FreDFT。所提出的方法采用了一种新颖的多模态频域注意力（MFDA）来挖掘模态间的互补信息，并通过混合尺度频域特征融合策略设计了一个频域前馈层（FDFFL），以更好地增强多模态特征。为了消除多模态信息的不平衡，我们构建了一个跨模态全局建模模块（CGMM），以空间和通道方式执行像素级模态间特征交互。此外，我们开发了一个局部特征增强模块（LFEM），通过使用各种卷积层和应用通道混洗来增强多模态局部特征表示并促进多模态特征融合。大量的实验结果验证了我们提出的FreDFT在多个公共数据集上与现有最先进方法相比取得了出色的性能。我们FreDFT的代码链接为https://github.com/WenCongWu/FreDFT。|
|**2025-11-07**|[GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation](http://arxiv.org/abs/2511.05477)|**[link](https://github.com/liguojie09/GroupKAN)**|医学图像分割需要准确、轻量级且可解释的模型。卷积架构缺乏自适应非线性和透明的决策制定，而Transformer架构受限于二次复杂度和不透明的注意力机制。U-KAN利用柯尔莫哥洛夫-阿诺德网络解决了这些挑战，实现了比卷积和基于注意力的方法更高的准确性，比Transformer变体更少的参数，以及比传统方法更好的可解释性。然而，其由于全通道变换导致的O(C^2)复杂度限制了其随通道数量增加时的可扩展性。为了克服这一点，我们引入了GroupKAN，一个轻量级分割网络，它结合了两个新颖的结构化功能模块：(1) 分组KAN变换，将通道分成G组进行多元样条映射，将复杂度降低到O(C^2/G)，以及(2) 分组KAN激活，在每个通道组内应用共享的基于样条的映射，以实现高效的、逐token的非线性。在三个医学基准数据集（BUSI、GlaS和CVC）上进行评估，GroupKAN的平均IoU达到79.80%，比U-KAN高出1.11%，同时仅需要47.6%的参数（3.02M对比6.35M），并显示出改进的可解释性。|
|**2025-11-07**|[An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones](http://arxiv.org/abs/2511.05265)|null|最后一英里物流中卡车-无人机协同系统的出现，使带无人机的旅行商问题（TSP-D）成为经典路径优化的关键延伸；尽管同步车辆协调有望显著提升运营效率并减少环境影响，但它引入了超出传统优化范式范围的NP-难组合复杂性。深度强化学习提供了一个理论基础框架，通过自监督策略学习和自适应决策来应对TSP-D固有的挑战。本研究提出了一种分层Actor-Critic深度强化学习框架来解决TSP-D问题。该架构由两个主要组成部分构成：一个Transformer启发式编码器和一个高效的最小门控单元解码器。编码器结合了一种新颖的、优化的k近邻稀疏注意力机制，专门用于关注相关的空间关系，并通过集成全局节点特征得到进一步增强。最小门控单元解码器处理这些编码表示，以高效生成解决方案序列。整个框架在一个异步优势Actor-Critic范式下运行。实验结果表明，在各种规模（N=10到100）的基准TSP-D实例上，与高性能启发式算法和现有强化学习方法相比，所提出的模型能够在更短的平均计算时间内获得具有竞争力甚至更优的解决方案。此外，与先进的强化学习算法基准相比，所提出的框架显著减少了所需的总训练时间，同时实现了卓越的最终性能，凸显了其在训练效率方面的显著优势。|
|**2025-11-05**|[Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility Environments](http://arxiv.org/abs/2511.03632)|null|波束成形对于提高多天线无线系统中的频谱效率和减轻干扰具有重要意义，有助于在密集和高移动性场景中实现空间复用和分集。传统的波束成形技术，如迫零波束成形（ZFBF）和最小均方误差（MMSE）波束成形，在恶劣信道条件下会遇到性能下降的问题。基于深度学习的波束成形通过从信道状态信息（CSI）到波束成形权重的非线性映射，提高了对动态信道环境的鲁棒性，从而提供了一种替代方案。基于Transformer的模型因其能够建模跨时间和频率的长距离依赖而特别有效。然而，其二次注意力复杂度限制了其在大型OFDM网格中的可扩展性。最近的研究通过稀疏注意力机制解决了这个问题，这些机制在降低复杂度的同时保持了表达能力，但通常采用忽略信道动态的模式，因为它们并非专门为无线通信场景设计。在这项工作中，我们提出了一种多普勒感知稀疏神经网络波束成形（Doppler-aware Sparse NNBF）模型，该模型在多用户单输入多输出（MU-SIMO）设置中结合了信道自适应稀疏注意力机制。所提出的稀疏性结构可根据信道动态沿二维时频轴进行配置，并经过理论证明，确保在p跳内实现完全连接，其中p是注意力头的数量。城市宏（UMa）信道条件下的仿真结果表明，在保持结构化稀疏性且每个查询关注键数量可控的情况下，Doppler-aware Sparse NNBF在高移动性场景中显著优于固定模式基线（称为标准稀疏NNBF）以及传统的ZFBF和MMSE波束成形技术。|
|**2025-11-04**|[Apriel-H1: Towards Efficient Enterprise Reasoning Models](http://arxiv.org/abs/2511.02651)|null|大语言模型（LLM）通过带有注意力机制的Transformer架构实现了卓越的推理能力。然而，Transformer在注意力模块（MHA）中存在二次方的时空复杂度，并且在推理过程中需要缓存键值状态，这严重限制了吞吐量和可扩展性。高推理吞吐量对于智能体任务、长上下文推理、高请求负载下的高效部署以及更高效的测试时计算扩展至关重要。状态空间模型（SSM），例如Mamba，通过具有固定大小隐藏状态的循环计算，提供了线性的推理复杂度和恒定的内存占用，从而成为一个有前景的替代方案。在本技术报告中，我们介绍了Apriel-H1系列混合型大语言模型，该系列模型结合了Transformer注意力机制和SSM序列混合器，以在150亿参数规模下实现高效推理。这些模型通过对预训练的推理Transformer Apriel-Nemotron-15B-Thinker进行增量蒸馏获得，逐步用线性Mamba块替换不那么关键的注意力层。我们发布了Apriel-H1-15B-Thinker的多个蒸馏后变体，这些变体具有不同的SSM与MHA比率，并分析了随着更多Mamba层替换MHA，推理性能如何下降。此外，我们发布了一个Apriel-H1的30/50混合变体，该变体在一个监督推理轨迹数据集上进行了进一步微调，在部署到生产就绪的vLLM环境中时，实现了超过2倍的推理吞吐量提升，同时推理性能下降最小。这表明蒸馏后的混合SSM-Transformer架构相较于预训练的Transformer对应模型，能够带来显著的效率提升，而不大幅损害推理质量。|
|**2025-11-04**|[Federated Attention: A Distributed Paradigm for Collaborative LLM Inference over Edge Networks](http://arxiv.org/abs/2511.02647)|null|大语言模型 (LLMs) 正在边缘侧迅速普及，在各种应用场景中提供智能能力。然而，它们在协作场景中的实际部署面临着基本挑战：隐私漏洞、通信开销和计算瓶颈。为解决这些问题，我们提出了联邦注意力 (FedAttn)，它将联邦范式融入自注意力机制，创建了一个新型分布式LLM推理框架，同时实现了隐私保护、通信效率和计算效率。FedAttn使参与者能够在自己的词元表示上执行本地自注意力，同时定期跨多个Transformer块交换和聚合键值 (KV) 矩阵，从而在不暴露私有提示的情况下协作生成LLM响应。此外，我们发现FedAttn中的上下文表示细化与联邦学习 (FL) 中跨私有数据、本地计算和全局聚合的参数优化之间存在结构对偶性。这一关键洞察为系统地将联邦优化技术移植到协作式LLM推理提供了原则性基础。在此框架基础上，我们理论分析了参与者内部的本地自注意力计算以及参与者之间异构的词元相关性如何影响跨Transformer块的误差传播动态。此外，我们刻画了响应质量与通信/计算效率之间的基本权衡，该权衡受同步间隔和参与者数量的控制。实验结果验证了我们的理论分析，并揭示了通过稀疏注意力和自适应KV聚合实现的显著优化机会，突出了FedAttn在实际边缘部署中提供可扩展性和效率的潜力。|
|**2025-11-04**|[Chronic Kidney Disease Prognosis Prediction Using Transformer](http://arxiv.org/abs/2511.02340)|null|慢性肾脏病 (CKD) 影响全球近 10% 的人口，并常进展为终末期肾衰竭。准确的预后预测对于及时干预和资源优化至关重要。我们提出了一个基于 Transformer 的框架，利用首尔大学医院 OMOP 通用数据模型中的多模态电子健康记录 (EHR) 来预测 CKD 进展。我们的方法 (ProQ-BERT) 整合了人口统计学、临床和实验室数据，采用基于量化的标记化处理连续实验室值，并利用注意力机制提高可解释性。该模型通过掩码语言建模进行预训练，并针对预测从 3a 期到 5 期进展的二分类任务进行微调，涵盖了不同的随访和评估期。在包含 91,816 名患者的队列中进行评估，我们的模型始终优于 CEHR-BERT，短期预测的 ROC-AUC 最高达 0.995，PR-AUC 最高达 0.989。这些结果突出了 Transformer 架构和时间设计选择在临床预后建模中的有效性，为个性化 CKD 护理提供了有前景的方向。|
|**2025-11-03**|[EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory](http://arxiv.org/abs/2511.01950)|null|标准循环神经网络，包括LSTMs，难以建模长距离依赖，尤其是在包含噪声或误导性信息的序列中。我们提出了一种新的架构原则——输出条件门控，它使模型能够根据其自身的过往推断来调节其内部记忆门，从而进行自我反思。这形成了一个稳定的反馈循环，增强了记忆保持能力。我们最终的模型EchoLSTM将该原则与注意力机制相结合。我们在一系列具有挑战性的基准上评估了EchoLSTM。在一项定制设计的干扰信号任务上，EchoLSTM达到了69.0%的准确率，显著优于标准LSTM基线33个百分点。此外，在标准ListOps基准上，EchoLSTM取得了与现代Transformer模型相媲美的性能，分别为69.8% 对 71.8%，同时参数效率高出5倍以上。最终的触发敏感度测试提供了定性证据，表明我们模型的自我反思机制能够带来一个从根本上更鲁棒的记忆系统。|
|**2025-11-03**|[UniLION: Towards Unified Autonomous Driving Model with Linear Group RNNs](http://arxiv.org/abs/2511.01768)|null|尽管Transformer模型在各个领域展示了卓越的能力，但其二次注意力机制在处理长序列数据时会引入显著的计算开销。在本文中，我们提出了一种统一的自动驾驶模型UniLION，它基于线性分组RNN算子（即对分组特征执行线性RNN），能够高效处理大规模激光雷达点云、高分辨率多视角图像乃至时间序列。值得注意的是，UniLION作为一种单一的多功能架构，能够无缝支持多种专门化变体（即，仅激光雷达、时间序列激光雷达、多模态和多模态时间融合配置），而无需显式的时间或多模态融合模块。此外，UniLION在广泛的核心任务中始终提供具有竞争力甚至是最先进的性能，这些任务包括3D感知（例如，3D目标检测、3D目标跟踪、3D占用预测、BEV地图分割）、预测（例如，运动预测）和规划（例如，端到端规划）。这种统一范式自然地简化了多模态多任务自动驾驶系统的设计，同时保持了卓越的性能。最终，我们希望UniLION能为自动驾驶领域3D基础模型的发展提供一个全新的视角。代码可在 https://github.com/happinesslz/UniLION 获取。|
|**2025-11-03**|[HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain](http://arxiv.org/abs/2511.01756)|null|2D到3D人体姿态提升是单目视频中3D人体姿态估计的一项基本挑战，其中图卷积网络（GCN）和注意力机制已被证明本质上适合编码骨骼关节点的时空相关性。然而，深度模糊性和2D姿态估计中的误差导致3D轨迹的不连贯性。先前研究试图通过约束相邻帧之间的差异来限制时域中的抖动，但却忽略了骨骼关节点运动的全局时空相关性。为解决这个问题，我们设计了HGFreNet，一种新颖的GraphFormer架构，其具有跳跃混合特征聚合和频域中的3D轨迹一致性。具体而言，我们提出了一个跳跃混合图注意力（HGA）模块和一个Transformer编码器来建模全局关节点时空相关性。HGA模块将骨骼关节点的所有k跳邻居分组为一个混合组，以扩大感受野，并应用注意力机制来全局发现这些组的潜在相关性。随后，我们通过约束频域中的轨迹一致性来利用全局时间相关性。为了提供跨帧深度推断的3D信息并随时间保持连贯性，我们应用了一个预估网络来估计3D姿态。在Human3.6M和MPI-INF-3DHP这两个标准基准数据集上进行了大量实验。结果表明，所提出的HGFreNet在位置精度和时间一致性方面均优于最先进（SOTA）方法。|
|**2025-11-04**|[CGF-DETR: Cross-Gated Fusion DETR for Enhanced Pneumonia Detection in Chest X-rays](http://arxiv.org/abs/2511.01730)|null|肺炎仍然是全球发病率和死亡率的主要原因，因此需要准确高效的自动化检测系统。尽管近期基于Transformer的检测器，如RT-DETR，在目标检测任务中展现出潜力，但它们在医学图像，特别是胸部X射线肺炎检测中的应用仍未得到充分探索。本文提出CGF-DETR，一种专为肺炎检测设计的增强型实时检测Transformer。我们在主干网络中引入XFABlock，通过结合CSP架构的卷积注意力机制来改进多尺度特征提取。为实现高效特征聚合，我们提出SPGA模块，该模块用动态门控机制和单头自注意力取代了标准的多头注意力。此外，GCFC3为颈部网络设计，通过多路径卷积融合增强特征表示，并通过结构重参数化保持实时性能。在RSNA肺炎检测数据集上进行的大量实验表明，CGF-DETR取得了82.2%的mAP@0.5，优于基线RT-DETR-l 3.7%，同时保持了48.1 FPS的可比推理速度。我们的消融实验证实，每个提出的模块都对整体性能提升做出了有意义的贡献，完整模型达到了50.4%的mAP@[0.5:0.95]。|
|**2025-11-03**|[KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records](http://arxiv.org/abs/2511.01249)|null|利用电子健康记录(EHR)进行临床风险预测对于促进及时干预和临床决策支持至关重要。然而，对异构且不规则的EHR时间数据进行建模带来了重大挑战。我们提出了KAT-GNN（知识增强型时间图神经网络），这是一个基于图的框架，它整合了临床知识和时间动态以进行风险预测。KAT-GNN首先从EHR中构建特定模态的患者图。这些图随后通过两种知识源进行增强：(1) 源自SNOMED CT的本体驱动边和 (2) 从EHR中提取的共现先验。随后，采用一个时间感知的Transformer来捕获图编码患者表示中的纵向动态。KAT-GNN在三个不同的数据集和任务上进行了评估：使用长庚研究数据库(CGRD)进行冠状动脉疾病(CAD)预测，以及使用MIMIC-III和MIMIC-IV数据集进行院内死亡率预测。KAT-GNN在CAD预测中达到了最先进的性能（AUROC: 0.9269 $\pm$ 0.0029），并在MIMIC-III（AUROC: 0.9230 $\pm$ 0.0070）和MIMIC-IV（AUROC: 0.8849 $\pm$ 0.0089）的死亡率预测中表现出强大的结果，持续优于GRASP和RETAIN等已建立的基线模型。消融研究证实，基于知识的增强和时间建模组件都是性能提升的重要贡献者。这些发现表明，将临床知识整合到图表示中，再结合时间感知注意力机制，为跨不同临床任务和数据集的风险预测提供了一种有效且可推广的方法。|
|**2025-11-03**|[Eyes on Target: Gaze-Aware Object Detection in Egocentric Video](http://arxiv.org/abs/2511.01237)|null|人类凝视在理解复杂视觉环境中的视觉注意力方面提供了丰富的监督信号。在本文中，我们提出了一种名为“目标聚焦”（Eyes on Target）的新颖深度感知和注视引导目标检测框架，专为以自我为中心的视频设计。我们的方法将注视派生特征注入到视觉Transformer (ViT) 的注意力机制中，有效地使空间特征选择偏向于人类关注的区域。与平等对待所有区域的传统目标检测器不同，我们的方法强调观察者优先区域，以增强目标检测。我们在一个以自我为中心的模拟器数据集上验证了我们的方法，在该数据集中人类视觉注意力对于任务评估至关重要，这阐明了其在评估模拟场景中人类表现方面的潜力。我们通过广泛的实验和消融研究评估了我们的注视集成模型的有效性，结果表明，在自定义模拟器数据集和包括Ego4D Ego-Motion及Ego-CH-Gaze数据集在内的公共基准测试集上，相较于与注视无关的基线，检测精度均持续提高。为了解释模型行为，我们还引入了一种注视感知注意力头重要性指标，揭示了注视线索如何调节Transformer注意力动态。|
|**2025-11-03**|[MoSa: Motion Generation with Scalable Autoregressive Modeling](http://arxiv.org/abs/2511.01200)|null|我们引入MoSa，这是一种新颖的层次化运动生成框架，用于文本驱动的3D人体运动生成，通过从粗到精的可伸缩生成过程增强了矢量量化引导的生成式Transformer (VQ-GT) 范式。在MoSa中，我们提出了一种多尺度Token保留策略 (MTPS)，并将其集成到层次化残差矢量量化变分自编码器 (RQ-VAE) 中。MTPS在每个层次化量化阶段采用插值，以有效地保留从粗到精的多尺度Token。借此，生成式Transformer支持可伸缩自回归 (SAR) 建模，其预测的是尺度Token，这与传统方法在每一步只预测一个Token不同。因此，MoSa仅需10个推理步骤，与RQ-VAE量化层的数量相匹配。为解决源于频繁插值可能导致的重建退化问题，我们提出了CAQ-VAE，这是一种轻量级但富有表现力的卷积-注意力混合VQ-VAE。CAQ-VAE增强了残差块设计并融入了注意力机制，以更好地捕获全局依赖性。大量实验表明，MoSa实现了最先进的生成质量和效率，在保真度和速度方面均优于现有方法。在Motion-X数据集上，MoSa实现了0.06的FID（相比MoMask的0.20），同时将推理时间缩短了27%。此外，MoSa在运动编辑等下游任务上表现出良好的泛化能力，无需额外的微调。代码可在https://mosa-web.github.io/MoSa-web获取。|
|**2025-10-31**|[SpecAttn: Speculating Sparse Attention](http://arxiv.org/abs/2510.27641)|null|大语言模型（LLMs）在推理过程中面临着显著的计算瓶颈，这主要是由于自注意力机制的二次复杂度，尤其是在上下文长度增加时。我们引入了SpecAttn，这是一种新颖的免训练方法，能与现有推测解码技术无缝集成，从而在预训练Transformer模型中实现高效的稀疏注意力。我们的关键见解是利用草稿模型在推测解码过程中已经计算出的注意力权重来识别目标模型的重要token，从而在保持输出质量的同时消除冗余计算。SpecAttn采用了三种核心技术：基于KL散度的草稿模型与目标模型之间的层对齐、一种GPU优化的无排序算法用于从草稿注意力模式中进行top-p token选择，以及由这些预测引导的动态键值（key-value）缓存剪枝。通过利用标准推测解码流程中已完成的计算工作，SpecAttn在PG-19数据集上实现了键值缓存访问减少超过75%，而困惑度仅增加15.29%，显著优于现有的稀疏注意力方法。我们的方法表明，推测执行可以得到增强以提供近似验证，而不会导致显著的性能下降。|
|**2025-10-31**|[MapSAM2: Adapting SAM2 for Automatic Segmentation of Historical Map Images and Time Series](http://arxiv.org/abs/2510.27547)|null|历史地图是独特而有价值的档案，记录了跨越不同时间段的地理特征。然而，由于历史地图图像广泛的风格多变性以及带标注训练数据的稀缺性，对其进行自动化分析仍然是一个重大挑战。从历史地图时间序列中构建关联的时空数据集甚至更加耗时费力，因为它需要综合来自多张地图的信息。此类数据集对于建筑测年、分析道路网络和聚落的发展、研究环境变化等应用至关重要。我们提出了MapSAM2，这是一个用于自动分割历史地图图像和时间序列的统一框架。MapSAM2 基于视觉基础模型，通过少样本微调能够适应各种分割任务。我们的主要创新是将历史地图图像和时间序列都视为视频。对于图像，我们将一组图块作为视频处理，使记忆注意力机制能够整合来自相似图块的上下文线索，从而提高几何精度，特别是对于区域特征。对于时间序列，我们引入了带标注的Siegfried建筑时间序列数据集，并且为了降低标注成本，提出了通过模拟常见的时态变换从单一年份地图中生成伪时间序列的方法。实验结果表明，MapSAM2 能够有效地学习时间关联，并且在有限监督或使用伪视频的情况下，能够准确地分割和关联时间序列中的建筑物。我们将发布我们的数据集和代码以支持未来的研究。|
|**2025-10-31**|[BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization](http://arxiv.org/abs/2510.27516)|null|基于Transformer的架构推动了文本摘要的发展，然而其二次复杂度限制了在长文档上的可扩展性。本文介绍了BiSparse-AAS（带有自适应跨度的双线性稀疏注意力），这是一种新颖的框架，它结合了稀疏注意力、自适应跨度和双线性注意力来解决这些局限性。稀疏注意力通过关注输入中最相关的部分来降低计算成本，而自适应跨度则动态调整注意力范围。双线性注意力通过在这种细化的上下文中建模复杂的token交互来补充前两者。BiSparse-AAS在抽取式和生成式摘要任务中始终优于最先进的基线模型，在CNN/DailyMail数据集上实现了约68.1%的平均ROUGE提升，在XSum数据集上实现了52.6%的平均ROUGE提升，同时在OpenWebText和Gigaword数据集上保持了强大的性能。通过解决效率、可扩展性和长序列建模问题，BiSparse-AAS为实际的文本摘要应用提供了一个统一的、实用的解决方案。|
|**2025-10-31**|[InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames](http://arxiv.org/abs/2510.27497)|null|基于Transformer的自回归模型已成为文本和图像等模态的统一范式，但其在3D分子生成领域的扩展仍未得到充分探索。这一空白源于两个基本挑战：(1) 将分子分词为对SE(3)变换和原子索引排列均不变的规范1D token序列；(2) 设计一种能够建模混合的基于原子的token的架构，该token将离散原子类型与连续3D坐标耦合。为应对这些挑战，我们引入了InertialAR。InertialAR设计了一种规范的分词方法，将分子对其惯性坐标系进行对齐，并重新排序原子以确保SE(3)和排列不变性。此外，InertialAR通过几何旋转位置编码（GeoRoPE）为注意力机制赋予了几何感知能力。另外，它利用分层自回归范式来预测下一个基于原子的token，首先预测原子类型，然后通过扩散损失（Diffusion loss）预测其3D坐标。实验结果表明，InertialAR在QM9、GEOM-Drugs和B3LYP数据集上的无条件分子生成任务中，在10项评估指标中的7项上实现了最先进的性能。此外，它在针对目标化学功能的受控生成中显著优于强基线，在所有5项指标上均取得了最先进的结果。|
|**2025-10-31**|[Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds](http://arxiv.org/abs/2510.27391)|null|模态对齐对于视觉-语言模型（VLM）有效整合跨模态信息至关重要。然而，现有方法从文本中提取层次化特征，同时将每张图像表示为单一特征，导致不对称且次优的对齐。为解决此问题，我们提出“跨树对齐”方法，该方法为图像和文本两种模态构建并对齐树状层次化特征。具体而言，我们引入一个语义感知视觉特征提取框架，该框架将交叉注意力机制应用于来自中间Transformer层的视觉类别token，由文本线索引导以提取具有从粗到细语义的视觉特征。接着，我们将两种模态的特征树嵌入到具有不同曲率的双曲流形中，以有效建模其层次结构。为了在具有不同曲率的异构双曲流形之间进行对齐，我们提出一种衡量异构流形上分布之间KL距离的度量方法，并通过最小化距离来学习一个用于流形对齐的中间流形。我们证明了最优中间流形的存在性和唯一性。在跨多个图像数据集的分类学开放集分类任务上的实验表明，我们的方法在少样本和跨域设置下始终优于强大的基线方法。|
|**2025-10-30**|[Semantic Frame Aggregation-based Transformer for Live Video Comment Generation](http://arxiv.org/abs/2510.26978)|**[link](https://github.com/yy1lab/SFAT)**|实时视频流评论在Twitch等平台上广受欢迎，通过动态互动提升了观众参与度。然而，自动生成上下文适宜的评论仍然是一项具有挑战性且令人兴奋的任务。视频流可能包含大量数据和冗余内容。现有方法往往忽视了优先处理与正在进行的观众互动最相关的视频帧这一重要方面。这种优先级处理对于生成上下文适宜的评论至关重要。为弥补这一不足，我们引入了一种新颖的基于语义帧聚合的Transformer (SFAT) 模型，用于实时视频评论生成。该方法不仅利用CLIP的视觉-文本多模态知识来生成评论，而且根据视频帧与正在进行的观众对话的语义相关性为其分配权重。它采用一种高效的帧加权和技术来强调信息丰富的帧，同时减少对不相关帧的关注。最后，我们的评论解码器采用交叉注意力机制，能够关注每种模态，确保生成的评论反映来自聊天和视频两方面的上下文线索。此外，为解决现有数据集主要侧重于中文内容且视频类别有限的局限性，我们构建了一个大规模、多样化、多模态的英文视频评论数据集。该数据集从Twitch提取，涵盖11个视频类别，总计438小时和320万条评论。我们通过将SFAT模型与现有方法进行比较，展示了其在从实时视频和正在进行的对话上下文中生成评论方面的有效性。|
|**2025-10-30**|[Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology](http://arxiv.org/abs/2510.26297)|null|敏捷对地观测卫星（AEOS）星座为监测地球表面提供了前所未有的灵活性，但在大规模场景、动态环境和严格约束下，它们的调度仍然具有挑战性。现有方法通常会简化这些复杂性，从而限制了它们的实际性能。我们通过一个统一框架来解决这一空白，该框架集成了标准化基准套件和新颖的调度模型。我们的基准套件AEOS-Bench包含3,907个精心调整的卫星资产和16,410个场景。每个场景包含1到50颗卫星和50到300个成像任务。这些场景通过高保真仿真平台生成，确保了真实的卫星行为，例如轨道动力学和资源约束。每个场景都提供了真值调度标注。据我们所知，AEOS-Bench是第一个专为现实星座调度定制的大规模基准套件。基于此基准，我们引入了AEOS-Former，一个基于Transformer的调度模型，它融合了约束感知注意力机制。一个专用内部约束模块明确地建模了每颗卫星的物理和操作限制。通过基于仿真的迭代学习，AEOS-Former适应各种场景，为AEOS星座调度提供了一个鲁棒的解决方案。实验结果表明，AEOS-Former在任务完成率和能源效率方面优于基线模型，消融研究突出了每个组件的贡献。代码和数据可在https://github.com/buaa-colalab/AEOSBench获取。|
|**2025-10-29**|[Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information](http://arxiv.org/abs/2510.25542)|null|揭示现实世界数据中隐藏的图结构是一个严峻挑战，在科学领域具有广泛应用。近来，利用注意力机制的基于Transformer的模型在捕获图中复杂依赖关系方面展现出强大的经验成功。然而，对其训练动态的理论理解仅限于树状图，其中每个节点仅依赖于单个父节点。将可证明的保证扩展到更一般的有向无环图（DAGs）——其中每个节点涉及多个父节点——仍然具有挑战性，主要原因是难以设计训练目标，使不同的注意力头能够分别学习多个不同的父子关系。在这项工作中，我们通过引入一种新颖的基于 $f$-散度的信息理论度量：核引导互信息（KG-MI）来解决这个问题。我们的目标将KG-MI与多头注意力框架相结合，其中每个注意力头都与一个独特的边际转移核相关联，以有效建模多样化的父子依赖关系。我们证明，给定由K个父节点DAG生成的序列，通过梯度上升训练单层多头Transformer能在多项式时间内收敛到全局最优。此外，我们刻画了收敛时的注意力分数模式。另外，当将$f$ -散度特殊化为KL散度时，所学习的注意力分数能准确反映真实邻接矩阵，从而可证明地恢复了底层图结构。实验结果验证了我们的理论发现。|
|**2025-10-29**|[Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography](http://arxiv.org/abs/2510.25522)|null|多期增强计算机断层扫描 (CECT) 中肝脏结构的分割在肝脏疾病（包括肿瘤检测）的计算机辅助诊断和治疗规划中起着关键作用。在本研究中，我们探究了基于UNet的架构在肝肿瘤分割中的性能，从原始UNet到采用各种骨干网络的UNet3+。我们评估了ResNet、基于Transformer和状态空间 (Mamba) 的骨干网络，所有网络均使用预训练权重初始化。令人惊讶的是，尽管现代架构取得了进步，但基于ResNet的模型在多个评估指标上持续优于基于Transformer和Mamba的替代方案。为了进一步提高分割质量，我们在骨干网络中引入了注意力机制，并观察到结合卷积块注意力模块 (CBAM) 产生了最佳性能。带有CBAM模块的ResNetUNet3+不仅取得了最佳的重叠度量，Dice分数达到0.755，IoU达到0.662，而且实现了最精确的边界描绘，HD95距离最低，为77.911。该模型的优越性进一步得到证实，其总准确率达到0.925，特异性达到0.926，展示了其准确识别病变和健康组织的强大能力。为了进一步增强可解释性，我们采用了Grad-CAM可视化技术来突出显示区域最有影响力的预测，从而深入了解其决策过程。这些发现表明，经典的ResNet架构与现代注意力模块结合时，在医学图像分割任务中仍具有高度竞争力，为临床实践中的肝肿瘤检测提供了有前景的方向。|
|**2025-10-28**|[Group Relative Attention Guidance for Image Editing](http://arxiv.org/abs/2510.24657)|null|近来，基于Diffusion-in-Transformer模型的图像编辑取得了快速发展。然而，现有编辑方法往往缺乏对编辑程度的有效控制，限制了它们实现更个性化结果的能力。为了解决这一局限性，我们研究了DiT模型中的MM-Attention机制，并观察到Query和Key tokens共享一个仅与层相关的偏置向量。我们将这种偏置解释为模型固有的编辑行为，而每个token与其对应偏置之间的差值则编码了内容特有的编辑信号。基于这一见解，我们提出了组相对注意力引导（Group Relative Attention Guidance, GRAG），这是一种简单而有效的方法，它通过重新加权不同token的delta值来调节模型对输入图像相对于编辑指令的关注程度，从而无需任何调优即可实现对编辑强度的连续细粒度控制。在现有图像编辑框架上进行的大量实验表明，GRAG只需四行代码即可集成，并持续提升编辑质量。此外，与常用的无分类器引导（Classifier-Free Guidance）相比，GRAG实现了对编辑程度更平滑、更精确的控制。我们的代码将发布在https://github.com/little-misfit/GRAG-Image-Editing。|
|**2025-10-28**|[SALS: Sparse Attention in Latent Space for KV cache Compression](http://arxiv.org/abs/2510.24273)|null|能够处理长上下文的大语言模型需求量很大，然而它们的推理仍然面临挑战，原因在于庞大的键值（KV）缓存大小和高内存带宽要求。先前的研究表明，KV缓存的隐维度中表现出低秩特性，这表明了有效压缩的潜力。然而，由于现代大语言模型中广泛采用的旋转位置编码（RoPE）机制，朴素的低秩压缩会导致严重的准确性下降或产生新的速度瓶颈，因为低秩缓存必须首先被重建才能应用RoPE。在本文中，我们提出了两个关键见解：首先，将RoPE应用于键向量会增加它们的方差，这反过来导致更高的秩；其次，在键向量被转换到潜在空间后，它们在大多数层中基本保持其表示。基于这些见解，我们提出了潜在空间稀疏注意力（SALS）框架。SALS通过低秩投影将KV缓存投影到紧凑的潜在空间，并在此空间中使用无RoPE的查询-键交互来执行稀疏令牌选择。通过仅重建一小部分重要令牌，它避免了完整KV缓存重建的开销。我们使用LLaMA2-7b-chat和Mistral-7b这两个大型模型在各种任务上全面评估了SALS，并额外使用LLaMA3.1-8B-Instruct在RULER-128k基准测试上验证了其可扩展性。实验结果表明，SALS通过保持有竞争力的准确性，实现了最先进（SOTA）的性能。在不同设置下，SALS在4K序列上实现了6.4倍的KV缓存压缩，并在注意力操作器中相比FlashAttention2实现了5.7倍的速度提升。对于端到端吞吐量性能，我们相比于GPT-fast分别在4k和32K序列上实现了1.4倍和4.5倍的提升。|
|**2025-10-28**|[EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale](http://arxiv.org/abs/2510.24173)|null|由于其多尺度相互作用，计算求解湍流仍然是流体力学中的一个核心挑战。通过直接数值模拟（DNS）完全解析大规模湍流的计算量巨大，这促使了数据驱动的机器学习替代方案的出现。在这项工作中，我们提出了EddyFormer，这是一种基于Transformer的谱元法（SEM）架构，用于大规模湍流模拟，它结合了谱方法的精度和注意力机制的可扩展性。我们引入了一种SEM标记化方法，将流场分解为网格尺度和亚网格尺度分量，从而能够捕获局部和全局特征。我们创建了一个新的三维各向同性湍流数据集，并训练EddyFormer在256^3分辨率下实现了DNS级别的精度，相比DNS提供了30倍的加速。当应用于比训练时大四倍的未见域时，EddyFormer在物理不变指标（能量谱、相关函数和结构函数）上保持了精度，显示出域泛化能力。在多样化湍流的The Well基准套件上，EddyFormer解决了之前机器学习模型无法收敛的案例，准确再现了广泛物理条件下的复杂动力学。|
|**2025-10-27**|[QoSGMAA: A Robust Multi-Order Graph Attention and Adversarial Framework for Sparse QoS Prediction](http://arxiv.org/abs/2510.22982)|null|随着互联网技术的快速发展，网络服务已成为为用户提供多样化和可靠应用程序的关键。然而，可用服务数量的指数级增长导致了许多相似的服务产品，这在选择最优服务方面带来了巨大挑战。因此，准确预测服务质量（QoS）成为了确保可靠性和用户满意度的基本前提。然而，现有的QoS预测方法往往未能捕获丰富的上下文信息，并在极端数据稀疏性和结构噪声下表现不佳。为了弥补这一差距，我们提出了一种新颖的架构QoSMGAA，专门旨在提高复杂和嘈杂网络服务环境中的预测准确性。QoSMGAA集成了多阶注意力机制，以聚合广泛的上下文数据并有效预测缺失的QoS值。此外，我们的方法还结合了对抗性神经网络，基于转换后的交互矩阵执行自回归监督学习。为了捕获用户和服务之间复杂的、高阶的交互，我们采用了一种离散采样技术，利用Gumbel-Softmax方法生成信息丰富的负样本。在 E规模真实世界数据集上进行的全面实验验证表明，我们提出的模型显著优于现有基线方法，突出了其在服务选择和推荐场景中实际部署的巨大潜力。|
|**2025-10-26**|[ConMatFormer: A Multi-attention and Transformer Integrated ConvNext based Deep Learning Model for Enhanced Diabetic Foot Ulcer Classification](http://arxiv.org/abs/2510.22743)|null|糖尿病足溃疡（DFU）检测是一项临床意义重大但具有挑战性的任务，原因在于公开可用数据集的稀缺性和可变性。为解决这些问题，我们提出了ConMatFormer，这是一种新型混合深度学习架构，它以协同工作的方式结合了ConvNeXt块、多种注意力机制（卷积块注意力模块（CBAM）和双注意力网络（DANet））以及Transformer模块。这种设计有助于提取更好的局部特征并理解全局上下文，从而使我们能够非常准确地建模跨越不同类型DFU的微小皮肤模式。为解决类别不平衡问题，我们采用了数据增强方法。在初始阶段，ConvNeXt块被用于获取详细的局部特征。随后，我们通过添加Transformer模块来增强长程依赖性，从而构建了模型。这使我们能够精确定位那些代表性不足或构成少数的DFU类别。在DS1 (DFUC2021)和DS2 (糖尿病足溃疡 (DFU))数据集上进行的测试表明，ConMatFormer在准确性、可靠性和灵活性方面均优于最先进的 (SOTA) 卷积神经网络 (CNN) 和视觉Transformer (ViT) 模型。所提出的方法在单次实验中达到了0.8961的准确率和0.9160的精确率，这比当前DFU分类标准有了显著提升。此外，通过4折交叉验证，所提出的模型达到了0.9755的准确率，标准差仅为0.0031。我们进一步应用了可解释人工智能 (XAI) 方法，例如Grad-CAM、Grad-CAM++和LIME，以持续监控决策过程的透明度和可信度。我们的发现为DFU分类设定了新基准，并为医学图像分析提供了一个混合注意力Transformer框架。|
|**2025-10-26**|[Scalable Neural Decoders for Practical Real-Time Quantum Error Correction](http://arxiv.org/abs/2510.22724)|null|实时、可扩展且精确的解码是实现容错量子计算机的关键组成部分。虽然基于Transformer的神经网络解码器（如AlphaQubit）已展现出高精度，但其核心注意力机制的计算复杂度随码距 $d$ 以 $\mathcal{O}(d^4)$ 增长，导致解码速度不足以满足实际实时应用需求。在这项工作中，我们介绍并评估了一种基于Mamba的解码器，它是一种具有 $\mathcal{O}(d^2)$ 复杂度的状态空间模型。在使用Sycamore硬件数据进行的内存实验中，我们的Mamba解码器性能与基于Transformer的对应模型相当，这表明其卓越的效率并未以牺牲性能为代价。至关重要的是，在考虑了解码器引入噪声的模拟实时场景中，Mamba解码器显著优于Transformer，展现出更高的错误阈值（$0.0104$ 相比于 $0.0097$ ）。这些结果表明，Mamba解码器在速度和精度之间实现了引人注目的平衡，使其成为一种有前景的架构，可用于可扩展的实时量子纠错。|
|**2025-10-26**|[AesCrop: Aesthetic-driven Cropping Guided by Composition](http://arxiv.org/abs/2510.22528)|null|美学驱动的图像裁剪对于视图推荐和缩略图生成等应用至关重要，因为视觉吸引力会显著影响用户参与度。视觉吸引力的一个关键因素是构图——图像中元素的有意排列。一些方法已通过基于评估和基于回归的范式成功融入了构图知识。然而，基于评估的方法缺乏全局性，而基于回归的方法缺乏多样性。最近，整合这两种范式的混合方法应运而生，弥补了二者之间的差距，以实现更好的多样性和全局性。值得注意的是，现有混合方法未能融入摄影构图指导，而这正是定义摄影美学的关键属性。在这项工作中，我们引入了AesCrop，一个构图感知的混合图像裁剪模型，它集成了VMamba图像编码器（通过新颖的Mamba构图注意力偏置MCAB进行增强）和一个Transformer解码器，以执行端到端基于排名的图像裁剪，生成多个裁剪结果及相应的质量分数。通过将构图线索显式编码到注意力机制中，MCAB指导AesCrop专注于构图上最显著的区域。大量实验表明，AesCrop优于当前最先进的方法，提供了卓越的定量指标和定性上更令人满意的裁剪结果。|
|**2025-10-28**|[LongCat-Video Technical Report](http://arxiv.org/abs/2510.22200)|null|视频生成是通向世界模型的关键路径，其中高效的长视频推理是一项关键能力。为此，我们引入了LongCat-Video，一个拥有136亿参数的基础视频生成模型，在多种视频生成任务上表现出强大的性能。它尤其擅长高效高质量的长视频生成，代表着我们迈向世界模型的第一步。主要特点包括：多任务统一架构：LongCat-Video基于扩散Transformer (DiT) 框架构建，通过单一模型支持文本到视频、图像到视频和视频续写任务；长视频生成：在视频续写任务上进行预训练，使LongCat-Video能够在生成数分钟长的视频时保持高质量和时间连贯性；高效推理：LongCat-Video通过沿时间轴和空间轴采用由粗到细的生成策略，在数分钟内生成720p、30fps的视频。块稀疏注意力进一步提高了效率，尤其在高分辨率下；基于多奖励RLHF的强大性能：多奖励RLHF训练使LongCat-Video的性能与最新的闭源模型和领先的开源模型相当。代码和模型权重已公开可用，以加速该领域的发展。|
|**2025-10-24**|[Transformer Based Linear Attention with Optimized GPU Kernel Implementation](http://arxiv.org/abs/2510.21956)|null|在极其成功的Transformer架构中，原始的基于softmax的注意力机制（常规注意力）计算 $N$个token之间的注意力，其中每个token都嵌入在$D$维的头部中，其时间复杂度为$O(N^2D)$。鉴于Transformer的成功，在训练和推理期间提高其运行效率是一个热门研究领域。其中一种方法是引入线性注意力（LA）机制，它提供了$O(ND^2)$ 的线性时间复杂度，并已证明与常规注意力具有可比的准确性。然而，线性注意力在实践中滞后于其理论效率。我们为线性注意力的前向和反向传播提出了一种新颖的方法，并提供了一个高度优化的CUDA实现。我们的方法在速度上超越了最先进技术3.3倍，并使内存消耗减少了3.6倍。我们通过训练一个14亿参数的语言模型，在单层和端到端设置中验证了这些改进，该模型在主要推理基准测试中表现出与常规注意力相似的表达能力。|
|**2025-10-24**|[BachVid: Training-Free Video Generation with Consistent Background and Character](http://arxiv.org/abs/2510.21696)|null|扩散Transformer (DiT) 最近在文本到视频 (T2V) 生成方面取得了显著进展。然而，生成具有一致角色和背景的多个视频仍然是一个重大挑战。现有方法通常依赖于参考图像或大量训练，并且通常只解决角色一致性，将背景一致性留给图像到视频模型。我们引入了BachVid，这是首个无需训练的方法，无需任何参考图像即可实现一致的视频生成。我们的方法基于对DiT注意力机制和中间特征的系统分析，揭示了其在去噪过程中提取前景掩码和识别匹配点的能力。我们的方法利用这一发现，首先生成一个身份视频并缓存中间变量，然后将这些缓存变量注入到新生成视频的相应位置，从而确保多个视频中的前景和背景一致性。实验结果表明，BachVid在无需额外训练的情况下，在生成的视频中实现了鲁棒的一致性，为无需依赖参考图像或额外训练的一致视频生成提供了一种新颖且高效的解决方案。|
|**2025-10-23**|[Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction](http://arxiv.org/abs/2510.20787)|null|将整个输入序列压缩成固定大小循环状态的线性注意力模型为Transformers提供了一种高效的替代方案，但其有限内存导致的遗忘问题损害了检索密集型任务。为缓解此问题，我们探索了一系列恢复对过去token直接访问的混合模型。我们交错使用了介于线性注意力和全注意力之间时间与空间复杂度的token混合器，包括带有token逐出的稀疏注意力以及查询感知的原生稀疏注意力。特别地，我们提出了一种新颖的可学习token逐出方法。结合滑动窗口注意力，一个端到端可训练的轻量级CNN从过去和未来相邻token中聚合信息，以自适应地为每个头保留一组有限的关键KV对，从而保持线性注意力恒定的时间和空间复杂性。我们为稀疏注意力机制提供了高效的Triton内核。在检索密集型基准上的经验评估支持了我们方法的有效性。|
|**2025-10-23**|[DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion](http://arxiv.org/abs/2510.20766)|**[link](https://github.com/guyyariv/DyPE)**|扩散Transformer模型能够生成具有卓越真实感和细节的图像，然而，由于自注意力机制的二次复杂度随图像token数量的增加而增长，在超高分辨率下训练它们仍然极其昂贵。本文介绍了一种新颖的、无需训练的方法——动态位置外推（DyPE），它使预训练的扩散Transformer能够在远超其训练数据的分辨率下合成图像，且无额外采样成本。DyPE利用了扩散过程固有的频谱演进特性，其中低频结构早期收敛，而高频则需要更多步骤来解析。具体而言，DyPE在每个扩散步骤中动态调整模型的位置编码，使其频谱与生成过程的当前阶段相匹配。这种方法使我们能够生成分辨率远超训练分辨率的图像，例如，使用FLUX生成1600万像素的图像。在多个基准测试中，DyPE持续提升性能，并在超高分辨率图像生成中实现了最先进的真实感，且增益在更高分辨率下变得更加显著。项目页面可在https://noamissachar.github.io/DyPE/访问。|
|**2025-10-23**|[Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems](http://arxiv.org/abs/2510.20640)|null|本文提出了DiRecGNN，一个用于微软云服务监控的注意力增强实体推荐框架。我们提供了云服务所有者所感知的此功能实用性的见解以及从部署中吸取的教训。具体来说，我们引入了为云服务推荐应由自动化看门狗（监控器）跟踪的最佳属性（维度）子集的问题。首先，我们构建了生产规模的监控异构图。这些实体的交互动态通常以有限的结构和参与信息为特征，导致现有最先进方法性能不佳。此外，传统方法由于其同质性，未能捕获跨越长距离的实体间依赖关系。因此，我们提出了一种受Transformer架构启发的注意力增强实体排序模型。我们的模型利用多头注意力机制来关注异构邻居及其属性，并进一步关注使用随机游走采样的路径以捕获长距离依赖关系。我们还采用多方面损失函数来优化相关推荐，同时尊重数据的固有稀疏性。经验评估表明，相对于现有方法有显著改进，我们的模型在MRR方面实现了43.1%的增长。此外，使用这些功能的产品团队认为该功能有用，并将其评为4.5（满分5分）。|
|**2025-10-23**|[A Transformer Inspired AI-based MIMO receiver](http://arxiv.org/abs/2510.20363)|null|我们提出 AttDet，这是一种受 Transformer 启发的 MIMO（多输入多输出）检测方法，它将每个传输层视为一个 token，并通过轻量级自注意力机制学习流间干扰。查询和键直接从估计的信道矩阵中获得，因此注意力分数量化了信道相关性。值由匹配滤波器输出初始化，并迭代地细化。AttDet 的设计结合了基于模型的解释性与数据驱动的灵活性。我们通过在真实的 5G 信道模型以及高阶混合 QAM 调制编码方案下的链路级仿真证明，AttDet 能够接近最优的 BER/BLER（误码率/误块率）性能，同时保持可预测的多项式复杂度。|
|**2025-10-22**|[Online Handwritten Signature Verification Based on Temporal-Spatial Graph Attention Transformer](http://arxiv.org/abs/2510.19321)|null|手写签名验证是身份认证的一个关键方面，在金融和电子商务等各种领域都有应用。然而，由于用户内部差异性和伪造风险，在签名验证中实现高精度仍然具有挑战性。本文提出了一种用于动态签名验证的新颖方法：时空图注意力Transformer (TS-GATR)。TS-GATR结合了图注意力网络 (GAT) 和门控循环单元 (GRU)，以建模签名数据中的空间和时间依赖性。TS-GATR通过将签名表示为图，其中每个节点捕获动态特征（例如位置、速度、压力），并利用注意力机制建模它们复杂的关联，从而提升了验证性能。所提出的方法进一步采用了双图注意力Transformer (DGATR) 模块，该模块利用k步和k近邻邻接图分别建模局部和全局空间特征。为了捕获长期时间依赖性，该模型集成了GRU，从而增强了其在签名验证过程中学习动态特征的能力。在MSDS和DeepSignDB等基准数据集上进行的全面实验表明，TS-GATR超越了当前最先进的方法，在各种场景下持续实现了更低的等错误率 (EER)。|
|**2025-10-21**|[Advancing Brain Tumor Segmentation via Attention-based 3D U-Net Architecture and Digital Image Processing](http://arxiv.org/abs/2510.19109)|**[link](https://github.com/eyadgad/Brain-Tumor-Segmentation-using-3D-U-Net-Architecture)**|在医学诊断领域，人工智能（AI）的快速发展已显著推动了脑肿瘤分割技术的显著提升。U-Net等编码器-解码器架构通过有效提取磁共振成像（MRI）扫描中的有意义表示，在三维脑肿瘤分割中发挥了变革性作用。然而，标准U-Net模型在准确勾勒肿瘤区域方面面临挑战，特别是在处理不规则形状和模糊边界时。此外，在BraTS数据集等高分辨率MRI数据上训练鲁棒的分割模型需要大量的计算资源，并且经常面临类别不平衡相关的挑战。本研究提出将注意力机制集成到三维U-Net模型中，使模型能够在分割过程中捕获复杂的细节并优先处理信息丰富的区域。此外，本研究利用一种基于数字图像处理技术的肿瘤检测算法来解决训练数据不平衡问题并减轻偏差。本研究旨在提高脑肿瘤分割的性能，最终提高诊断的可靠性。为实现这一目标，所提出的模型在BraTS 2020数据集上使用各种性能指标进行了彻底评估和衡量。所得结果表明，该模型优于相关研究，表现出0.975的Dice系数、0.988的特异性和0.995的敏感性，这表明所提出模型在改善脑肿瘤分割方面的有效性，为临床环境中可靠诊断提供了宝贵见解。|
|**2025-10-21**|[UltraGen: High-Resolution Video Generation with Hierarchical Attention](http://arxiv.org/abs/2510.18775)|null|视频生成领域的近期进展使得制作视觉上引人入胜的视频成为可能，在内容创作、娱乐和虚拟现实等领域具有广泛应用。然而，由于注意力机制相对于输出宽度和高度的二次计算复杂度，大多数现有基于扩散Transformer的视频生成模型局限于低分辨率输出 (<=720P)。这种计算瓶颈使得原生高分辨率视频生成 (1080P/2K/4K) 在训练和推理时都变得不切实际。为应对这一挑战，我们提出了UltraGen，一种新颖的视频生成框架，能够实现i) 高效且ii) 端到端的原生高分辨率视频合成。具体而言，UltraGen采用了一种基于全局-局部注意力分解的分层双分支注意力架构，将完整注意力分解为一个用于高保真区域内容的局部注意力分支和一个用于整体语义一致性的全局注意力分支。我们进一步提出了一种空间压缩全局建模策略以高效学习全局依赖，以及一种分层跨窗口局部注意力机制以降低计算成本，同时增强不同局部窗口之间的信息流。大量实验表明，UltraGen能够首次有效地将预训练的低分辨率视频模型扩展到1080P乃至4K分辨率，在定性和定量评估中均优于现有最先进方法和基于超分辨率的两阶段流水线。|
|**2025-10-21**|[MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation](http://arxiv.org/abs/2510.18692)|null|使用扩散Transformer (DiT) 生成长视频时，全注意力机制与序列长度的二次复杂度增长是其瓶颈。由于注意力高度冗余，输出主要由一小部分查询-键对决定。现有的稀疏方法依赖于块级粗略估计，其准确性与效率的权衡受限于块大小。本文介绍了一种高效的稀疏注意力机制——组混合注意力 (MoGA)，它使用轻量级、可学习的token路由器来精确匹配token，而无需块级估计。通过语义感知路由，MoGA 实现了有效的长程交互。作为一种无核方法，MoGA 可以与现代注意力堆栈（包括FlashAttention和序列并行）无缝集成。基于MoGA，我们开发了一个高效的长视频生成模型，该模型能够端到端地生成分钟级、多镜头、480p、24帧/秒的视频，其上下文长度约为580k。在各种视频生成任务上的全面实验验证了我们方法的有效性。|
|**2025-10-21**|[AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression](http://arxiv.org/abs/2510.18422)|null|数字射频存储器（DRFM）电子对抗的日益增多对雷达系统的生存能力和有效性构成了严重威胁。这些干扰器能够生成大量欺骗性假目标，使雷达的处理能力不堪重负并掩盖真实目标。因此，鲁棒地分辨真实目标和复杂干扰信号的能力，尤其是在低信噪比（SNR）环境中，至关重要。本文介绍了基于注意力的双树小波散射原型网络（AWSPNet），这是一种专为同时进行雷达目标识别和干扰抑制而设计的深度学习框架。AWSPNet的核心是编码器，它利用双树复小波变换来提取对噪声和信号平移具有固有鲁棒性的特征。这些特征通过注意力机制和预训练骨干网络得到进一步提炼。为解决标注数据有限的挑战并增强泛化能力，我们在训练阶段采用了有监督对比学习策略。分类由原型网络执行，该网络在少样本学习场景中特别有效，能够快速适应新的信号类型。我们通过广泛的实验证明了我们方法的有效性。结果表明，AWSPNet在-6 dB信噪比下达到了90.45%的准确率。此外，我们通过t-SNE可视化提供了网络内部工作原理的物理解释，分析了模型不同阶段的特征可分离性。最后，通过将AWSPNet与时域滑动窗口方法相结合，我们提出了一个完整算法，该算法不仅能够识别而且能够有效抑制各种类型的干扰，从而验证了其在复杂电磁环境中实际应用的潜力。|
|**2025-10-21**|[Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference](http://arxiv.org/abs/2510.18413)|**[link](https://github.com/FibonaccciYan/Adamas)**|大语言模型 (LLMs) 现在支持数十万到数百万个token的上下文窗口，从而能够实现长文档摘要、大规模代码合成、多文档问答和持久多轮对话等应用。然而，如此扩展的上下文加剧了自注意力机制的二次方成本，导致自回归解码中出现严重的延迟。现有的稀疏注意力方法缓解了这些成本，但依赖于启发式模式，难以召回每个查询的关键键值 (KV) 对，从而导致准确性下降。我们引入了 Adamas，一种专为长上下文推理设计的轻量级但高度准确的稀疏注意力机制。Adamas 应用哈达玛变换、分桶和 2 比特压缩来生成紧凑表示，并利用曼哈顿距离估计进行高效的 top-k 选择。实验表明，Adamas 仅用 64 个token的预算就能与全注意力机制的准确性相匹配，在 128 个token时实现了近乎无损的性能，并且支持比现有最先进 (SOTA) 方法高出 8 倍的稀疏度，同时在 32K 长度序列上在自注意力方面提供高达 4.4 倍、端到端方面提供 1.5 倍的加速。值得注意的是，Adamas 达到了与全注意力机制相当甚至更低的困惑度，强调了其在激进稀疏度下保持准确性的有效性。|
|**2025-10-21**|[Learning Human-Object Interaction as Groups](http://arxiv.org/abs/2510.18357)|null|人-物交互检测（HOI-DET）旨在定位人-物对并识别它们之间的交互关系。为了聚合上下文线索，现有方法通常通过自注意力机制在所有检测到的实体之间传播信息，或使用二分图在人与物之间建立消息传递。然而，它们主要关注成对关系，忽略了现实世界中的交互往往源于集体行为（多个人和物体参与联合活动）。鉴于此，我们从群体视角重新审视关系建模，并提出了GroupHOI，这是一个基于几何邻近性和语义相似性传播上下文信息的框架。为了利用几何邻近性，我们使用一个基于从边界框中提取的空间特征的可学习邻近性估计器，将人和物体分成不同的簇。在每个组中，通过自注意力计算软对应关系，以聚合和分派上下文线索。为了纳入语义相似性，我们使用来自人-物对特征的局部上下文线索增强了传统的基于Transformer的交互解码器。在HICO-DET和V-COCO基准测试上的大量实验证明了GroupHOI优于现有最先进方法。它还在更具挑战性的非语言交互检测（NVI-DET）任务中表现出领先性能，该任务涉及群体内部各种形式的高阶交互。|
|**2025-10-21**|[LIME: Link-based user-item Interaction Modeling with decoupled xor attention for Efficient test time scaling](http://arxiv.org/abs/2510.18239)|null|扩展大型推荐系统需要在三个主要方面取得进展：处理更长的用户历史、扩展候选集以及增加模型容量。尽管前景广阔，Transformer的计算成本随用户序列长度呈二次方增长，并随候选数量呈线性增长。这种权衡使得在推理时扩展候选集或增加序列长度变得极其昂贵，尽管性能有显著提升。我们引入了LIME，一种新颖的架构，解决了这种权衡。通过两项关键创新，LIME从根本上降低了计算复杂度。首先，低秩“链接嵌入”通过解耦用户和候选交互，使得注意力权重能够预计算，从而使推理成本几乎与候选集大小无关。其次，一种线性注意力机制LIME-XOR，将用户序列长度的复杂度从二次方( $O(N^2)$)降低到线性($O(N)$ )。在公共和工业数据集上的实验表明，LIME与最先进的Transformer模型性能不相上下，但在大型候选集或长序列长度下，推理速度提高了10倍。在一个主要的推荐平台进行测试时，LIME提升了用户参与度，同时在候选集大小和用户历史长度方面保持了极低的推理成本，为高效且富有表现力的推荐系统开创了新范式。|
|**2025-10-20**|[Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models](http://arxiv.org/abs/2510.17196)|null|有效处理长上下文是语言模型面临的关键挑战。虽然标准Transformer受限于二次复杂度和较差的长度外推能力，但滑动窗口注意力（sliding window attention）和状态空间模型（state space models）等替代架构由于其固定大小的内存，牺牲了有效利用完整上下文的能力。基于分块的稀疏注意力（chunk-based sparse attention）已成为实现极限长度泛化的一种有前途的范式，然而其成功的关键架构原则尚未被完全理解。在这项工作中，我们对这些模型进行了系统性剖析，以识别驱动其性能的核心组件。通过一个统一框架和全面的消融研究，我们证明了以下三个设计原则的组合至关重要：(1) 一个表达能力强、非线性的分块编码器（Chunk Encoder），带有专用的CLS token，用于生成检索表示；(2) 一个旁路残差路径（Bypassing Residual Path），用于稳定整合检索到的全局信息，使其不被局部残差流覆盖；以及(3) 在预训练期间强制选择稀疏性，以弥合训练-测试分布差距。我们为块内信息处理和地标生成提供了理论动机。通过结合这些原则，我们在免训练长度外推方面建立了新的最先进水平，成功地将基于4K上下文训练的模型泛化到RULER和BABILong上的3200万个token。我们的发现为开发未来高性能长上下文语言模型提供了一套清晰且经验证的设计原则。|
|**2025-10-19**|[ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning](http://arxiv.org/abs/2510.16824)|null|多模态分子表示学习通过联合建模分子图及其文本描述，整合结构信息和语义信息，从而实现对药物毒性、生物活性和理化性质更鲁棒、更可靠的预测，进而提高预测准确性和可解释性。然而，现有的多模态方法存在两个主要局限性：（1）它们通常仅在最终编码器层进行跨模态交互，从而忽略了层次语义依赖；（2）它们缺乏统一的原型空间以实现模态间鲁棒对齐。为解决这些局限性，我们提出了ProtoMol，一种原型引导的多模态框架，旨在实现分子图和文本描述之间的细粒度融合和一致语义对齐。ProtoMol集成了双分支层次编码器，利用图神经网络处理结构化分子图，并利用Transformer编码非结构化文本，从而获得全面的逐层表示。接着，ProtoMol引入了一种逐层双向跨模态注意力机制，逐步对齐跨层的语义特征。此外，ProtoMol构建了一个具有可学习的、类别特定的锚点的共享原型空间，以引导两种模态获得连贯且具有判别性的表示。在多个基准数据集上进行的大量实验表明，ProtoMol在各种分子性质预测任务中持续优于最先进的基线方法。|
|**2025-10-19**|[Efficient High-Accuracy PDEs Solver with the Linear Attention Neural Operator](http://arxiv.org/abs/2510.16816)|null|神经算子提供了一个强大的数据驱动框架，用于学习函数空间之间的映射，其中基于Transformer的神经算子架构面临着一个根本性的可扩展性-准确性权衡：Softmax注意力提供了出色的保真度，但在网格点数量 $N$和隐藏维度$d$方面会带来二次复杂度$\mathcal{O}(N^2 d)$，而线性注意力变体将成本降低到$\mathcal{O}(N d^2)$，却常常遭受显著的准确性下降。为了解决上述挑战，本文提出了一种新型神经算子——线性注意力神经算子（LANO），它通过基于代理的机制重新设计注意力，实现了可扩展性和高准确性。LANO通过引入一组紧凑的$M$个代理token ($M \ll N$) 来介导$N$个token之间的全局交互，从而解决了这一困境。这种代理注意力机制产生了一个具有线性复杂度$\mathcal{O}(MN d)$ 的算子层，同时保留了Softmax注意力的表达能力。理论上，我们证明了其通用逼近性质，从而证明了改进的条件性和稳定性。经验上，LANO超越了当前最先进的神经偏微分方程求解器，包括采用基于切片的Softmax注意力的Transolver，在标准基准测试中平均实现了19.5%的准确性提升。通过弥合线性复杂度和Softmax级别性能之间的差距，LANO为科学机器学习应用建立了可扩展、高准确性的基础。|
|**2025-10-19**|[EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation](http://arxiv.org/abs/2510.16776)|null|基于X射线图像的医学报告生成（MRG）是人工智能领域的一个关键方向，可以显著减轻临床医生的诊断负担并缩短患者等待时间。现有的MRG模型主要依赖大型语言模型（LLMs）来改进报告生成，对预训练视觉基础模型或高级微调技术的探索有限。主流框架要么避免微调，要么采用LoRA等简化方法，往往忽略了增强交叉注意力机制的潜力。此外，尽管基于Transformer的模型在视觉-语言任务中占据主导地位，但非Transformer架构（例如Mamba网络）在医学报告生成方面仍未得到充分探索，为未来的研究提供了一个有前景的方向。在本文中，我们提出了EMRRG，一个新颖的X射线报告生成框架，该框架使用参数高效方法微调预训练的Mamba网络。具体而言，X射线图像被分割成图像块、进行标记化，并通过基于SSM的视觉骨干网络进行处理以提取特征，其中Partial LoRA取得了最佳性能。一个带有混合解码器的大型语言模型生成医学报告，实现了端到端训练，并在基准数据集上取得了优异结果。在三个广泛使用的基准数据集上进行的广泛实验充分验证了我们为X射线MRG提出的策略的有效性。本文的源代码将发布在https://github.com/Event-AHU/Medical_Image_Analysis。|
|**2025-10-16**|[Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection](http://arxiv.org/abs/2510.14726)|null|近年来，目标检测方法通过利用注意力机制提高特征判别性，取得了显著进展。然而，大多数现有方法仅限于细化单层特征或融合双层特征，忽视了多尺度表示中丰富的层间依赖关系。这限制了它们捕获全面上下文信息的能力，而这些信息对于检测尺度变化较大的目标至关重要。在本文中，我们提出了一种新颖的跨层特征自注意力模块（CFSAM），它能够整体建模多尺度特征图中的局部和全局依赖关系。CFSAM由三个关键组件组成：一个卷积局部特征提取器，一个基于Transformer的全局建模单元，用于高效捕获跨层交互，以及一个特征融合机制，用于恢复和增强原始表示。当集成到SSD300框架中时，CFSAM显著提升了检测性能，在PASCAL VOC上实现了78.6%的mAP（基线为75.5%），在COCO上实现了52.1%的mAP（基线为43.1%），优于现有注意力模块。此外，该模块在训练过程中加速了收敛，而没有引入大量的计算开销。我们的工作强调了显式跨层注意力建模在推动多尺度目标检测方面的重要性。|
|**2025-10-15**|[Context-Selective State Space Models: Feedback is All You Need](http://arxiv.org/abs/2510.14027)|null|由注意力机制驱动的Transformer模型是大多数基础模型的核心，但它们面临二次复杂度问题，并且难以处理输入序列中的长程依赖。最近的研究表明，状态空间模型（SSM）提供了一种高效的替代方案，其中Mamba架构核心的S6模块在长序列基准测试上取得了最先进的结果。在本文中，我们引入了COFFEE（COntext From FEEdback）模型，这是一种新颖的时变SSM，它融入了状态反馈以实现上下文依赖的选择性，同时仍允许并行实现。S6的选择性机制仅依赖于当前输入，而COFFEE则从内部状态计算它，内部状态作为序列历史的紧凑表示。这一转变使得模型能够根据累积的上下文调节其动态，从而提高了其捕获长程依赖的能力。除了状态反馈，我们还采用了一种高效的模型参数化方法，该方法消除了S6中存在的冗余，并带来了更紧凑、更易于训练的公式。在归纳头任务上，与S6相比，COFFEE在参数量和训练序列数量少两个数量级的情况下，实现了近乎完美的准确率。在MNIST数据集上，COFFEE在相同架构下大幅优于S6，仅用3585个参数就达到了97%的准确率。这些结果展示了状态反馈作为构建可扩展且高效序列模型的关键机制的作用。|
|**2025-10-14**|[Dual-attention ResNet outperforms transformers in HER2 prediction on DCE-MRI](http://arxiv.org/abs/2510.13897)|null|乳腺癌是女性最常诊断的癌症，其HER2状态对治疗决策至关重要。从动态对比增强MRI (DCE-MRI) 无创预测HER2状态可以简化诊断流程并减少对活检的依赖。然而，将高动态范围DCE-MRI预处理成用于预训练神经网络的标准化8位RGB格式并非易事，并且归一化策略显著影响模型性能。我们使用一个处理来自三个DCE期RGB融合时间序列的三头双注意力ResNet，对强度归一化策略进行了基准测试。该模型在I-SPY试验的多中心队列（n=1,149）上进行训练，并在BreastDCEDL_AMBL（n=43个病灶）上进行外部验证，其性能优于基于Transformer的架构，在I-SPY测试数据上达到了0.75的准确率和0.74的AUC。N4偏置场校正略微降低了性能。未经微调，外部验证的AUC为0.66，证明了跨机构的泛化能力。这些发现强调了双注意力机制在捕获可迁移的时空特征以进行HER2分层方面的有效性，推动了乳腺癌影像学中可复现的深度学习生物标志物的发展。|
|**2025-10-15**|[T3former: Temporal Graph Classification with Topological Machine Learning](http://arxiv.org/abs/2510.13789)|null|时序图分类在网络安全、大脑连接分析、社会动态和交通监控等应用中发挥着关键作用。尽管其重要性，与时序链接预测或节点预测相比，该问题仍未得到充分探索。现有方法通常依赖于基于快照或循环架构，这些架构要么丢失细粒度时序信息，要么难以处理长程依赖。此外，局部消息传递方法存在过平滑和过压缩问题，限制了它们捕获复杂时序结构的能力。我们提出T3former，一种新颖的拓扑时序Transformer，它利用滑动窗口拓扑和谱描述符作为一等公民标记，并通过专门的描述符注意力机制进行集成。这种设计保持了时序保真度，增强了鲁棒性，并在不进行刚性离散化的情况下实现了原则性的跨模态融合。T3former在包括动态社交网络、大脑功能连接数据集和交通网络在内的多个基准上取得了最先进的性能。它还在时序和结构扰动下提供了理论上的稳定性保证。我们的结果突出了结合拓扑和谱学见解对于推进时序图学习前沿的力量。|
|**2025-10-14**|[Efficient Adaptive Transformer: An Empirical Study and Reproducible Framework](http://arxiv.org/abs/2510.12856)|null|高效自适应Transformer (EAT) 框架将渐进式词元剪枝、稀疏注意力和动态提前退出这三种自适应效率技术统一到一个单一的、可复现的架构中，以实现输入自适应推理。EAT提供了一个开源基准测试管道，该管道可自动化GLUE任务（SST-2、QQP、MNLI）中的数据处理、计时和消融实验。尽管这项经验研究发现，在浅层六层模型中结合这些机制可能会增加延迟，但它证明了EAT在SST-2上实现了比优化过的DistilBERT基线略高的准确性，这说明了动态计算在延迟敏感型NLP中的潜力。其主要贡献是这个开放的、端到端可复现的框架——包含脚本、CSV日志记录和分析工具——旨在作为社区工具，用于对自适应Transformer的进一步研究。|
|**2025-10-14**|[Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis](http://arxiv.org/abs/2510.12704)|null|基于Transformer的深度学习模型通过利用注意力机制进行特征表示和可解释性，在医学成像领域展现出卓越性能。然而，这些模型容易学习到虚假关联，导致偏差和泛化能力受限。尽管人机注意力对齐可以缓解这些问题，但它通常依赖于昂贵的人工监督。在这项工作中，我们提出了一种混合解释引导学习（H-EGL）框架，该框架结合了自监督和人工引导约束，以增强注意力对齐并提高泛化能力。H-EGL的自监督组件利用类别区分性注意力，而不依赖于限制性先验，从而提升了鲁棒性和灵活性。我们使用Vision Transformer (ViT) 在胸部X光分类任务上验证了我们的方法，结果表明H-EGL超越了两种最先进的解释引导学习（EGL）方法，展现出卓越的分类准确性和泛化能力。此外，它生成的注意力图与人类专业知识更好地对齐。|
|**2025-10-15**|[Self-attention enabled quantum path analysis of high-harmonic generation in solids](http://arxiv.org/abs/2510.12443)|null|固体中的高次谐波产生（HHG）提供了一个强大的平台来探测超快电子动力学和跨带-带内耦合。然而，在HHG谱中分离复杂的多个体贡献仍然具有挑战性。本文引入了一种基于Transformer编码器的机器学习方法，用于分析和重建从一维Kronig--Penney模型计算出的HHG信号。自注意力机制内在突出了时间偶极子动力学与高频谱分量之间的相关性，使我们能够识别非绝热能带耦合的特征，而这些特征在标准傅里叶分析中会被掩盖。通过将注意力图与Gabor时频分析相结合，我们提取并放大了对偶次谐波和反常光谱特征有贡献的弱耦合通道。我们的结果表明，多头自注意力充当了时域中强耦合事件的选择性滤波器，从而实现了对高维量子动力学的物理学知情解释。这项工作确立了基于Transformer的注意力作为固态强场物理学的通用工具，为阿秒光谱学和非线性光子学中的可解释机器学习开辟了新的可能性。|
|**2025-10-14**|[Self-attention enabled quantum path analysis of high-harmonic generation in solids](http://arxiv.org/abs/2510.12443)|null|固体中高次谐波产生（HHG）为探测超快电子动力学和跨带-带内耦合提供了强大平台。然而，分离HHG谱中复杂的多体贡献仍然具有挑战性。本文中，我们引入了一种基于Transformer编码器的机器学习方法，用于分析和重构从一维Kronig-Penney模型计算得到的HHG信号。自注意力机制本质上突出了时间偶极动力学与高频谱成分之间的关联，使我们能够识别出在标准傅里叶分析中被掩盖的非绝热能带耦合特征。通过将注意力图与Gabor时频分析相结合，我们提取并放大了对偶次谐波和反常谱特征有贡献的弱耦合通道。我们的结果表明，多头自注意力在时域中充当强耦合事件的选择性滤波器，从而实现了对高维量子动力学的物理学信息指导的解释。这项工作确立了基于Transformer的注意力作为固态强场物理学的一种多功能工具，为阿秒光谱学和非线性光子学中的可解释机器学习开辟了新的可能性。|
|**2025-10-14**|[Biased-Attention Guided Risk Prediction for Safe Decision-Making at Unsignalized Intersections](http://arxiv.org/abs/2510.12428)|null|无信号交叉口处的自动驾驶决策因复杂的动态交互和高冲突风险而极具挑战性。为实现主动安全控制，本文提出了一种融合偏置注意力机制的深度强化学习（DRL）决策框架。该框架基于Soft Actor-Critic (SAC) 算法。其核心创新点在于利用偏置注意力构建交通风险预测器。该预测器评估车辆驶入交叉口时的长期碰撞风险，并将该风险转化为密集奖励信号，以指导SAC智能体做出安全高效的驾驶决策。最后，仿真结果表明，所提出的方法有效提升了交叉口的交通效率和车辆安全，从而证明了该智能决策框架在复杂场景中的有效性。我们的工作代码可在https://github.com/hank111525/SAC-RWB获取。|
|**2025-10-14**|[Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models](http://arxiv.org/abs/2510.12137)|null|大语言模型（LLM）会产生幻觉，即生成事实不正确但自信的断言。我们认为这源于Transformer的Softmax函数，该函数通过将模糊的注意力分数坍缩为单一概率分布，从而在每一层丢弃不确定性信息，进而产生“人工确定性”。为了解决这个问题，我们引入了Credal Transformer，它用基于证据理论的Credal注意力机制（CAM）取代了标准注意力。CAM产生一个“可信集”（一个分布集合）而非单一注意力向量，该集合的大小直接衡量模型的不确定性。我们通过将注意力分数重新概念化为Dirichlet分布的证据质量来实现这一点：充分的证据会恢复标准注意力，而不充分的证据则会产生一个扩散分布，代表模糊性。经验上，Credal Transformer能够识别出分布外输入，量化模糊性，并通过拒绝回答显著减少在无法回答问题上的自信错误。我们的贡献是一种减轻幻觉的新架构，以及一种将不确定性量化直接集成到模型中的设计范式，为更可靠的人工智能奠定了基础。|
|**2025-10-13**|[Evaluating the Explainability of Vision Transformers in Medical Imaging](http://arxiv.org/abs/2510.12021)|null|理解模型决策在医学影像中至关重要，因为可解释性直接影响临床信任和采纳。视觉Transformer (ViT) 在诊断成像中展现了最先进的性能；然而，其复杂的注意力机制对可解释性提出了挑战。本研究使用梯度注意力展开和Grad-CAM评估了不同视觉Transformer架构和预训练策略（ViT、DeiT、DINO和Swin Transformer）的可解释性。我们对两个医学影像任务：外周血细胞分类和乳腺超声图像分类，进行了定量和定性分析。我们的发现表明，DINO结合Grad-CAM在跨数据集中提供了最忠实和局部化的解释。Grad-CAM始终生成类别区分性且空间精确的热力图，而梯度注意力展开则产生了更分散的激活。即使在错误分类的情况下，DINO结合Grad-CAM也能突出显示似乎误导了模型的临床相关形态学特征。通过提高模型透明度，本研究支持将ViT可靠且可解释地集成到关键的医学诊断工作流程中。|
|**2025-10-13**|[WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation](http://arxiv.org/abs/2510.11839)|null|时间序列在许多涉及预测、分类和因果推断任务的应用中无处不在，例如医疗保健、金融、音频信号处理和气候科学。然而，大规模、高质量的时间序列数据集仍然稀缺。合成生成可以解决这一局限性；但当前局限于时域或频域的模型难以重现真实世界时间序列固有的多尺度结构。我们引入了WaveletDiff，一个新颖的框架，它直接在小波系数上训练扩散模型，以利用时间序列数据固有的多分辨率结构。该模型为每个分解层级结合了专用Transformer，并带有跨层级注意力机制，通过自适应门控实现时域和频域尺度之间的选择性信息交换。它还根据帕塞瓦尔定理为每个层级引入了能量守恒约束，以在整个扩散过程中保持频谱保真度。对来自能源、金融和神经科学领域的六个真实世界数据集进行的全面测试表明，WaveletDiff在短期和长期时间序列上，通过五种不同的性能指标，持续优于最先进的时域和频域生成方法。例如，WaveletDiff在所有数据集上的判别分数和Context-FID分数平均比次优基线小3倍。|
|**2025-10-13**|[Deconstructing Attention: Investigating Design Principles for Effective Language Modeling](http://arxiv.org/abs/2510.11602)|null|Transformer语言模型的成功广泛归因于它们的点积注意力机制，该机制融合了一系列关键设计原则：跨位置信息混合（实现多词元交互）、序列依赖的激活（注意力权重适应每个输入）、特定的数学形式（点积相似度加上softmax加权），以及查询和键与演化隐藏状态的耦合（将注意力锚定在当前层）。然而，这些原则中每个的必要性仍未得到充分检验。在这项工作中，我们通过设计受控变体来系统地解构注意力，这些变体有选择地放宽了上述原则，既统一应用于所有层，也应用于仅有部分层保留标准注意力的混合架构。我们的实证分析表明，词元混合机制是不可或缺的，因为它们的缺失会导致模型崩溃，表现出接近随机的行为；而精确的数学形式和序列依赖性可以被大幅放宽，尤其是在仅保留在部分层中时。令人惊讶的是，即使是单独失败的变体，当与标准注意力交错使用时也能实现稳健的性能，这凸显了一种协作效应。这些发现深化了我们对注意力有效性真正基础的理解，并为在不牺牲性能的情况下简化语言模型开辟了新途径。|
|**2025-10-13**|[An AI dose engine for fast carbon ion treatment planning](http://arxiv.org/abs/2510.11271)|null|蒙特卡罗(MC)模拟为碳离子治疗剂量计算提供金标准精度，但计算密集。解析式笔形束算法速度快，但在异质组织中精度降低。我们开发了首个基于AI的剂量引擎，能够预测碳离子治疗中吸收剂量以及用于相对生物学效应(RBE)加权优化的alpha和beta参数，以大幅缩短计算时间实现MC级别精度。我们扩展了基于Transformer的DoTA模型来预测吸收剂量(C-DoTA-d)、alpha(C-DoTA-alpha)和beta(C-DoTA-beta)，并为alpha和beta引入了交叉注意力机制以结合剂量和能量输入。训练数据集包含来自187名头颈部患者的约70,000个笔形束，真值通过GPU加速的MC工具包FRED获得。性能通过gamma通过率(1%/1毫米)、深度剂量曲线和等剂量线Dice系数在独立测试集上进行评估。我们进行了基于MC dropout的不确定性分析。所有预测的中位gamma通过率均超过98%(剂量为99.76%，alpha为99.14%，beta为98.74%)，在最异质的解剖结构中最小值也高于85%。1%等剂量线的Dice系数为0.95，在高梯度区域一致性略有降低。与MC FRED相比，推理速度快400多倍(每个笔形束0.032秒 vs. 14秒)，同时保持了精度。不确定性分析显示出高稳定性，所有模型的平均标准差均低于0.5%。C-DoTA实现了每个射束约30毫秒的MC质量吸收剂量和RBE模型参数预测。其速度和精度支持在线自适应规划，为更有效的碳离子治疗工作流程铺平了道路。未来工作将扩展到额外的解剖部位、射束几何形状和临床射束线。|
|**2025-10-13**|[Text-Enhanced Panoptic Symbol Spotting in CAD Drawings](http://arxiv.org/abs/2510.11091)|null|随着计算机辅助设计 (CAD) 图纸在工程、建筑和工业设计领域的广泛应用，准确解释和分析这些图纸的能力变得越来越重要。在各种子任务中，全景符号识别 (panoptic symbol spotting) 在支持 CAD 自动化和设计检索等下游应用中扮演着至关重要的角色。现有方法主要关注 CAD 图纸中的几何图元来解决此任务，但它们面临以下主要问题：通常忽略了 CAD 图纸中丰富的文本标注，并且缺乏对图元之间关系的显式建模，导致对整体图纸的理解不全面。为了弥补这一空白，我们提出了一个融入文本标注的全景符号识别框架。该框架通过联合建模几何图元和文本图元来构建统一的表示。然后，该框架使用预训练卷积神经网络 (CNN) 提取的视觉特征作为初始表示，并采用基于 Transformer 的骨干网络，该网络通过类型感知注意力机制进行增强，以显式建模各种图元之间不同类型的空间依赖关系。在真实世界数据集上进行的广泛实验表明，所提出的方法在涉及文本标注的符号识别任务上优于现有方法，并且在应用于复杂 CAD 图纸时表现出卓越的鲁棒性。|
|**2025-10-13**|[ContextGen: Contextual Layout Anchoring for Identity-Consistent Multi-Instance Generation](http://arxiv.org/abs/2510.11000)|**[link](https://github.com/nenhang/ContextGen)**|多实例图像生成（MIG）对于现代扩散模型而言仍是一个重大挑战，主要原因是其在实现对物体布局的精确控制以及保持多个不同主体的身份方面存在局限性。为解决这些局限性，我们引入了ContextGen，一个新颖的扩散Transformer框架，用于由布局和参考图像共同指导的多实例生成。我们的方法结合了两项关键技术贡献：一个上下文布局锚定（CLA）机制，它将复合布局图像整合到生成上下文中，以稳健地将物体锚定在其所需位置；以及一个身份一致性注意力（ICA）机制，这是一种创新的注意力机制，它利用上下文参考图像来确保多实例的身份一致性。鉴于这项任务缺乏大规模、分层结构的数据集，我们引入了IMIG-100K，这是第一个具有详细布局和身份标注的数据集。大量实验表明，ContextGen在控制精度、身份保真度和整体视觉质量方面均优于现有方法，达到了新的最先进水平。|
|**2025-10-08**|[Transformer-Based Indirect Structural Health Monitoring of Rail Infrastructure with Attention-Driven Detection and Localization of Transient Defects](http://arxiv.org/abs/2510.07606)|null|间接结构健康监测（iSHM）利用车载传感器进行断轨检测，为铁路轨道评估提供了一种经济高效的范式，然而，由于复杂的车辆动力学、信号噪声以及限制监督方法的标注数据稀缺性，可靠地检测小型瞬态异常（2-10厘米）仍然是一个重大挑战。本研究通过无监督深度学习解决了这些问题。我们引入了一个增量合成数据基准，旨在系统地评估模型在应对iSHM中遇到的逐渐复杂的挑战（例如速度变化、多通道输入和真实噪声模式）时的鲁棒性。利用这个基准，我们评估了几种成熟的无监督模型以及我们提出的注意力聚焦Transformer。我们的模型采用自注意力机制，通过重建进行训练，但创新性地主要从学习到的注意力权重的偏差中推导出异常分数，旨在实现有效性和计算效率。基准测试结果表明，尽管基于Transformer的模型通常优于其他模型，但所有测试的模型都对高频局部噪声表现出显著的脆弱性，将此确定为实际部署的关键瓶颈。值得注意的是，我们提出的模型实现了与最先进解决方案相当的准确性，同时展现出更好的推理速度。这凸显了未来iSHM模型中增强噪声鲁棒性的关键需求，并将我们更高效的基于注意力的方法定位为开发实用车载异常检测系统的一个有前景的基础。|
|**2025-10-08**|[Attention to Order: Transformers Discover Phase Transitions via Learnability](http://arxiv.org/abs/2510.07401)|null|相变标志着集体行为的质性重组，然而，在缺乏解析解和传统模拟失效的情况下，识别其边界仍然具有挑战性。在此我们引入可学习性作为普适判据，其定义为包含注意力机制的Transformer模型从微观态中提取结构的能力。利用自监督学习和二维伊辛模型的蒙特卡洛生成构型，我们表明有序相对应于增强的可学习性，这体现在训练损失的降低和结构化注意力模式的出现，而无序相则仍然难以学习。两种无监督诊断方法，即训练损失的急剧跳变和注意力熵的上升，恢复了临界温度，并与精确值高度一致。我们的结果确立了可学习性作为相变的数据驱动标记，并强调了凝聚态物质中长程有序与现代语言模型中结构涌现之间的深刻并行性。|
|**2025-10-08**|[Grouped Differential Attention](http://arxiv.org/abs/2510.06949)|null|自注意力机制作为现代Transformer架构的基础，存在一个关键的低效率问题：它经常将大量注意力分配给冗余或噪声上下文。差分注意力通过使用用于信号和噪声的减法注意力图解决了这个问题，但其所需的平衡头部分配对表征灵活性和可扩展性施加了严格限制。为了克服这一点，我们提出了分组差分注意力（GDA），这是一种新颖的方法，它在信号保留组和噪声控制组之间引入了不平衡的头部分配。GDA通过策略性地将更多头部分配给信号提取，将更少头部分配给噪声控制，并通过受控重复（类似于GQA）来稳定后者，从而显著增强了信号聚焦能力。这种设计以极小的计算开销实现了更强的信号保真度。我们进一步将这一原则扩展到分组差异化增长，这是一种可扩展的策略，仅选择性地复制关注信号的头部，从而确保高效的容量扩展。通过大规模预训练和持续训练实验，我们证明GDA中的适度不平衡比例与对称基线相比，在泛化能力和稳定性方面产生了显著改进。我们的结果共同表明，比例感知头部分配和选择性扩展为设计可扩展、计算高效的Transformer架构提供了一条有效且实用的途径。|
|**2025-10-08**|[Lung Infection Severity Prediction Using Transformers with Conditional TransMix Augmentation and Cross-Attention](http://arxiv.org/abs/2510.06887)|null|肺部感染，特别是肺炎，会带来严重的健康风险，尤其在大流行期间可能迅速升级。从医学影像中准确地进行基于AI的严重程度预测对于支持及时的临床决策和优化患者预后至关重要。在这项工作中，我们提出了一种适用于CT扫描和胸部X光片来评估肺部感染严重程度的新颖方法。我们的贡献有两方面：(i) QCross-Att-PVT，一种基于Transformer的架构，它整合了并行编码器、交叉门控注意力机制和特征聚合器，以捕获丰富的多尺度特征；以及 (ii) Conditional Online TransMix，一种定制的数据增强策略，旨在通过在训练期间生成混合标签图像块来解决数据集不平衡问题。在两个基准数据集RALO CXR和Per-COVID-19 CT上进行评估，我们的方法持续优于几种最先进的深度学习模型。结果强调了数据增强和门控注意力在提高鲁棒性和预测准确性方面的关键作用。这种方法提供了一种可靠、适应性强的工具，可支持临床诊断、疾病监测和个性化治疗方案规划。本工作的源代码可在https://github.com/bouthainas/QCross-Att-PVT获取。|
|**2025-10-08**|[TimeFormer: Transformer with Attention Modulation Empowered by Temporal Characteristics for Time Series Forecasting](http://arxiv.org/abs/2510.06680)|null|尽管Transformer模型在自然语言处理方面表现出色，但由于未充分考虑文本模态和时间模态之间的差异，其在时间序列预测领域的扩展仍然具有挑战性。在本文中，我们开发了一种专为时间序列数据设计的新颖Transformer架构，旨在最大化其表示能力。我们识别出时间序列的两个关键但常被忽视的特性：(1) 过去对未来的单向影响，以及 (2) 影响随时间衰减的现象。这些特性被引入以增强Transformer模型的注意力机制。我们提出了TimeFormer，其核心创新是带有两个调制项（MoSA）的自注意力机制，旨在在Hawkes过程和因果掩码的约束下捕获时间序列的这些时间先验。此外，TimeFormer引入了一个基于多尺度和子序列分析的框架，以捕获不同时间尺度上的语义依赖性，从而丰富了时间依赖性。在多个真实世界数据集上进行的大量实验表明，TimeFormer显著优于最先进的方法，与最佳基线相比，MSE降低高达7.45%，并在94.04%的评估指标上设立了新基准。此外，我们证明MoSA机制可以广泛应用于增强其他基于Transformer的模型的性能。|
|**2025-10-08**|[Rethinking Nonlinearity: Trainable Gaussian Mixture Modules for Modern Neural Architectures](http://arxiv.org/abs/2510.06660)|null|广义的神经网络，从多层感知机(MLPs)和卷积神经网络(CNNs)到基于注意力的Transformer，均由线性组合层和随后的非线性操作（如ReLU、Sigmoid或Softmax）构建而成。尽管这些传统设计功能强大，但在引入非线性方面，它们往往受限于激活函数的选择。在这项工作中，我们引入了高斯混合启发式非线性模块 (GMNM)，这是一类新型的可微分模块，它借鉴了通用密度近似的高斯混合模型(GMMs)以及高斯核的距离特性(度量空间)。通过放松概率约束并采用高斯投影的灵活参数化，GMNM可以无缝集成到各种神经网络架构中，并使用基于梯度的方法进行端到端训练。我们的实验表明，将GMNM整合到多层感知机(MLPs)、卷积神经网络(CNNs)、注意力机制和长短期记忆网络(LSTMs)等架构中，其性能始终优于标准基线。这些结果突显了GMNM作为一种强大而灵活的模块，在广泛的机器学习应用中提高效率和准确性的潜力。|
|**2025-10-07**|[ $\bf{D^3}$QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection](http://arxiv.org/abs/2510.05891)|null|视觉自回归（AR）模型的出现彻底改变了图像生成领域，同时也为合成图像检测带来了新的挑战。与以往的GAN或基于扩散的方法不同，AR模型通过离散令牌预测生成图像，这不仅在图像合成质量上表现出显著改进，而且在其矢量量化表示中呈现出独特的特性。在本文中，我们提出利用离散分布差异感知量化误差（D$^3$QE）进行自回归生成图像检测，该方法利用了真实图像和伪造图像中存在的码本的独特模式和频率分布偏差。我们引入了一个离散分布差异感知Transformer，它将动态码本频率统计信息集成到其注意力机制中，融合了语义特征和量化误差潜在表示。为了评估我们的方法，我们构建了一个名为ARForensics的综合数据集，涵盖了7种主流视觉AR模型。实验表明，D$^3$ QE在不同AR模型上具有卓越的检测精度和强大的泛化能力，并且对现实世界扰动具有鲁棒性。代码可在https://github.com/Zhangyr2022/D3QE获取。|
|**2025-10-07**|[When Does Global Attention Help? A Unified Empirical Study on Atomistic Graph Learning](http://arxiv.org/abs/2510.05583)|null|图神经网络（GNNs）被广泛用作昂贵实验和第一性原理模拟的替代方法，以研究化合物在原子尺度上的行为，其架构复杂性不断增加，以实现复杂物理现象的建模。尽管大多数最新的GNNs结合了更传统的消息传递神经网络（MPNNs）层来模拟短程相互作用，以及更先进的图Transformer（GTs）与全局注意力机制来模拟长程相互作用，但由于实现、特征或超参数调整的不一致，目前仍不清楚全局注意力机制何时能比经过精心调优的MPNN层提供真正的优势。我们引入了第一个统一的、可复现的基准测试框架——基于HydraGNN构建——该框架支持在四种受控模型类别之间无缝切换：MPNN、带有化学/拓扑编码器的MPNN、MPNN与全局注意力机制的GPS风格混合模型，以及带有编码器的完全融合的局部-全局模型。通过使用七个多样化的开源数据集进行回归和分类任务的基准测试，我们系统地分离了消息传递、全局注意力和基于编码器的特征增强的贡献。我们的研究表明，经过编码器增强的MPNNs构成了一个强大的基线，而融合的局部-全局模型对于受长程相互作用效应支配的属性产生了最明显的优势。我们进一步量化了注意力的准确性-计算权衡，并报告了其内存开销。总之，这些结果建立了原子图学习中全局注意力的首次受控评估，并为未来的模型开发提供了一个可复现的测试平台。|
|**2025-10-07**|[ATOM: A Pretrained Neural Operator for Multitask Molecular Dynamics](http://arxiv.org/abs/2510.05482)|null|分子动力学 (MD) 模拟支撑着现代计算药物发现、材料科学和生物化学。近期机器学习模型无需重复求解量子力学力即可提供高保真度MD预测，从而显著加速相较于传统流程。然而，许多此类方法通常强制执行严格的等变性并依赖于顺序展开，从而限制了它们的灵活性和模拟效率。它们也通常是单任务的，在单个分子和固定时间帧上训练，这限制了其对未见化合物和扩展时间步长的泛化能力。为了解决这些问题，我们提出了分子原子级变换器算子 (ATOM)，这是一种用于多任务分子动力学的预训练变换器神经算子。ATOM采用准等变设计，无需显式分子图，并采用时间注意力机制，从而实现多个未来状态的精确并行解码。为了支持算子在不同化学物质和时间尺度上的预训练，我们整理了TG80，这是一个大型、多样化且数值稳定的MD数据集，包含跨越80种化合物的超过250万飞秒的轨迹。ATOM在已建立的单任务基准测试（例如MD17、RMD17和MD22）上取得了最先进的性能。在TG80上进行多任务预训练后，ATOM对未见分子在不同时间范围上展现出卓越的零样本泛化能力。我们相信ATOM代表了迈向准确、高效且可迁移的分子动力学模型的重要一步。|
|**2025-10-06**|[The End of Transformers? On Challenging Attention and the Rise of Sub-Quadratic Architectures](http://arxiv.org/abs/2510.05364)|null|Transformer模型在过去七年间主导了序列处理任务，其中尤以语言建模最为显著。然而，随着上下文长度的增加，其注意力机制固有的二次复杂度仍然是一个显著的瓶颈。本文综述了为克服这一瓶颈而做出的最新努力，包括（亚二次复杂度）注意力变体、循环神经网络、状态空间模型和混合架构等方面的进展。我们从计算和内存复杂度、基准测试结果以及基本局限性等方面批判性地分析了这些方法，以评估纯注意力Transformer模型的主导地位是否可能很快受到挑战。|
|**2025-10-06**|[AUREXA-SE: Audio-Visual Unified Representation Exchange Architecture with Cross-Attention and Squeezeformer for Speech Enhancement](http://arxiv.org/abs/2510.05295)|null|本文提出AUREXA-SE（一种结合交叉注意力机制和Squeezeformer的音视频统一表示交换架构，用于语音增强），这是一个专为音视频语音增强（AVSE）设计的渐进式双模态框架。AUREXA-SE通过采用一个基于U-Net的一维卷积编码器处理音频以及一个Swin Transformer V2用于高效且富有表现力的视觉特征提取，联合利用原始音频波形和视觉线索。该架构的核心是一种新颖的双向交叉注意力机制，它促进了模态之间深度的上下文融合，从而实现丰富且互补的表示学习。为了捕获融合嵌入中的时间依赖性，我们引入了一堆结合卷积和注意力模块的轻量级Squeezeformer块。增强后的嵌入随后通过一个U-Net风格的解码器进行解码，用于直接波形重建，确保输出的语音在感知上一致且清晰可懂。实验评估证明了AUREXA-SE的有效性，相比于噪声基线取得了显著的性能提升，STOI达到0.516，PESQ达到1.323，SI-SDR达到-4.322 dB。AUREXA-SE的源代码可在https://github.com/mtanveer1/AVSEC-4-Challenge-2025获取。|
|**2025-10-06**|[On Structured State-Space Duality](http://arxiv.org/abs/2510.04944)|**[link](https://github.com/AlwaysFHao/TiM4Rec)**|结构化状态空间对偶性（SSD）[Dao & Gu, ICML 2024] 是一种简单的结构化状态空间模型（SSM）与掩码注意力机制之间的等价性。具体而言，一个具有标量乘单位矩阵状态矩阵的状态空间模型等价于一个具有1-半可分因果掩码的掩码自注意力。因此，相同的序列变换（模型）有两种算法实现方式：线性时间 $O(T)$递推或平方时间$O(T^2)$ 注意力。在这篇笔记中，我们形式化并推广了这种对偶性：(i) 我们将SSD从标量-单位矩阵情况扩展到通用对角SSM（对角状态矩阵）；(ii) 我们表明这些对角SSM在支持更丰富动态的同时，仍能达到标量情况的训练复杂度下界；(iii) 我们建立了一个SSM等价于1-半可分掩码注意力的充要条件；(iv) 我们证明了这种对偶性由于秩爆炸而无法扩展到标准softmax注意力。总而言之，这些结果紧密连接了循环SSM和Transformers，并拓宽了表达力强且高效的序列模型的设计空间。|
|**2025-10-05**|[Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention](http://arxiv.org/abs/2510.04212)|**[link](https://github.com/ucker/why-low-precision-training-fails)**|对计算效率的追求推动了在训练Transformer模型时采用低精度格式。然而，这一进展常被臭名昭著的训练不稳定性所阻碍。本文首次对一个长期存在且悬而未决的失败案例提供了机制性解释，该案例中在低精度设置下使用Flash Attention训练会导致灾难性的损失爆炸。我们的深入分析揭示，这种失败并非随机现象，而是由两种相互交织的现象引起的：注意力机制中相似低秩表示的出现，以及低精度算术中固有的有偏舍入误差的复合效应。我们展示了这些因素如何形成一个误差累积的恶性循环，从而破坏权重更新，最终导致训练动态失控。为了验证我们的发现，我们对Flash Attention进行了最小程度的修改，以减轻舍入误差中的偏差。这一简单的改变稳定了训练过程，证实了我们的分析，并为这个长期存在的问题提供了一个实用解决方案。|
|**2025-10-05**|[A Mathematical Explanation of Transformers for Large Language Models and GPTs](http://arxiv.org/abs/2510.03989)|null|Transformer架构彻底改变了序列建模领域，并支撑着大语言模型（LLMs）的近期突破。然而，解释其结构和操作的完备数学理论仍然难以捉摸。在这项工作中，我们提出了一种新颖的连续框架，将Transformer严格解释为结构化积分-微分方程的离散化。在这种表述下，自注意力机制自然地出现为非局部积分算子，而层归一化则被表征为到时间相关约束的投影。这种算子理论和变分视角为理解该架构的核心组件（包括注意力、前馈层和归一化）提供了统一且可解释的基础。我们的方法通过将整个Transformer操作嵌入令牌索引和特征维度的连续域中，超越了先前的理论分析。这形成了一个有原则且灵活的框架，不仅深化了理论洞察，而且为架构设计、分析和基于控制的解释提供了新方向。这种新解释为弥合深度学习架构和连续数学建模之间的差距迈出了一步，并为可解释且有理论基础的神经网络模型的持续发展贡献了基础性视角。|
|**2025-10-04**|[Sliding Window Attention for Learned Video Compression](http://arxiv.org/abs/2510.03926)|null|为了管理视频压缩中Transformer模型的复杂性，局部注意力机制是实际必需的。然而，将帧分割成图像块的常见方法会产生不规则感受野等架构缺陷。当适用于时间自回归模型时，以视频压缩Transformer (VCT) 为代表的这种范式还需要计算冗余的重叠窗口。本文引入了3D滑动窗口注意力 (SWA)，这是一种无图像块的局部注意力形式。通过实现一种统一空间和时间上下文处理的仅解码器架构，并提供统一的感受野，我们的方法显著提高了率失真性能，相较于VCT基线，实现了高达18.6%的Bj{\o}rntegaard Delta-rate节省。同时，通过消除对重叠窗口的需求，我们的方法将整体解码器复杂度降低了2.8倍，而其熵模型的效率则提高了近3.5倍。我们进一步分析了模型的行为，并表明虽然它受益于长距离时间上下文，但过多的上下文可能会降低性能。|
|**2025-10-04**|[Rare Text Semantics Were Always There in Your Diffusion Transformer](http://arxiv.org/abs/2510.03886)|**[link](https://github.com/seilk/tora)**|基于流和扩散的Transformer模型，多模态扩散Transformer (MM-DiT) 重塑了文本到视觉生成，并因其卓越的视觉保真度而广受赞誉。随着这些模型的进步，用户不断通过富有想象力或罕见的提示词来拓展边界，然而先进模型在生成这些内容时仍然力有不逮，因为这些概念在预训练期间通常过于稀疏，难以留下深刻的印记。在本文中，我们提出了一种简单而有效的干预方法，能够在MM-DiT内部显现稀有语义，且无需额外的训练步骤、数据、去噪时间优化或依赖外部模块（例如，大型语言模型）。具体来说，MM-DiT固有的联合注意力机制在整个Transformer块中顺序更新文本嵌入和图像嵌入。我们发现，通过在联合注意力块之前，通过方差放大在文本token嵌入周围数学性地扩展表示盆地，稀有语义在MM-DiT的输出中清晰地显现。此外，我们的结果在各种文本到视觉任务中有效泛化，包括文本到图像、文本到视频和文本驱动的图像编辑。我们的工作促使生成模型揭示用户所期望的语义，这些语义曾经隐藏但已准备好浮现。|
|**2025-10-03**|[Signature-Informed Transformer for Asset Allocation](http://arxiv.org/abs/2510.03129)|**[link](https://github.com/Yoontae6719/Signature-Informed-Transformer-For-Asset-Allocation)**|鲁棒资产配置是量化金融中的一个关键挑战，其中深度学习预测器常因目标不匹配和误差放大而表现不佳。我们引入了签名信息Transformer (SIT)，这是一种通过直接优化风险感知金融目标来学习端到端配置策略的新颖框架。SIT的核心创新包括利用路径签名来丰富地几何表示资产动态，以及将金融归纳偏置（如领先-滞后效应）嵌入模型中的签名增强注意力机制。在每日标普100股票数据上进行评估，SIT显著优于传统和深度学习基线模型，尤其是在与先预测后优化模型相比时。这些结果表明，投资组合感知目标和几何感知归纳偏置对于机器学习系统中的风险感知资本配置至关重要。|
|**2025-10-03**|[A Novel Unified Lightweight Temporal-Spatial Transformer Approach for Intrusion Detection in Drone Networks](http://arxiv.org/abs/2510.02711)|null|无人机在商业、工业和民用领域的日益融合带来了严峻的网络安全挑战，特别是由于无人机网络易受各种网络攻击。现有的入侵检测机制往往缺乏无人机动态和资源受限运行环境所需的适应性、效率和泛化能力。本文提出了TSLT-Net，一种新颖的轻量级统一的时空Transformer入侵检测系统，专为无人机网络量身定制。通过利用自注意力机制，TSLT-Net能够有效建模网络流量中的时间模式和空间依赖性，从而实现对各种入侵类型的准确检测。该框架包含一个精简的预处理流程，并在单一架构内支持多类攻击分类和二元异常检测。在包含超过230万条标记记录的ISOT无人机异常检测数据集上进行的广泛实验表明，TSLT-Net在多类检测中达到了99.99%的准确率，在二元异常检测中达到了100%的准确率，同时保持了仅0.04 MB的最小内存占用和9722个可训练参数。这些结果表明TSLT-Net是一种有效且可扩展的实时无人机网络安全解决方案，特别适用于任务关键型无人机系统中的边缘设备部署。|
|**2025-10-02**|[RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided Modeling](http://arxiv.org/abs/2510.02414)|null|重建高分辨率降雨场对洪水预报、水文建模和气候分析至关重要。然而，现有空间插值方法——无论是基于自动气象站 (AWS) 测量还是结合卫星/雷达观测——往往过度平滑关键结构，未能捕捉急剧转变和局部极端值。我们引入了RainSeer，一个结构感知重建框架，它将雷达反射率重新解释为物理基础的结构先验，捕获降雨何时、何地以及如何发展。然而，这种转变带来了两个基本挑战：(i) 将高分辨率体积雷达场转换为稀疏点式降雨观测，以及 (ii) 弥合高空水凝物与地面降水之间的物理断裂。RainSeer通过一个物理信息两阶段架构解决这些问题：一个结构到点映射器通过双向映射，将中尺度雷达结构投影到局部地面降雨中，执行空间对齐；一个地理感知降雨解码器通过因果时空注意力机制，捕获水凝物在下降、融化和蒸发过程中的语义转换。我们在两个公开数据集——RAIN-F（韩国，2017-2019）和MeteoNet（法国，2016-2018）——上评估了RainSeer，并观察到相对于最先进基线的持续改进，将平均绝对误差（MAE）降低了超过13.31%，并显著提高了重建降雨场的结构保真度。|
|**2025-10-02**|[HRTFformer: A Spatially-Aware Transformer for Personalized HRTF Upsampling in Immersive Audio Rendering](http://arxiv.org/abs/2510.01891)|null|个性化头部相关传输函数（HRTF）正开始被引入许多商业沉浸式音频应用中，对于真实感空间音频渲染至关重要。然而，其引入的主要顾虑之一是，由于HRTF测量过程的复杂性，大规模创建个性化HRTF不切实际。为了缓解这一缺点，HRTF空间上采样已被提出，旨在减少所需的测量次数。尽管先前工作采用不同的机器学习（ML）方法取得了成功，但这些模型在高上采样因子下往往难以处理远距离空间一致性和泛化能力。在本文中，我们提出了一种新颖的基于Transformer的HRTF上采样架构，利用注意力机制更好地捕捉跨HRTF球面的空间相关性。在球谐（SH）域中工作，我们的模型学习从稀疏输入测量中重建高分辨率HRTF，并显著提高了准确性。为了增强空间连贯性，我们引入了一种邻域不相似损失，以促进幅度平滑性，从而产生更真实的采样结果。我们使用感知定位模型和客观频谱失真度量来评估我们的方法。实验表明，我们的模型在生成真实、高保真度的HRTF方面，以显著优势超越了主流方法。|
|**2025-10-02**|[Sparse Query Attention (SQA): A Computationally Efficient Attention Mechanism with Query Heads Reduction](http://arxiv.org/abs/2510.01817)|null|以多头注意力（MHA）机制为核心的Transformer架构已成为人工智能领域最先进模型的事实标准。然而，MHA针对序列长度的二次计算复杂度对扩展性方面构成了显著障碍，特别是对于涉及长上下文的应用。当前解决方案，例如多查询注意力（MQA）和分组查询注意力（GQA），通过共享键（Key）和值（Value）投影，有效地解决了在自回归推理延迟中占据主导地位的内存带宽瓶颈。尽管这些方法非常成功，但它们并未减少注意力分数计算所需的基本浮点运算（FLOPs）数量，这仍然是训练和全序列处理的一个关键瓶颈。本文介绍了稀疏查询注意力（SQA），一种新颖的注意力架构，它寻求一条替代且互补的优化途径。SQA没有减少键/值头，而是减少了查询头的数量。这种架构修改直接降低了注意力机制的计算复杂度，降低的倍数与查询头数量的减少成正比，从而降低了总体FLOPs。这项工作介绍了SQA的理论基础、其数学公式以及一系列架构变体。在长序列（32k-200k token）上的经验基准测试表明，SQA在模型预训练、微调和基于编码器的任务等计算受限场景中，可以实现高达3倍的显著吞吐量提升，而在初步的小规模实验中，对模型质量的影响极小。SQA是在即将推出的Reactive Transformer架构的开发过程中被偶然发现的，这表明其作为构建更高效、更可扩展模型的强大工具的潜力。|
|**2025-10-02**|[CAT: Curvature-Adaptive Transformers for Geometry-Aware Learning](http://arxiv.org/abs/2510.01634)|null|Transformer模型在不同领域取得了强大的性能，但其注意力机制隐式地假定了欧几里得几何，这限制了它们在具有非欧几里得结构的数据上的有效性。尽管最近将Transformer扩展到双曲和球面空间分别在处理层次结构和周期性模式方面展现出潜力，但它们需要先验地选择单一几何，这在数据表现出混合几何特性时降低了灵活性。我们引入了曲率自适应Transformer (CAT)，这是一种新颖的架构，它通过轻量级、可微分的门控机制，动态学习每个token在三个几何注意力分支之间的路由。与固定几何方法不同，CAT能够实现自适应几何特化，根据token的局部关系结构将其路由到适当的曲率空间。路由网络提供了可解释的曲率偏好，同时每个分支采用针对其各自流形优化的几何特定操作。在知识图谱补全基准测试（FB15k-237、WN18RR）中，CAT在MRR和Hits@10上比固定几何基线提升了约10%，且开销极小（参数量增加5%，推理时间相当）。这些结果表明，学习到的几何自适应在复杂的关联推理中优于任何单一固定几何，从而将CAT确立为跨语言、视觉和多模态领域的混合几何架构的可扩展且可解释的基础。|
|**2025-10-02**|[ReSSFormer: A Recursive Sparse Structured Transformer for Scalable and Long-Context Reasoning](http://arxiv.org/abs/2510.01585)|null|尽管Transformer架构在跨领域展现出令人印象深刻的可扩展性，但它们在长上下文推理、计算效率和结构泛化能力方面仍面临挑战，这主要归因于刚性层堆叠、密集注意力和对位置编码的依赖。我们提出了ReSSFormer，一种递归稀疏结构化Transformer，它整合了三项互补的创新：用于有界深度迭代推理的循环推理与记忆单元（R2MU），用于高效且聚焦上下文选择的自适应稀疏注意力模块（ASAM），以及用于无位置结构归纳的自组织编码器结构（SOES）。ReSSFormer用循环推理取代了传统的深度堆叠，用令牌级和专家级稀疏性取代了完全注意力，并直接从内容中建模潜在的令牌拓扑。在语言建模、多跳问答和结构敏感任务中，ReSSFormer在同等FLOPs和参数预算下持续优于强基线，突显了其可扩展性、效率和结构灵活性。|
|**2025-10-01**|[Local Linear Attention: An Optimal Interpolation of Linear and Softmax Attention For Test-Time Regression](http://arxiv.org/abs/2510.01450)|**[link](https://github.com/Yifei-Zuo/Flash-LLA)**|Transformer架构在各个领域取得了显著成功。尽管针对Softmax注意力的高效替代方案已被广泛研究，但对基于理论洞察的更具表达力机制（即使计算成本更高）的探索相对不足。在这项工作中，我们通过提出局部线性注意力（LLA）弥补了这一空白，这是一种通过测试时回归的视角源于非参数统计的新颖注意力机制。首先，我们通过偏差-方差权衡分析表明，LLA在关联记忆方面比线性注意力和Softmax注意力具有理论优势。接下来，我们解决了其计算挑战，并提出了两种内存高效的原语来处理 $\Theta(n^2 d)$和$\Theta(n d^2)$ 的复杂度。然后，我们引入了FlashLLA，一种硬件高效的块状算法，可在现代加速器上实现可扩展的并行计算。此外，我们实现并分析了一个定制化的推理内核，显著降低了内存开销。最后，我们通过测试时回归、上下文内回归、关联回忆和状态跟踪任务，经验性地验证了LLA的优点和局限性。实验结果表明，LLA能有效适应非平稳性，在测试时训练和上下文学习中优于强大的基线模型，并为其在大规模模型中的可扩展性和适用性提供了有前景的证据。代码可在https://github.com/Yifei-Zuo/Flash-LLA获取。|
|**2025-10-01**|[CosmoUiT: A Vision Transformer-UNet Hybrid for Fast and Accurate Emulation of 21-cm Maps from the Epoch of Reionization](http://arxiv.org/abs/2510.01121)|null|对来自星系际介质的红移21厘米信号的观测将以前所未有的细节探测再电离时期（EoR）。各种模拟正在开发并使用，以预测和理解该信号的性质和形态。然而，这些模拟在大量生成时计算成本非常高且耗时。为了克服这个问题，需要一个高效的该信号的场级模拟器。然而，EoR 21厘米信号是高度非高斯的；因此，使用神经网络捕获该信号不同尺度之间的相关性，这与再电离的演化直接相关，是相当困难的。在此，我们引入CosmoUiT，一个基于UNet集成的视觉Transformer架构，以克服这些困难。CosmoUiT根据给定的输入暗物质密度场、光晕密度场和再电离参数，模拟来自EoR的21厘米信号的三维立方体。CosmoUiT利用Transformer的多头自注意力机制来捕获长程依赖，并利用UNet中的卷积层来捕获目标21厘米场中的小尺度变化。此外，模拟器的训练以输入再电离参数为条件，以便它能为不同组输入再电离参数提供21厘米场的快速准确预测。我们通过比较模拟器生成和模拟的图的各种统计量（例如，气泡尺寸分布、功率谱）和形态特征来评估我们模拟器的预测。我们进一步证明，这种基于视觉Transformer的架构能够在大尺度和小尺度上高精度地模拟整个三维21厘米信号立方体。|
|**2025-10-01**|[Gather-Scatter Mamba: Accelerating Propagation with Efficient State Space Model](http://arxiv.org/abs/2510.00862)|**[link](https://github.com/Ko-Lani/GSMamba)**|状态空间模型（SSM）——最显著的是循环神经网络（RNN）——在序列建模中历来扮演着核心角色。尽管Transformer等注意力机制因其建模全局上下文的能力而占据主导地位，但其二次复杂度及有限的可扩展性使其不太适合处理长序列。视频超分辨率（VSR）方法传统上依赖循环架构来跨帧传播特征。然而，此类方法存在梯度消失、缺乏并行性和推理速度慢等众所周知的问题。Mamba等选择性SSM的最新进展提供了一种引人注目的替代方案：通过实现具有线性时间复杂度的输入依赖状态转换，Mamba在保持强大的长程建模能力的同时，缓解了这些问题。尽管有这种潜力，由于其因果性质和缺乏显式上下文聚合，单独的Mamba难以捕获细粒度的空间依赖。为了解决这个问题，我们提出了一种混合架构，它结合了用于空间上下文聚合的移位窗口自注意力与用于高效时间传播的基于Mamba的选择性扫描。此外，我们引入了Gather-Scatter Mamba（GSM），这是一种对齐感知机制，它在Mamba传播之前将特征扭曲到时间窗口内的中心锚帧，并在之后将其散布回去，从而有效减少遮挡伪影并确保聚合信息在所有帧间的有效重新分布。官方实现可在以下网址获取：https://github.com/Ko-Lani/GSMamba。|
|**2025-10-01**|[CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation](http://arxiv.org/abs/2510.00726)|null|通过监督式模仿学习来训练机器人操纵策略，当策略遇到训练中未明确涵盖的执行变异时，仍然具有挑战性。尽管通过注意力机制整合历史上下文可以提高鲁棒性，但标准方法按顺序处理所有过去的状态，没有明确建模演示可能包含的时间结构，例如失败和恢复模式。我们提出了一种跨状态转换注意力Transformer，它采用一种新颖的状态转换注意力（STA）机制，根据学习到的状态演化模式来调节标准注意力权重，从而使策略能够根据执行历史更好地调整其行为。我们的方法将这种结构化注意力与训练期间的时间掩蔽相结合，其中视觉信息从最近的时间步中随机移除，以鼓励从历史上下文中进行时间推理。仿真评估表明，STA在所有任务上始终优于标准交叉注意力和时间建模方法（如TCN和LSTM网络），并在精度关键任务上实现了相较于交叉注意力超过2倍的改进。|
|**2025-10-01**|[Continual Learning with Query-Only Attention](http://arxiv.org/abs/2510.00365)|null|持续学习涉及从数据流中学习，不重复数据点，这种场景由于任务间的分布偏移而本质上复杂。我们提出了一种仅查询注意力机制，它丢弃了键和值，但保留了Transformer架构的核心归纳偏置。在持续学习场景中，这种简化机制显著缓解了可塑性损失和灾难性遗忘，优于选择性重新初始化等基线。我们建立了仅查询注意力、完全Transformer注意力以及模型无关元学习之间的概念联系，将它们视为元学习的实例。我们进一步提供了基于查询的模型和注意力网络为何有助于在持续学习环境中保持可塑性的直觉。最后，通过初步的Hessian谱分析，我们观察到在不同任务中保持较高曲率秩的模型倾向于保持可塑性。我们的发现表明，完全注意力可能不是捕捉持续学习中元学习益处的必需。|
|**2025-10-02**|[Large Language Models Inference Engines based on Spiking Neural Networks](http://arxiv.org/abs/2510.00133)|null|基于Transformer架构的基础模型目前在通用语言建模以及材料科学和气候等科学领域都处于最先进水平。然而，训练和部署这些模型在计算上具有挑战性，因为其时间和空间复杂度与输入序列长度呈二次关系。为解决这些局限性，已经开展了一些探索高效计算范式和模型架构的工作。在这项工作中，我们探索使用脉冲神经网络（SNN）来设计Transformer模型。使用现有代理学习方法训练大规模SNN效率低下且耗时，这是一个挑战。另一方面，将现有基于Transformer的模型转换为其等效SNN的技术无法扩展，因为实现最佳性能需要以大量脉冲时间步为代价，即增加了延迟。为此，我们提出NeurTransformer，这是一种使用现有转换方法结合监督微调方法设计用于推理的基于Transformer的SNN的方法。所提出的方法通过以下方式实现：(1) 用基于脉冲的自注意力（SSA）替换自注意力机制，(2) 将训练好的Transformer模型的前馈块转换为其等效SNN，以及 (3) 使用基于SNN的代理学习算法微调SSA块。我们对所提出的方法进行了基准测试，并使用三种模型尺寸递增的GPT-2模型变体展示了其准确性和可扩展性。我们观察到，转换后的GPT-2小型模型表现出5-12%的余弦相似度损失和9.7%的困惑度降低。最后，我们展示了SSA块与ASA块相比的能效，并表明在数字硬件上实现自注意力机制时，估计能耗降低了64.71%至85.28%。|
|**2025-09-30**|[HilbertA: Hilbert Attention for Image Generation with Diffusion Models](http://arxiv.org/abs/2509.26538)|null|为扩散Transformer设计稀疏注意力需要兼顾二维空间局部性和GPU效率，而当前方法难以实现这种权衡。现有方法强制实现二维空间局部性，但通常会导致非合并内存访问。我们提出了HilbertA，一种二维感知且GPU高效的稀疏注意力机制。HilbertA沿希尔伯特曲线重新排序图像token，以实现连续内存布局同时保留空间邻域，并在各层中采用滑动调度，从而在没有重复或非合并内存访问的情况下实现长距离信息传播。为了进一步增强跨瓦片通信和位置感知，HilbertA引入了一个小的中心共享区域。在Triton中实现的HilbertA在Flux.1-dev上相较于现有方法实现了可比的图像质量和显著加速，证明了硬件对齐的二维稀疏注意力在高分辨率图像生成中的可行性。HilbertA在生成1024×1024图像时实现了2.3倍的注意力加速，在2048×2048时最高可达4.17倍，同时实现了与基线相当或超越基线的图像质量。|
|**2025-09-30**|[TrackFormers Part 2: Enhanced Transformer-Based Models for High-Energy Physics Track Reconstruction](http://arxiv.org/abs/2509.26411)|null|高能物理实验生成的数据量正在迅速增长，这一趋势将随着即将到来的高亮度大型强子对撞机（HL-LHC）升级而加剧。数据的激增需要对整个数据处理流程进行关键性修订，其中粒子径迹重建是主要的改进对象。在我们之前的工作中，我们引入了“TrackFormers”，这是一系列基于Transformer的一次性编码器专用模型，能够有效地将“命中”（hits）与预期径迹（expected tracks）相关联。在本研究中，我们通过引入考虑“命中”之间相关性的损失函数、对（各种）Transformer注意力机制进行详细研究以及对高级别对象重建的研究，扩展了我们之前的工作。此外，我们讨论了新的数据集，这些数据集允许在“命中”级别对一系列物理过程进行训练。这些进展共同旨在提高我们径迹模型的准确性，并可能提高其效率，从而提供一个强大的解决方案，以满足下一代高能物理实验的需求。|
|**2025-09-30**|[The silence of the weights: an investigation of structural pruning strategies for attention-based audio signal architectures](http://arxiv.org/abs/2509.26207)|null|归功于注意力机制，基于Transformer的模型已在从自然语言处理到机器听觉等多个领域成为最先进的技术。然而，注意力层在训练和推理过程中都需要大量的参数和高端硬件。我们提出了一种专门针对注意力机制的新颖剪枝技术，其中我们解耦了注意力块中四个层（即查询（query）、键（keys）、值（values）和输出投影矩阵）的剪枝。我们还研究了沿头部（head）和通道（channel）维度进行剪枝的策略，并比较了音频频谱Transformer (AST) 模型在不同剪枝场景下的性能。我们的结果表明，即使剪枝50%的注意力参数，性能下降也小于1%。|
|**2025-09-30**|[VRWKV-Editor: Reducing quadratic complexity in transformer-based video editing](http://arxiv.org/abs/2509.25998)|**[link](https://github.com/abdo-RG/VRWKV-Editor)**|鉴于视频编辑领域的最新进展，侧重于空间和时间依赖性的深度学习模型已成为主要方法。然而，这些模型受传统注意力机制的二次计算复杂度困扰，使其难以适应长时长和高分辨率视频。这一限制阻碍了它们在实时视频处理等实际场景中的应用。为应对这一挑战，我们提出了一种方法，通过引入VRWKV-Editor来降低这些系统的时间和空间复杂度。VRWKV-Editor是一种新颖的视频编辑模型，它将线性时空聚合模块集成到基于视频的扩散模型中。VRWKV-Editor利用RWKV Transformer的双向加权键值循环机制来捕获全局依赖性，同时保持时间一致性，从而在不牺牲质量的情况下实现了线性复杂度。大量实验表明，与最先进的基于扩散的视频编辑方法相比，所提出的方法实现了高达3.7倍的速度提升和60%的内存使用量降低，同时在帧一致性和文本对齐方面保持了具有竞争力的性能。此外，我们对不同序列长度视频进行的比较分析证实，在长视频上，我们的方法与带有自注意力机制的架构之间的编辑速度差距变得更为显著。|
|**2025-09-30**|[EEG-based AI-BCI Wheelchair Advancement: Hybrid Deep Learning with Motor Imagery for Brain Computer Interface](http://arxiv.org/abs/2509.25667)|null|本文提出了一种融合人工智能（AI）的新颖方法，用于开发基于脑机接口（BCI）的轮椅，利用运动想象左右手运动机制进行控制。该系统旨在利用脑电图（EEG）数据，基于运动想象的左右手运动来模拟轮椅导航。一个从开源EEG存储库获取的预过滤数据集被分割成19x200的数组，以捕获手部运动的起始。数据采集的采样频率为200Hz。该系统集成了一个基于Tkinter的界面，用于模拟轮椅运动，为用户提供了一个功能性且直观的控制系统。我们提出了一种BiLSTM-BiGRU模型，与XGBoost、EEGNet和基于Transformer的模型等各种机器学习基线模型相比，该模型表现出92.26%的优越测试准确率。该基于注意力的Bi-LSTM-BiGRU模型通过交叉验证实现了90.13%的平均准确率，展示了注意力机制在BCI应用中的潜力。|
|**2025-09-29**|[FlashOmni: A Unified Sparse Attention Engine for Diffusion Transformers](http://arxiv.org/abs/2509.25401)|null|多模态扩散Transformer (DiT) 在视觉合成方面表现出卓越的能力，但其部署仍受限于巨大的计算需求。为了缓解这一瓶颈，许多基于稀疏性的加速方法已被提出。然而，它们多样化的稀疏模式通常需要定制化的核函数来实现高性能推理，这限制了其普适性。我们提出了FlashOmni，一个兼容任意DiT架构的统一稀疏注意力引擎。FlashOmni引入了灵活的稀疏符号，以标准化表示特征缓存和块稀疏跳过等多种稀疏策略。这种统一的抽象使得在单个注意力核函数内执行多样化的稀疏计算成为可能。此外，FlashOmni为注意力块设计了优化的稀疏GEMM，利用稀疏符号消除冗余计算，进一步提高了效率。实验表明，FlashOmni在注意力机制和GEMM-Q中实现了接近线性且与稀疏度比例（1:1）紧密匹配的加速，并在GEMM-O中实现了2.5倍至3.8倍的加速（最高可达理论极限的约87.5%）。结合多粒度稀疏策略应用时，它使得混元模型（33K）能够实现约1.5倍的端到端加速，且不降低视觉质量。|
|**2025-09-29**|[A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland](http://arxiv.org/abs/2509.25393)|**[link](https://github.com/WendongYao/Wendong_2025_Spatiotemporal_InSAR_dataset_prediction)**|预测高分辨率地表沉降是一项关键但具有挑战性的任务，原因在于其复杂、非线性的动态特性。尽管ConvLSTM等标准架构通常难以建模长程依赖性，但我们认为先前工作的一个更根本的局限在于单模态数据范式。为解决此问题，我们提出了多模态时空Transformer (MM-STT)，这是一种融合动态位移数据与静态物理先验知识的新颖框架。其核心创新在于一种联合时空注意力机制，该机制以统一的方式处理所有多模态特征。在公开的EGMS数据集上，MM-STT建立了新的最先进水平，与所有基线方法（包括STGCN和STAEformer等SOTA方法）相比，将长程预测的RMSE降低了一个数量级。我们的结果表明，对于这类问题，架构固有的深度多模态融合能力对于实现变革性性能至关重要。|
|**2025-09-29**|[VideoAnchor: Reinforcing Subspace-Structured Visual Cues for Coherent Visual-Spatial Reasoning](http://arxiv.org/abs/2509.25151)|null|多模态大语言模型（MLLMs）在视觉-语言对齐方面取得了令人瞩目的进展，但在视觉-空间推理方面仍存在局限性。我们首先发现，这一局限性源于注意力机制：视觉 token 被语言 token 掩盖，从而阻止模型持续识别跨帧的相同视觉线索。为了解决这一挑战，我们在稀疏子空间聚类的自表达特性与 Transformer 中的注意力机制之间建立了一种新颖的联系。基于这一洞察，我们提出了 VideoAnchor，一个即插即用模块，它利用子空间亲和性在无需重新训练的情况下增强跨帧的视觉线索，有效地将注意力锚定到共享的视觉结构上。在多个基准测试和骨干模型上的大量实验显示出持续的性能提升，例如，在使用 InternVL2-8B 和 Qwen2.5VL-72B 时，在 VSI-Bench 和 Video-MME（空间相关任务）上分别提高了3.2%和4.6%，同时定性分析表明其实现了更连贯的子空间划分和更强的视觉基础。我们的代码将在 https://github.com/feufhd/VideoAnchor 公开。|
|**2025-09-29**|[Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion Transformer](http://arxiv.org/abs/2509.24899)|null|基于Transformer的视频扩散模型（VDM）提供了最先进的视频生成质量，但受限于自注意力的二次成本，这使得处理长序列和高分辨率时的计算成本高昂。虽然线性注意力提供了亚二次复杂度，但先前的尝试未能匹配Softmax注意力的表达能力，除非进行高昂的重新训练。我们引入了“注意力手术”（Attention Surgery），这是一个高效的框架，用于在预训练VDM中实现注意力机制的线性化或混合化，而无需从头开始训练。受语言模型最新进展的启发，我们的方法结合了一种新颖的混合注意力机制——混合了Softmax和线性token——以及一个轻量级的蒸馏和微调流程，仅需数个GPU-天。此外，我们引入了成本感知块率策略，以平衡跨层的表达能力和效率。将“注意力手术”应用于最先进的基于DiT的VDM Wan2.1 1.3B，我们实现了首个具有竞争力的亚二次注意力视频扩散模型，将FLOPs衡量的注意力成本降低了高达40%，同时在标准VBench和VBench-2.0基准测试中保持了生成质量。|
|**2025-09-29**|[InfLLM-V2: Dense-Sparse Switchable Attention for Seamless Short-to-Long Adaptation](http://arxiv.org/abs/2509.24663)|null|长序列处理是现代大型语言模型的关键能力。然而，标准Transformer架构中的自注意力机制在处理长序列时面临严重的计算和内存瓶颈。尽管可训练的稀疏注意力方法提供了一种有前景的解决方案，但NSA等现有方法引入了过多的额外参数，并打破了传统的“短序列预训练，长序列微调”工作流，导致收敛缓慢和加速困难。为了克服这些限制，我们引入了密-稀可切换注意力框架，命名为InfLLM-V2。InfLLM-V2是一种可训练的稀疏注意力，能够无缝地将模型从短序列适应到长序列。具体来说，InfLLM-V2通过无参数架构修改重用密集注意力参数，保持了短序列和长序列处理之间的一致性。此外，InfLLM-V2通过对短输入使用密集注意力，并平滑过渡到长序列的稀疏注意力，确保了所有序列长度下的计算效率。为了实现实际加速，我们进一步引入了InfLLM-V2的高效实现，显著降低了计算开销。我们在长上下文理解和思维链推理方面的实验表明，InfLLM-V2比密集注意力快4倍，同时分别保持了98.1%和99.7%的性能。基于InfLLM-V2框架，我们训练并开源了MiniCPM4.1（https://huggingface.co/openbmb/MiniCPM4.1-8B），这是一个混合推理模型，为研究社区提供了一个可复现的实现。|
|**2025-09-26**|[RAPID^3: Tri-Level Reinforced Acceleration Policies for Diffusion Transformer](http://arxiv.org/abs/2509.22323)|null|扩散Transformer (DiT) 在视觉生成方面表现出色，但仍受限于缓慢的采样速度。现有的免训练加速器——如步长缩减、特征缓存和稀疏注意力——能够提升推理速度，但通常依赖于对所有图像采用统一的启发式方法或手动设计的自适应策略，牺牲了一定的生成质量。另一方面，动态神经网络提供了每图像自适应加速，但其高昂的微调成本限制了更广泛的应用。为解决这些局限性，我们引入了RAPID3：用于扩散Transformer的三级强化加速策略，该框架在不对基础生成器进行任何更新的情况下实现了图像级加速。具体而言，三个轻量级策略头——步长跳过、缓存重用和稀疏注意力——观察当前的去噪状态，并在每个时间步独立决定其相应的加速策略。所有策略参数通过组相对策略优化 (GRPO) 进行在线训练，同时生成器保持冻结。同时，一个对抗学习的判别器增强了奖励信号，仅当生成的样本与原始模型的分布保持接近时才提升回报，从而阻止奖励作弊。在包括Stable Diffusion 3和FLUX在内的最先进DiT骨干网络上，RAPID3实现了近3倍的采样加速，且保持了具有竞争力的生成质量。|
|**2025-09-26**|[Statistical Advantage of Softmax Attention: Insights from Single-Location Regression](http://arxiv.org/abs/2509.21936)|null|大型语言模型依赖于采用 softmax 激活的注意力机制。然而，softmax 相对于替代方案（例如逐分量或线性）的优势仍知之甚少，并且许多理论研究侧重于更易于分析的线性化注意力。在这项工作中，我们通过对单位置回归任务进行一项有原则的研究来弥补这一空白，其中输出取决于随机位置处单个输入 token 的线性变换。借鉴统计物理学的思想，我们开发了在高维极限下对基于注意力的预测器的分析，其中泛化性能由一小部分序参数捕获。在总体层面，我们表明 softmax 达到了贝叶斯风险，而线性注意力则根本不足。然后我们检查其他激活函数，以确定哪些属性对于最优性能是必要的。最后，我们分析了有限样本机制：我们提供了测试误差的渐近表征，并表明，虽然 softmax 不再是贝叶斯最优的，但它始终优于线性注意力。我们讨论了与基于梯度的算法优化的联系。|
|**2025-09-26**|[SynerGen: Contextualized Generative Recommender for Unified Search and Recommendation](http://arxiv.org/abs/2509.21777)|null|大规模推荐系统中主流的“检索-然后-排序”流水线由于其架构分离和不同的优化目标，面临校准不当和工程开销问题。尽管近期的生成式序列模型通过自回归地生成排序后的项目，在统一检索和排序方面展现出潜力，但现有解决方案通常只解决个性化搜索或无查询推荐中的一个，并且在尝试统一两者时常常表现出性能权衡。我们提出了SynerGen，这是一种新颖的生成式推荐模型，通过为个性化搜索和推荐提供单一的生成式骨干，弥补了这一关键空白，同时在检索和排序任务中表现出色。我们的仅解码器Transformer在行为序列上进行训练，利用InfoNCE进行检索的联合优化和混合点对损失进行排序，从而使来自搜索的语义信号能够改善推荐，反之亦然。我们还提出了一种新颖的时间感知旋转位置嵌入，以有效地将时间信息整合到注意力机制中。与强大的生成式推荐器和联合搜索推荐基线模型相比，SynerGen在广泛采用的推荐和搜索基准上取得了显著改进。这项工作证明了单一生成式基础模型在工业规模统一信息访问方面的可行性。|
|**2025-09-25**|[Decoupled-Value Attention for Prior-Data Fitted Networks: GP Inference for Physical Equations](http://arxiv.org/abs/2509.20950)|null|先验数据拟合网络 (PFNs) 是耗时的高斯过程 (GP) 推断的一种有前途的替代方案，可用于创建物理系统的快速替代模型。PFN通过将GP中的贝叶斯推断替换为学习到的预测模型的单次前向传播，减轻了GP训练的计算负担。然而，使用标准的Transformer注意力机制，PFNs在高维回归任务上表现出有限的有效性。我们引入了解耦值注意力机制 (DVA)，其灵感来源于GP的特性，即函数空间完全由输入上的核函数刻画，且预测均值是训练目标的加权和。DVA仅从输入计算相似度，并仅通过值传播标签。因此，所提出的DVA模拟了高斯过程的更新，同时保持无核化。我们证明，扩展PFNs的关键因素是注意力规则而不是架构本身。具体而言，我们的结果表明 (a) 局部注意力机制在不同维度设置下的PFNs中持续降低了样本外验证损失，在五维和十维情况下，验证损失降低了50%以上，并且 (b) 注意力机制的作用比骨干架构的选择更具决定性，表明基于CNN的PFNs可以与基于Transformer的PFNs表现相当。所提出的PFNs提供了64维潮流方程近似，平均绝对误差约为1E-3，同时比精确GP推断快80多倍。|
|**2025-09-25**|[Why Attention Fails: The Degeneration of Transformers into MLPs in Time Series Forecasting](http://arxiv.org/abs/2509.20942)|null|基于Transformer的架构在自然语言处理和计算机视觉领域取得了高性能，然而许多研究表明，它们在时间序列预测中并未展现出明显优势，甚至在某些情况下表现不如简单的线性基线。然而，这些研究大多未能彻底探究Transformer失败背后的原因。为了更好地理解时间序列Transformer (TST)，我们设计了一系列实验，逐步将Transformer修改为多层感知机(MLP)以探究注意力机制的影响。令人惊讶的是，在现有的时间序列Transformer中，Transformer块经常退化为简单的多层感知机。我们设计了一个可解释的数据集来探究注意力机制失败背后的原因，并揭示了注意力机制并未以预期方式工作。我们从理论上分析了这种现象背后的原因，表明当前的嵌入方法未能使Transformer在结构良好的潜在空间中发挥作用，并进一步分析了嵌入失败更深层次的根本原因。|
|**2025-09-25**|[DENet: Dual-Path Edge Network with Global-Local Attention for Infrared Small Target Detection](http://arxiv.org/abs/2509.20701)|null|红外小目标检测对于灾害预警和海上监视等遥感应用至关重要。然而，由于缺乏独特的纹理和形态特征，红外小目标极易融入杂乱和嘈杂的背景中。为该任务设计深度模型的一个根本挑战在于，捕获微小目标的高分辨率空间细节与提取较大目标的鲁棒语义上下文之间存在内在冲突，这通常会导致特征错位和次优性能。现有方法通常依赖于固定梯度算子或简单的注意力机制，这些方法不足以在低对比度和高噪声条件下准确提取目标边缘。在本文中，我们提出了一种新颖的双路径边缘网络，通过将边缘增强和语义建模解耦为两个互补的处理路径来明确解决这一挑战。第一条路径采用双向交互模块，该模块使用局部自注意力和全局自注意力来捕获多尺度局部和全局特征依赖性。基于Transformer架构的全局注意力机制整合了长距离语义关系和上下文信息，确保了鲁棒的场景理解。第二条路径引入了多边缘细化器，该细化器使用级联的泰勒有限差分算子在多个尺度上增强细粒度边缘细节。这种数学方法结合注意力驱动的门控机制，实现了对不同尺寸目标的精确边缘定位和特征增强，同时有效抑制噪声。我们的方法为精确的红外小目标检测和定位提供了一个有前景的解决方案，在一个统一的框架中结合了结构语义和边缘细化。|
|**2025-09-25**|[From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training](http://arxiv.org/abs/2509.20072)|null|大语言模型（LLMs）的近期进展引起了将LLMs能力扩展到多模态场景的广泛关注，特别是对于语音到语音对话系统。然而，现有处理交错音频和文本的多模态模型依赖于自回归方法，忽略了文本依赖于目标-目标关系，而音频主要依赖于源-目标关系。在这项工作中，我们提出了Text-to-Talk（TtT），一个统一的音频-文本框架，它将自回归（AR）文本生成与非自回归（NAR）音频扩散集成在一个Transformer中。通过利用吸收离散扩散的任意顺序自回归特性，我们的方法为文本和音频提供了一个统一的训练目标。为了支持这种混合生成范式，我们设计了一种模态感知注意力机制，该机制对文本强制执行因果解码，同时允许在音频片段内进行双向建模，并进一步引入了三种训练策略以减少训练-测试差异。在推理过程中，TtT采用块级扩散以并行合成音频，同时灵活处理可变长度输出。在音频问答（Audio-QA）和自动语音识别（ASR）任务上的大量实验证明了我们方法的有效性，并通过详细的消融研究验证了每个提出的组件。我们将开源我们的模型、数据和代码，以促进该方向的未来研究。|
|**2025-09-23**|[Mamba Modulation: On the Length Generalization of Mamba](http://arxiv.org/abs/2509.19633)|null|Transformer模型中注意力机制的二次复杂度促使了具有次二次缩放特性的替代架构（如状态空间模型）的发展。其中，Mamba已成为一种领先架构，在一系列语言建模任务中取得了最先进的结果。然而，当Mamba应用于比预训练时更长的上下文时，其性能会显著下降，这揭示了其对上下文长度扩展的显著敏感性。通过详细分析，我们将这一局限性归因于其状态空间动态的分布外行为，特别是在状态转移矩阵 $\mathbf{A}$的参数化中。与近期将这种敏感性归因于离散化时间步长累积消失（即$\exp(-\sum_{t=1}^N\Delta_t)$）的工作不同，我们建立了输入长度趋于无穷大时状态收敛行为与转移矩阵$\mathbf{A}$的谱之间的联系，为$\mathbf{A}$在长度扩展中的作用提供了充分依据的解释。接下来，为了克服这一挑战，我们提出了一种方法，通过选择性地调制每一层中$\mathbf{A}$矩阵的谱，将谱缩放应用于预训练的Mamba模型，以实现鲁棒的长上下文泛化。我们表明，在仅调制$\Delta_t$ 会失败的设置中，我们的方法可以显著提高性能，从而验证了我们的见解，并为具有结构化转移矩阵的状态空间模型实现更好的长度泛化提供了途径。|
|**2025-09-23**|[Circuit Complexity From Physical Constraints: Scaling Limitations of Attention](http://arxiv.org/abs/2509.19161)|null|我们认为，源自 $NC, AC, TC$的标准电路复杂性度量提供的实用信息有限，并且现在不足以进一步区分模型表达能力。为了解决这些新限制，我们定义了一种新颖的局部一致性概念，以及一个捕捉扩展物理电路基本约束的电路复杂性类别$RC(\cdot)$家族。借助于$RC(\cdot)$的视角，我们表明运行时为$\omega(n^{3/2})$ 的注意力机制无法扩展以适应日益复杂数据集的熵。我们的结果同时为定义Transformer表达能力的有意义界限提供了一种方法，并自然地揭示了注意力机制有限的适用性。|
|**2025-09-23**|[BiGraspFormer: End-to-End Bimanual Grasp Transformer](http://arxiv.org/abs/2509.19142)|null|双手抓取对于机器人操作大型复杂物体至关重要。然而，现有方法要么仅专注于单臂抓取，要么采用独立的抓取生成和双手评估阶段，导致了包括碰撞风险和受力不均在内的协调问题。为解决这些局限性，我们提出了BiGraspFormer，一个统一的端到端Transformer框架，可以直接从物体点云中生成协调的双手抓取。我们的核心思想是单臂引导双手 (SGB) 策略，该策略首先使用Transformer解码器生成多样化的单臂抓取候选，然后通过专门的注意力机制利用它们学到的特征，联合预测双手姿态和质量分数。这种条件策略降低了12自由度搜索空间的复杂性，同时确保了协调的双手操作。综合仿真实验和真实世界验证表明，BiGraspFormer持续优于现有方法，同时保持了高效的推理速度 (<0.05秒)，证实了我们框架的有效性。代码和补充材料可在 https://sites.google.com/bigraspformer 获取。|
|**2025-09-23**|[Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model](http://arxiv.org/abs/2509.19028)|null|本文提出了一种用于食物图像的弱监督语义分割方法，该方法利用了Segment Anything模型（SAM）的零样本能力和可提示性，以及视觉Transformer（ViT）的注意力机制。具体而言，我们使用来自ViT的类激活图（CAM）为SAM生成提示，从而得到适用于食物图像分割的掩码。该ViT模型（Swin Transformer）仅使用图像级标注进行训练，消除了训练过程中对像素级标注的需求。此外，为了提高SAM生成掩码的质量，我们研究了结合图像预处理技术以及单掩码和多掩码SAM生成策略的使用。该方法在FoodSeg103数据集上进行了评估，平均每张图像生成2.4个掩码（不包括背景），并在多掩码情景下实现了0.54的平均交并比（mIoU）。我们设想所提出的方法可作为加速食物图像标注任务的工具，或作为食物和营养追踪应用中的集成组件。|
|**2025-09-23**|[Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models](http://arxiv.org/abs/2509.18816)|**[link](https://github.com/MyParadise21/MATA)**|大型音频语言模型（LALMs）常面临音频-文本注意力不平衡问题，尤其是在Transformer架构的多模态融合层中，模型倾向于优先处理文本信息而非声学信息。这种偏差阻碍了LALMs充分利用声学线索的能力，导致其在音频推理任务上性能欠佳。为缓解此问题，我们提出MATA，这是一种新颖的免训练方法，能动态地促使LALMs在自注意力机制中更多地关注音频token。具体而言，MATA在原始注意力得分计算后进行干预，仅针对中间层的最后一个token，且不引入额外参数或计算开销。在MMAU和MMAR基准上的实验证实了MATA的有效性，并带来了持续的性能提升。值得注意的是，在MMAR上，MATA首次使一个开源模型超越了专有的Gemini 2.0 Flash。我们的工作为缓解注意力偏差提供了一种有效的解决方案，并为增强多模态模型的音频处理能力开辟了新的研究方向。|
|**2025-09-23**|[Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification](http://arxiv.org/abs/2509.18692)|null|随着社会的快速发展和科学技术的不断进步，食品工业对生产质量和效率的要求越来越高。食品图像分类在实现生产线上的自动化质量控制、支持食品安全监管和推动智慧农业生产方面发挥着至关重要的作用。然而，由于 Vision Transformer 模型参数量大、计算复杂度高，这项任务面临挑战。为了解决这些问题，我们提出了一种融合窗口多头注意力机制（WMHAM）和空间注意力机制（SAM）的轻量级食品图像分类算法。WMHAM 通过高效的窗口划分捕获局部和全局上下文特征，从而降低了计算成本，而 SAM 则自适应地强调关键空间区域，以提高判别性特征表示。在 Food-101 和 Vireo Food-172 数据集上进行的实验表明，我们的模型分别达到了 95.24% 和 94.33% 的准确率，同时与基线方法相比显著减少了参数量和 FLOPs。这些结果证实，所提出的方法在计算效率和分类性能之间实现了有效平衡，使其非常适合部署在资源受限的环境中。|
|**2025-09-22**|[GluMind: Multimodal Parallel Attention and Knowledge Retention for Robust Cross-Population Blood Glucose Forecasting](http://arxiv.org/abs/2509.18457)|null|本文提出了GluMind，一种基于Transformer的多模态框架，专为连续和长期血糖预测而设计。GluMind设计了两种注意力机制，包括交叉注意力（cross-attention）和多尺度注意力（multi-scale attention），它们并行运行并提供了准确的预测性能。交叉注意力有效地整合了血糖数据与其他生理和行为信号，例如活动、压力和心率，解决了与采样率变化相关的挑战以及它们对鲁棒预测的不利影响。此外，多尺度注意力机制捕获了长程时间依赖性。为了减轻灾难性遗忘，GluMind将一种知识保留技术融入基于Transformer的预测模型中。知识保留模块不仅增强了模型保留先验知识的能力，而且提升了其整体预测性能。我们在最近发布的AIREADI数据集上评估了GluMind，该数据集包含来源于健康人、糖尿病前期患者和2型糖尿病患者的行为和生理数据。我们研究了GluMind在引入新患者队列时进行持续学习的性能稳定性和适应性。实验结果表明，GluMind持续优于其他最先进的预测模型，在均方根误差（RMSE）和平均绝对误差（MAE）方面分别实现了约15%和9%的改进。|
|**2025-09-22**|[Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers](http://arxiv.org/abs/2509.18096)|**[link](https://github.com/cvlab-kaist/Seg4Diff)**|文本到图像扩散模型通过其跨模态注意力机制隐式地关联文本概念，擅长将语言提示翻译成逼真的图像。近期的多模态扩散Transformer通过在拼接的图像和文本token上引入联合自注意力，扩展了这一能力，实现了更丰富、更具扩展性的跨模态对齐。然而，关于这些注意力图如何以及在何处对图像生成做出贡献的详细理解仍然有限。在本文中，我们引入了Seg4Diff（Diffusion的分割），这是一个用于分析MM-DiT注意力结构的系统框架，重点关注特定层如何将语义信息从文本传播到图像。通过全面的分析，我们识别出一个语义关联专家层，这是一个特定的MM-DiT模块，能够持续地将文本token与空间上连贯的图像区域对齐，自然地生成高质量的语义分割掩码。我们进一步证明，应用一种使用带有掩码标注的图像数据的轻量级微调方案，可以增强这些层的语义分组能力，从而提高了分割性能和生成图像的保真度。我们的研究结果表明，语义分组是扩散Transformer的一种涌现特性，并且可以被选择性地放大，以提升分割和生成性能，为弥合视觉感知和生成之间鸿沟的统一模型铺平道路。|
|**2025-09-22**|[M3ET: Efficient Vision-Language Learning for Robotics based on Multimodal Mamba-Enhanced Transformer](http://arxiv.org/abs/2509.18005)|null|近年来，多模态学习在机器人视觉和信息融合中已变得至关重要，尤其是在理解复杂环境中人类行为方面。然而，当前方法难以充分利用文本模态，它们依赖于监督预训练模型，这限制了在无监督机器人环境中进行语义提取，尤其是在存在显著模态损失的情况下。这些方法也往往是计算密集型的，导致在实际应用中资源消耗较高。为了应对这些挑战，我们提出了多模态Mamba增强型Transformer (M3ET)，这是一种轻量级模型，旨在实现高效多模态学习，特别是在移动平台上。通过结合Mamba模块和一种基于语义的自适应注意力机制，M3ET优化了特征融合、对齐和模态重建。我们的实验表明，M3ET提升了跨任务性能，预训练推理速度提高了2.3倍。具体而言，M3ET在核心VQA任务上的准确率保持在0.74，而模型参数量减少了0.67。尽管在EQA任务上的性能有限，但M3ET的轻量级设计使其非常适合部署在资源受限的机器人平台上。|
|**2025-09-22**|[Training-free Truthfulness Detection via Value Vectors in LLMs](http://arxiv.org/abs/2509.17932)|null|大型语言模型经常生成事实不准确的输出，这促使人们努力检测其内容的真实性。大多数现有方法依赖于对内部激活进行训练探针，但这些方法存在可扩展性和泛化性问题。一种近期无需训练的方法NoVo通过利用模型本身的统计模式来解决这一挑战。然而，它只专注于注意力机制，可能忽略了多层感知机（MLP）模块——Transformer模型中一个已知支持事实回忆的核心组件。在本文中，我们展示了MLP模块中某些值向量表现出与真实性相关的统计模式。基于这一发现，我们提出TruthV，一种简单且可解释的无需训练方法，通过利用这些值向量来检测内容的真实性。在NoVo基准测试中，TruthV显著优于NoVo和对数似然基线，这表明MLP模块——尽管在之前的无需训练工作中被忽视——编码了丰富而有用的真实性检测信号。这些发现为真实性在大型语言模型中是如何内部表示的提供了新见解，并推动了对可扩展和可解释的真实性检测的进一步研究。|
|**2025-09-22**|[Conv-like Scale-Fusion Time Series Transformer: A Multi-Scale Representation for Variable-Length Long Time Series](http://arxiv.org/abs/2509.17845)|null|时间序列分析在处理变长数据和实现鲁棒泛化方面面临严峻挑战。尽管基于Transformer的模型推动了时间序列任务的发展，但它们常常面临特征冗余和有限泛化能力的问题。借鉴经典CNN架构的金字塔结构，我们提出了一种基于类卷积尺度融合Transformer的多尺度表示学习框架。我们的方法引入了一种类似时间卷积的结构，将分块操作与多头注意力相结合，从而实现了渐进式时间维度压缩和特征通道扩展。我们还进一步开发了一种新颖的跨尺度注意力机制，用于在不同时间尺度上进行有效的特征融合，以及一种用于变长序列的对数空间归一化方法。大量实验表明，与最先进的方法相比，我们的框架在预测和分类任务中实现了卓越的特征独立性、降低了冗余并获得了更优的性能。|
|**2025-09-19**|[Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers](http://arxiv.org/abs/2509.16058)|null|注意力机制已成为人工智能中不可或缺的一部分，通过借鉴人类认知，显著提升了模型性能和可扩展性。与此同时，认知科学中的注意力图式理论（AST）提出，个体通过构建注意力自身的模型来管理注意力，从而有效分配认知资源。受AST启发，我们引入了ASAC（基于注意力图式的注意力控制），将注意力图式概念整合到人工神经网络中。我们的初步实验专注于将ASAC模块嵌入Transformer架构中。该模块采用矢量量化变分自编码器（VQVAE）作为注意力抽象器和控制器，促进精确的注意力管理。通过显式建模注意力分配，我们的方法旨在提高系统效率。我们证明了ASAC在视觉和自然语言处理（NLP）领域均有效，强调了其提高分类准确性和加快学习过程的能力。我们对视觉Transformer在各种数据集上的实验表明，注意力控制器不仅提高了分类准确性，还加速了学习。此外，我们还证明了模型在噪声和分布外数据集上的鲁棒性和泛化能力。另外，我们展示了在多任务设置中的性能提升。快速实验表明，基于注意力图式的模块增强了对对抗攻击的韧性，优化注意力以提高学习效率，并促进了有效的迁移学习和少样本学习。这些有前景的结果建立了认知科学与机器学习之间的联系，揭示了AI系统中注意力机制的有效利用。|
|**2025-09-19**|[Interplay Between Belief Propagation and Transformer: Differential-Attention Message Passing Transformer](http://arxiv.org/abs/2509.15637)|null|基于Transformer的神经网络译码器已成为纠错编码的一种有前景的方法，它结合了数据驱动的适应性与长程依赖的有效建模。本文提出了一种新颖的译码器架构，将经典的信念传播原理与Transformer设计相结合。我们引入了一个利用全局码本结构的可微分伴随式损失函数，以及一个优化比特和伴随式嵌入交互的差分注意力机制。实验结果表明，与现有基于Transformer的译码器相比，性能有持续改进，我们的方法在短到中等长度的LDPC码上超越了传统的信念传播译码器。|
|**2025-09-18**|[Hierarchical Self-Attention: Generalizing Neural Attention Mechanics to Multi-Scale Problems](http://arxiv.org/abs/2509.15448)|null|Transformer模型及其注意力机制在机器学习领域具有革命性意义。虽然最初提出用于语言数据，但它们很快被应用于图像、视频、图等具有各种信号几何结构的数据模态。尽管具有这种多功能性，将注意力机制泛化到数据以不同尺度、可能来自不同模态呈现的场景并非易事。尝试在Transformer中整合层次结构和多模态主要基于特设启发式方法，这些方法无法无缝泛化到具有潜在不同结构的类似问题。为解决此问题，在本文中，我们采取了一种根本不同的方法：我们首先提出了一种数学构造来表示多模态、多尺度数据。然后，我们从熵最小化的第一性原理出发，数学推导了所提出的构造的神经注意力机制。我们表明，所推导的公式在与标准Softmax注意力最接近的意义上是最佳的，同时整合了源于问题层次/几何信息的归纳偏置。我们进一步提出了一种基于动态规划的高效算法来计算我们推导出的注意力机制。通过将其整合到Transformer中，我们表明所提出的层次注意力机制不仅可以用于从头开始训练层次/多模态设置下的Transformer模型，而且还可以用于在训练后向经典的、预训练的Transformer模型注入层次信息，从而以零样本方式获得更高效的模型。|
|**2025-09-18**|[SPH-Net: A Co-Attention Hybrid Model for Accurate Stock Price Prediction](http://arxiv.org/abs/2509.15414)|null|预测股票价格走势在金融分析中构成严峻挑战，这归因于市场数据固有的波动性、非平稳性和非线性特征。本文介绍了SPH-Net（股票价格预测混合神经网络），这是一种创新的深度学习框架，旨在提高金融市场时间序列预测的准确性。所提出的架构采用一种新颖的协同注意力机制，该机制首先通过Vision Transformer处理时间模式，随后通过注意力机制进行精炼的特征提取，从而捕获市场数据中的全局和局部依赖关系。为了严格评估模型的性能，我们在八个多样化的股票数据集上进行了全面的实验：AMD、Ebay、Facebook、FirstService Corp、Tesla、Google、Mondi ADR和Matador Resources。每个数据集都使用六个基本市场指标进行标准化：开盘价、最高价、最低价、收盘价、调整后收盘价和成交量，代表了一整套用于全面市场分析的特征。实验结果表明，SPH-Net在所有评估指标上始终优于现有的股票预测模型。该模型的卓越性能源于其有效捕获复杂时间模式的能力，同时保持对市场噪声的鲁棒性。通过显著提高金融时间序列分析中的预测准确性，SPH-Net为投资者和金融分析师提供了宝贵的决策支持能力，有可能在波动的市场条件下实现更明智的投资策略和风险评估。|
|**2025-09-18**|[Attention Beyond Neighborhoods: Reviving Transformer for Graph Clustering](http://arxiv.org/abs/2509.15024)|null|注意力机制已成为现代神经网络的核心，推动了各个领域的突破性进展。然而，它们在图结构数据（其中捕获拓扑连接至关重要）上的应用仍探索不足且性能欠佳，尤其是在图聚类任务中，相较于图神经网络（GNNs）。GNN 倾向于过分强调邻域聚合，导致节点表示的同质化。相反，Transformer 倾向于过度关注全局，突出远距离节点却牺牲了有意义的局部模式。这种对立提出了一个关键问题：注意力机制对于无监督图学习是否本质上是多余的？为了解决这个问题，我们进行了一项全面的实证分析，揭示了 GNN 和 Transformer 在图聚类中的互补弱点。受这些见解的启发，我们提出了注意力图聚类网络（AGCN），这是一种新颖的架构，重新诠释了“图即注意力”这一理念。AGCN 直接将注意力机制嵌入到图结构中，从而实现有效的全局信息提取，同时保持对局部拓扑线索的敏感。我们的框架结合了理论分析，以对比 AGCN 与 GNN 和 Transformer 的行为，并引入了两项创新：(1) 一种 KV 缓存机制，以提高计算效率；(2) 一种成对间隔对比损失，以提升注意力空间的判别能力。广泛的实验结果表明，AGCN 的性能优于现有最先进的方法。|
|**2025-09-18**|[Exploring the Global-to-Local Attention Scheme in Graph Transformers: An Empirical Study](http://arxiv.org/abs/2509.14863)|null|图形Transformer (GT) 在图表示学习中展现出巨大潜力。GT 的架构通常将图神经网络 (GNN) 与全局注意力机制并行集成或作为注意力机制的前置，从而形成局部-全局或局部到全局的注意力方案。然而，由于全局注意力机制主要捕获节点间的长程依赖关系，这些集成方案可能会遭受信息损失，即 GNN 学习到的局部邻域信息可能会被注意力机制稀释。因此，我们提出了 G2LFormer，它采用了一种新颖的全局到局部注意力方案，其中浅层网络层使用注意力机制捕获全局信息，而深层网络层则采用 GNN 模块学习局部结构信息，从而防止节点忽略其直接邻居。为使局部层能够保留来自全局层的有益信息并减轻信息损失，我们引入了一种有效的跨层信息融合策略，同时在可扩展性方面实现了可接受的权衡。为了验证全局到局部注意力方案的可行性，我们在节点级和图级任务上将 G2LFormer 与最先进的线性 GT 和 GNN 进行了比较。结果表明，G2LFormer 表现出优异的性能，同时保持了线性复杂度。|
|**2025-09-18**|[Stochastic Clock Attention for Aligning Continuous and Ordered Sequences](http://arxiv.org/abs/2509.14678)|null|我们为连续且有序的序列提出了一种明确地作为对齐模型发挥作用的注意力机制，该机制是许多序列到序列任务的核心。标准的缩放点积注意力依赖于位置编码和掩码，但它不强制连续性或单调性，而这对于帧同步目标至关重要。我们提出了针对源和目标学习的非负“时钟”，并将注意力建模为这些时钟的相遇概率；路径积分推导得到一个封闭形式的、类高斯的评分规则，该规则具有对因果、平滑、近对角线对齐的内在偏置，无需外部位置正则化器。该框架支持两种互补的模式：当全局长度可用时，用于并行解码的归一化时钟，以及用于自回归解码的未归一化时钟——两者都是几乎无参数的、可直接替换的方案。在Transformer文本到语音测试平台中，这种构造产生了更稳定的对齐，并提高了对全局时间尺度变化的鲁棒性，同时与缩放点积基线相比，准确性持平或有所提高。我们推测它适用于其他连续目标，包括视频和时序信号建模。|
|**2025-09-18**|[SpeechMLC: Speech Multi-label Classification](http://arxiv.org/abs/2509.14677)|null|本文提出一个多标签分类框架，用于检测语音样本中的多种说话风格。与以往主要关注识别单一目标风格的研究不同，我们的框架能在一个统一的结构中有效捕获多种说话者特征，使其适用于广义的人机交互应用。所提出的框架在Transformer解码器内部整合了交叉注意力机制，以从输入语音中提取与每个目标标签相关的显著特征。为了缓解多标签语音数据集中固有的数据不平衡问题，我们采用了一种基于语音生成模型的数据增强技术。我们通过在已知语料库和未知语料库上的多项客观评估，验证了我们模型的有效性。此外，我们通过考虑人类标注一致性对模型性能的影响，分析了人类感知对分类准确性的影响。|
|**2025-09-17**|[White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](http://arxiv.org/abs/2509.13907)|null|少样本三维点云分割（FS-PCS）旨在仅给定少量标记样本的情况下，预测未标记点云的每个点的标签。为了从有限的支持集中提取判别性表示，现有方法使用最远点采样等传统算法构建原型。然而，我们指出其初始随机性显著影响FS-PCS性能，并且原型生成过程尽管普遍存在但仍未得到充分探索。这促使我们研究一种基于注意力机制的先进原型生成方法。尽管注意力机制有其潜力，我们发现朴素模块存在可学习原型tokens与支持特征之间的分布差异问题。为了克服这一问题，我们提出了白化聚合与恢复模块（WARM），该模块通过将交叉注意力置于白化和着色变换之间来解决错位问题。具体来说，白化操作在注意力处理之前将支持特征与原型tokens对齐，随后着色操作恢复经过注意力处理的tokens的原始分布。这种简单而有效的设计实现了鲁棒的注意力，从而通过捕获支持特征之间的语义关系生成具有代表性的原型。我们的方法在多个FS-PCS基准上以显著优势实现了最先进的性能，并通过广泛的实验证明了其有效性。|
|**2025-09-17**|[ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](http://arxiv.org/abs/2509.13753)|null|交通预测在智能交通系统中是一个关键问题。在近期研究中，大型语言模型（LLMs）已成为一种有前景的方法，但其主要为序列化标记处理而设计的内在结构，在有效捕捉空间依赖性方面带来了显著挑战。具体而言，LLMs在建模空间关系方面的固有局限性及其与图结构空间数据在架构上的不兼容性，在很大程度上仍未得到解决。为克服这些局限性，我们引入了ST-LINK，这是一个新颖的框架，旨在增强大型语言模型捕捉时空依赖性的能力。其关键组成部分是空间增强注意力（SE-Attention）和记忆检索前馈网络（MRFFN）。SE-Attention扩展了旋转位置嵌入，将空间相关性作为直接的旋转变换整合到注意力机制中。这种方法在最大化空间学习的同时，保留了LLM固有的序列处理结构。同时，MRFFN动态检索并利用关键历史模式，以捕捉复杂的时序依赖性并提高长期预测的稳定性。在基准数据集上的综合实验表明，ST-LINK超越了传统的深度学习和LLM方法，并能有效捕捉常规交通模式和突发变化。|
|**2025-09-16**|[SAGA: Selective Adaptive Gating for Efficient and Expressive Linear Attention](http://arxiv.org/abs/2509.12817)|null|尽管Transformer架构在建模长距离依赖方面表现出色，使其在视觉任务中得到广泛应用，但基于softmax的注意力机制的二次复杂度带来了主要瓶颈，尤其是在处理高分辨率图像时。线性注意力通过将注意力计算从 $(QK)V$重新表述为$Q(KV)$，从而将复杂度从$\mathcal{O}(N^2)$降低到$\mathcal{O}(N)$，同时保留了全局感受野，提供了一种有前景的替代方案。然而，大多数现有方法均匀地压缩历史键值（KV）信息，这可能导致特征冗余以及与查询（Q）的方向对齐丢失。这种均匀压缩导致低秩$KV$特征图，从而导致与softmax注意力相比的性能差距。为了缓解这一局限性，我们提出了用于高效且富有表现力的线性注意力的选择性自适应门控（SAGA），该方法引入了输入自适应的可学习门控，以选择性地调节信息聚合到$KV$特征图中。这些门控增强了语义多样性，并缓解了传统线性注意力中固有的低秩约束。此外，我们提出了一种高效的Hadamard积分解方法用于门控计算，该方法不引入额外的内存开销。实验表明，SAGA在分辨率为$1280 \times 1280$ 时，与PVT-T相比，在吞吐量方面实现了1.76倍的提升，在峰值GPU内存方面实现了2.69倍的降低。此外，它在ImageNet数据集上的top-1准确率提高了高达4.4%，证明了计算效率和模型有效性。|
|**2025-09-16**|[BATR-FST: Bi-Level Adaptive Token Refinement for Few-Shot Transformers](http://arxiv.org/abs/2509.12768)|null|视觉Transformer (ViT) 在计算机视觉应用中展现出巨大潜力。然而，它们在小样本学习中的性能受限于细化token级交互、难以处理有限训练数据以及建立强大归纳偏置等挑战。现有方法常依赖不灵活的token匹配或基本相似性度量，这限制了全局上下文的有效融合和局部特征的细化。为解决这些挑战，我们提出针对小样本Transformer的双层自适应Token细化 (BATR-FST)，这是一种两阶段方法，能逐步改进token表示并为小样本分类保持鲁棒的归纳偏置。在预训练阶段，掩码图像建模 (MIM) 通过重建被掩码的图像区域，为视觉Transformer (ViT) 提供可迁移的块级表示，为后续适应奠定鲁棒基础。在元微调阶段，BATR-FST 融合了一个双层自适应Token细化模块，该模块利用Token聚类来捕获局部交互，通过不确定性感知Token加权优先处理可靠特征，并采用双层注意力机制来平衡簇内和簇间关系，从而促进彻底的token细化。此外，图Token传播确保了支持集和查询集实例之间的语义一致性，而类别分离惩罚则保持了不同类别边界，增强了判别能力。在三个基准小样本数据集上进行的大量实验表明，BATR-FST 在1-shot和5-shot场景中均取得了优异结果，并改进了基于Transformer的小样本分类。|
|**2025-09-15**|[Dynamic Relational Priming Improves Transformer in Multivariate Time Series](http://arxiv.org/abs/2509.12196)|null|Transformer模型中的标准注意力机制采用静态的token表示，这些表示在每一层的所有成对计算中保持不变。这限制了它们在表示上与每对token交互中潜在的多元关系动态的对齐。虽然它们在关系相对同质的领域表现出色，但标准注意力机制的静态关系学习难以捕捉多元时间序列（MTS）数据中多样化、异构的通道间依赖关系——在单个系统中，不同通道对之间的交互可能受完全不同的物理定律或时间动态支配。为了更好地调整注意力机制以适应此类领域现象，我们提出了带有动态关系预置（prime attention）的注意力机制。与标准注意力机制不同，在标准注意力机制中，每个token在其所有成对交互中都呈现相同的表示，而prime attention通过可学习的调制动态地（或按每次交互）调整每个token，以最好地捕捉每对token独特的关联动态，从而为该特定关系优化每次成对交互。prime attention的这种表示可塑性使得在MTS中有效提取关系特定信息成为可能，同时保持与标准注意力机制相同的渐近计算复杂度。我们的结果表明，prime attention在各项基准测试中始终优于标准注意力机制，实现了高达6.5%的预测准确性提升。此外，我们发现与标准注意力机制相比，prime attention在使用减少高达40%的序列长度时，取得了相当或更优的性能，进一步证明了其卓越的关系建模能力。|
|**2025-09-14**|[Length-Aware Rotary Position Embedding for Text-Speech Alignment](http://arxiv.org/abs/2509.11084)|null|许多近期文本到语音（TTS）系统基于Transformer架构，并采用交叉注意力机制用于文本-语音对齐。在这些系统中，旋转位置编码（RoPE）常被用于编码文本和语音表示中的位置信息。在这项工作中，我们引入了长度感知RoPE（LARoPE），作为RoPE的一个简单而有效的扩展，能够改善文本-语音对齐。与依赖绝对索引的RoPE不同，LARoPE使用长度归一化索引计算查询（query）和键（key）位置之间的相对距离。实验结果表明，LARoPE持续优于RoPE，提供了更快的损失收敛、更准确的文本-语音对齐和更高的整体TTS质量。此外，LARoPE对发音时长变化表现出更强的鲁棒性，并在长达30秒的扩展语音生成中保持稳定性能，而RoPE则出现显著性能下降。值得注意的是，我们的方法在标准零样本TTS基准测试上，词错误率达到了最先进水平。|
|**2025-09-11**|[Efficient Transformer-Based Piano Transcription With Sparse Attention Mechanisms](http://arxiv.org/abs/2509.09318)|null|本文研究基于计算高效但性能优越的Transformer变体的自动钢琴转录，这些变体能够捕捉整个音乐片段的长期依赖关系。近来，基于Transformer的序列到序列模型在钢琴转录中表现出卓越的性能。然而，由于自注意力机制的二次复杂度，这些模型无法一次性处理整个乐曲，因此，在实践中，音乐信号通常以滑动窗口的方式进行处理。为了克服这一局限性，我们提出了一种采用稀疏注意力机制的高效架构。具体来说，我们为编码器和解码器引入了滑动窗口自注意力机制，并提出了一种根据MIDI令牌类型关注不同跨度的混合全局-局部交叉注意力机制。我们还在编码器和解码器之间使用了一种分层池化策略，以进一步降低计算负载。我们在MAESTRO数据集上的实验表明，所提出的模型显著降低了计算成本和内存使用量，加快了推理速度，同时保持了与全注意力基线相当的转录性能。这使得在相同硬件上可以使用更长的音频上下文进行训练，证明了稀疏注意力机制在构建高效高性能钢琴转录系统方面的可行性。代码可在https://github.com/WX-Wei/efficient-seq2seq-piano-trans获取。|
|**2024-09-10**|[AgileIR: Memory-Efficient Group Shifted Windows Attention for Agile Image Restoration](http://arxiv.org/abs/2409.06206)|null|图像Transformer在图像恢复任务中取得了巨大成功。然而，大多数基于Transformer的模型都严格受限于过高的内存占用。我们的目标是减少Swin Transformer的内存消耗，同时加速模型在训练过程中的运行。因此，我们引入了AgileIR，一种结合窗口注意力的组移位注意力机制，它在架构上稀疏地简化了模型。我们提出了组移位窗口注意力（GSWA），将移位窗口多头自注意力（SW-MSA）和窗口多头自注意力（W-MSA）分解为跨注意力头的组，从而有助于减少反向传播中的内存使用。除此之外，我们在训练过程中保留了移位窗口掩码及其移位可学习偏置，以促使模型在通道内跨窗口进行交互。我们还重新分配了投影参数以加速注意力矩阵计算，我们发现这只会导致性能的微小下降。实验结果表明，与我们的基线SwinIR及其他高效量化模型相比，AgileIR在Set5评估数据集上仍保持32.20 dB的性能，超越了采用定制化高效方法的其他方法，并在采用大批量尺寸时节省了超过50%的内存。|
|**2024-12-20**|[Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads](http://arxiv.org/abs/2406.19391)|null|视觉Transformer (ViT) 等Transformer架构已被证明在解决视觉感知任务方面是有效的。然而，它们面临两个主要限制：首先，自注意力的二次复杂度限制了可处理的tokens数量；其次，Transformer通常需要大量训练数据才能达到最先进的性能。在本文中，我们提出了一种名为Fibottention的新型多头自注意力 (MHSA) 变体，它可以取代Transformer架构中的MHSA。Fibottention具有数据效率高且在计算上比标准MHSA更适合处理大量tokens的特点。它采用基于膨胀斐波那契序列的结构化稀疏注意力，其独特之处在于在不同注意力头之间有所不同，从而在各注意力头之间产生Inception式的多样化特征。斐波那契序列的间距遵循Wythoff数组，这最大限度地减少了在不同注意力头之间聚合的token交互的冗余，同时通过token对交互仍然捕获了足够的互补信息。这些稀疏注意力模式在现有稀疏注意力机制中是独一无二的，并导致 $O(N \log N)$的复杂度，其中$N$ 是tokens的数量。仅利用自注意力头中2-6%的元素，嵌入到流行的、最先进的Transformer架构中的Fibottention可以显著提高图像分类、视频理解和机器人学习任务等数据有限领域的预测性能，并降低计算复杂度。我们进一步验证了不同自注意力头产生的特征表示多样性的改善，以及我们的模型设计与其它稀疏注意力机制的对比。|
|**2022-09-30**|[Adaptive Sparse and Monotonic Attention for Transformer-based Automatic Speech Recognition](http://arxiv.org/abs/2209.15176)|null|基于自注意力与多头注意力的Transformer架构模型在离线端到端自动语音识别（ASR）中取得了显著成功。然而，自注意力与多头注意力难以直接应用于流式或在线ASR。对于Transformer ASR中的自注意力，基于softmax归一化函数的注意力机制使其无法突出重要的语音信息。对于Transformer ASR中的多头注意力，难以在不同头中建模单调对齐。为克服这两个限制，我们将稀疏注意力和单调注意力集成到基于Transformer的ASR中。稀疏机制引入了一种学习到的稀疏方案，使每个自注意力结构更好地适应对应的头。单调注意力采用正则化方法，对多头注意力结构中的冗余头进行剪枝。实验表明，我们的方法能够有效改进语音识别广泛使用的基准上的注意力机制。|
|**2023-01-16**|[Dilated Neighborhood Attention Transformer](http://arxiv.org/abs/2209.15001)|null|Transformer模型正迅速成为跨模态、领域和任务应用最广泛的深度学习架构之一。在视觉领域，除了对普通Transformer的持续研究外，分层Transformer也因其优异的性能和易于集成到现有框架的能力而获得了广泛关注。这些模型通常采用局部注意力机制，例如滑动窗口邻域注意力（NA）或Swin Transformer的移位窗口自注意力。尽管局部注意力在降低自注意力的二次复杂度方面很有效，但它削弱了自注意力两个最理想的特性：远距离相互依赖建模和全局感受野。在本文中，我们引入了膨胀邻域注意力（DiNA），这是一种自然、灵活且高效的NA扩展，它能够捕获更全局的上下文并以指数方式扩展感受野，而无需额外成本。NA的局部注意力和DiNA的稀疏全局注意力相互补充，因此我们引入了膨胀邻域注意力Transformer（DiNAT），这是一种基于两者的新型分层视觉Transformer。DiNAT变体相较于NAT、Swin和ConvNeXt等强劲基线模型取得了显著的改进。我们的L模型更快，并且在COCO目标检测中高出其Swin对应模型1.6%的box AP，在COCO实例分割中高出1.4%的mask AP，在ADE20K语义分割中高出1.4%的mIoU。结合新框架，我们的L变体在COCO（58.5 PQ）和ADE20K（49.4 PQ）上是新的最先进全景分割模型，在Cityscapes（45.1 AP）和ADE20K（35.4 AP）上是新的最先进实例分割模型（无额外数据）。它还在ADE20K上匹配了最先进的专用语义分割模型（58.1 mIoU），并在Cityscapes上排名第二（84.5 mIoU）（无额外数据）。|
|**2022-09-01**|[Deep Sparse Conformer for Speech Recognition](http://arxiv.org/abs/2209.00260)|null|Conformer通过利用Transformer捕捉基于内容的全局交互和卷积神经网络利用局部特征的能力，在自动语音识别（ASR）中取得了显著成果。在Conformer中，两个类似马卡龙的前馈层通过半步残差连接，将多头自注意力和卷积模块夹在其中，随后进行层归一化。我们从“稀疏化”和“深度化”两个方向提升了Conformer的长序列表示能力。我们采用了一种时间复杂度和内存使用均为 $\mathcal{O}(L\text{log}L)$ 的稀疏自注意力机制。在进行残差连接时，我们利用深度归一化策略，以确保我们能够训练百层级的Conformer块。在日本CSJ-500小时数据集上，这种深度稀疏Conformer在三个评估集上分别取得了5.52%、4.03%和4.50%的字符错误率，当集成12到16、17、50以及最终100个编码器层的五个深度稀疏Conformer变体时，字符错误率分别为4.16%、2.84%和3.20%。|
|**2022-01-27**|[Multi-View Self-Attention Based Transformer for Speaker Recognition](http://arxiv.org/abs/2110.05036)|null|最初为自然语言处理（NLP）开发的Transformer模型，现已因其强大的序列建模能力而广泛应用于语音处理任务，例如说话人识别。然而，传统的自注意力机制最初是为文本序列建模而设计的，未考虑语音和说话人建模的特点。此外，针对说话人识别的不同Transformer变体尚未得到充分研究。在这项工作中，我们提出了一种新颖的多视角自注意力机制，并对带有或不带有我们提出的注意力机制的不同Transformer变体在说话人识别任务上进行了实证研究。具体而言，为了平衡捕获全局依赖和建模局部性的能力，我们为说话人Transformer提出了一种多视角自注意力机制，其中不同的注意力头可以关注感受野的不同范围。此外，我们介绍并比较了五种具有不同网络架构、嵌入位置和池化方法，用于学习说话人嵌入的Transformer变体。在VoxCeleb1和VoxCeleb2数据集上的实验结果表明，所提出的多视角自注意力机制在说话人识别性能上取得了提升，并且所提出的说话人Transformer网络与最先进模型相比取得了优异的结果。|
|**2021-09-08**|[Sparsity and Sentence Structure in Encoder-Decoder Attention of Summarization Systems](http://arxiv.org/abs/2109.03888)|null|Transformer模型已在包括摘要在内的广泛自然语言处理（NLP）任务中取得了最先进的结果。使用大型Transformer模型进行训练和推理的计算开销可能很高。先前的工作侧重于一个重要的瓶颈，即编码器中二次方的自注意力机制。诸如LED或LoBART等改进的编码器架构使用局部注意力模式来解决摘要任务中的这个问题。相比之下，本文侧重于Transformer的编码器-解码器注意力机制。在需要模型生成历史信息的推理或训练方法中，这种注意力的开销变得更为显著。首先，我们考察了编码器-解码器注意力的复杂性。我们通过实验证明，文档摘要中存在稀疏的句子结构，通过将注意力机制限制在输入句子的一个子集上，可以在保持系统性能的同时加以利用。其次，我们提出了一种改进的架构，用于选择句子的子集以限制编码器-解码器注意力。实验在包括CNN/DailyMail、XSum、Spotify Podcast和arXiv在内的抽象式摘要任务上进行。|
|**2021-09-13**|[Voxel Transformer for 3D Object Detection](http://arxiv.org/abs/2109.02497)|null|我们提出Voxel Transformer (VoTr)，一种新颖且有效的基于体素的Transformer骨干网络，用于点云3D目标检测。传统的基于体素的3D检测器中的3D卷积骨干网络由于感受野有限，无法有效捕获大范围上下文信息，而这对于目标识别和定位至关重要。在本文中，我们通过引入一种基于Transformer的架构来解决这个问题，该架构通过自注意力机制实现体素之间的长程关系。鉴于非空体素天然稀疏但数量众多，直接将标准Transformer应用于体素并非易事。为此，我们提出了稀疏体素模块和子流形体素模块，它们能够有效处理空体素和非空体素位置。为了进一步扩大注意力范围，同时保持与卷积对应物相当的计算开销，我们在这两个模块中提出了两种用于多头注意力的注意力机制：局部注意力(Local Attention)和膨胀注意力(Dilated Attention)，并且我们进一步提出了快速体素查询(Fast Voxel Query)以加速多头注意力中的查询过程。VoTr包含一系列稀疏和子流形体素模块，并且可以应用于大多数基于体素的检测器。我们提出的VoTr在KITTI数据集和Waymo Open数据集上显示出相对于卷积基线的持续改进，同时保持了计算效率。|
|**2019-05-24**|[SCRAM: Spatially Coherent Randomized Attention Maps](http://arxiv.org/abs/1905.10308)|null|注意力机制和非局部均值操作通常是许多最先进深度学习技术的关键组成部分。特别是，基于多头自注意力的Transformer模型最近在自然语言处理和计算机视觉领域取得了巨大成功。然而，计算n像素图像Transformer的原始算法具有O(n^2)复杂度，这对于大规模图像数据而言通常极其缓慢，有时甚至昂贵得令人望而却步。在本文中，我们提出了一种快速随机算法——SCRAM——它仅需要O(n log(n))时间即可生成图像注意力图。如此显著的加速归因于我们观察到真实世界图像上的注意力图通常表现出(1)空间一致性和(2)稀疏结构。SCRAM的核心思想是利用随机对应算法PatchMatch，首先快速确定每个查询最兼容的键（argmax），然后利用这些知识设计非局部均值操作的稀疏近似。使用argmax（众数）动态构建稀疏近似，使我们的算法区别于所有现有的稀疏近似方法，并使其非常高效。此外，SCRAM是一种广泛适用于任何非局部均值层的近似方法，与一些只能近似自注意力的稀疏近似方法形成对比。我们的初步实验结果表明，SCRAM确实有望加速或扩展Transformer中注意力图的计算。|

## 生成模型

| Publish Date | Title | Code | Abstract |
|:---------|:-----------------------|:------|:-------------------------------------------------|
|**2025-12-19**|[Both Semantics and Reconstruction Matter: Making Representation Encoders Ready for Text-to-Image Generation and Editing](http://arxiv.org/abs/2512.17909)|null|Modern Latent Diffusion Models (LDMs) typically operate in low-level Variational Autoencoder (VAE) latent spaces that are primarily optimized for pixel-level reconstruction. To unify vision generation and understanding, a burgeoning trend is to adopt high-dimensional features from representation encoders as generative latents. However, we empirically identify two fundamental obstacles in this paradigm: (1) the discriminative feature space lacks compact regularization, making diffusion models prone to off-manifold latents that lead to inaccurate object structures; and (2) the encoder's inherently weak pixel-level reconstruction hinders the generator from learning accurate fine-grained geometry and texture. In this paper, we propose a systematic framework to adapt understanding-oriented encoder features for generative tasks. We introduce a semantic-pixel reconstruction objective to regularize the latent space, enabling the compression of both semantic information and fine-grained details into a highly compact representation (96 channels with 16x16 spatial downsampling). This design ensures that the latent space remains semantically rich and achieves state-of-the-art image reconstruction, while remaining compact enough for accurate generation. Leveraging this representation, we design a unified Text-to-Image (T2I) and image editing model. Benchmarking against various feature spaces, we demonstrate that our approach achieves state-of-the-art reconstruction, faster convergence, and substantial performance gains in both T2I and editing tasks, validating that representation encoders can be effectively adapted into robust generative components.|
|**2025-12-19**|[Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting](http://arxiv.org/abs/2512.17908)|null|Monocular depth estimation remains challenging as recent foundation models, such as Depth Anything V2 (DA-V2), struggle with real-world images that are far from the training distribution. We introduce Re-Depth Anything, a test-time self-supervision framework that bridges this domain gap by fusing DA-V2 with the powerful priors of large-scale 2D diffusion models. Our method performs label-free refinement directly on the input image by re-lighting predicted depth maps and augmenting the input. This re-synthesis method replaces classical photometric reconstruction by leveraging shape from shading (SfS) cues in a new, generative context with Score Distillation Sampling (SDS). To prevent optimization collapse, our framework employs a targeted optimization strategy: rather than optimizing depth directly or fine-tuning the full model, we freeze the encoder and only update intermediate embeddings while also fine-tuning the decoder. Across diverse benchmarks, Re-Depth Anything yields substantial gains in depth accuracy and realism over the DA-V2, showcasing new avenues for self-supervision by augmenting geometric reasoning.|
|**2025-12-19**|[Dexterous World Models](http://arxiv.org/abs/2512.17907)|**[link](https://github.com/snuvclab/dwm)**|Recent progress in 3D reconstruction has made it easy to create realistic digital twins from everyday environments. However, current digital twins remain largely static and are limited to navigation and view synthesis without embodied interactivity. To bridge this gap, we introduce Dexterous World Model (DWM), a scene-action-conditioned video diffusion framework that models how dexterous human actions induce dynamic changes in static 3D scenes.   Given a static 3D scene rendering and an egocentric hand motion sequence, DWM generates temporally coherent videos depicting plausible human-scene interactions. Our approach conditions video generation on (1) static scene renderings following a specified camera trajectory to ensure spatial consistency, and (2) egocentric hand mesh renderings that encode both geometry and motion cues to model action-conditioned dynamics directly. To train DWM, we construct a hybrid interaction video dataset. Synthetic egocentric interactions provide fully aligned supervision for joint locomotion and manipulation learning, while fixed-camera real-world videos contribute diverse and realistic object dynamics.   Experiments demonstrate that DWM enables realistic and physically plausible interactions, such as grasping, opening, and moving objects, while maintaining camera and scene consistency. This framework represents a first step toward video diffusion-based interactive digital twins and enables embodied simulation from egocentric actions.|
|**2025-12-19**|[RadarGen: Automotive Radar Point Cloud Generation from Cameras](http://arxiv.org/abs/2512.17897)|null|We present RadarGen, a diffusion model for synthesizing realistic automotive radar point clouds from multi-view camera imagery. RadarGen adapts efficient image-latent diffusion to the radar domain by representing radar measurements in bird's-eye-view form that encodes spatial structure together with radar cross section (RCS) and Doppler attributes. A lightweight recovery step reconstructs point clouds from the generated maps. To better align generation with the visual scene, RadarGen incorporates BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which guide the stochastic generation process toward physically plausible radar patterns. Conditioning on images makes the approach broadly compatible, in principle, with existing visual datasets and simulation frameworks, offering a scalable direction for multimodal generative simulation. Evaluations on large-scale driving data show that RadarGen captures characteristic radar measurement distributions and reduces the gap to perception models trained on real data, marking a step toward unified generative simulation across sensing modalities.|
|**2025-12-19**|[Map2Video: Street View Imagery Driven AI Video Generation](http://arxiv.org/abs/2512.17883)|**[link](https://github.com/jgamble77/REST-API)**|AI video generation has lowered barriers to video creation, but current tools still struggle with inconsistency. Filmmakers often find that clips fail to match characters and backgrounds, making it difficult to build coherent sequences. A formative study with filmmakers highlighted challenges in shot composition, character motion, and camera control. We present Map2Video, a street view imagery-driven AI video generation tool grounded in real-world geographies. The system integrates Unity and ComfyUI with the VACE video generation model, as well as OpenStreetMap and Mapillary for street view imagery. Drawing on familiar filmmaking practices such as location scouting and rehearsal, Map2Video enables users to choose map locations, position actors and cameras in street view imagery, sketch movement paths, refine camera motion, and generate spatially consistent videos. We evaluated Map2Video with 12 filmmakers. Compared to an image-to-video baseline, it achieved higher spatial accuracy, required less cognitive effort, and offered stronger controllability for both scene replication and open-ended creative exploration.|
|**2025-12-19**|[Inverse-Designed Phase Prediction in Digital Lasers Using Deep Learning and Transfer Learning](http://arxiv.org/abs/2512.17879)|null|Digital lasers control the laser beam by dynamically updating the phase patterns of the spatial light modulator (SLM) within the laser cavity. Due to the presence of nonlinear effects, such as mode competition and gain saturation in digital laser systems, it is often necessary to rely on specifically manually tailored approach or iteration processes to find suitable loaded phases in Digital lasers. This study proposes a model based on Conditional Generative Adversarial Networks (cGAN) and a modified U-Net architecture, with designed loss functions to inverse design the loaded phases. In this work, we employ deep neural networks to learn the nonlinear effects in simulated L-shape digital lasers, enabling the prediction of SLM-loaded phases for both analytical and non-analytical arbitrary structured light fields. The results demonstrate superior performance on non-analytical light fields compared to the current methods in L-shape Digital lasers. Furthermore, a transfer learning strategy is introduced, allowing knowledge obtained from one class of structured beams to be effectively reused for another, thereby enhancing generalization and improving performance under limited training data. Importantly, this method, the first proposed learning framework for digital lasers, is not limited to the L-shaped digital lasers discussed in this study, providing an efficient alternative for generating structured light in other digital laser systems.|
|**2025-12-19**|[Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow](http://arxiv.org/abs/2512.17878)|null|Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.   A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.|
|**2025-12-19**|[InSPECT: Invariant Spectral Features Preservation of Diffusion Models](http://arxiv.org/abs/2512.17873)|null|Modern diffusion models (DMs) have achieved state-of-the-art image generation. However, the fundamental design choice of diffusing data all the way to white noise and then reconstructing it leads to an extremely difficult and computationally intractable prediction task. To overcome this limitation, we propose InSPECT (Invariant Spectral Feature-Preserving Diffusion Model), a novel diffusion model that keeps invariant spectral features during both the forward and backward processes. At the end of the forward process, the Fourier coefficients smoothly converge to a specified random noise, enabling features preservation while maintaining diversity and randomness. By preserving invariant features, InSPECT demonstrates enhanced visual diversity, faster convergence rate, and a smoother diffusion process. Experiments on CIFAR-10, Celeb-A, and LSUN demonstrate that InSPECT achieves on average a 39.23% reduction in FID and 45.80% improvement in IS against DDPM for 10K iterations under specified parameter settings, which demonstrates the significant advantages of preserving invariant features: achieving superior generation quality and diversity, while enhancing computational efficiency and enabling faster convergence rate. To the best of our knowledge, this is the first attempt to analyze and preserve invariant spectral features in diffusion models.|
|**2025-12-19**|[InfinityEBSD : Metrics-Guided Infinite-Size EBSD Map Generation With Diffusion Models](http://arxiv.org/abs/2512.17859)|null|Materials performance is deeply linked to their microstructures, which govern key properties such as strength, durability, and fatigue resistance. EBSD is a major technique for characterizing these microstructures, but acquiring large and statistically representative EBSD maps remains slow, costly, and often limited to small regions. In this work, we introduce InfinityEBSD, a diffusion-based method for generating monophase realistic EBSD maps of arbitrary size, conditioned on physically meaningful microstructural metrics. This approach supports two primary use cases: extending small experimental EBSD maps to arbitrary sizes, and generating entirely new maps directly from statistical descriptors, without any input map. Conditioning is achieved through eight microstructural descriptors, including grain size, grain perimeter, grain inertia ratio, coordination number and disorientation angle distribution, allowing the model to generate maps that are both visually realistic and physically interpretable. A patch-wise geometric extension strategy ensures spatial continuity across grains, enabling the model to produce large-scale EBSD maps while maintaining coherent grain boundaries and orientation transitions. The generated maps can also be exported as valid Channel Text Files (CTF) for immediate post-processing and analysis in software such as MTEX or simulation environments like DIGIMU. We quantitatively validate our results by comparing distributions of the guiding metrics before and after generation, showing that the model respects the statistical targets while introducing morphological diversity. InfinityEBSD demonstrates that diffusion models, guided by physical metrics, can bridge the gap between synthetic and realistic materials representation, paving the way for future developments such as 3D realistic microstructure generation from 2D data.|
|**2025-12-19**|[InfSplign: Inference-Time Spatial Alignment of Text-to-Image Diffusion Models](http://arxiv.org/abs/2512.17851)|null|Text-to-image (T2I) diffusion models generate high-quality images but often fail to capture the spatial relations specified in text prompts. This limitation can be traced to two factors: lack of fine-grained spatial supervision in training data and inability of text embeddings to encode spatial semantics. We introduce InfSplign, a training-free inference-time method that improves spatial alignment by adjusting the noise through a compound loss in every denoising step. Proposed loss leverages different levels of cross-attention maps extracted from the backbone decoder to enforce accurate object placement and a balanced object presence during sampling. The method is lightweight, plug-and-play, and compatible with any diffusion backbone. Our comprehensive evaluations on VISOR and T2I-CompBench show that InfSplign establishes a new state-of-the-art (to the best of our knowledge), achieving substantial performance gains over the strongest existing inference-time baselines and even outperforming the fine-tuning-based methods. Codebase is available at GitHub.|
|**2025-12-18**|[Depth Any Panoramas: A Foundation Model for Panoramic Depth Estimation](http://arxiv.org/abs/2512.16913)|null|In this work, we present a panoramic metric depth foundation model that generalizes across diverse scene distances. We explore a data-in-the-loop paradigm from the view of both data construction and framework design. We collect a large-scale dataset by combining public datasets, high-quality synthetic data from our UE5 simulator and text-to-image models, and real panoramic images from the web. To reduce domain gaps between indoor/outdoor and synthetic/real data, we introduce a three-stage pseudo-label curation pipeline to generate reliable ground truth for unlabeled images. For the model, we adopt DINOv3-Large as the backbone for its strong pre-trained generalization, and introduce a plug-and-play range mask head, sharpness-centric optimization, and geometry-centric optimization to improve robustness to varying distances and enforce geometric consistency across views. Experiments on multiple benchmarks (e.g., Stanford2D3D, Matterport3D, and Deep360) demonstrate strong performance and zero-shot generalization, with particularly robust and stable metric predictions in diverse real-world scenes. The project page can be found at: \href{https://insta360-research-team.github.io/DAP_website/} {https://insta360-research-team.github.io/DAP\_website/}|
|**2025-12-18**|[Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning](http://arxiv.org/abs/2512.16911)|null|Standard practice across domains from robotics to language is to first pretrain a policy on a large-scale demonstration dataset, and then finetune this policy, typically with reinforcement learning (RL), in order to improve performance on deployment domains. This finetuning step has proved critical in achieving human or super-human performance, yet while much attention has been given to developing more effective finetuning algorithms, little attention has been given to ensuring the pretrained policy is an effective initialization for RL finetuning. In this work we seek to understand how the pretrained policy affects finetuning performance, and how to pretrain policies in order to ensure they are effective initializations for finetuning. We first show theoretically that standard behavioral cloning (BC) -- which trains a policy to directly match the actions played by the demonstrator -- can fail to ensure coverage over the demonstrator's actions, a minimal condition necessary for effective RL finetuning. We then show that if, instead of exactly fitting the observed demonstrations, we train a policy to model the posterior distribution of the demonstrator's behavior given the demonstration dataset, we do obtain a policy that ensures coverage over the demonstrator's actions, enabling more effective finetuning. Furthermore, this policy -- which we refer to as the posterior behavioral cloning (PostBC) policy -- achieves this while ensuring pretrained performance is no worse than that of the BC policy. We then show that PostBC is practically implementable with modern generative models in robotic control domains -- relying only on standard supervised learning -- and leads to significantly improved RL finetuning performance on both realistic robotic control benchmarks and real-world robotic manipulation tasks, as compared to standard behavioral cloning.|
|**2025-12-18**|[SFTok: Bridging the Performance Gap in Discrete Tokenizers](http://arxiv.org/abs/2512.16910)|null|Recent advances in multimodal models highlight the pivotal role of image tokenization in high-resolution image generation. By compressing images into compact latent representations, tokenizers enable generative models to operate in lower-dimensional spaces, thereby improving computational efficiency and reducing complexity. Discrete tokenizers naturally align with the autoregressive paradigm but still lag behind continuous ones, limiting their adoption in multimodal systems. To address this, we propose \textbf{SFTok}, a discrete tokenizer that incorporates a multi-step iterative mechanism for precise reconstruction. By integrating \textbf{self-forcing guided visual reconstruction} and \textbf{debias-and-fitting training strategy}, SFTok resolves the training-inference inconsistency in multi-step process, significantly enhancing image reconstruction quality. At a high compression rate of only 64 tokens per image, SFTok achieves state-of-the-art reconstruction quality on ImageNet (rFID = 1.21) and demonstrates exceptional performance in class-to-image generation tasks (gFID = 2.29).|
|**2025-12-18**|[Alchemist: Unlocking Efficiency in Text-to-Image Model Training via Meta-Gradient Data Selection](http://arxiv.org/abs/2512.16905)|null|Recent advances in Text-to-Image (T2I) generative models, such as Imagen, Stable Diffusion, and FLUX, have led to remarkable improvements in visual quality. However, their performance is fundamentally limited by the quality of training data. Web-crawled and synthetic image datasets often contain low-quality or redundant samples, which lead to degraded visual fidelity, unstable training, and inefficient computation. Hence, effective data selection is crucial for improving data efficiency. Existing approaches rely on costly manual curation or heuristic scoring based on single-dimensional features in Text-to-Image data filtering. Although meta-learning based method has been explored in LLM, there is no adaptation for image modalities. To this end, we propose **Alchemist**, a meta-gradient-based framework to select a suitable subset from large-scale text-image data pairs. Our approach automatically learns to assess the influence of each sample by iteratively optimizing the model from a data-centric perspective. Alchemist consists of two key stages: data rating and data pruning. We train a lightweight rater to estimate each sample's influence based on gradient information, enhanced with multi-granularity perception. We then use the Shift-Gsampling strategy to select informative subsets for efficient model training. Alchemist is the first automatic, scalable, meta-gradient-based data selection framework for Text-to-Image model training. Experiments on both synthetic and web-crawled datasets demonstrate that Alchemist consistently improves visual quality and downstream performance. Training on an Alchemist-selected 50% of the data can outperform training on the full dataset.|
|**2025-12-18**|[Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image](http://arxiv.org/abs/2512.16899)|null|Reward models (RMs) are essential for training large language models (LLMs), but remain underexplored for omni models that handle interleaved image and text sequences. We introduce Multimodal RewardBench 2 (MMRB2), the first comprehensive benchmark for reward models on multimodal understanding and (interleaved) generation. MMRB2 spans four tasks: text-to-image, image editing, interleaved generation, and multimodal reasoning ("thinking-with-images"), providing 1,000 expert-annotated preference pairs per task from 23 models and agents across 21 source tasks. MMRB2 is designed with: (1) practical but challenging prompts; (2) responses from state-of-the-art models and agents; and (3) preference pairs with strong human-expert consensus, curated via an ensemble filtering strategy. Using MMRB2, we study existing judges for each subtask, including multimodal LLM-as-a-judge and models trained with human preferences. The latest Gemini 3 Pro attains 75-80% accuracy. GPT-5 and Gemini 2.5 Pro reach 66-75% accuracy, compared to >90% for humans, yet surpass the widely used GPT-4o (59%). The best performing open-source model Qwen3-VL-32B achieves similar accuracies as Gemini 2.5 Flash (64%). We also show that MMRB2 performance strongly correlates with downstream task success using Best-of-N sampling and conduct an in-depth analysis that shows key areas to improve the reward models going forward.|
|**2025-12-18**|[Sceniris: A Fast Procedural Scene Generation Framework](http://arxiv.org/abs/2512.16896)|null|Synthetic 3D scenes are essential for developing Physical AI and generative models. Existing procedural generation methods often have low output throughput, creating a significant bottleneck in scaling up dataset creation. In this work, we introduce Sceniris, a highly efficient procedural scene generation framework for rapidly generating large-scale, collision-free scene variations. Sceniris also provides an optional robot reachability check, providing manipulation-feasible scenes for robot tasks. Sceniris is designed for maximum efficiency by addressing the primary performance limitations of the prior method, Scene Synthesizer. Leveraging batch sampling and faster collision checking in cuRobo, Sceniris achieves at least 234x speed-up over Scene Synthesizer. Sceniris also expands the object-wise spatial relationships available in prior work to support diverse scene requirements. Our code is available at https://github.com/rai-inst/sceniris|
|**2025-12-18**|[Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation](http://arxiv.org/abs/2512.16893)|null|Portrait animation has witnessed tremendous quality improvements thanks to recent advances in video diffusion models. However, these 2D methods often compromise 3D consistency and speed, limiting their applicability in real-world scenarios, such as digital twins or telepresence. In contrast, 3D-aware facial animation feedforward methods -- built upon explicit 3D representations, such as neural radiance fields or Gaussian splatting -- ensure 3D consistency and achieve faster inference speed, but come with inferior expression details. In this paper, we aim to combine their strengths by distilling knowledge from a 2D diffusion-based method into a feed-forward encoder, which instantly converts an in-the-wild single image into a 3D-consistent, fast yet expressive animatable representation. Our animation representation is decoupled from the face's 3D representation and learns motion implicitly from data, eliminating the dependency on pre-defined parametric models that often constrain animation capabilities. Unlike previous computationally intensive global fusion mechanisms (e.g., multiple attention layers) for fusing 3D structural and animation information, our design employs an efficient lightweight local fusion strategy to achieve high animation expressivity. As a result, our method runs at 107.31 FPS for animation and pose control while achieving comparable animation quality to the state-of-the-art, surpassing alternative designs that trade speed for quality or vice versa. Project website is https://research.nvidia.com/labs/amri/projects/instant4d|
|**2025-12-18**|[GenEval 2: Addressing Benchmark Drift in Text-to-Image Evaluation](http://arxiv.org/abs/2512.16853)|null|Automating Text-to-Image (T2I) model evaluation is challenging; a judge model must be used to score correctness, and test prompts must be selected to be challenging for current T2I models but not the judge. We argue that satisfying these constraints can lead to benchmark drift over time, where the static benchmark judges fail to keep up with newer model capabilities. We show that benchmark drift is a significant problem for GenEval, one of the most popular T2I benchmarks. Although GenEval was well-aligned with human judgment at the time of its release, it has drifted far from human judgment over time -- resulting in an absolute error of as much as 17.7% for current models. This level of drift strongly suggests that GenEval has been saturated for some time, as we verify via a large-scale human study. To help fill this benchmarking gap, we introduce a new benchmark, GenEval 2, with improved coverage of primitive visual concepts and higher degrees of compositionality, which we show is more challenging for current models. We also introduce Soft-TIFA, an evaluation method for GenEval 2 that combines judgments for visual primitives, which we show is more well-aligned with human judgment and argue is less likely to drift from human-alignment over time (as compared to more holistic judges such as VQAScore). Although we hope GenEval 2 will provide a strong benchmark for many years, avoiding benchmark drift is far from guaranteed and our work, more generally, highlights the importance of continual audits and improvement for T2I and related automated model evaluation benchmarks.|
|**2025-12-18**|[Kling-Omni Technical Report](http://arxiv.org/abs/2512.16776)|null|We present Kling-Omni, a generalist generative framework designed to synthesize high-fidelity videos directly from multimodal visual language inputs. Adopting an end-to-end perspective, Kling-Omni bridges the functional separation among diverse video generation, editing, and intelligent reasoning tasks, integrating them into a holistic system. Unlike disjointed pipeline approaches, Kling-Omni supports a diverse range of user inputs, including text instructions, reference images, and video contexts, processing them into a unified multimodal representation to deliver cinematic-quality and highly-intelligent video content creation. To support these capabilities, we constructed a comprehensive data system that serves as the foundation for multimodal video creation. The framework is further empowered by efficient large-scale pre-training strategies and infrastructure optimizations for inference. Comprehensive evaluations reveal that Kling-Omni demonstrates exceptional capabilities in in-context generation, reasoning-based editing, and multimodal instruction following. Moving beyond a content creation tool, we believe Kling-Omni is a pivotal advancement toward multimodal world simulators capable of perceiving, reasoning, generating and interacting with the dynamic and complex worlds.|
|**2025-12-18**|[Task-Oriented Data Synthesis and Control-Rectify Sampling for Remote Sensing Semantic Segmentation](http://arxiv.org/abs/2512.16740)|null|With the rapid progress of controllable generation, training data synthesis has become a promising way to expand labeled datasets and alleviate manual annotation in remote sensing (RS). However, the complexity of semantic mask control and the uncertainty of sampling quality often limit the utility of synthetic data in downstream semantic segmentation tasks. To address these challenges, we propose a task-oriented data synthesis framework (TODSynth), including a Multimodal Diffusion Transformer (MM-DiT) with unified triple attention and a plug-and-play sampling strategy guided by task feedback. Built upon the powerful DiT-based generative foundation model, we systematically evaluate different control schemes, showing that a text-image-mask joint attention scheme combined with full fine-tuning of the image and mask branches significantly enhances the effectiveness of RS semantic segmentation data synthesis, particularly in few-shot and complex-scene scenarios. Furthermore, we propose a control-rectify flow matching (CRFM) method, which dynamically adjusts sampling directions guided by semantic loss during the early high-plasticity stage, mitigating the instability of generated images and bridging the gap between synthetic data and downstream segmentation tasks. Extensive experiments demonstrate that our approach consistently outperforms state-of-the-art controllable generation methods, producing more stable and task-oriented synthetic data for RS semantic segmentation.|
|**2025-12-12**|[V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties](http://arxiv.org/abs/2512.11799)|**[link](https://github.com/Aleafy/V-RGBX)**|Large-scale video generation models have shown remarkable potential in modeling photorealistic appearance and lighting interactions in real-world scenes. However, a closed-loop framework that jointly understands intrinsic scene properties (e.g., albedo, normal, material, and irradiance), leverages them for video synthesis, and supports editable intrinsic representations remains unexplored. We present V-RGBX, the first end-to-end framework for intrinsic-aware video editing. V-RGBX unifies three key capabilities: (1) video inverse rendering into intrinsic channels, (2) photorealistic video synthesis from these intrinsic representations, and (3) keyframe-based video editing conditioned on intrinsic channels. At the core of V-RGBX is an interleaved conditioning mechanism that enables intuitive, physically grounded video editing through user-selected keyframes, supporting flexible manipulation of any intrinsic modality. Extensive qualitative and quantitative results show that V-RGBX produces temporally consistent, photorealistic videos while propagating keyframe edits across sequences in a physically plausible manner. We demonstrate its effectiveness in diverse applications, including object appearance editing and scene-level relighting, surpassing the performance of prior methods.|
|**2025-12-12**|[AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis](http://arxiv.org/abs/2512.11797)|null|The collection of large-scale and diverse robot demonstrations remains a major bottleneck for imitation learning, as real-world data acquisition is costly and simulators offer limited diversity and fidelity with pronounced sim-to-real gaps. While generative models present an attractive solution, existing methods often alter only visual appearances without creating new behaviors, or suffer from embodiment inconsistencies that yield implausible motions. To address these limitations, we introduce AnchorDream, an embodiment-aware world model that repurposes pretrained video diffusion models for robot data synthesis. AnchorDream conditions the diffusion process on robot motion renderings, anchoring the embodiment to prevent hallucination while synthesizing objects and environments consistent with the robot's kinematics. Starting from only a handful of human teleoperation demonstrations, our method scales them into large, diverse, high-quality datasets without requiring explicit environment modeling. Experiments show that the generated data leads to consistent improvements in downstream policy learning, with relative gains of 36.4% in simulator benchmarks and nearly double performance in real-world studies. These results suggest that grounding generative world models in robot motion provides a practical path toward scaling imitation learning.|
|**2025-12-12**|[Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation](http://arxiv.org/abs/2512.11792)|null|Reality is a dance between rigid constraints and deformable structures. For video models, that means generating motion that preserves fidelity as well as structure. Despite progress in diffusion models, producing realistic structure-preserving motion remains challenging, especially for articulated and deformable objects such as humans and animals. Scaling training data alone, so far, has failed to resolve physically implausible transitions. Existing approaches rely on conditioning with noisy motion representations, such as optical flow or skeletons extracted using an external imperfect model. To address these challenges, we introduce an algorithm to distill structure-preserving motion priors from an autoregressive video tracking model (SAM2) into a bidirectional video diffusion model (CogVideoX). With our method, we train SAM2VideoX, which contains two innovations: (1) a bidirectional feature fusion module that extracts global structure-preserving motion priors from a recurrent model like SAM2; (2) a Local Gram Flow loss that aligns how local features move together. Experiments on VBench and in human studies show that SAM2VideoX delivers consistent gains (+2.60\% on VBench, 21-22\% lower FVD, and 71.4\% human preference) over prior baselines. Specifically, on VBench, we achieve 95.51\%, surpassing REPA (92.91\%) by 2.60\%, and reduce FVD to 360.57, a 21.20\% and 22.46\% improvement over REPA- and LoRA-finetuning, respectively. The project website can be found at https://sam2videox.github.io/ .|
|**2025-12-12**|[Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously](http://arxiv.org/abs/2512.11783)|null|The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.   Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.|
|**2025-12-12**|[Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints](http://arxiv.org/abs/2512.11771)|null|Model fingerprint detection techniques have emerged as a promising approach for attributing AI-generated images to their source models, but their robustness under adversarial conditions remains largely unexplored. We present the first systematic security evaluation of these techniques, formalizing threat models that encompass both white- and black-box access and two attack goals: fingerprint removal, which erases identifying traces to evade attribution, and fingerprint forgery, which seeks to cause misattribution to a target model. We implement five attack strategies and evaluate 14 representative fingerprinting methods across RGB, frequency, and learned-feature domains on 12 state-of-the-art image generators. Our experiments reveal a pronounced gap between clean and adversarial performance. Removal attacks are highly effective, often achieving success rates above 80% in white-box settings and over 50% under constrained black-box access. While forgery is more challenging than removal, its success significantly varies across targeted models. We also identify a utility-robustness trade-off: methods with the highest attribution accuracy are often vulnerable to attacks. Although some techniques exhibit robustness in specific settings, none achieves high robustness and accuracy across all evaluated threat models. These findings highlight the need for techniques balancing robustness and accuracy, and identify the most promising approaches for advancing this goal.|
|**2025-12-12**|[Reducing Domain Gap with Diffusion-Based Domain Adaptation for Cell Counting](http://arxiv.org/abs/2512.11763)|null|Generating realistic synthetic microscopy images is critical for training deep learning models in label-scarce environments, such as cell counting with many cells per image. However, traditional domain adaptation methods often struggle to bridge the domain gap when synthetic images lack the complex textures and visual patterns of real samples. In this work, we adapt the Inversion-Based Style Transfer (InST) framework originally designed for artistic style transfer to biomedical microscopy images. Our method combines latent-space Adaptive Instance Normalization with stochastic inversion in a diffusion model to transfer the style from real fluorescence microscopy images to synthetic ones, while weakly preserving content structure.   We evaluate the effectiveness of our InST-based synthetic dataset for downstream cell counting by pre-training and fine-tuning EfficientNet-B0 models on various data sources, including real data, hard-coded synthetic data, and the public Cell200-s dataset. Models trained with our InST-synthesized images achieve up to 37\% lower Mean Absolute Error (MAE) compared to models trained on hard-coded synthetic data, and a 52\% reduction in MAE compared to models trained on Cell200-s (from 53.70 to 25.95 MAE). Notably, our approach also outperforms models trained on real data alone (25.95 vs. 27.74 MAE). Further improvements are achieved when combining InST-synthesized data with lightweight domain adaptation techniques such as DACS with CutMix. These findings demonstrate that InST-based style transfer most effectively reduces the domain gap between synthetic and real microscopy data. Our approach offers a scalable path for enhancing cell counting performance while minimizing manual labeling effort. The source code and resources are publicly available at: https://github.com/MohammadDehghan/InST-Microscopy.|
|**2025-12-12**|[SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder](http://arxiv.org/abs/2512.11749)|**[link](https://github.com/KlingTeam/SVG-T2I)**|Visual generation grounded in Visual Foundation Model (VFM) representations offers a highly promising unified pathway for integrating visual understanding, perception, and generation. Despite this potential, training large-scale text-to-image diffusion models entirely within the VFM representation space remains largely unexplored. To bridge this gap, we scale the SVG (Self-supervised representations for Visual Generation) framework, proposing SVG-T2I to support high-quality text-to-image synthesis directly in the VFM feature domain. By leveraging a standard text-to-image diffusion pipeline, SVG-T2I achieves competitive performance, reaching 0.75 on GenEval and 85.78 on DPG-Bench. This performance validates the intrinsic representational power of VFMs for generative tasks. We fully open-source the project, including the autoencoder and generation model, together with their training, inference, evaluation pipelines, and pre-trained weights, to facilitate further research in representation-driven visual generation.|
|**2025-12-12**|[Multiscale Causal Geometric Deep Learning for Modeling Brain Structure](http://arxiv.org/abs/2512.11738)|**[link](https://github.com/xxxcz222/Multiscale-Causal-Geometric-Deep-Learning-for-Modeling-Brain-Structure)**|Multimodal MRI offers complementary multi-scale information to characterize the brain structure. However, it remains challenging to effectively integrate multimodal MRI while achieving neuroscience interpretability. Here we propose to use Laplacian harmonics and spectral graph theory for multimodal alignment and multiscale integration. Based on the cortical mesh and connectome matrix that offer multi-scale representations, we devise Laplacian operators and spectral graph attentions to construct a shared latent space for model alignment. Next, we employ a disentangled learning combined with Graph Variational Autoencoder architectures to separate scale-specific and shared features. Lastly, we design a mutual information-informed bilevel regularizer to separate causal and non-causal factors based on the disentangled features, achieving robust model performance with enhanced interpretability. Our model outperforms baselines and other state-of-the-art models. The ablation studies confirmed the effectiveness of the proposed modules. Our model promises to offer a robust and interpretable framework for multi-scale brain structure analysis.|
|**2025-12-12**|[Reframing Music-Driven 2D Dance Pose Generation as Multi-Channel Image Generation](http://arxiv.org/abs/2512.11720)|null|最近的姿态到视频模型能够将2D姿态序列转换为真实感、身份保持的舞蹈视频，因此，关键挑战在于从音乐生成时间连贯、节奏对齐的2D姿态，尤其是在复杂、高方差的野外分布下。我们通过将音乐到舞蹈生成重新定义为音乐令牌条件下的多通道图像合成问题来解决此问题：2D姿态序列被编码为独热图像，经预训练图像VAE压缩，并使用DiT风格骨干网络进行建模，这使我们能够继承现代文本到图像模型在架构和训练方面的进展，并更好地捕捉高方差的2D姿态分布。在此公式的基础上，我们引入了(i)一种时间共享的时间索引方案，它显式地同步音乐令牌和姿态潜在变量随时间的变化，以及(ii)一种参考姿态条件策略，该策略在保持主体特定的身体比例和屏幕上的尺度的同时，实现了长范围分段和拼接生成。在大型野外2D舞蹈语料库和经过校准的AIST++2D基准上进行的实验表明，与代表性音乐到舞蹈方法相比，我们的方法在姿态空间和视频空间指标以及人类偏好方面均显示出持续改进，并且消融实验验证了表示、时间索引和参考条件的贡献。补充视频请参见https://hot-dance.github.io|
|**2025-12-12**|[EditMGT: Unleashing Potentials of Masked Generative Transformers in Image Editing](http://arxiv.org/abs/2512.11715)|**[link](https://github.com/weichow23/EditMGT)**|Recent advances in diffusion models (DMs) have achieved exceptional visual quality in image editing tasks. However, the global denoising dynamics of DMs inherently conflate local editing targets with the full-image context, leading to unintended modifications in non-target regions. In this paper, we shift our attention beyond DMs and turn to Masked Generative Transformers (MGTs) as an alternative approach to tackle this challenge. By predicting multiple masked tokens rather than holistic refinement, MGTs exhibit a localized decoding paradigm that endows them with the inherent capacity to explicitly preserve non-relevant regions during the editing process. Building upon this insight, we introduce the first MGT-based image editing framework, termed EditMGT. We first demonstrate that MGT's cross-attention maps provide informative localization signals for localizing edit-relevant regions and devise a multi-layer attention consolidation scheme that refines these maps to achieve fine-grained and precise localization. On top of these adaptive localization results, we introduce region-hold sampling, which restricts token flipping within low-attention areas to suppress spurious edits, thereby confining modifications to the intended target regions and preserving the integrity of surrounding non-target areas. To train EditMGT, we construct CrispEdit-2M, a high-resolution dataset spanning seven diverse editing categories. Without introducing additional parameters, we adapt a pre-trained text-to-image MGT into an image editing model through attention injection. Extensive experiments across four standard benchmarks demonstrate that, with fewer than 1B parameters, our model achieves similarity performance while enabling 6 times faster editing. Moreover, it delivers comparable or superior editing quality, with improvements of 3.6% and 17.6% on style change and style transfer tasks, respectively.|
|**2025-12-11**|[Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration](http://arxiv.org/abs/2512.10954)|null|In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rather than limited to just the patches within an image. This enables images to be jointly denoised at inference time, learning both intra and inter-image correspondence. We observe a clear scaling effect - larger group sizes yield stronger cross-sample attention and better generation quality. Furthermore, we introduce a qualitative measure to capture this behavior and show that its strength closely correlates with FID. Built on standard diffusion transformers, our GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256. Our work reveals cross-sample inference as an effective, previously unexplored mechanism for generative modeling.|
|**2025-12-11**|[Bidirectional Normalizing Flow: From Data to Noise and Back](http://arxiv.org/abs/2512.10953)|null|Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ( $\textbf{BiFlow}$ ), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation ("1-NFE") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.|
|**2025-12-11**|[Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](http://arxiv.org/abs/2512.10949)|**[link](https://github.com/Ivan-Tang-3D/3DGen-R1)**|Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.|
|**2025-12-11**|[AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation](http://arxiv.org/abs/2512.10943)|null|Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applications such as compositional video synthesis, storyboarding, and controllable animation. We propose AlcheMinT, a unified framework that introduces explicit timestamps conditioning for subject-driven video generation. Our approach introduces a novel positional encoding mechanism that unlocks the encoding of temporal intervals, associated in our case with subject identities, while seamlessly integrating with the pretrained video generation model positional embeddings. Additionally, we incorporate subject-descriptive text tokens to strengthen binding between visual identity and video captions, mitigating ambiguity during generation. Through token-wise concatenation, AlcheMinT avoids any additional cross-attention modules and incurs negligible parameter overhead. We establish a benchmark evaluating multiple subject identity preservation, video fidelity, and temporal adherence. Experimental results demonstrate that AlcheMinT achieves visual quality matching state-of-the-art video personalization methods, while, for the first time, enabling precise temporal control over multi-subject generation within videos. Project page is at https://snap-research.github.io/Video-AlcheMinT|
|**2025-12-11**|[Mull-Tokens: Modality-Agnostic Latent Thinking](http://arxiv.org/abs/2512.10941)|null|Reasoning goes beyond language; the real world requires reasoning about space, time, affordances, and much more that words alone cannot convey. Existing multimodal models exploring the potential of reasoning with images are brittle and do not scale. They rely on calling specialist tools, costly generation of images, or handcrafted reasoning data to switch between text and image thoughts. Instead, we offer a simpler alternative -- Mull-Tokens -- modality-agnostic latent tokens pre-trained to hold intermediate information in either image or text modalities to let the model think free-form towards the correct answer. We investigate best practices to train Mull-Tokens inspired by latent reasoning frameworks. We first train Mull-Tokens using supervision from interleaved text-image traces, and then fine-tune without any supervision by only using the final answers. Across four challenging spatial reasoning benchmarks involving tasks such as solving puzzles and taking different perspectives, we demonstrate that Mull-Tokens improve upon several baselines utilizing text-only reasoning or interleaved image-text reasoning, achieving a +3% average improvement and up to +16% on a puzzle solving reasoning-heavy split compared to our strongest baseline. Adding to conversations around challenges in grounding textual and visual reasoning, Mull-Tokens offers a simple solution to abstractly think in multiple modalities.|
|**2025-12-11**|[OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis](http://arxiv.org/abs/2512.10940)|null|Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D data. We introduce OmniView, a unified framework that generalizes across a wide range of 4D consistency tasks. Our method separately represents space, time, and view conditions, enabling flexible combinations of these inputs. For example, OmniView can synthesize novel views from static, dynamic, and multiview inputs, extrapolate trajectories forward and backward in time, and create videos from text or image prompts with full camera control. OmniView is competitive with task-specific models across diverse benchmarks and metrics, improving image quality scores among camera-conditioned diffusion models by up to 33\% in multiview NVS LLFF dataset, 60\% in dynamic NVS Neural 3D Video benchmark, 20\% in static camera control on RE-10K, and reducing camera trajectory errors by 4x in text-conditioned video generation. With strong generalizability in one model, OmniView demonstrates the feasibility of a generalist 4D video model. Project page is available at https://snap-research.github.io/OmniView/|
|**2025-12-11**|[GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting](http://arxiv.org/abs/2512.10939)|**[link](https://github.com/madhav1ag/GaussianHeadTalk)**|Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot settings. Gaussian Splatting approaches are real-time, yet inaccuracies in facial tracking, or inconsistent Gaussian mappings, lead to unstable outputs and video artifacts that are detrimental to realistic use cases. We address this problem by mapping Gaussian Splatting using 3D Morphable Models to generate person-specific avatars. We introduce transformer-based prediction of model parameters, directly from audio, to drive temporal consistency. From monocular video and independent audio speech inputs, our method enables generation of real-time talking head videos where we report competitive quantitative and qualitative performance.|
|**2025-12-11**|[Iterative Compositional Data Generation for Robot Control](http://arxiv.org/abs/2512.10891)|**[link](https://github.com/anhquanpham/iterative-comp-rl-generation)**|Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, they do not exploit the compositional structure of robotic domains and struggle to generalize to unseen task combinations. We propose a semantic compositional diffusion transformer that factorizes transitions into robot-, object-, obstacle-, and objective-specific components and learns their interactions through attention. Once trained on a limited subset of tasks, we show that our model can zero-shot generate high-quality transitions from which we can learn control policies for unseen task combinations. Then, we introduce an iterative self-improvement procedure in which synthetic data is validated via offline reinforcement learning and incorporated into subsequent training rounds. Our approach substantially improves zero-shot performance over monolithic and hard-coded compositional baselines, ultimately solving nearly all held-out tasks and demonstrating the emergence of meaningful compositional structure in the learned representations.|
|**2025-12-11**|[Guided Transfer Learning for Discrete Diffusion Models](http://arxiv.org/abs/2512.10877)|null|Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.|
|**2025-12-11**|[Scaling Behavior of Discrete Diffusion Language Models](http://arxiv.org/abs/2512.10858)|null|Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However, their scaling behavior has not yet been fully explored, with prior work suggesting that they require more data and compute to match the performance of ALMs.   We study the scaling behavior of DLMs on different noise types by smoothly interpolating between masked and uniform diffusion while paying close attention to crucial hyperparameters such as batch size and learning rate. Our experiments reveal that the scaling behavior of DLMs strongly depends on the noise type and is considerably different from ALMs. While all noise types converge to similar loss values in compute-bound scaling, we find that uniform diffusion requires more parameters and less data for compute-efficient training compared to masked diffusion, making them a promising candidate in data-bound settings. We scale our uniform diffusion model up to 10B parameters trained for $10^{22}$ FLOPs, confirming the predicted scaling behavior and making it the largest publicly known uniform diffusion model to date.|
|**2025-12-04**|[On the treatment of thermal effects in the equation of state on neutron star merger remnants](http://arxiv.org/abs/2512.05118)|null|我们展示了使用完全列表式有限温度物态方程及其对应的混合表示对双中子星并合进行长期数值相对论模拟的结果。模拟持续长达150毫秒，这使我们能够评估有限温度效应处理方式对超大质量中子星遗迹动力学的作用。我们的研究重点是分析并合后引力波信号的频谱，以及这些频谱如何受到两种物态方程表示中热效应处理方式的影响。我们的模拟突出了与物态方程热建模相关的引力波频率演化的显著差异，表明与既定准普适关系的偏差在并合后期变得显著。此外，我们研究了超大质量中子星对流的稳定性。我们同时采用勒杜判据（对流不稳定发展所必需的条件）和索尔伯格-霍伊兰德判据（基于布伦特-瓦伊萨拉频率和周转频率组合分析的轴对称扰动广义判据），结果表明超大质量中子星中的差速转动和热分层产生了局部（但持续）的对流模式，这些模式在并合后持续超过100毫秒。这些对流模式在列表式和混合式物态方程处理之间存在显著差异，它们触发了频率低于基频四极模态的惯性模态的激发，并可能由第三代引力波探测器探测到。先前基于混合式物态方程研究中报道的惯性模态的后期激发，得到了本文提出的列表式有限温度物态方程模拟的充分支持，这些模拟以更一致的方式考虑了热效应。|
|**2025-12-04**|[Value Gradient Guidance for Flow Matching Alignment](http://arxiv.org/abs/2512.05116)|null|尽管存在将流匹配模型（一类流行且有效的生成模型）与人类偏好对齐的方法，但现有方法未能同时实现适应效率和概率上合理的先验保持。在这项工作中，我们利用最优控制理论，提出了一种基于梯度匹配的微调预训练流匹配模型的方法VGG-Flow。该算法的核心思想是，微调后的速度场与预训练速度场之间的最优差异应与价值函数的梯度场匹配。这种方法不仅融入了来自奖励模型的一阶信息，而且受益于价值函数的启发式初始化以实现快速适应。经验上，我们在一个流行的文本到图像流匹配模型Stable Diffusion 3上展示，我们的方法可以在有限的计算预算下微调流匹配模型，同时实现有效且先验保持的对齐。|
|**2025-12-04**|[Light-X: Generative 4D Video Rendering with Camera and Illumination Control](http://arxiv.org/abs/2512.05115)|null|光照控制方面的最新进展将基于图像的方法扩展到视频，但仍面临光照保真度与时间一致性之间的权衡。超越重打光，实现真实世界场景生成建模的关键一步是相机轨迹和光照的联合控制，因为视觉动态本质上是由几何形状和光照共同塑造的。为此，我们提出了Light-X，一个视频生成框架，能够从单目视频进行可控渲染，并同时具备视点和光照控制能力。1) 我们提出了一种解耦设计，将几何形状和光照信号解耦：几何形状和运动通过沿用户定义相机轨迹投影的动态点云捕获，而光照线索由一个一致地投影到相同几何形状中的重打光帧提供。这些明确的、细粒度的线索实现了有效的解耦并引导高质量的光照。2) 为了解决缺乏配对的多视角和多光照视频的问题，我们引入了Light-Syn，一个基于降级且带有逆映射的流水线，用于从野外单目素材合成训练对。这种策略产生了一个涵盖静态、动态和AI生成的场景的数据集，从而确保了鲁棒的训练。大量实验表明，Light-X在联合相机-光照控制方面优于基线方法，并在文本条件和背景条件设置下超越了现有的视频重打光方法。|
|**2025-12-04**|[DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation](http://arxiv.org/abs/2512.05112)|**[link](https://github.com/CaraJ7/DraCo)**|近期统一多模态大语言模型 (MLLM) 展示了令人印象深刻的能力，通过结合思维链 (CoT) 推理增强了文本到图像的生成。然而，现有方法仍然存在局限性，要么仅将模型视为一个独立的生成器，要么依赖抽象的文本规划。为此，我们提出了Draft-as-CoT (DraCo)，这是一种新颖的交错推理范式，它在CoT中充分利用文本和视觉内容，以实现更好的规划和验证。我们的方法首先生成低分辨率草图图像作为预览，提供更具体和结构化的视觉规划与指导。然后，我们利用模型固有的理解能力来验证草图与输入提示之间潜在的语义错位，并通过选择性修正结合超分辨率进行细化。通过这种方式，我们的方法解决了两个基本挑战：文本规划的粗粒度性质以及生成稀有属性组合的难度。为了支持训练，我们整理了DraCo-240K数据集，旨在增强涵盖通用修正、实例操作和布局重组三种原子能力。在DraCo-CFG（一种专用于交错推理的无分类器引导 (CFG) 策略）的支持下，DraCo在GenEval上实现了8%的巨大提升，在Imagine-Bench上提升了0.91，在GenEval++上提升了3%，显著优于直接生成和受CoT赋能的其他生成方法。|
|**2025-12-04**|[ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning](http://arxiv.org/abs/2512.05111)|**[link](https://github.com/InternLM/ARM-Thinker)**|奖励模型对于将视觉-语言系统与人类偏好对齐至关重要，然而当前方法存在幻觉、视觉接地能力弱以及无法使用工具进行验证的问题，这限制了它们在复杂多模态推理任务上的可靠性。我们提出了ARM-Thinker，一个智能体式多模态奖励模型，它能够自主调用外部工具（例如，图像裁剪、文档页面检索），将判断建立在可验证的证据之上，取代了静态、非交互式的奖励评分。这使得模型能够验证细粒度视觉细节、交叉引用多页证据并验证推理主张，这些能力是现有奖励模型所不具备的。我们使用多阶段强化学习训练ARM-Thinker，联合优化工具调用决策和判断准确性。为了评估智能体式奖励模型，我们引入了ARMBench-VL，该基准包含三个子任务，用于评估细粒度视觉接地能力（图像级工具）、多页文档理解能力（检索工具）和指令遵循能力（文本级验证）。ARM-Thinker在奖励模型基准上实现了平均16.2%的提升，在工具使用任务上提升了9.6%，并在多模态数学和逻辑推理基准上超越了基线。我们的结果表明，智能体能力显著增强了奖励模型的准确性和可解释性。|
|**2025-12-04**|[ShadowDraw: From Any Object to Shadow-Drawing Compositional Art](http://arxiv.org/abs/2512.05110)|null|我们引入了 ShadowDraw，一个将普通三维物体转化为影绘构图艺术的框架。给定一个三维物体，我们的系统预测场景参数（包括物体姿态和光照）以及一个局部线条画，使得投射的阴影将该线条画补全为一个可识别的图像。为此，我们优化场景配置以揭示有意义的阴影，利用阴影笔触引导线条画生成，并采用自动评估以确保影绘连贯性和视觉质量。实验表明，ShadowDraw 在多种输入（从真实世界扫描、精选数据集到生成资产）上均产生了引人注目的结果，并自然地扩展到多物体场景、动画和物理部署。我们的工作为创建影绘艺术提供了一个实用流程，拓宽了计算视觉艺术的设计空间，弥合了算法设计与艺术叙事之间的鸿沟。访问我们的项目页面 https://red-fairy.github.io/ShadowDraw/ 查看更多结果以及我们流程的端到端真实世界演示！|
|**2025-12-04**|[NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation](http://arxiv.org/abs/2512.05106)|null|标准扩散使用高斯噪声破坏数据，其傅里叶系数具有随机幅度和随机相位。尽管对无条件或文本到图像生成有效，但破坏相位分量会破坏空间结构，使其不适合需要几何一致性的任务，例如重渲染、模拟增强和图像到图像翻译。我们引入了相位保持扩散φ-PD，这是对扩散过程的一种模型无关的重新表述，它在随机化幅度的同时保持输入相位，从而无需架构更改或额外参数即可实现结构对齐的生成。我们进一步提出了频率选择结构化（FSS）噪声，通过单一频率截止参数提供对结构刚度的连续控制。φ-PD不增加推理时间成本，并且与任何用于图像或视频的扩散模型兼容。在真实感和风格化重渲染以及用于驾驶规划器的模拟到真实增强中，φ-PD均产生可控的、空间对齐的结果。当应用于CARLA模拟器时，φ-PD将CARLA到Waymo规划器的性能提高了50%。该方法与现有条件化方法互补，并广泛适用于图像到图像和视频到视频生成。视频、更多示例和代码可在我们的项目页面上获取。|
|**2025-12-04**|[Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning](http://arxiv.org/abs/2512.05105)|null|大型语言模型（LLMs）中的长上下文推理通过思维链（CoT）推理展现了其认知能力的增强。这类模型的训练通常通过在基于推理的问题（如数学和编程）中使用可验证奖励强化学习（RLVR）完成。然而，RLVR受到几个瓶颈的限制，例如缺乏密集奖励和样本效率不足。因此，它在训练后阶段需要大量的计算资源。为了克服这些局限性，在这项工作中，我们提出了语义软自举（SSB），这是一种自蒸馏技术，其中相同的基本语言模型同时扮演教师和学生的角色，但在训练时接收关于其结果正确性的不同语义上下文。模型首先被提示一个数学问题，并生成多个推理过程。从中筛选出正确和最常见的错误响应，然后作为上下文提供给模型，以产生更鲁棒、分步的解释和经过验证的最终答案。这个流程无需任何人工干预，即可从原始问题-答案数据中自动构建配对的教师-学生训练集。这个生成过程还会产生一个logit序列，这是学生模型在训练阶段仅凭问题本身试图匹配的目标。在我们的实验中，我们对Qwen2.5-3B-Instruct模型在GSM8K数据集上进行了参数高效微调。然后，我们在MATH500和AIME2024基准上测试了其准确性。我们的实验表明，与常用的RLVR算法组相对策略优化（GRPO）相比，准确率分别提高了10.6%和10%。我们的代码可在https://github.com/purbeshmitra/semantic-soft-bootstrapping获取，模型和策展数据集可在https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping获取。|
|**2025-12-04**|[EvoIR: Towards All-in-One Image Restoration via Evolutionary Frequency Modulation](http://arxiv.org/abs/2512.05104)|null|一体化图像复原（AiOIR）任务通常涉及多样化的退化，需要鲁棒且通用的策略。然而，大多数现有方法通常缺乏显式频率建模，并依赖固定或启发式的优化调度，这限制了其在异构退化场景下的泛化能力。为解决这些局限性，我们提出了EvoIR，一个专用于AiOIR的框架，它引入了演化频率调制用于动态自适应图像复原。具体而言，EvoIR采用了频率调制模块（FMM），以显式方式将特征分解为高频和低频分支，并自适应地调制它们以增强结构保真度和精细细节。作为EvoIR的核心，演化优化策略（EOS）通过基于种群的演化过程迭代调整频率感知目标，动态平衡结构准确性和感知保真度。它的演化指导进一步缓解了跨退化的梯度冲突，并加速了收敛。通过协同FMM和EOS，EvoIR取得了比单独使用任一组件更大的改进，突显了它们互补的作用。在多个基准上的广泛实验表明，EvoIR优于最先进的AiOIR方法。|
|**2025-12-04**|[TV2TV: A Unified Framework for Interleaved Language and Video Generation](http://arxiv.org/abs/2512.05103)|null|视频生成模型正在快速发展，但在处理需要大量语义分支或对接下来发生的事情进行重复高级推理的复杂视频输出时，仍可能面临挑战。在本文中，我们引入了一种新型的全能视频-文本模型，它整合了近期语言模型推理进展中的思想，以应对这一挑战。更具体地说，我们提出了TV2TV，这是一个统一的生成建模框架，它将视频生成分解为一个交错的文本和视频生成过程。TV2TV使用Transformer混合（MoT）架构，联合学习语言建模（下一词元预测）和视频流匹配（下一帧预测）。在推理时，TV2TV决定何时在生成文本和视频帧之间交替，从而允许模型在“以像素行动”生成帧之前，“以词语思考”后续内容。这种设计将决定接下来发生什么的大部分责任转移到语言建模塔，从而提高了生成视频的视觉质量和提示对齐度。它还实现了细粒度可控性，允许用户通过在过程中的任何点进行文本干预来修改视频生成轨迹。在视频游戏数据上的受控实验中，TV2TV在视觉质量和可控性两方面都表现出显著改进。TV2TV也适用于自然视频，正如我们通过使用视觉-语言模型（VLM）为体育视频增强交错的自然语言动作描述所展示的。在此语料库上训练TV2TV产生了强大的视觉质量和提示对齐度，展示了模型对复杂真实世界动作序列进行推理和生成的能力。综上所述，这些结果突显了TV2TV是迈向具有开放式文本推理和控制的视频生成的一个有前景的步骤。|
|**2025-12-02**|[MagicQuillV2: Precise and Interactive Image Editing with Layered Visual Cues](http://arxiv.org/abs/2512.03046)|**[link](https://github.com/zliucz/MagicQuillV2)**|我们提出MagicQuill V2，一个新颖的系统，它将分层组合范式引入生成式图像编辑，弥合了扩散模型的语义能力与传统图形软件的粒度控制之间的差距。尽管扩散Transformer擅长整体生成，但它们使用单一、整体的提示，无法分离用户在内容、位置和外观上的不同意图。为了克服这一问题，我们的方法将创作意图解构为一系列可控的视觉线索：一个内容层用于创建什么，一个空间层用于放置在哪里，一个结构层用于形状如何，以及一个颜色层用于其调色板。我们的技术贡献包括一个用于上下文感知内容集成的专门数据生成管道、一个用于处理所有视觉线索的统一控制模块，以及一个用于精确局部编辑（包括对象移除）的微调空间分支。大量实验验证了这种分层方法有效解决了用户意图差距，赋予创作者对生成过程的直接、直观控制。|
|**2025-12-02**|[CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models](http://arxiv.org/abs/2512.03045)|**[link](https://github.com/cvlab-kaist/CAMEO)**|多视角扩散模型最近作为新颖视图合成的强大范式出现，然而其实现视角一致性的潜在机制仍不清楚。在这项工作中，我们首先验证了这些模型的注意力图在整个训练过程中获得了几何对应性，能够关注参考视图和目标视图之间几何对应的区域，从而实现视角一致的生成。然而，这种对应信号仍然不完整，其准确性在大视点变化下会下降。基于这些发现，我们引入了CAMEO，这是一种简单而有效的训练技术，它利用几何对应性直接监督注意力图，以提升多视角扩散模型的训练效率和生成质量。值得注意的是，监督单个注意力层足以引导模型学习精确的对应关系，从而保留参考图像的几何和结构，加速收敛，并提高新颖视图合成性能。CAMEO将达到收敛所需的训练迭代次数减少了一半，同时在相同迭代次数下实现了卓越的性能。我们进一步证明CAMEO与模型无关，可以应用于任何多视角扩散模型。|
|**2025-12-02**|[Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling](http://arxiv.org/abs/2512.03044)|**[link](https://github.com/jiayueru/Video2Act)**|鲁棒感知和动力学建模是真实世界机器人策略学习的基础。最近的方法采用视频扩散模型（VDM）来增强机器人策略，提升它们对物理世界的理解和建模能力。然而，现有方法忽视了VDM中固有地编码在帧间的连贯且物理一致的运动表征。为此，我们提出了Video2Act，一个通过显式整合空间和运动感知表征来有效指导机器人动作学习的框架。基于VDM的固有表征，我们提取前景边界和帧间运动变化，同时过滤掉背景噪声和与任务无关的偏差。这些精炼的表征随后被用作扩散Transformer（DiT）动作头的额外条件输入，使其能够推理要操纵什么以及如何移动。为减轻推理效率低下问题，我们提出了一种异步双系统设计，其中VDM作为慢速的系统2，DiT头作为快速的系统1，两者协同工作以生成自适应动作。通过向系统1提供运动感知条件，Video2Act即使在VDM低频更新的情况下也能保持稳定的操纵。在评估中，Video2Act在仿真中和真实世界任务中的平均成功率分别超越了之前最先进的VLA方法7.7%和21.7%，并进一步展现出强大的泛化能力。|
|**2025-12-02**|[OneThinker: All-in-one Reasoning Model for Image and Video](http://arxiv.org/abs/2512.03043)|**[link](https://github.com/isLinXu/OneThinker)**|强化学习（RL）最近在激发多模态大语言模型（MLLMs）的视觉推理能力方面取得了显著成功。然而，现有方法通常为不同任务训练独立的模型，并将图像和视频推理视为不相交的领域。这导致了面向多模态推理通才的可扩展性有限，从而限制了实际的多功能性，并阻碍了任务和模态之间潜在的知识共享。为此，我们提出了OneThinker，一个一体化推理模型，它统一了图像和视频理解，涵盖了多种基本视觉任务，包括问答、图像描述、空间和时间定位、跟踪以及分割。为实现这一目标，我们构建了涵盖所有这些任务的OneThinker-600k训练语料库，并采用商业模型进行CoT标注，从而产生了用于SFT冷启动的OneThinker-SFT-340k。此外，我们提出了EMA-GRPO，通过跟踪任务奖励标准差的移动平均值来处理多任务RL中的奖励异质性，以实现平衡优化。在多样化的视觉基准上进行的大量实验表明，OneThinker在涵盖10个基本视觉理解任务的31个基准测试中表现出色。此外，它在某些任务之间展现出有效的知识迁移能力和初步的零样本泛化能力，这标志着向统一的多模态推理通才迈进了一步。所有代码、模型和数据均已发布。|
|**2025-12-02**|[PPTArena: A Benchmark for Agentic PowerPoint Editing](http://arxiv.org/abs/2512.03042)|null|我们引入了PPTArena，这是一个用于PowerPoint编辑的基准，用于衡量在自然语言指令下对真实幻灯片的可靠修改。与图像-PDF渲染或文本到幻灯片生成不同，PPTArena专注于100个演示文稿、2125张幻灯片上的原地编辑，涵盖文本、图表、表格、动画和母版级样式等800多次有针对性的编辑。每个案例都包含一个真值演示文稿、一个完全指定的目标结果，以及一个双VLM（视觉语言模型）判官管线，该管线使用结构差异和幻灯片图像分别对指令遵循和视觉质量进行评分。在此基础上，我们提出了PPTPilot，一个结构感知幻灯片编辑代理，它规划语义编辑序列，在高级编程工具和确定性XML操作之间进行路由以实现精确控制，并通过迭代的“规划-编辑-检查”循环对照任务特定约束来验证输出。在我们的实验中，PPTPilot在复合、布局敏感和跨幻灯片编辑方面，比强大的专有代理和前沿VLM系统高出10个百分点以上，在视觉保真度和演示文稿整体一致性方面取得了特别显著的提升。尽管有这些改进，现有代理在PPTArena中的长期、文档级任务上仍然表现不佳，凸显了可靠PPT编辑中存在的挑战。|
|**2025-12-02**|[MultiShotMaster: A Controllable Multi-Shot Video Generation Framework](http://arxiv.org/abs/2512.03041)|null|当前的视频生成技术擅长生成单镜头片段，但难以生成叙事性的多镜头视频，这需要灵活的镜头编排、连贯的叙事以及超越文本提示的可控性。为解决这些挑战，我们提出了MultiShotMaster，一个用于高度可控多镜头视频生成的框架。我们通过整合两种新颖的RoPE变体来扩展一个预训练的单镜头模型。首先，我们引入了多镜头叙事RoPE，它在镜头过渡时应用显式相位偏移，从而实现灵活的镜头编排，同时保持时间叙事顺序。其次，我们设计了时空位置感知RoPE，以整合参考tokens和接地信号，从而实现时空接地的参考注入。此外，为克服数据稀缺问题，我们建立了一个自动化数据标注流程，用于提取多镜头视频、字幕、跨镜头接地信号和参考图像。我们的框架利用固有的架构特性来支持多镜头视频生成，其特点是文本驱动的镜头间一致性、具有运动控制的自定义主体以及背景驱动的自定义场景。镜头数量和持续时间都可以灵活配置。大量实验证明了我们框架的卓越性能和出色的可控性。|
|**2025-12-02**|[Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation](http://arxiv.org/abs/2512.03040)|null|我们研究视频生成模型能否仅使用视觉数据展现出视觉空间智能，这是一种对人类认知至关重要的能力。为此，我们提出了Video4Spatial，这是一个框架，表明仅以基于视频的场景上下文为条件的视频扩散模型能够执行复杂的空间任务。我们在两项任务上进行了验证：场景导航——即遵循摄像机姿态指令，同时与场景的三维几何保持一致；以及物体定位——这需要语义定位、指令遵循和规划。这两项任务都只使用视频输入，不使用深度或姿态等辅助模态。凭借框架中简单而有效的设计选择以及数据整理，Video4Spatial展现出从视频上下文的强大空间理解能力：它能够端到端地规划导航并定位目标物体，在遵循摄像机姿态指令的同时保持空间一致性，并泛化到长上下文和域外环境。综上所述，这些结果推动了视频生成模型向通用视觉空间推理发展。|
|**2025-12-02**|[Neutron stars in $f(\mathbb{Q})$ gravity](http://arxiv.org/abs/2512.03037)|null|我们研究了在$f(\mathbb{Q})$引力中构建中子星(NS)解所面临的挑战，强调了将仿射联络视为理论中活跃的、动力学组分的重要性。我们首先阐明了在何种条件下，标准简化——例如重合规范或广义相对论(GR)类联络——即使在非平凡的$f(\mathbb{Q})$模型中，也会无意中导致GR行为。基于之前在黑洞(BH)时空中的工作，我们将该形式体系应用于中子星，并将其扩展到非真空构型。聚焦于两个代表性模型，$f(\mathbb{Q}) = \mathbb{Q} + α\mathbb{Q}^2$和$f(\mathbb{Q}) = \mathbb{Q}^β$，我们的分析表明，在标准正则性假设下，具有麦克劳林/洛朗型级数的解会恢复GR动力学，这表明更复杂的结构可能是超越GR效应的根源，并反映了联络动力学对真正超越GR解的渐近行为施加的约束。然后，我们将该问题表述为边值问题(BVP)，并指出了可能出现的数值病态，以及预防这些病态的可能策略。这项工作旨在为未来的数值研究提供一个具体框架，并概述了在$f(\mathbb{Q})$ 引力中构建具有物理意义的超越GR中子星解所需的理论一致性条件。|
|**2025-12-02**|[ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation](http://arxiv.org/abs/2512.03036)|**[link](https://github.com/kszpxxzmc/ViSAudio)**|尽管视频到音频生成取得了进展，但该领域主要关注单声道输出，缺乏空间沉浸感。现有的双耳方法仍受限于两阶段流程，即首先生成单声道音频，然后进行空间化，这经常导致错误累积和时空不一致。为解决这一局限性，我们引入了直接从无声视频生成端到端双耳空间音频的任务。为支持这项任务，我们提出了BiAudio数据集，该数据集包含约9.7万个视频-双耳音频对，涵盖多样化的真实世界场景和摄像机旋转轨迹，通过半自动化流程构建。此外，我们提出了ViSAudio，这是一个端到端框架，采用条件流匹配和双分支音频生成架构，其中两个专用分支对音频潜在流进行建模。结合条件时空模块，它平衡了通道之间的一致性，同时保留了独特的空间特性，确保了音频与输入视频之间精确的时空对齐。全面实验表明，ViSAudio在客观指标和主观评估方面均优于现有的最先进方法，能够生成高质量的双耳音频，具有空间沉浸感，并能有效适应视点变化、声源运动和多样化的声学环境。项目网站：https://kszpxxzmc.github.io/ViSAudio-project。|
|**2025-12-02**|[MAViD: A Multimodal Framework for Audio-Visual Dialogue Understanding and Generation](http://arxiv.org/abs/2512.03034)|null|我们提出MAViD，一个用于音视频对话理解与生成的新颖多模态框架。现有方法主要关注非交互式系统，并且局限于生成受限且不自然的人类语音。该任务的主要挑战在于有效整合理解和生成能力，以及实现无缝的多模态音视频融合。为了解决这些问题，我们提出了一种“指挥者-创造者”架构，将对话系统分为两个主要组件。指挥者负责理解、推理和生成指令，通过将指令分解为动作和语音组件，从而实现对交互的细粒度控制。创造者随后基于这些指令提供交互式响应。此外，为了解决使用双DiT结构生成具有一致身份、音色和语气的长视频的困难，创造者采用了一种结合自回归（AR）模型和扩散模型的结构。AR模型负责音频生成，而扩散模型确保高质量视频生成。此外，我们提出了一种新颖的融合模块，以增强上下文连续的片段和模态之间的连接，从而实现同步的长时长音视频内容生成。大量实验表明，我们的框架能够生成生动且上下文连贯的长时长对话交互，并准确解释用户的多模态查询。|
|**2025-11-28**|[Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models](http://arxiv.org/abs/2511.23478)|**[link](https://github.com/mbzuai-oryx/Video-R2)**|针对动态视觉内容的推理仍然是多模态大型语言模型面临的一个核心挑战。近期的思维模型会生成显式推理轨迹以提高可解释性；然而，它们的推理常常看似令人信服，却在逻辑上不一致或缺乏视觉证据的薄弱支撑。我们通过两个诊断指标识别并形式化了这些问题：思维答案一致性 (TAC)，它衡量推理与答案之间的一致性；以及视频注意力分数 (VAS)，它捕捉推理在多大程度上依赖于视觉线索而非文本线索。对11个视频推理基准的分析表明，当前模型严重依赖语言先验知识而非视觉内容。为解决此问题，我们提出了一种强化学习方法，该方法能同时提升时间精度和推理一致性。我们的方法将时间戳感知监督微调与由一种新颖的时间对齐奖励 (TAR) 指导的群体相对策略优化 (GRPO) 相结合。这一双步后训练阶段鼓励实现时间对齐且因果连贯的视频推理。所得模型 Video R2 在多个基准上持续获得更高的TAC、VAS和准确性，表明时间对齐和推理连贯性的改进能带来更准确、更值得信赖的视频理解。我们的代码、数据集和模型将开源。|
|**2025-11-28**|[AnyTalker: Scaling Multi-Person Talking Video Generation with Interactivity Refinement](http://arxiv.org/abs/2511.23475)|**[link](https://github.com/HKUST-C4G/AnyTalker)**|近来，多人视频生成开始崭露头角。尽管一些初步工作探索了音频驱动的多人说话视频生成，但它们常面临挑战，原因在于多样化多人数据采集成本高昂，以及驱动多个身份实现连贯交互性存在困难。为解决这些挑战，我们提出了AnyTalker，这是一个具有可扩展多流处理架构的多人生成框架。具体而言，我们通过一种新颖的身份感知注意力机制扩展了Diffusion Transformer的注意力块，该机制迭代处理身份-音频对，允许可驱动身份的任意扩展。此外，训练多人生成模型需要大量多人数据。我们提出的训练流程仅依赖单人视频来学习多人说话模式，并仅用少量真实多人剪辑细化交互性。进一步地，我们贡献了一个专用指标和数据集，旨在评估生成的多人视频的自然度和交互性。大量实验表明，AnyTalker实现了卓越的唇部同步、视觉质量和自然交互性，在数据成本和身份可扩展性之间取得了良好的平衡。|
|**2025-11-28**|[Wilson loops, symmetries, and selective bulk-boundary correspondence in higher-order topological insulators](http://arxiv.org/abs/2511.23471)|null|我们研究了手征对称布洛赫哈密顿量族中的高阶体边对应。这些模型推广了 $π$ 磁通量方格晶格，即典型的拓扑四极绝缘体，并包含了具有扩展跳跃和对角跳跃的可分离模型和不可分离模型。对于可分离系统，子系统手征缠绕数的乘积能正确预测零能角态的数量。然而，该不变量在不可分离模型中失效，这促使我们开发新的动量空间诊断方法。我们引入了规范无关的瓦尼尔哈密顿量镜像过滤缠绕数，其构建方法是将镜像本征态投影到占据子空间。此外，通过将手征Floquet理论中的周期化威尔逊线应用于具有动量相关手征算符的情况，我们定义了与瓦尼尔能隙直接相关的新不变量。这些不变量提供了瓦尼尔能带拓扑的详细表征。超越对称模型，我们发现某些镜像对称破缺模式会导致选择性边界能隙闭合，这些闭合局限于单一边界方向，而体相和其他边界仍保持有能隙。这种机制可扩展到三维，产生铰链和角选择性转变。我们的结果阐明了高阶拓扑相中手征对称性、镜像对称性和威尔逊环之间的相互作用，并指出了在为一般不可分离模型建立动量空间不变量方面的开放性挑战。|
|**2025-11-28**|[Visual Generation Tuning](http://arxiv.org/abs/2511.23469)|**[link](https://github.com/ali-vilab/FreeScale)**|大型视觉语言模型（VLM）通过大规模预训练有效弥合模态鸿沟，获取了与语言对齐的复杂视觉表示。然而，目前尚不清楚这些针对多模态理解任务进行优化的表示是否蕴含着固有的视觉生成潜力。在本文中，我们提出了VGT（视觉生成微调），这是一种旨在激发任何视觉语言模型中潜在视觉生成能力的新颖范式。通过对预训练良好的VLM进行高效的视觉生成微调，我们显著降低了对齐成本，并加速了连续空间中自回归建模的收敛（20倍加速）。具体而言，我们摒弃了为扩散Transformer设计的纠缠像素级VAE，并通过将预训练VLM中的语义编码器与像素解码器的潜在表示对齐，提出了VGT-AE。在图像重建任务中，我们在28倍压缩比下实现了26.67 PSNR和0.50 rFID，优于专门的VAE；在视觉生成任务中，我们在自回归模型中取得了最先进的结果，在GenEval上达到0.77，在DPG-Bench上达到78.73。此外，我们提出的VGT展现出巨大的扩展潜力，并且能够灵活地赋予任何经过多模态理解训练的VLM视觉生成能力，这为探索下一代统一多模态基础模型开辟了新途径。模型和代码可在 https://github.com/hustvl/VGT 获取。|
|**2025-11-28**|[The $L$-test: Increasing the Linear Model $F$-test's Power Under Sparsity Without Sacrificing Validity](http://arxiv.org/abs/2511.23466)|null|我们提出了一种新方法，用于检验在$n \geq d$的高斯线性模型中一组回归系数的显著性。我们的方法，$L$检验，提供了与经典$F$检验相同的统计有效性保证，同时当干扰系数稀疏时，能获得更高的功效。尽管$L$ 检验需要蒙特卡洛采样，但每次采样的运行时间主要由简单的矩阵-向量乘法决定，从而使整个检验仍具有计算效率。此外，我们还提供了一种免蒙特卡洛变体，可用于特别大规模的多重检验应用。我们直观地解释了我们方法的功效，通过广泛的模拟验证了其优势，并通过将其应用于HIV耐药性数据集，展示了其在单次检验和多重检验场景中的实用性。在结论中，我们还讨论了我们的方法如何应用于更广泛的参数模型类别，这些模型具有渐近高斯估计量。|
|**2025-11-28**|[SmallWorlds: Assessing Dynamics Understanding of World Models in Isolated Environments](http://arxiv.org/abs/2511.23465)|null|当前世界模型缺乏统一且受控的设置用于系统评估，使得难以评估它们是否真正捕获了控制环境动态的底层规则。在这项工作中，我们通过引入SmallWorld基准解决了这一开放挑战，SmallWorld基准是一个旨在评估世界模型在隔离且精确受控动态下能力的测试平台，无需依赖人工设计的奖励信号。利用该基准，我们在完全可观测的状态空间中针对包括循环状态空间模型、Transformer、扩散模型和神经ODE在内的代表性架构进行了全面的实验，考察它们在六个不同领域中的行为。实验结果揭示了这些模型捕获环境结构的有效性以及它们的预测在长时间推演中如何恶化，突出了当前建模范式的优势和局限性，并为未来在表征学习和动态建模方面的改进方向提供了见解。|
|**2025-11-28**|[Kinetic Mixing and the Phantom Illusion: Axion-Dilaton Quintessence in Light of DESI DR2](http://arxiv.org/abs/2511.23463)|null|DESI重子声学振荡（BAO）分析的最新结果表明，暗能量可能不是宇宙学常数，而是动态的。此外，数据表明，其状态方程在遥远的过去可能处于幻影区域，并最近经历了一次幻影穿越。在这项工作中，我们研究了这种偏好是否可以在动能混合轴子-膨胀子（KMIX）精质模型中实现，该模型是一个弦理论启发系统，其中类轴子场与类膨胀子（模）场指数耦合。关键在于，KMIX在标准Chevallier-Polarski-Linder (CPL)分析中可以呈现幻影行为。为了将模型与数据进行对比，我们开发了一个基于归一化流的快速流程，该流程（i）从KMIX实现中学习关于 $(w_0,w_a)$的理论指导先验，以及（ii）提供从CPL参数到物理KMIX参数的逆映射。通过使用此框架对预计算的CPL链进行重要性采样，我们有效地将普适现象学约束转化为对潜在KMIX理论的直接、计算高效的约束，避免了完整参数空间探索的过高成本。应用于Planck+DESI DR2 BAO测量结果，我们的框架发现KMIX的支持度为$2.5σ$，而基础CPL拟合为$3.1σ$，这表明KMIX可能解释DESI的偏好，而无需援引真正的幻影行为。当额外包含Ia型超新星数据时，我们发现对于Union3和DES Y5，偏好仍然高于$3σ$，但在Pantheon+数据下下降到$2.1σ$。后者结合DESI全形状功率谱和双谱数据，进一步将偏好降低到$1.7σ$ 。最终，如果DESI偏差在未来数据中持续存在，KMIX可能为从现象学拟合中推断出的类幻影特征提供一个理论上充分合理的解释。|
|**2025-11-28**|[New Particles at the Z-Pole: Tera-Z factories as discovery and precision machines](http://arxiv.org/abs/2511.23461)|**[link](https://github.com/liyuanzhen98/LLPatTeraZ)**|几个未来拟建的轻子对撞机，包括FCC-ee、CEPC、LEP3和LEP-Z，能够产生数万亿个Z玻色子。这些太Z工厂可以发现与Z玻色子耦合比当前限制小几个数量级的新基本粒子。对于接近当前已排除参数区域的耦合，它们可以产生足够大的样本以详细研究新粒子的性质，从而集发现与精密测量功能于一体。我们利用简单的解析估算，量化了长寿命粒子搜寻中预期事件产额对所产生的Z玻色子数量和探测器尺寸的依赖性。据此，我们推导出了此类设施可实现的发现范围和测量精度估算值。尽管此类估算的精度当然无法与精确模拟相比，但解析方法适用于快速评估给定设计的灵敏度。我们以重中性轻子和轴子类粒子两个例子对此进行说明。在乐观假设下，它们可以分别以百万和十亿的数量产生，有效地将未来轻子对撞机转变为奇异粒子工厂。我们提供了一个代码，可快速生成本文中显示的灵敏度曲线，并可扩展到https://github.com/liyuanzhen98/LLPatTeraZ上的其他模型。|
|**2025-11-28**|[Object-Centric Data Synthesis for Category-level Object Detection](http://arxiv.org/abs/2511.23450)|null|深度学习目标检测方法已在图像中实现了特定对象类别的可靠检测。然而，将模型的检测能力扩展到新的对象类别需要大量的标注训练数据，这些数据获取成本高昂且耗时，特别是对于在现有数据集中表示不足的长尾类别。在此，我们引入了以对象为中心的数据设置，即当有限数据以以对象为中心的数据形式（多视图图像或3D模型）可用时，并系统地评估了四种不同数据合成方法的性能，以在此设置下对新颖对象类别上的目标检测模型进行微调。这些方法基于简单的图像处理技术、3D渲染和图像扩散模型，并利用以对象为中心的数据合成逼真、杂乱的图像，这些图像具有不同的上下文连贯性和复杂性。我们评估了这些方法如何使模型在真实世界数据中实现类别级泛化，并证明了在此数据受限的实验设置下性能的显著提升。|
|**2025-11-28**|[ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts](http://arxiv.org/abs/2511.23442)|null|离线强化学习（RL）使智能体能够从预收集数据集中学习最优策略。然而，包含次优和碎片化轨迹的数据集对奖励传播构成了挑战，导致价值估计不准确和策略性能下降。尽管通过生成模型进行轨迹拼接提供了一个有前景的解决方案，但现有增强方法经常生成局限于行为策略支持域或违反底层动力学的轨迹，从而限制了它们对策略改进的有效性。我们提出了ASTRO，一个为离线RL生成具有分布新颖性和动力学一致性的轨迹的数据增强框架。ASTRO首先学习一种时序距离表示，以识别独特且可达的拼接目标。我们随后采用一个动力学引导的拼接规划器，通过展开偏差反馈（定义为目标状态序列与执行预测动作后实际到达状态序列之间的差距）来自适应地生成连接动作序列，以提高轨迹拼接的可行性和可达性。这种方法促进了通过拼接进行的有效增强，并最终提升了策略学习。ASTRO在各种算法上超越了先前的离线RL增强方法，在具有挑战性的OGBench基准套件上取得了显著的性能提升，并在诸如D4RL等标准离线RL基准上展示了持续的改进。|
|**2025-11-26**|[Revisiting Generalization Across Difficulty Levels: It's Not So Easy](http://arxiv.org/abs/2511.21692)|null|我们研究大型语言模型（LLM）在不同任务难度上的泛化能力，这是有效数据管理和评估的关键问题。现有研究结果不一，关于在更简单或更困难数据上训练是否能带来更好结果，以及这些提升是在更简单还是更困难的测试数据上体现。我们通过对LLM在不同模型、数据集和细粒度示例难度组上的泛化能力进行系统性评估来解决这个问题。我们利用数千个不同LLM的输出和项目反应理论（IRT）对六个数据集中的示例进行排序，IRT是教育测试中一种成熟的难度度量方法。与以往工作不同，我们的难度评级因此仅由许多不同LLM的能力决定，排除了人类对难度的看法。通过更客观、更大规模和更细粒度的分析，我们发现跨难度泛化能力通常有限；在简单或困难数据上训练都无法在所有难度范围内实现一致的改进。这些结果表明LLM的训练和评估数据中包含不同难度范围的重要性，并且在难度问题上采取捷径是冒险的。|
|**2025-11-26**|[Canvas-to-Image: Compositional Image Generation with Multimodal Controls](http://arxiv.org/abs/2511.21691)|**[link](https://github.com/snap-research/canvas-to-image)**|现代扩散模型虽然在生成高质量和多样化图像方面表现出色，但在高保真构图和多模态控制方面仍然面临挑战，尤其当用户需要同时指定文本提示、主题参考、空间布局、姿态约束和布局标注时。我们引入了Canvas-to-Image，这是一个统一的框架，它将这些异构控制整合到单一的画布界面中，使用户能够生成忠实反映其意图的图像。我们的核心思想是将多样化的控制信号编码成单一的复合画布图像，模型可以直接解释该图像以实现集成视觉空间推理。我们进一步构建了一套多任务数据集，并提出了一种多任务画布训练策略，该策略优化扩散模型，使其在统一的学习范式下联合理解并将异构控制整合到文本到图像生成中。这种联合训练使Canvas-to-Image能够跨多个控制模态进行推理，而不是依赖于任务特定的启发式方法，并且在推理过程中对多控制场景具有良好的泛化能力。大量实验表明，Canvas-to-Image在身份保留和控制依从性方面显著优于最先进的方法，并在包括多人构图、姿态控制构图、布局约束生成和多控制生成在内的挑战性基准测试中表现出色。|
|**2025-11-26**|[TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos](http://arxiv.org/abs/2511.21690)|null|仅凭少量演示在新平台和新场景中学习新的机器人任务仍然具有挑战性。尽管其他形态（如人类和不同机器人）的视频资源丰富，但形态、相机和环境的差异阻碍了它们的直接使用。我们通过引入一种统一的符号表示——一个紧凑的3D“轨迹空间”（场景级轨迹）——来解决小数据问题，该表示能够从跨形态、跨环境和跨任务的视频中进行学习。我们提出了TraceGen，这是一个世界模型，它在轨迹空间而非像素空间中预测未来运动，抽象掉了外观，同时保留了操作所需的几何结构。为了大规模训练TraceGen，我们开发了TraceForge，这是一个数据处理流水线，能将异构的人类和机器人视频转换为一致的3D轨迹，从而生成了一个包含12.3万个视频和180万个观测-轨迹-语言三元组的数据集。在该数据集上进行预训练，可以生成一个可迁移的3D运动先验，该先验能够高效适应：仅用五个目标机器人视频，TraceGen在四个任务中达到了80%的成功率，同时推理速度比最先进的基于视频的世界模型快50-600倍。在更具挑战性的情况下，即仅有五个通过手持手机捕获的未校准人类演示视频可用时，它仍然在真实机器人上达到了67.5%的成功率，这突显了TraceGen跨形态适应的能力，而不依赖于物体检测器或大量的像素空间生成。|
|**2025-11-26**|[ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration](http://arxiv.org/abs/2511.21689)|null|大型语言模型是强大的通才模型，然而解决人类终极考试（HLE）等深度复杂问题在概念上仍具挑战性，且计算成本高昂。我们表明，管理其他模型和各种工具的小型编排器既可以提升智能上限，也可以提高解决困难代理任务的效率。我们引入了ToolOrchestra，这是一种训练小型编排器以协调智能工具的方法。ToolOrchestra明确使用强化学习，其奖励机制考虑了结果、效率和用户偏好。利用ToolOrchestra，我们开发了Orchestrator，一个80亿参数模型，它以比以往工具使用智能体更低的成本实现了更高的准确性，同时符合用户对于给定查询应使用哪些工具的偏好。在HLE上，Orchestrator取得了37.1%的分数，优于GPT-5（35.1%），同时效率提高了2.5倍。在tau2-Bench和FRAMES上，Orchestrator大幅超越GPT-5，而成本仅为约30%。广泛分析表明，Orchestrator在多个指标下实现了性能和成本之间的最佳权衡，并且对未见过的工具具有强大的泛化能力。这些结果表明，将多样化工具与轻量级编排模型结合，比现有方法更高效、更有效，为实用且可扩展的工具增强推理系统铺平了道路。|
|**2025-11-26**|[Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework](http://arxiv.org/abs/2511.21686)|null|合成数据在训练大型语言模型方面变得越来越重要，特别是在真实数据稀缺、昂贵或涉及隐私时。许多此类生成任务需要协调的多智能体工作流，其中专业智能体协同工作，以生成更高质量、更多样化且结构更丰富的数据。然而，现有的多智能体合成框架往往依赖于一个中心化编排器，从而造成可扩展性瓶颈，或者针对特定领域进行硬编码，限制了灵活性。我们提出了Matrix，这是一个去中心化框架，它将控制流和数据流都表示为通过分布式队列传递的序列化消息。这种点对点设计消除了中心化编排器。每个任务通过轻量级智能体独立进行，而计算密集型操作，例如大型语言模型推理或容器化环境，则由分布式服务处理。基于Ray构建，Matrix可扩展到数万个并发智能体工作流，并提供模块化、可配置的设计，使得其能够轻松适应广泛的数据生成工作流。我们在各种合成场景中评估了Matrix，例如多智能体协作对话、基于网络的推理数据提取以及客户服务环境中的工具使用轨迹生成。在所有情况下，Matrix在相同的硬件资源下，数据生成吞吐量实现了2到15倍的提升，且不影响输出质量。|
|**2025-11-26**|[On BPI in Symmetric Extensions Part 1](http://arxiv.org/abs/2511.21684)|null|历史上，不带选择公理的模型中BPI的证明依赖于Halpern引入的矛盾框架。我们引入置换模型和对称扩张的滤子扩张性质，它形式化了通过最小增量重复扩张滤子将任意滤子扩张为超滤子的朴素方法。我们利用这个框架首次在广义Cohen模型 $N(I,Q)$中给出了BPI的直接证明，该模型在一个满足ZFC的基模型$M$上增加了一个Dedekind有限的相互$Q$-generic滤子集。在索引集$I$很大的情况下，我们借鉴Harrington对Halpern-Läuchli定理的证明来证明这个结果。然后，我们推广了Karagila和Schlicht的结果，以表明不失一般性地可以假设$I$ 很大。Harrington证明所给出的方法本质上是动态的，我们表明该技术可以用于置换模型中重新证明Blass定理的一个方向：一个称为Ramsey性质的动态条件足以使得BPI在置换模型中成立。然后我们引入了Ramsey性质的一个动态推广，称为虚拟Ramsey性质，它抽象了我们借鉴Harrington证明的核心特征，并且我们证明了虚拟Ramsey性质足以使得BPI在对称扩张中成立。|
|**2025-11-26**|[Mean-field Modelling of Moiré Materials: A User's Guide with Selected Applications to Twisted Bilayer Graphene](http://arxiv.org/abs/2511.21683)|null|我们回顾了莫尔材料的理论建模，通过哈特里-福克平均场理论的视角，考察了魔角扭曲双层石墨烯（MA-TBG）的各个方面。我们首先初步介绍了莫尔能带结构的连续介质模型，并解释了如何引入相互作用以研究关联态。随后，我们讨论了如何在此背景下进行基态结构和集体激发的平均场模拟。在此基础上，我们通过讨论理想化的“手性平带”强耦合极限，阐明了平均场近似在MA-TBG中的有效性，在该极限下，与莫尔超晶格相称的电子密度下的基态可被平均场猜想精确描述。接着，我们阐述了此极限在唯象学上的不足，这自然引出了对中等耦合非公度Kekulé螺旋（IKS）序及其源于普遍存在的异质应变的讨论。IKS及其在扩展哈特里-福克流形中的定位构成了我们的第一个“案例研究”。我们的第二个案例研究涉及时间依赖性，重点关注MA-TBG中各种破缺对称绝缘体的集体模式。作为第三个也是最后一个案例研究，我们回到强耦合图像，该图像可通过将MA-TBG与hBN衬底对齐来稳定。在此极限下，我们展示了如何将平均场理论应用于平移非不变场景，以定量研究轨道陈绝缘态中畴壁的能量学。最后，我们讨论了扩展和进一步应用。本综述既可作为独立参考资料，也可与随附的开源代码配合使用，旨在使具备能带理论和多体物理学基础知识的读者能够系统地构建和分析通用莫尔体系的详细模型。|
|**2025-11-26**|[DSD: A Distributed Speculative Decoding Solution for Edge-Cloud Agile Large Model Serving](http://arxiv.org/abs/2511.21669)|null|大语言模型（LLM）推理常面临高解码延迟以及在异构边缘-云环境中可扩展性有限的问题。现有推测解码（SD）技术能够加速令牌生成，但仍局限于单节点执行。我们提出了DSD，一个分布式推测解码框架，通过协同的草稿-目标执行将SD扩展到多设备部署。鉴于此前缺乏模拟这种范式的工作，我们首先介绍了DSD-Sim，一个捕捉网络、批处理和调度动态的离散事件模拟器。基于DSD-Sim的洞察，我们进一步设计了一种自适应窗口控制（AWC）策略，该策略动态调整推测窗口大小以优化吞吐量。跨不同工作负载的实验表明，DSD相比现有SD基线实现了高达1.1倍的加速和9.7%更高的吞吐量，从而实现在边缘和云端敏捷且可扩展的LLM服务。|
|**2025-11-26**|[Through the telecom lens: Are all training samples important?](http://arxiv.org/abs/2511.21668)|null|人工智能在电信领域的兴起，从优化无线接入网络到管理用户体验，大幅增加了数据量和训练需求。电信数据通常噪声大、高维，存储、处理和标注成本高昂。尽管人工智能发挥着关键作用，但标准工作流程仍然假设所有训练样本的贡献相同。另一方面，下一代系统要求人工智能模型具备准确性、效率和可持续性。本文通过重点应用和分析单个样本在电信训练中的作用，并评估所提出的模型是否优化了计算和能源使用，从而质疑了等同重要性的假设。我们进行了跨越多个训练周期的样本级梯度分析，以识别模型学习中的影响模式和冗余。基于此，我们提出了一个样本重要性框架，该框架选择性地优先处理有影响的数据，并在不损害准确性的前提下减少计算量。在三个真实世界电信数据集上的实验表明，我们的方法在保持性能的同时，减少了数据需求和计算开销，从而推动了电信领域可持续人工智能的目标。|
|**2025-11-26**|[Escaping the Verifier: Learning to Reason via Demonstrations](http://arxiv.org/abs/2511.21667)|null|训练大型语言模型 (LLMs) 进行推理通常依赖于使用任务专用验证器的强化学习 (RL)。然而，许多现实世界中推理密集型任务缺乏验证器，尽管它们提供了丰富的专家演示，但这些演示在以推理为中心的训练中仍未得到充分利用。我们引入了 RARO（相对对抗推理优化），它通过逆强化学习仅从专家演示中学习强大的推理能力。我们的方法在策略（生成器）和相对评论器（判别器）之间建立了一种对抗性交互：策略学习模仿专家答案，而评论器学习比较并区分策略和专家答案。我们的方法通过强化学习联合且持续地训练策略和评论器，并且我们确定了实现鲁棒学习所需的关键稳定技术。经验上，RARO 在我们所有的评估任务——倒计时、DeepMath 和诗歌创作——上显著优于强大的无验证器基线，并且在可验证任务上展现出与强化学习相同的鲁棒扩展趋势。这些结果表明，我们的方法仅从专家演示中有效地激发了强大的推理性能，即使在任务专用验证器不可用时，也能实现鲁棒的推理学习。|
|**2025-11-25**|[RubricRL: Simple Generalizable Rewards for Text-to-Image Generation](http://arxiv.org/abs/2511.20651)|null|强化学习（RL）最近已成为一种有前途的方法，用于使文本到图像生成模型与人类偏好对齐。然而，一个关键挑战在于设计有效且可解释的奖励。现有方法通常依赖于具有固定权重的组合度量（例如CLIP、OCR和真实感得分）或从人类偏好模型中提取的单一标量奖励，这会限制可解释性和灵活性。我们提出了RubricRL，一个简单通用的基于评分标准的奖励设计框架，提供了更高的可解释性、可组合性和用户控制。RubricRL没有使用黑盒标量信号，而是为每个提示动态构建一个结构化评分标准——这是一个针对输入文本量身定制的细粒度视觉标准的可分解清单，例如对象正确性、属性准确性、OCR保真度和真实感。每个标准由一个多模态判断器（例如o4-mini）独立评估，并且一个提示自适应加权机制会强调最相关的维度。这种设计不仅为策略优化（例如GRPO或PPO）产生了可解释、模块化的监督信号，而且还能让用户直接调整奖励或惩罚哪些方面。使用自回归文本到图像模型进行的实验表明，RubricRL提高了提示忠实度、视觉细节和泛化能力，同时为跨文本到图像架构的可解释RL对齐提供了一个灵活且可扩展的基础。|
|**2025-11-25**|[MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse Medical Imaging Modalities](http://arxiv.org/abs/2511.20650)|**[link](https://github.com/toobatehreem/MedROV)**|传统医学图像目标检测模型在封闭集范式下运行，限制了它们检测新标签目标的能力。开放词汇目标检测（OVOD）解决了这一局限，但由于数据集稀缺和弱文本-图像对齐问题，在医学成像领域仍未得到充分探索。为了弥合这一差距，我们引入了MedROV，这是首个用于医学成像的实时开放词汇检测模型。为了实现开放词汇学习，我们构建了一个大规模数据集Omnis，包含涵盖九种成像模态的60万个检测样本，并引入了一种伪标签策略来处理多源数据集中缺失的标注。此外，我们通过结合来自大型预训练基础模型的知识，增强了泛化能力。通过利用对比学习和跨模态表示，MedROV能有效检测已知和新颖的结构。实验结果表明，MedROV优于先前最先进的医学图像检测基础模型，平均绝对改进40 mAP50，并超越封闭集检测器3 mAP50以上，同时以70 FPS的速度运行，在医学检测领域树立了新标杆。我们的源代码、数据集和训练模型可在https://github.com/toobatehreem/MedROV获取。|
|**2025-11-25**|[Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges From Autoregressive Self-Rollout](http://arxiv.org/abs/2511.20649)|null|当前自回归视频扩散模型受限于三个核心瓶颈：(i) 基础模型3D旋转位置嵌入（3D-RoPE）施加的有限时间范围，(ii) 在长序列生成过程中维持细粒度动作控制时的提示响应缓慢，以及 (iii) 无法在单一生成流中实现不连续的电影转场。我们引入了 $\infty$-RoPE，这是一个统一的推理时框架，通过三个相互关联的组件解决了所有这三个局限性：块相对论RoPE、KV刷新和RoPE剪切。块相对论RoPE将时间编码重新表述为一个移动的局部参考系，其中每个新生成的潜在块相对于基础模型的最大帧范围进行旋转，而较早的块则向后旋转以保持相对时间几何结构。这种相对论性公式消除了固定时间位置，从而实现了远远超出基础位置限制的连续视频生成。为了在无需重新编码的情况下获得细粒度动作控制，KV刷新通过仅保留两个潜在帧（全局汇聚点和最后生成的潜在帧）来更新KV缓存，从而确保即时提示响应。最后，RoPE剪切在时间RoPE坐标中引入了受控的不连续性，从而在单次连续生成中实现了多镜头场景转场。这些组件共同将$\infty$-RoPE确立为无限时间范围、可控且电影级视频扩散的无需训练的基础。全面实验表明，$\infty$ -RoPE在总体VBench分数上持续超越了先前的自回归模型。|
|**2025-11-25**|[LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight](http://arxiv.org/abs/2511.20648)|null|模型若要在世界中行动，必须能够识别其所见并了解其三维位置。当今的视觉-语言模型（VLMs）在开放式二维描述和定位方面表现出色，然而多目标三维检测在VLM工具箱中仍 largely 缺失。我们提出了LocateAnything3D，这是一种VLM原生的方法，它将三维检测视为一个下一词元预测问题。关键在于一个简短而明确的“视觉链”（Chain-of-Sight, CoS）序列，它模仿人类从图像中推理的方式：首先在二维空间中找到一个物体，然后推断其距离、大小和姿态。解码器首先以视觉思维链的形式输出二维检测结果，然后在一个从易到难的课程下预测三维包围盒：在物体之间，采用从近到远的顺序，以减少早期歧义并匹配以自我为中心的实用性；在每个物体内部，通过“从相机中心”、“尺寸”和“旋转”的分解，根据稳定性和可学习性对信息进行排序。这种VLM原生接口保留了开放词汇和视觉提示能力，无需专门的头部。在富有挑战性的Omni3D基准测试中，我们的模型取得了最先进的结果，AP_3D达到49.89，即使基线模型被提供了真实二维包围盒，也绝对提升了15.51，超越了之前的最佳水平。它还能够零样本泛化到未见类别，并具有强大的鲁棒性。通过将三维检测转化为一个规范的下一词元问题，LocateAnything3D为模型提供了在三维空间中感知世界的实用基础。|
|**2025-11-25**|[Diverse Video Generation with Determinantal Point Process-Guided Policy Optimization](http://arxiv.org/abs/2511.20647)|null|尽管最近的文本到视频（T2V）扩散模型在质量和提示对齐方面取得了令人瞩目的成就，但它们在从单个文本提示中采样多个视频时，往往生成多样性较低的输出。我们通过将其表述为一个集合级策略优化问题来应对这一挑战，旨在训练一个能够覆盖给定提示的各种合理结果的策略。为此，我们引入了DPP-GRPO，这是一种新颖的视频多样性生成框架，它结合了行列式点过程（DPPs）和群组相对策略优化（GRPO）理论，以对多样性生成施加显式奖励。我们的目标通过DPP对冗余样本施加递减回报，并通过GRPO在候选集上提供群组反馈，从而将多样性转化为一个显式信号。我们的框架是即插即用且与模型无关的，它在不牺牲提示忠实度或感知质量的前提下，鼓励在视觉外观、摄像机运动和场景结构方面生成多样性。我们在WAN和CogVideoX上实现了我们的方法，并表明我们的方法在VBench、VideoScore和人类偏好研究等最先进的基准上持续提高了视频多样性。此外，我们发布了代码以及包含30,000个多样化提示的新基准数据集，以支持未来的研究。|
|**2025-11-25**|[PixelDiT: Pixel Diffusion Transformers for Image Generation](http://arxiv.org/abs/2511.20645)|null|潜在空间建模一直是扩散Transformer (DiT) 的标准范式。然而，它依赖于两阶段流水线，其中预训练自编码器引入有损重建，导致误差累积并阻碍联合优化。为了解决这些问题，我们提出了PixelDiT，一个单阶段、端到端的模型，它消除了对自编码器的需求，并直接在像素空间中学习扩散过程。PixelDiT采用完全基于Transformer的架构，其特点是双层设计：一个捕获全局语义的块级DiT和一个细化纹理细节的像素级DiT，这使得像素空间扩散模型能够高效训练，同时保留了精细细节。我们的分析表明，有效的像素级token建模对于像素扩散的成功至关重要。PixelDiT在ImageNet 256x256上实现了1.61的FID，大幅超越了现有像素生成模型。我们进一步将PixelDiT扩展到文本到图像生成，并在像素空间中以1024x1024的分辨率对其进行预训练。它在GenEval上达到了0.74，在DPG-bench上达到了83.5，接近了最佳潜在扩散模型。|
|**2025-11-25**|[Concept-Aware Batch Sampling Improves Language-Image Pretraining](http://arxiv.org/abs/2511.20643)|null|视觉语言模型应该在什么数据上进行训练？为了回答这个问题，许多数据整理工作都围绕数据集的质量展开。然而，大多数现有方法都是(i)离线的，即它们根据一组预设的过滤标准生成静态数据集，以及(ii)概念无关的，即它们使用基于模型的过滤器，这会引入额外的数据偏差。在这项工作中，我们超越了这些离线、概念无关的方法，提倡更灵活、任务自适应的在线基于概念的数据整理。我们的首个贡献是DataConcept，这是一个包含1.28亿个网络爬取的图像-文本对的集合，其中标注了关于其概念组成的细粒度细节。基于DataConcept，我们引入了概念感知批次采样（CABS），这是一个简单而有效的批次采样框架，能够根据特定的目标分布实时灵活地构建批次。我们提出了两种变体：(i) 多样性最大化（CABS-DM），用于整理包含广泛可用概念的批次，以及(ii) 频率最大化（CABS-FM），用于整理具有高对象多重性的批次。通过对28个基准进行广泛评估，我们证明了CABS方法显著有益于CLIP/SigLIP模型类别，并产生了高性能模型。总的来说，CABS代表了专有在线数据整理算法的一个强大开源替代方案，使从业者能够定义自定义概念分布，以针对特定下游任务进行优化。|
|**2025-11-25**|[Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition](http://arxiv.org/abs/2511.20641)|null|长尾多标签视觉识别提出了重大挑战，因为图像通常包含具有严重不平衡类别分布的多个标签，导致模型偏向头部类别，而在尾部类别上表现不佳。最近的研究利用了预训练视觉-语言模型（如CLIP）以及长尾学习技术，以利用丰富的视觉-文本先验来提高性能。然而，现有方法通常直接从不平衡数据集中推导语义类间关系，由于数据稀缺性，导致尾部类别的关联性不可靠。此外，CLIP的零样本范式是为单标签图像-文本匹配优化的，这使其不适用于多标签任务。为了解决这些问题，我们提出了关联适应提示网络（CAPNET），这是一种新颖的端到端框架，它从CLIP的文本编码器中明确建模标签关联。该框架结合了用于标签感知传播的图卷积网络和用于精炼嵌入的可学习软提示。它利用具有类别感知重加权的分布平衡Focal损失，以在不平衡条件下优化训练。此外，它通过测试时集成提高了泛化能力，并使用参数高效微调重新对齐视觉-文本模态，从而避免在尾部类别上过拟合，同时不损害头部类别性能。在VOC-LT、COCO-LT和NUS-WIDE等基准数据集上的大量实验和消融研究表明，CAPNET在最新方法上取得了显著提升，验证了其在实际长尾多标签视觉识别中的有效性。|
|**2025-11-25**|[MotionV2V: Editing Motion in a Video](http://arxiv.org/abs/2511.20640)|null|尽管生成式视频模型在保真度和一致性方面取得了卓越成就，但将这些能力应用于视频编辑仍然是一个复杂挑战。近期研究已将运动可控性作为增强文本到视频生成或图像动画的手段；然而，我们认为精确的运动控制是编辑现有视频的一种有前景但尚未充分探索的范式。在这项工作中，我们提出通过直接编辑从输入中提取的稀疏轨迹来修改视频运动。我们将输入和输出轨迹之间的偏差称为“运动编辑”，并证明这种表示与生成骨干网络结合时，能够实现强大的视频编辑能力。为此，我们引入了一个生成“运动反事实”（即内容相同但运动不同的视频对）的流程，并在此数据集上微调了一个运动条件视频扩散架构。我们的方法允许编辑从任何时间戳开始并自然传播。在一项四选一的对比用户研究中，我们的模型获得了超过65%的偏好，优于现有工作。请访问我们的项目页面：https://ryanndagreat.github.io/MotionV2V|
|**2025-11-25**|[Latent Collaboration in Multi-Agent Systems](http://arxiv.org/abs/2511.20639)|**[link](https://github.com/Gen-Verse/LatentMAS)**|多智能体系统（MAS）将大语言模型（LLMs）从独立的单模型推理扩展到协作的系统级智能。尽管现有的LLM智能体依赖基于文本的中介进行推理和通信，但我们通过使模型在连续的潜在空间内直接协作，向前迈进了一步。我们引入了LatentMAS，这是一个端到端免训练框架，能够在LLM智能体之间实现纯潜在协作。在LatentMAS中，每个智能体首先通过最后一层隐藏嵌入执行自回归潜在思维生成。一个共享潜在工作记忆随后保存并传输每个智能体的内部表示，确保无损信息交换。我们提供了理论分析，证明LatentMAS比传统基于文本的MAS具有更高的表达能力和无损信息保存，同时复杂性显著降低。此外，在涵盖数学和科学推理、常识理解以及代码生成的9个综合基准测试中的经验评估表明，LatentMAS持续优于强大的单模型和基于文本的MAS基线，实现了高达14.6%的更高准确率，将输出token使用量减少了70.8%-83.7%，并提供了4倍至4.3倍的端到端推理速度。这些结果表明，我们新的潜在协作框架在无需任何额外训练的情况下，提高了系统级推理质量，同时提供了显著的效率提升。代码和数据已在https://github.com/Gen-Verse/LatentMAS完全开源。|
|**2025-11-21**|[RynnVLA-002: A Unified Vision-Language-Action and World Model](http://arxiv.org/abs/2511.17502)|null|我们介绍了RynnVLA-002，一个统一的视觉-语言-动作（VLA）和世界模型。该世界模型利用动作和视觉输入来预测未来的图像状态，学习环境的底层物理原理以优化动作生成。相反，VLA模型根据图像观测生成后续动作，从而增强视觉理解并支持世界模型的图像生成。RynnVLA-002的统一框架实现了环境动力学和动作规划的联合学习。我们的实验表明，RynnVLA-002超越了单独的VLA模型和世界模型，展示了它们之间的相互增强。我们在模拟和真实世界的机器人任务中评估了RynnVLA-002。RynnVLA-002在LIBERO模拟基准测试中未经预训练即达到了97.4%的成功率，而在真实世界的LeRobot实验中，其集成的世界模型将整体成功率提升了50%。|
|**2025-11-21**|[Native 3D Editing with Full Attention](http://arxiv.org/abs/2511.17501)|null|指令引导的三维编辑是一个快速兴起的研究领域，有潜力拓宽三维内容创作的普及性。然而，现有方法面临关键局限：基于优化的方法速度过慢，而依赖多视角二维编辑的前馈方法常遭受几何不一致和视觉质量下降的问题。为解决这些问题，我们提出了一种新颖的原生三维编辑框架，能够在单次高效的前馈过程中直接操作三维表示。具体而言，我们创建了一个大规模多模态数据集，用于指令引导的三维编辑，涵盖了多样化的添加、删除和修改任务。该数据集经过精心策划，旨在确保编辑后的对象忠实遵循指令性修改，同时保持未编辑区域与原始对象的一致性。在此数据集的基础上，我们为模型探索了两种不同的条件作用策略：一种是传统的交叉注意力机制，另一种是新颖的三维token拼接方法。我们的结果表明，token拼接方法具有更高的参数效率并实现了卓越的性能。大量评估表明，我们的方法优于现有的二维提升方法，在生成质量、三维一致性和指令依从性方面树立了新的基准。|
|**2025-11-21**|[Local equations for the generalized Lotka-Volterra model on sparse asymmetric graphs](http://arxiv.org/abs/2511.17499)|null|真实生态系统以稀疏和不对称的相互作用为特征，这对理论分析提出了重大挑战。我们引入了一种新方法来研究稀疏图上具有随机动力学的广义Lotka-Volterra模型。通过推导局部Fokker-Planck方程并采用平均场闭合，我们能够高效地计算对称和不对称相互作用的稳态。我们通过将结果与动力学方程的直接积分进行比较以及重现已知结果来验证我们的方法，并且首次绘制了稀疏不对称网络的相图。我们的框架为探索现实生态群落的稳定性提供了一个多功能工具，并可以推广到不同背景下的应用，例如经济学和演化博弈论。|
|**2025-11-21**|[MDG: Masked Denoising Generation for Multi-Agent Behavior Modeling in Traffic Environments](http://arxiv.org/abs/2511.17496)|null|建模真实且交互式的多智能体行为对于自动驾驶和交通仿真至关重要。然而，现有的扩散模型和自回归方法受限于迭代采样、序列解码或特定任务设计，这阻碍了效率和复用性。我们提出了掩码去噪生成（MDG），这是一种统一的生成框架，它将多智能体行为建模重新表述为独立加噪时空张量的重建。MDG不依赖于扩散时间步或离散分词，而是应用连续的、针对每个智能体和每个时间步的噪声掩码，从而在单次或少量前向传播中实现局部去噪和可控轨迹生成。这种掩码驱动的公式在一个模型中推广应用于开环预测、闭环仿真、运动规划和条件生成。MDG在大型真实世界驾驶数据集上进行训练，在Waymo Sim Agents和nuPlan Planning基准测试中取得了有竞争力的闭环性能，同时提供了高效、一致且可控的开环多智能体轨迹生成。这些结果表明MDG是多智能体行为建模中一种简单而通用的范式。|
|**2025-11-21**|[EvDiff: High Quality Video with an Event Camera](http://arxiv.org/abs/2511.17492)|null|作为神经形态传感器，事件相机异步记录亮度变化，形成稀疏事件流，具有高时间分辨率和高动态范围的优点。由于绝对亮度的固有模糊性，从事件中重建强度图像是一项高度不适定任务。早期方法通常遵循端到端回归范式，以确定性方式直接将事件映射到强度帧。尽管这些方法在某种程度上有效，但它们通常产生感知质量较差的结果，并且难以在模型容量和训练数据方面进行扩展。在这项工作中，我们提出了EvDiff，一种基于事件的扩散模型，它遵循替代训练框架来生成高质量视频。为了降低高帧率视频生成的巨大计算成本，我们设计了一个只执行单个前向扩散步骤的基于事件的扩散模型，并配备了时序一致的EvEncoder。此外，我们新颖的替代训练框架消除了对成对事件-图像数据集的依赖，使模型能够利用大规模图像数据集以获得更高的容量。所提出的EvDiff能够仅从单色事件流生成高质量彩色视频。在真实世界数据集上的实验表明，我们的方法在保真度和真实感之间取得了最佳平衡，在像素级和感知指标上均优于现有方法。|
|**2025-11-21**|[Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination](http://arxiv.org/abs/2511.17490)|null|理解富文本视频需要阅读微小、瞬态的文本线索，这些线索常常需要重复检查。然而，大多数视频问答模型依赖于对固定帧的单次感知，导致幻觉和在细粒度证据上的失败。受人类暂停、放大和重读关键区域方式的启发，我们引入了Video-R4（通过视觉反刍增强富文本视频推理），这是一个执行视觉反刍的视频推理LMM：它迭代选择帧、放大信息区域、重新编码检索到的像素，并更新其推理状态。我们构建了两个具有可执行反刍轨迹的数据集：Video-R4-CoT-17k用于监督实践，Video-R4-RL-30k用于强化学习。我们提出了一种多阶段反刍学习框架，通过SFT和基于GRPO的RL逐步微调一个7B的LMM，以学习原子和混合视觉操作。Video-R4-7B在M4-ViteVQA上取得了最先进的结果，并进一步泛化到多页文档问答、幻灯片问答和通用视频问答，证明了迭代反刍是像素级多模态推理的有效范式。|
|**2025-11-21**|[Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models](http://arxiv.org/abs/2511.17487)|null|扩展多模态模型规模已在视觉理解和推理方面取得了显著进展，但实际需求要求开发更小、更高效的系统。在这项工作中，我们对多模态模型中的智能缩减进行了系统性分析，考察了缩减大语言模型（LLM）容量如何影响多模态能力。我们的初步发现揭示了一个有趣的趋势：LLM规模缩小不成比例地影响视觉能力，而不是继承自LLM的能力。我们随后考察了这一下降是否主要反映了视觉推理的预期下降，还是更根本的感知能力丧失。隔离LLM规模缩小对感知的影响后，我们发现性能仍然急剧下降，往往与对推理的影响相当甚至超过。为解决这一瓶颈，我们引入了视觉提取微调，它明确训练模型在不同任务中一致地提取与指令相关的视觉细节。凭借这些提取出的视觉细节，我们随后应用分步推理来生成答案。这些组件共同构成了我们的“提取+思考”（Extract+Think）方法，在该领域为效率和性能树立了新标准。|
|**2025-11-21**|[The Atlas Model and SDEs with Boundary Interaction](http://arxiv.org/abs/2511.17486)|null|我们研究了Atlas模型的均场极限及其与依赖于击中时间和局部时间分布的随机微分方程的联系。Atlas模型描述了实数轴上的一组布朗粒子系统，其中只有排名最低的粒子会受到一个正向漂移，该漂移与粒子数量成比例。我们表明，在均场极限下，粒子系统收敛到一种新颖的、在移动边界处发生反射的随机微分方程，其运动使得在边界处花费的平均局部时间以恒定速率增长。通常，该边界由一个测度表示，因此反射必须以一种松弛的意义来解释。然而，对于足够正则的初始粒子分布，我们证明该边界是一个连续函数。我们的分析依赖于通过McKean--Vlasov随机微分方程对问题的重新表述，其中相互作用是通过击中时间和局部时间进行的。|
|**2025-11-21**|[Radar2Shape: 3D Shape Reconstruction from High-Frequency Radar using Multiresolution Signed Distance Functions](http://arxiv.org/abs/2511.17484)|null|从高频雷达信号中确定三维物体的形状在分析上很复杂，但对于商业和航空航天应用至关重要。先前的深度学习方法已应用于雷达建模，然而，它们通常无法表示任意形状，或者难以处理在有限视角下收集的真实世界雷达信号。现有光学三维重建方法可以从有限的相机视角生成任意形状，但当它们天真地将雷达信号视为相机视角时，就会遇到困难。在这项工作中，我们提出了Radar2Shape，一种去噪扩散模型，它通过将其频率与多分辨率形状特征相关联，来处理部分可观测的雷达信号以进行三维重建。我们的方法包括一个两阶段方法：首先，Radar2Shape学习一个具有分层分辨率形状特征的正则化潜在空间；其次，它通过以雷达信号的频率为条件，以一种类似从粗到精的方式扩散到这个潜在空间中。我们证明了Radar2Shape即使是从部分观测的雷达信号中也能成功重建任意三维形状，并且我们展示了对两种不同仿真方法和真实世界数据的鲁棒泛化能力。此外，我们发布了两个合成基准数据集，以鼓励高频雷达领域的未来研究，以便像Radar2Shape这样的模型可以安全地应用于真实世界的雷达系统。|
|**2025-11-21**|[Counterfactual World Models via Digital Twin-conditioned Video Diffusion](http://arxiv.org/abs/2511.17481)|null|世界模型学习在给定控制信号的情况下预测视觉观测的时间演变，这可能使智能体能够通过前向模拟对环境进行推理。由于侧重于前向模拟，当前的世界模型基于事实观测生成预测。对于许多新兴应用，例如在不同条件下全面评估物理AI行为，世界模型回答反事实查询（例如“如果移除此对象会发生什么？”）的能力变得日益重要。我们形式化了反事实世界模型，它额外将干预作为显式输入，在对观测场景属性进行假设性修改的情况下预测时间序列。传统世界模型直接操作纠缠的像素空间表示，其中对象属性和关系无法选择性地修改。这种建模选择阻止了对特定场景属性的有针对性干预。我们引入了CWMDT，这是一个克服这些限制的框架，它将标准视频扩散模型转化为有效的反事实世界模型。首先，CWMDT构建观测场景的数字孪生，以显式编码对象及其关系，并以结构化文本形式表示。其次，CWMDT应用大型语言模型对这些表示进行推理，并预测反事实干预如何随时间传播以改变观测到的场景。第三，CWMDT使用修改后的表示条件化视频扩散模型，以生成反事实视觉序列。在两个基准上的评估表明，CWMDT方法实现了最先进的性能，这表明视频的替代表示（例如此处考虑的数字孪生）为基于视频前向模拟的世界模型提供了强大的控制信号。|
|**2025-11-20**|[Dataset Distillation for Pre-Trained Self-Supervised Vision Models](http://arxiv.org/abs/2511.16674)|null|数据集蒸馏任务旨在找到一小组合成图像，使得在此图像集上训练模型能够复现该模型在更大规模真实样本数据集上训练所达到的性能。现有蒸馏方法侧重于合成能够训练随机初始化模型的数据集。相比之下，最先进的视觉方法正越来越多地基于大型预训练自监督模型，而非从头开始训练。在本文中，我们研究了蒸馏数据集的问题，这些数据集能够使我们在此类大型预训练视觉模型之上优化训练线性探针。我们引入了一种用于此任务的数据集蒸馏方法，称为线性梯度匹配，该方法优化合成图像，使其在通过预训练特征提取器后，在线性分类器中产生的梯度类似于真实数据产生的梯度。我们的方法生成的合成数据优于所有真实图像基线，并且显著地跨预训练视觉模型泛化，例如，使我们能够使用通过DINO骨干网络蒸馏的数据集训练一个具有竞争力的线性CLIP探针。此外，我们表明我们蒸馏出的数据集对于细粒度分类非常有效，并为模型可解释性提供了一个有价值的工具，例如预测在柏拉图式表征假设下两个模型的嵌入空间有多相似，或者模型是否对对抗性数据集中的虚假相关性敏感。|
|**2025-11-20**|[EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards](http://arxiv.org/abs/2511.16672)|null|大型多模态模型（LMM）的近期进展使其具备了令人印象深刻的推理和感知能力，然而，大多数现有训练流程仍依赖于人工整理的数据或外部验证的奖励模型，这限制了它们的自主性和可扩展性。在这项工作中，我们致力于以纯粹的无监督方式（无需任何标注数据或奖励蒸馏）提升LMM的推理能力。为此，我们提出了一个名为 EvoLMM 的自演化框架，它从一个单一骨干模型中实例化出两个协作智能体：一个提问者（Proposer），负责生成多样化的、基于图像的问题，以及一个解答者（Solver），负责通过内部一致性来解决这些问题，学习过程通过一个持续的自我奖励机制进行。这种动态反馈鼓励了信息丰富的查询的生成和结构化推理的完善，而无需依赖真值或人工判断。当使用流行的 Qwen2.5-VL 作为基础模型时，我们的 EvoLMM 仅使用原始训练图像，在 ChartQA、MathVista 和 MathVision 等多模态数学推理基准测试上取得了高达约3%的持续提升。我们希望这种简单而有效的方法能为未来以完全无监督方式改进LMM的研究提供一个坚实的基线。我们的代码和模型可在 https://github.com/mbzuai-oryx/EvoLMM 获取。|
|**2025-11-20**|[Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO](http://arxiv.org/abs/2511.16669)|**[link](https://github.com/KlingTeam/VANS)**|尽管语言模型已在许多实际应用中产生巨大影响，但视频生成仍主要局限于娱乐领域。鉴于视频在展示仅凭语言难以传达的物理世界信息方面具有固有能力（例如，想象一下仅通过文本教人打领带），我们发现了一个未充分利用的机会，即将视频扩展为下一事件预测（NEP）的一种新型回答模态，并将其形式化为视频下一事件预测（VNEP）。既定的NEP任务以带有过程性或预测性问题的视频作为输入，以文本形式预测下一事件，而VNEP则需要动态视频响应。这种从“告知”到“展示”的转变，为过程学习和创造性探索提供了更直观和个性化的答案。然而，这项任务对现有模型而言仍具挑战性，因为它需要理解多模态输入、指令条件推理以及生成具有视觉和语义一致性的视频。为解决此问题，我们引入了VANS，这是一个利用强化学习将视觉-语言模型（VLM）与视频扩散模型（VDM）对齐以实现VNEP的模型。VANS的核心是我们提出的Joint-GRPO，它协调VLM和VDM作为一个整体运作。在各自输出的共享奖励驱动下，Joint-GRPO优化VLM以生成既准确又易于可视化的字幕，同时指导VDM生成忠实于这些字幕和输入视觉上下文的视频。为了实现这种学习，我们构建了VANS-Data-100K，一个专用于VNEP任务的数据集。在过程性和预测性基准上的实验表明，VANS在视频事件预测和可视化方面均达到了最先进的性能。代码已在https://github.com/KlingTeam/VANS发布。|
|**2025-11-20**|[V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models](http://arxiv.org/abs/2511.16668)|null|生成式视频模型（如Veo-3）的最新进展展示了惊人的零样本推理能力，这使得对它们进行系统化且可靠的评估的需求日益增长。我们引入了V-ReasonBench，这是一个旨在从四个关键维度评估视频推理能力的基准测试：结构化问题解决、空间认知、基于模式的推理和物理动力学。该基准测试由合成图像序列和真实世界图像序列构建而成，提供了一系列多样化、答案可验证、可复现、可扩展且无歧义的任务。对六种最先进视频模型的评估揭示了明显的维度差异，在结构化推理、空间推理、基于模式的推理和物理推理方面存在显著差异。我们进一步将视频模型与强大的图像模型进行比较，分析了常见的幻觉行为，并研究了视频时长如何影响帧链推理。总的来说，V-ReasonBench为衡量视频推理提供了一个统一且可复现的框架，旨在支持开发具有更可靠、更符合人类认知的推理技能的模型。|
|**2025-11-20**|[SceneDesigner: Controllable Multi-Object Image Generation with 9-DoF Pose Manipulation](http://arxiv.org/abs/2511.16666)|**[link](https://github.com/FudanCVL/SceneDesigner)**|可控图像生成近年来受到越来越多的关注，使用户能够操纵身份、风格等视觉内容。然而，实现对多个物体9D姿态（位置、尺寸和方向）的同时控制仍然是一个开放的挑战。尽管最近取得了进展，但现有方法常常存在可控性有限和质量下降的问题，未能实现全面的多物体9D姿态控制。为了解决这些局限性，我们提出了SceneDesigner，这是一种用于精确灵活地操纵多物体9自由度姿态的方法。SceneDesigner将分支网络引入预训练的基础模型，并利用一种新的表示——CNOCS图，该图编码了相机视角下的9D姿态信息。这种表示具有很强的几何解释性，从而实现更高效稳定的训练。为了支持训练，我们构建了一个新的数据集ObjectPose9D，它聚合了来自不同来源的图像以及9D姿态标注。为了进一步解决数据不平衡问题，特别是低频姿态上的性能下降，我们引入了一种结合强化学习的两阶段训练策略，其中第二阶段使用基于奖励的目标在重新平衡的数据上微调模型。在推理时，我们提出了解耦物体采样技术，该技术缓解了复杂多物体场景中物体生成不足和概念混淆的问题。此外，通过整合用户特定的个性化权重，SceneDesigner能够实现对参考主体的定制化姿态控制。大量的定性和定量实验表明，SceneDesigner在可控性和质量两方面均显著优于现有方法。代码已公开发布于https://github.com/FudanCVL/SceneDesigner。|
|**2025-11-20**|[Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter](http://arxiv.org/abs/2511.16665)|null|具有强大推理能力的大语言模型（LLM）的出现标志着一个重要的里程碑，为复杂问题解决开辟了新领域。然而，这些推理模型（通常使用强化学习 (RL) 进行训练）的训练面临关键效率瓶颈：RL 训练期间的响应生成呈现持续的长尾分布，其中少数极长的响应占据了大部分执行时间，导致资源浪费和成本增加。为了解决这个问题，我们提出了 TLT，一个通过整合自适应推测解码，无损地加速推理 RL 训练的系统。在 RL 中应用推测解码具有挑战性，原因在于动态工作负载、不断演进的目标模型以及草稿模型的训练开销。TLT 通过两个协同组件克服了这些障碍：(1) 自适应草稿器（Adaptive Drafter），一个轻量级草稿模型，在长尾生成期间利用空闲 GPU 持续训练，以在无额外成本的情况下保持与目标模型的对齐；以及 (2) 自适应策略执行引擎（Adaptive Rollout Engine），它维护一个内存高效的预捕获 CUDAGraph 池，并为每个输入批次自适应选择合适的推测解码（SD）策略。评估表明，TLT 相较于最先进的系统实现了超过 1.7 倍的端到端 RL 训练加速，同时保持了模型准确性，并产生了一个高质量的草稿模型作为免费副产品，适用于高效部署。代码已发布于 https://github.com/mit-han-lab/fastrl。|
|**2025-11-20**|[TriDiff-4D: Fast 4D Generation through Diffusion-based Triplane Re-posing](http://arxiv.org/abs/2511.16662)|null|随着对3D动画日益增长的需求，从文本描述生成高保真、可控的4D虚拟形象仍然是一个重大挑战。尽管在4D生成建模方面付出了显著努力，现有方法仍存在根本性局限，阻碍了它们的广泛应用，包括时间性和几何不一致性、感知伪影、运动不规则性、高计算成本以及对动态的有限控制。为了解决这些挑战，我们提出了TriDiff-4D，这是一种新颖的4D生成流程，采用基于扩散的三平面重姿态来生成高质量、时间连贯的4D虚拟形象。我们的模型采用自回归策略来生成任意长度的4D序列，通过单一扩散过程合成每个3D帧。通过显式学习大规模3D和运动数据集中的3D结构和运动先验，TriDiff-4D实现了骨架驱动的4D生成，在时间一致性、运动准确性、计算效率和视觉保真度方面表现出色。具体而言，TriDiff-4D首先从文本提示生成一个规范的3D虚拟形象和对应的运动序列，然后使用第二个扩散模型根据运动序列来驱动虚拟形象，支持任意长度的4D生成。实验结果表明，TriDiff-4D显著优于现有方法，通过消除优化过程将生成时间从数小时缩短到数秒，同时大幅提高了具有高保真外观和精确3D几何的复杂运动的生成能力。|
|**2025-11-20**|[Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](http://arxiv.org/abs/2511.16654)|null|检索增强生成（RAG）的最新进展已使大语言模型（LLMs）能够访问包含文本和视觉信息（例如金融文档中的图表、示意图和表格）的多模态知识库。然而，现有的多模态RAG系统在预处理过程中依赖基于LLM的摘要将图像转换为文本，仅将文本表示存储在向量数据库中，这导致了对下游检索和问答至关重要的上下文信息和视觉细节的丢失。为解决这一局限性，我们对多模态RAG系统的两种检索方法进行了全面比较分析，包括基于文本块的检索（其中图像在嵌入前被汇总为文本）和直接多模态嵌入检索（其中图像以原生形式存储在向量空间中）。我们在一项新创建的金融财报电话会议基准上评估了所有这三种方法，该基准包含40个问答对，每个问答对与2个文档（1个图像和1个文本块）配对，并使用了6个LLM模型和2个多模态嵌入模型。实验结果表明，直接多模态嵌入检索显著优于基于LLM摘要的方法，在平均精度均值（mAP@5）上取得了13%的绝对提升，在归一化折现累积增益上取得了11%的绝对提升。这些提升对应着mAP@5上32%和nDCG@5上20%的相对提升，为其实际影响提供了更有力的证据。我们还发现，通过LLM作为评判者的成对比较衡量，直接多模态检索产生更准确、事实更一致的答案。我们证明LLM摘要在预处理过程中引入了信息损失，而直接多模态嵌入保留了视觉上下文以用于检索和推理。|
|**2025-11-20**|[Evolution Strategies at the Hyperscale](http://arxiv.org/abs/2511.16652)|null|我们引入了进化引导的低秩学习通用优化（EGGROLL），这是一种进化策略（ES）算法，旨在将无反向传播优化扩展到大规模种群，以适应具有数十亿参数的现代大型神经网络架构。进化策略是一组强大的黑盒优化方法，能够处理不可微或带噪声的目标函数，并通过并行化具有出色的扩展潜力。朴素进化策略在处理大规模问题时，由于生成矩阵扰动 $E\in\mathbb{R}^{m\times n}$ 以及计算每个成员前向传播所需的批处理矩阵乘法所带来的计算和内存成本，会变得极其昂贵。EGGROLL 通过生成 $r\ll \min(m,n)$ 的随机矩阵 $A\in \mathbb{R}^{m\times r},\ B\in \mathbb{R}^{n\times r}$ 来形成低秩矩阵扰动 $A B^\top$，并用其代替全秩扰动 $E$，从而克服这些瓶颈。由于整体更新是N个工作器种群的平均值，这仍然能够实现高秩更新，但显著节省了内存和计算，与全秩进化策略相比，每层的辅助存储从 $mn$ 减少到 $r(m+n)$，前向传播的成本从 $\mathcal{O}(mn)$ 降低到 $\mathcal{O}(r(m+n))$。理论分析表明，我们的低秩更新以快速的 $\mathcal{O}\left(\frac{1}{r}\right)$ 速率收敛于全秩更新。我们的实验表明：(1) 尽管速度更快，EGGROLL 在白板强化学习设置中并未影响进化策略的性能；(2) 作为改进大型语言模型推理能力的技术，它与GRPO具有竞争力；(3) EGGROLL 能够稳定预训练纯粹以整数数据类型运行的非线性循环语言模型。|
|**2025-11-20**|[InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy](http://arxiv.org/abs/2511.16651)|null|近期工作探讨了真实数据和合成数据如何促进视觉-语言-动作(VLA)模型的泛化能力。尽管当前VLA模型已显示出大规模真实机器人预训练的强大有效性，但合成数据此前尚未在大规模上展示出可比的能力。本文首次证明，仅合成数据就能够匹敌最强的 $π$数据集在VLA模型预训练中的性能，揭示了大规模仿真的巨大价值。所得模型还在多项挑战性任务上展现出令人惊讶的零样本仿真到真实迁移能力。我们的合成数据集InternData-A1包含超过63万条轨迹和7433小时数据，涵盖4种具身形态、18种技能、70项任务和227个场景，覆盖刚体、铰接体、可变形体和流体对象的操纵。它通过一个高度自主、完全解耦和组合式的仿真管线生成，该管线能够实现长程技能组合、灵活任务组装和异构具身形态，且仅需少量手动调整。我们采用与$π_0$相同的架构，完全在InternData-A1上预训练了一个模型，发现其性能与官方$π_0$ 在49项仿真任务、5项真实世界任务和4项长程灵巧任务上相匹配。我们发布了该数据集，并将开源其生成管线，以扩大对大规模机器人数据的访问，并降低具身AI研究中可扩展数据创建的门槛。|
|**2025-11-18**|[ARC Is a Vision Problem!](http://arxiv.org/abs/2511.14761)|**[link](https://github.com/rprokap/pset-9)**|抽象推理语料库（ARC）旨在促进对抽象推理的研究，这是人类智能的一个基本方面。针对ARC的常见方法将其视为一个以语言为导向的问题，通过大型语言模型（LLM）或循环推理模型来解决。然而，尽管ARC中的谜题式任务本质上是视觉的，现有研究却很少从以视觉为中心的角度来处理这个问题。在这项工作中，我们在视觉范式内构建ARC，将其定义为图像到图像的翻译问题。为了融合视觉先验知识，我们将输入表示在一个“画布”上，该画布可以像自然图像一样进行处理。于是我们很自然地应用标准视觉架构，例如一个普通的Vision Transformer（ViT），来执行图像到图像的映射。我们的模型完全基于ARC数据从头开始训练，并通过测试时训练泛化到未见过的任务。我们的框架，称为Vision ARC（VARC），在ARC-1基准测试中达到了60.4%的准确率，大幅优于同样从头开始训练的现有方法。我们的结果与领先的LLM表现相当，并缩小了与人类平均表现的差距。|
|**2025-11-18**|[UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning](http://arxiv.org/abs/2511.14760)|null|我们提出 UniGen-1.5，一个用于高级图像理解、生成和编辑的统一多模态大语言模型 (MLLM)。在 UniGen 的基础上，我们全面增强了模型架构和训练流程，以增强图像理解和生成能力，同时解锁了强大的图像编辑能力。特别地，我们提出了一种统一的强化学习 (RL) 策略，该策略通过共享奖励模型共同改进图像生成和图像编辑。为了进一步提升图像编辑性能，我们提出一个轻量级的编辑指令对齐阶段，该阶段显著提高了编辑指令理解能力，这对于强化学习训练的成功至关重要。实验结果表明，UniGen-1.5 展示了有竞争力的理解和生成性能。具体来说，UniGen-1.5 在 GenEval 和 ImgEdit 上分别取得了 0.89 和 4.31 的总分，这些分数超越了 BAGEL 等最先进模型，并达到了与 GPT-Image-1 等专有模型相当的性能。|
|**2025-11-18**|[ $π^{*}_{0.6}$: a VLA That Learns From Experience](http://arxiv.org/abs/2511.14759)|null|我们研究了视觉-语言-动作（VLA）模型如何通过强化学习（RL）在真实世界部署中得到改进。我们提出了一种通用方法，即基于优势条件策略的经验与修正强化学习（RECAP），该方法通过优势条件化实现VLA的强化学习训练。我们的方法将异构数据整合到自我提升过程中，包括演示数据、策略在线收集的数据以及在自主执行过程中提供的专家远程操作干预。RECAP首先通过离线强化学习预训练一个通用VLA模型，我们称之为$π^{*}_{0.6}$，该模型随后可以通过机器人端数据收集进行专门化，以在下游任务中获得高性能。我们展示了使用完整的RECAP方法训练的$π^{*}_{0.6}$ 模型能够在真实家庭中叠放衣物、可靠地组装盒子以及使用专业意式咖啡机制作意式浓缩咖啡。在一些最困难的任务上，RECAP使任务吞吐量增加一倍以上，并将任务失败率大约减半。|
|**2025-11-18**|[Pseudo-Poisson Distributions with Nonlinear Conditional Rates](http://arxiv.org/abs/2511.14741)|**[link](https://github.com/LKHJAR001/Pseudo-Poisson-Nonlinear)**|Arnold & Manjunath (2021) 声称，二元伪泊松分布因其简约结构和简便的参数估计，非常适用于一个等离差边际和一个超离差边际的二元计数数据。在 Leiter & Hamdan (1973) 的公式中， $X_2$ 的条件均值被指定为 $X_1$ 的函数；Arnold & Manjunath (2021) 随后通过添加一个截距来增强此规范，从而产生了一个线性条件率。这种构造的一个直接含义是，二元伪泊松分布只能表示两个变量之间的正相关。本研究通过引入曲率，推广了条件率，以适应负相关数据集。这种增强提供了额外的好处，即允许模型在适当情况下表现出近似线性，同时充分处理边界情况 $(x_1,x_2)=(0,0)$ 。根据赤池信息准则 (AIC)，本研究中提出的模型优于 Arnold & Manjunath (2021) 的线性模型。|
|**2025-11-18**|[LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data](http://arxiv.org/abs/2511.14738)|null|大语言模型（LLM）展现出超越其预训练数据进行泛化的卓越能力，且微调大语言模型能够将性能提升到人类水平甚至超越。然而，在实际应用场景中，缺乏标注数据常常阻碍从业者获得性能良好的模型，从而迫使从业者高度依赖基于提示的方法，而这些方法通常繁琐、低效且受试错驱动。为缓解缺乏标注数据这一问题，我们提出了一个将大语言模型与用于未标注数据集的主动学习（LAUD）相结合的学习框架。LAUD通过利用零样本学习构建初始标注集来缓解冷启动问题。实验结果表明，源自LAUD的大语言模型在商品名称分类任务上优于采用零样本或少样本学习的大语言模型，证明了LAUD的有效性。|
|**2025-11-18**|[Starlight-driven flared-staircase geometry in radiation hydrodynamic models of protoplanetary disks](http://arxiv.org/abs/2511.14733)|null|在毫米连续谱和散射光中观测到的原行星盘显示出多种细微结构。盘中各种物理过程可能触发此类特征——其中之一是先前被理论化用于被动盘的热波不稳定性——张角盘可能因直接被照亮区域的膨胀并在其后方投射阴影而变得不稳定。这将表现为明暗环以及盘光学表面上的阶梯状结构。我们提供了一个真实的辐射流体动力学模型，以检验受辐射盘中热波不稳定性的极限。我们进行了全局轴对称二维流体静力学和动力学模拟，其中包括具有频率相关射线追踪辐射和流量限制扩散（FLD）的辐射传输。我们发现，星光驱动的阴影在光学厚、缓慢冷却的盘中最为显著，这在我们的模型中通过高表面密度和亚微米尘埃的尘气比为0.01的情况得到体现。我们确认在流体静力学极限下，热波形成并向内传播。相比之下，我们的流体动力学模型在30 AU以内显示出凸起和阴影，这些在数个辐射扩散时间尺度上收敛到准稳态——表明存在一个长寿命的阶梯状结构。我们发现，现有的热压凸起可以产生并增强这种效应，在下游形成次级阴影。相比之下，具有自洽尘埃沉降的流体静力学模型则显示出一个过热的尘埃辐射吸收面，其径向温度分布平滑，没有阶梯。我们得出结论，使用流量限制扩散，可以在受辐射原行星盘的辐射流体动力学模拟中重现热诱导的张角阶梯状结构。我们强调了自洽地模拟尘埃动力学对于解释星光驱动阴影的重要性。|
|**2025-11-18**|[Towards AC Feasibility of DCOPF Dispatch](http://arxiv.org/abs/2511.14725)|null|直流最优潮流（DCOPF）因其简单性和计算效率而在电力系统运行中得到广泛应用。然而，其无损、无功功率无关模型常常产生在实际运行场景下（例如非线性交流潮流（ACPF）方程）不可行的调度结果。尽管理论分析表明DCOPF解本质上是交流不可行的，但它们在工业界的广泛应用表明其具有显著的实用价值。本文开发了一个统一的DCOPF-ACPF流程，用于从基于DCOPF的调度中恢复交流可行解。该流程利用了四种DCOPF变体，并结合分布式松弛分配和PV/PQ切换来恢复交流可行性。主要目标是确定恢复交流可行性最有效的流程。在各种测试案例上超过10,000个调度场景下进行的评估表明，该结构化ACPF模型产生了满足ACPF方程和所有工程不等式约束的解。在一个13,659节点的案例中，与传统的单松弛母线方法相比，DCOPF和ACOPF之间的平均绝对误差和成本差异分别减少了75%和93%。在极端负荷条件下，该流程将不等式约束违反减少了3到5倍。|
|**2025-11-18**|[When AI Democratizes Exploitation: LLM-Assisted Strategic Manipulation of Fair Division Algorithms](http://arxiv.org/abs/2511.14722)|null|Spliddit平台等公平资源分配算法因其复杂性，传统上被认为最终用户难以操纵。本文展示了大型语言模型（LLMs）如何通过普及战略专业知识的获取来消除这些保护性障碍。通过对Spliddit算法上的租金分配场景进行实证分析，我们表明用户可以通过对AI助手进行简单的对话式查询来获得可操作的操纵策略。我们提出了四种不同的操纵场景：多数人剥削少数人的排他性串通、适得其反的防御性反策略、对特定参与者的善意补贴以及成本最小化联盟。我们的实验表明，LLMs能够解释算法机制、识别有利可图的偏离，并为协调一致的偏好虚报生成具体的数值输入——这些能力以前需要深入的技术知识。这些发现将算法集体行动理论从分类语境扩展到资源分配场景，其中协调一致的偏好操纵取代了特征操纵。其影响超越了租金分配，延伸到任何使用算法公平机制进行资源分配的领域。尽管AI辅助的操纵对系统完整性构成风险，但它也为应得公平的群体创造了获得优惠待遇的机会。我们认为，有效的应对措施必须结合算法鲁棒性、参与式设计和公平获取AI能力，并承认战略精明度不再是一种稀缺资源。|
|**2025-11-18**|[AdamHD: Decoupled Huber Decay Regularization for Language Model Pre-Training](http://arxiv.org/abs/2511.14721)|null|采用解耦权重衰减的自适应优化器（如AdamW）已成为预训练大型基于Transformer的生成模型的实际标准。然而，权重衰减中嵌入的 $\ell_2$惩罚的二次性质以相同的速率将所有参数推向原点，使得更新易受稀有但极端的梯度方向影响，并常常过度惩罚条件良好的坐标。我们提出了AdamHuberDecay，它是AdamW的即插即用替代品，用解耦平滑Huber正则化器取代了$\ell_2$惩罚。所得更新在参数幅度低于阈值$δ$时以二次方式衰减参数，一旦超过$δ$则呈线性（类似$\ell_1$）衰减，从而产生(i)有界的正则化梯度，(ii)对逐坐标二阶矩重新缩放的不变性，以及(iii)对过大权重施加更强的稀疏性压力。我们推导了闭合形式的解耦Huber衰减步骤，并展示了如何以$O(1)$ 的额外开销将其与任何Adam系列优化器集成。对GPT-2和GPT-3预训练进行的大量实验表明，AdamHuberDecay (a)在挂钟时间上收敛速度提高10-15%，(b)验证困惑度降低多达4点，(c)在下游任务中带来2.5-4.7%的性能提升，以及(d)产生明显更稀疏的权重直方图，在幅度剪枝后可节省20-30%的内存，且无需在AdamW使用的默认网格之外调整衰减系数。消融实验证实了其对离群梯度和大批量训练模式的鲁棒性，同时理论分析在噪声更新下限制了期望参数范数。因此，AdamHuberDecay为下一代基础生成式Transformer的更高效和更有韧性的训练提供了一条简单且有原则的途径。|
|**2025-11-18**|[Graph Neural Networks for Vehicular Social Networks: Trends, Challenges, and Opportunities](http://arxiv.org/abs/2511.14720)|null|图神经网络（GNN）已成为建模复杂互联数据的强大工具，使其特别适用于广泛的智能交通系统（ITS）应用。本综述首次全面致力于回顾GNN在车载社交网络（VSN）中的应用。通过利用欧几里得和非欧几里得的交通相关数据，包括交通模式、道路使用者和天气状况，GNN为分析和增强VSN应用提供了有前景的解决方案。本综述系统地根据主要的VSN相关任务对现有研究进行分类和分析，这些任务包括交通流量和轨迹预测、交通预测、信号控制、驾驶辅助、路由问题和连接管理。它进一步提供了定量见解，并总结了文献综述中得出的关键结论。此外，本综述审视了可用数据集，并概述了推动基于GNN的VSN应用发展所需的开放研究方向。研究结果表明，尽管GNN在提高任务特定或子VSN图的准确性、鲁棒性和实时性能方面展现出强大潜力，但仍显著缺乏建模涵盖所有功能组件的完整独立VSN的研究。随着数据可用性的增加和图学习的持续进展，GNN有望在实现未来大规模和完全集成的VSN应用中发挥核心作用。|
|**2025-11-14**|[LARM: A Large Articulated-Object Reconstruction Model](http://arxiv.org/abs/2511.11563)|null|建模具有逼真几何形状、纹理和运动学的三维铰接对象对于广泛的应用至关重要。然而，现有的基于优化的重建方法通常需要密集的Aunque, los métodos de reconstrucción basados en optimización existentes a menudo requieren entradas de múltiples vistas densas y una optimización costosa por instancia, lo que limita su escalabilidad.多视角输入和昂贵的逐实例优化，限制了它们的可扩展性。最近的前馈方法提供了更快的替代方案，但经常产生粗糙的几何形状，缺乏纹理重建，并且依赖于脆弱、复杂的多阶段管道。我们引入了LARM，这是一个统一的前馈框架，它通过联合恢复详细的几何形状、逼真的纹理和精确的关节结构，从稀疏视角图像中重建三维铰接对象。LARM将最近用于静态三维对象的新视角合成（NVS）方法LVSM扩展到铰接设置中，通过使用基于Transformer的架构联合推理相机姿态和铰接变化，从而实现可扩展和准确的新视角合成。此外，LARM生成深度图和部件掩码等辅助输出，以促进显式三维网格提取和关节估计。我们的管道消除了对密集监督的需求，并支持跨不同对象类别的高保真重建。大量实验表明，LARM在新视角和状态合成以及三维铰接对象重建方面均优于最先进的方法，生成与输入图像高度吻合的高质量网格。project page: https://sylviayuan-sy.github.io/larm-site/|
|**2025-11-14**|[Human-AI collaborative autonomous synthesis with pulsed laser deposition for remote epitaxy](http://arxiv.org/abs/2511.11558)|null|自主实验室通常依赖数据驱动的决策，偶尔辅以人在环监督以注入领域专业知识。然而，充分利用AI智能体需要紧密耦合的协作工作流，涵盖假设生成、实验规划、执行和解释。为此，我们开发并部署了一种人机协作（HAIC）工作流，该工作流集成了大型语言模型用于假设生成和分析，并通过协作策略更新驱动自主脉冲激光沉积（PLD）实验，以实现BaTiO $_3$/石墨烯的远程外延生长。HAIC加速了假设形成和实验设计，并高效地将生长空间映射到石墨烯损伤。原位拉曼光谱表明，化学作用驱动降解，而最高能量的羽流组分则引发缺陷，从而确定了一个低氧压、低温的合成窗口，该窗口能保护石墨烯，但与最佳BaTiO$_3$生长不兼容。因此，我们发现需要进行两步氩/氧沉积，以剥离铁电BaTiO$_3$ ，同时保持单层石墨烯中间层。HAIC在自主批次之间通过AI推理引入人类洞察，以推动快速科学进展，为许多现有的人在环自主工作流提供了演进。|
|**2025-11-14**|[Building far-from-equilibrium effective field theories using shift symmetries](http://arxiv.org/abs/2511.11555)|null|对量子场论中热化的当代理解主要源于对平衡态瞬态激发性质的理解。这些非流体动力学激发已知在弱耦合和强耦合量子场论之间结构上有所不同，但在相互作用强度的中间值方面尚无已知结果。我们证明，瞬态激发的已知行为可以理解为移位对称性这一对称原理的不同实现的结果，该原理应用于我们明确构建的流体动力学有效作用量的远离平衡推广层面。我们的方法自然地包含了流体动力学范围之外随机涨落的影响，并允许明确构建在弱耦合和强耦合行为之间插值的混合模型。我们研究了受核碰撞中热化启发的一个此类模型的性质，并结合了QCD的跑动耦合。|
|**2025-11-14**|[Testing the cosmological Euler equation: viscosity, equivalence principle, and gravity beyond general relativity](http://arxiv.org/abs/2511.11554)|null|我们研究在粘性暗物质、等效原理 (EP) 违背以及引力修正存在的情况下，如何检验宇宙学欧拉方程，同时依赖最少的理论假设。扩展了之前的分析，我们将量化EP违背的可观测量 $E_P$ 推广到 $\tilde{E}_P$，讨论了体粘度和剪切粘度与EP违背效应之间的简并性，并明确表明在小粘度极限下EP仍然可以被检验。此外，我们确定了一个模型无关的可观测量 $C_{\rm vis,0}$，它表征了当前的暗物质粘度，并且可以通过互相关两类星系群从相对论星系计数中测量。我们对三个即将到来的第四阶段巡天项目：DESI、欧几里得 (Euclid) 和平方公里阵列第二阶段 (SKA2) 进行了预报，发现 $C_{\rm vis,0}$ 可以被严格约束，在所有情况下都达到 $10^{-6}$ 量级或更优。在这些巡天项目中，SKA2 提供了最严格的约束，使得 $C_{\rm vis,0}$ 的 $1\sigma$ 不确定度为 $1.08 \times 10^{-7}$ 。|
|**2025-11-14**|[DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding](http://arxiv.org/abs/2511.11552)|null|理解长篇视觉文档（其中信息分布在大量的文本页和视觉元素中）对于现代视觉语言模型（VLMs）而言是一项关键但具有挑战性的任务。现有方法在一个基本挑战——证据定位上表现不佳。它们难以检索相关页面，并忽略视觉元素中的细粒度细节，从而导致性能受限和模型幻觉。为了解决这个问题，我们提出了DocLens，一个工具增强型多智能体框架，它能像镜头一样有效地“聚焦”证据。它首先从整个文档导航到相关页面上的特定视觉元素，然后采用采样-裁决机制生成一个单一且可靠的答案。配合Gemini-2.5-Pro，DocLens在MMLongBench-Doc和FinRAGBench-V上取得了最先进的性能，甚至超越了人类专家。该框架的优越性在以视觉为中心和无法回答的查询上尤其明显，展示了其增强定位能力的强大。|
|**2025-11-14**|[Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping](http://arxiv.org/abs/2511.11551)|null|决策型AI智能体的部署面临一个严峻挑战，即如何在复杂动态环境中运行时，与人类价值观或准则保持一致。仅为实现其目标而训练的智能体可能会采取有害行为，这揭示了最大化奖励函数与保持对齐之间的一个关键权衡。对于预训练智能体而言，确保对齐尤为困难，因为再训练可能是一个昂贵且缓慢的过程。代表用于对齐的伦理价值观的多样化且可能相互冲突的属性使这一问题变得更加复杂。为了解决这些挑战，我们提出了一种基于模型引导的策略塑形的测试时对齐技术。我们的方法能够精确控制个体行为属性，泛化到各种强化学习（RL）环境，并在无需智能体再训练的情况下，促进伦理对齐与奖励最大化之间的原则性权衡。我们使用MACHIAVELLI基准评估了我们的方法，该基准包含134个基于文本的游戏环境和数千个涉及伦理决策的标注场景。RL智能体首先被训练以最大化其各自游戏中的奖励。在测试时，我们通过场景-动作属性分类器应用策略塑形，以确保决策与伦理属性保持一致。我们将我们的方法与先前的训练时方法和通用智能体进行了比较，并研究了几种类型的伦理违规和权力寻求行为。我们的结果表明，测试时策略塑形为减轻各种环境和对齐属性中的不道德行为提供了一种有效且可扩展的解决方案。|
|**2025-11-14**|[ $CPT$ -Symmetric Kähler-Dirac Fermions](http://arxiv.org/abs/2511.11548)|null|凯勒-狄拉克 (KD) 旋量在晶格规范理论学界引起了广泛关注，它们是解决普通 (狄拉克、马约拉纳或外尔) 旋量在晶格上离散化时所面临的“费米子倍增”问题的一种方式，并有助于解释标准模型的结构。然而，如果天真地在洛伦兹度规下对该理论进行量子化，就会出现问题：一半的KD场具有“错误符号”的拉格朗日量，并导致负范数态。在此，我们提出了一种新的解决方案/解释：KD场实际上存在于一个双层时空上，两层之间通过PT对称性关联，或者通过i↔-i关联。并且，为避免两层之间出现任何非物理相互作用，KD场遵循一个实数条件 (我们称之为“KD-马约拉纳条件”)，它迫使一层上的每个粒子都伴随着另一层上的一个镜像（反）粒子。我们讨论了标准模型如何适应这一框架，费米子（动能和汤川）项如何简化，以及它可能如何与CPT对称宇宙模型相关。|
|**2025-11-14**|[Probing the era of giant collisions: millimeter observations of the HD 166191 system](http://arxiv.org/abs/2511.11535)|null|我们展示了对HD 166191星盘的非同时ALMA 7波段和SMA观测结果，该星盘最近被认为在其类地行星区发生了一次碰撞。两次观测都探测到了尘埃连续谱辐射，ALMA观测还探测到了星周盘发出的12CO J=3-2谱线。我们没有探测到SiO，这是一种巨型碰撞的潜在指标，但我们为该系统中总的SiO质量设定了一个上限。与之前在红外波段的观测不同，我们将2024年的ALMA连续谱观测与2014年碰撞前的SMA观测进行比较，没有发现在毫米波长处存在可变性的证据。我们对CO和连续谱可见度进行了建模，发现CO和尘埃都勉强实现了空间分辨，并且都位于距中心恒星20天文单位以内。CO的建模表明星盘外围区域富含气体，尽管需要进一步观测来确认总气体质量。该系统的演化状态在文献中一直存在争议，而我们的观测虽然不具有决定性，但通常与该星盘类似于演化的原行星盘或过渡/混合盘的观点一致。这可能表明HD 166191类地行星区内的碰撞正在发生，而星盘正处于过渡阶段，其中内侧几个天文单位的气体已耗尽。这使得HD 166191成为理解原行星盘和碎屑盘之间过渡以及碰撞发生阶段的重要研究对象。|
|**2025-11-14**|[Mutated Hilltop Inflation in the Era of Present and Future CMB Experiments](http://arxiv.org/abs/2511.11534)|null|本文我们将变异山顶暴胀模型的大场区和小场区与最新观测结果进行对比。我们首先将变异山顶暴胀的预测与普朗克-2018和BICEP/Keck-2018数据的联合分析结果进行对比。随后，我们通过结合ACT-DR6数据、普朗克-2018、BICEP/Keck-2018和DESI-Y1观测数据来扩展我们的分析。在这两种情况下，变异山顶暴胀的预测都与观测约束表现出良好的一致性。我们还预测了即将进行的宇宙微波背景(CMB)实验LiteBIRD和赛蒙斯天文台及其组合对变异山顶暴胀模型的约束。在这里我们也发现变异山顶暴胀的预测与这些即将进行的CMB实验结果一致。原则上，变异山顶暴胀的小场区可以探测到 $r\sim \mathcal{O}(10^{-4})$ ，其张量振幅与当前上限一致，并可能被下一代CMB任务探测到。然而，为了适应标量谱指数的高观测值，变异山顶暴胀可能需要相对更高的e折叠数。变异山顶暴胀模型的一个关键吸引人的特点是它能够与LiteBIRD和/或赛蒙斯天文台可能无法探测到原初引力波的情况保持一致。|
|**2025-11-14**|[Bridging Hidden States in Vision-Language Models](http://arxiv.org/abs/2511.11526)|null|视觉语言模型（VLMs）是一类将图像内容与自然语言对齐的新型模型。现有方法通常通过以下两种方式进行融合：(a) 早期融合：在编码器内部混合tokens/特征；或 (b) 晚期融合：通过比较池化嵌入。许多方法还将融合与自回归解码器绑定。然而，两种模态的隐藏状态本身就携带着丰富的、模态特定的结构（视觉中的空间布局；文本中的句法和语义），因此直接对齐这些状态是匹配两种模态所“思考”内容的自然方式。我们提出了一种轻量级融合模块：在两个编码器顶部附近放置少量仅进行跨模态的双向注意力层。每个层将视觉和文本编码器隐藏状态序列投影到一个共享空间，进行跨模态注意力，并传回门控残差更新，辅以简单的稳定器以改善对齐。编码器在理解方面保持非因果和强大，而生成则通过一个可选的解码器保持干净地解耦。在标准检索、VQA和视觉推理基准测试中，BRIDGE超越了可比的VLMs，同时保持了对比模型双编码器的效率。我们已将代码公开发布在https://github.com/jfeinashley/BRIDGE。|
|**2025-11-07**|[On Flow Matching KL Divergence](http://arxiv.org/abs/2511.05480)|null|我们推导了流量匹配分布近似的Kullback-Leibler (KL)散度的一个确定性的非渐近上界。特别地，如果 $L_2$流量匹配损失被$\epsilon^2 > 0$限制，那么真实数据分布与估计分布之间的KL散度被$A_1 \epsilon + A_2 \epsilon^2$限制。在此，常数$A_1$和$A_2$ 仅取决于数据场和速度场的正则性。因此，该上界隐含了流量匹配Transformer在全变差(TV)距离下的统计收敛速率。我们表明，流量匹配在估计平滑分布方面实现了近乎minimax最优的效率。我们的结果使得流量匹配的统计效率在TV距离下可与扩散模型相媲美。关于合成和学习到的速度的数值研究证实了我们的理论。|
|**2025-11-07**|[Unsupervised Discovery of High-Redshift Galaxy Populations with Variational Autoencoders](http://arxiv.org/abs/2511.05439)|null|我们利用变分自编码器，在无需先验分类知识的情况下，自动发现使用公开可用的高红移JWST光谱的星系族群。我们的无监督方法识别出独特且令人振奋的星系类型，形成不同的天体物理类别，这展示了大型光谱巡天的自动发现能力。|
|**2025-11-07**|[Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction](http://arxiv.org/abs/2511.05396)|null|异动力学强化学习 (RL)，即训练和部署的转移动力学不同的场景，可以被建模为在鲁棒马尔可夫决策过程 (RMDP) 中的学习，其中转移动力学存在不确定性。现有文献大多假设可以访问允许任意状态-动作查询的生成模型，或者预先收集的、对部署环境具有良好状态覆盖的数据集，从而规避了探索的挑战。在这项工作中，我们研究了一个更现实和具有挑战性的设定，其中智能体仅限于与训练环境进行在线交互。为了捕捉在线 RMDP 中探索的内在难度，我们引入了上确界访问比，这是一个衡量训练动力学和部署动力学之间不匹配程度的新颖量。我们表明，如果这个比率是无界的，在线学习将变得指数级困难。我们提出了第一个计算高效的算法，该算法在具有基于 $f$ -散度的转移不确定性的在线 RMDP 中实现了次线性遗憾。我们还建立了匹配的遗憾下界，表明我们的算法在上确界访问比和交互回合数上都达到了最优依赖性。最后，我们通过综合数值实验验证了我们的理论结果。|
|**2025-11-07**|[Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media](http://arxiv.org/abs/2511.05357)|null|我们提出了一种用于电磁逆向设计的条件扩散模型，该模型能够直接从目标微分散射截面曲线生成结构化介质几何形状，从而避免了昂贵的迭代优化。我们采用逐特征线性调制的一维U-Net架构学习将期望的角散射模式映射到2x2介电球结构，通过采样多样化的有效设计，自然地解决了逆向问题的不唯一性。该模型在11,000个模拟超表面上进行训练，在未见目标上实现了低于19%的中位数MPE（最佳：1.39%），性能优于CMA-ES演化优化，同时将设计时间从数小时缩短至数秒。这些结果表明，采用扩散模型有望推动电磁逆向设计研究，可能实现对复杂超表面架构的快速探索，并加速下一代光子和无线通信系统的开发。代码已公开，网址为https://github.com/mikzuker/inverse_design_metasurface_generation。|
|**2025-11-07**|[SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning](http://arxiv.org/abs/2511.05355)|null|流匹配 (FM) 在数据驱动规划中展现出良好的前景。然而，它本质上缺乏确保状态和动作约束的形式化保证，而这些约束的满足是各种系统上规划轨迹安全性与可采纳性的基本且关键要求。此外，现有FM规划器不保证动力学一致性，这可能导致轨迹无法执行。我们通过提出SAD-Flower来解决这些缺点，SAD-Flower是一个用于生成安全、可采纳且动力学一致轨迹的新颖框架。我们的方法依赖于通过虚拟控制输入对流进行扩充。从而，可以利用非线性控制理论技术得出原理性指导，为状态约束、动作约束和动力学一致性提供形式化保证。至关重要的是，SAD-Flower无需重新训练即可运行，从而能够在测试时满足未曾见过的约束。通过在多项任务中进行广泛实验，我们证明了SAD-Flower在确保约束满足方面优于各种基于生成模型的基线方法。|
|**2025-11-07**|[Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation](http://arxiv.org/abs/2511.05308)|null|随着3D点云成为现代技术的基石，对精密生成模型和可靠评估指标的需求呈指数级增长。在这项工作中，我们首先揭示了一些用于评估生成点云的常用指标，特别是那些基于倒角距离（CD）的指标，在用作质量指标时，缺乏对缺陷的鲁棒性，并且未能捕捉几何保真度和局部形状一致性。我们进一步表明，在距离计算前引入样本对齐，并用密度感知倒角距离（DCD）替换CD，是确保点云生成模型评估指标一致性和鲁棒性的简单但必要的步骤。尽管现有指标主要侧重于直接比较3D欧几里得坐标，我们提出了一种名为表面法线一致性（SNC）的新颖指标，它通过比较估计的点法线来近似表面相似性。这种新指标与传统指标结合时，能对生成样本的质量提供更全面的评估。最后，我们利用用于点云分析的基于Transformer模型的最新进展，例如序列化补丁注意力，提出了一种用于生成高保真3D结构的新架构——扩散点Transformer。我们在ShapeNet数据集上进行了广泛的实验和比较，表明我们的模型优于以前的解决方案，尤其是在生成点云的质量方面，达到了新的SOTA。代码可在https://github.com/matteo-bastico/DiffusionPointTransformer获取。|
|**2025-11-07**|[Shallow IQP circuit and graph generation](http://arxiv.org/abs/2511.05267)|null|我们引入浅层瞬时量子多项式时间 (IQP) 电路作为生成图模型，利用边-量子比特编码将图映射到量子态。针对二分图和Erdős-Rényi分布，我们通过模拟和大规模实验研究了它们的表达能力和鲁棒性。对28个量子比特（8节点图）的无噪声模拟揭示，浅层IQP模型可以学习关键结构特征，例如边密度和二分划分。在IBM的Aachen量子处理单元 (QPU) 上，我们将实验规模从28个扩展到153个量子比特（8到18个节点），以表征其在真实量子硬件上的性能。局部统计量，例如度分布，在不同规模下保持准确，总变差距离范围为0.04到0.20，而全局属性，如严格二分性，在最大系统规模（91和153个量子比特）下出现退化。值得注意的是，谱二分性作为严格二分性的一种松弛，在更高量子比特数量下仍相对稳健。这些结果为浅层IQP电路在当前量子硬件上的性能建立了实用基线，并表明，即使没有错误缓解，此类电路也能学习和重现图数据中有意义的结构模式，为NISQ时代及以后的量子生成建模的未来发展提供指导。|
|**2025-11-07**|[Integrating Score-Based Diffusion Models with Machine Learning-Enhanced Localization for Advanced Data Assimilation in Geological Carbon Storage](http://arxiv.org/abs/2511.05266)|null|准确表征地下非均质性对于地质碳储存（GCS）项目的安全有效实施至关重要。本文探讨了在CO $_2$注入过程中，如何通过一个将基于分数的扩散模型与河道型储层中机器学习增强的局部化相结合的框架，利用机器学习方法增强GCS的数据同化。我们采用一个机器学习增强的局部化框架，该框架使用大型集合（$N_s = 5000$），其中渗透率由扩散模型生成，状态由简单的机器学习算法计算，以改进多数据同化集合平滑器（ESMDA）的协方差估计。我们将机器学习算法应用于一个由地质统计模型FLUVSIM生成的先验河道型渗透率场集合。我们的方法应用于使用代尔夫特高级研究地球模拟器（DARTS）模拟的CO$_2$ 注入情景。我们基于机器学习的局部化，相比未应用局部化的情况，保持了显著更多的集合方差，同时实现了可比的数据匹配质量。该框架对GCS项目具有实际意义，有助于提高用于风险评估的不确定性量化的可靠性。|
|**2025-11-07**|[The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss](http://arxiv.org/abs/2511.05236)|null|尤德亚·珀尔将结构因果模型（SCM）视为反事实推理引擎的愿景，其核心在于忠实溯因：对潜在外生噪声的精确推断。几十年来，将这一步骤应用于复杂非线性机制一直是一个重大的计算挑战。扩散模型（一种强大的通用函数逼近器）的出现提供了一个有前景的解决方案。然而，我们认为其标准设计（针对感知生成而非逻辑推理进行优化）为此经典问题引入了一个根本缺陷：一种我们称之为结构重建误差（SRE）的固有信息损失。为解决这一挑战，我们将因果信息守恒（CIC）原理形式化为忠实溯因的必要条件。随后，我们引入了BELM-MDCM，这是首个通过解析可逆机制在构造上消除SRE、从而实现因果正确性的基于扩散的模型框架。为了操作化这一框架，我们采用了一种目标建模策略提供结构正则化，同时一个混合训练目标灌输了强大的因果归纳偏置。严格的实验表明，我们的零SRE框架不仅达到了最先进的准确性，更重要的是，它实现了深入因果探究所需的高保真、个体层面的反事实。我们的工作提供了一个基础蓝图，调和了现代生成模型的强大能力与经典因果理论的严谨性，为这一新兴领域建立了新的、更严格的标准。|
|**2025-11-07**|[FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction](http://arxiv.org/abs/2511.05219)|null|控制扩散模型生成图像的空间和语义结构仍然是一个挑战。ControlNet等现有方法依赖于手工制作的条件图和重训练，限制了灵活性和泛化能力。基于反演的方法提供了更强的对齐，但由于双路径去噪而产生高昂的推理成本。我们提出了FreeControl，一个用于扩散模型中语义结构控制的无需训练的框架。与之前在多个时间步提取注意力的方法不同，FreeControl从单个、最优选择的关键时间步执行一步注意力提取，并在整个去噪过程中重复使用。这实现了无需反演或重训练的高效结构引导。为了进一步提高质量和稳定性，我们引入了潜在条件解耦（LCD）：对用于注意力提取的关键时间步和带噪声潜在表示进行原则性分离。LCD提供了对注意力质量的更精细控制，并消除了结构伪影。FreeControl还支持通过从多个来源组合的参考图像进行组合式控制——实现了直观的场景布局设计和更强的提示对齐。FreeControl为测试时控制引入了一种新范式，实现了直接从原始图像生成结构和语义对齐、视觉连贯的图像，并具有直观组合设计的灵活性，同时兼容现代扩散模型，额外成本约为5%。|
|**2025-11-06**|[InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation](http://arxiv.org/abs/2511.04675)|null|我们引入了InfinityStar，一个用于高分辨率图像和动态视频合成的统一时空自回归框架。基于自回归建模在视觉和语言领域最近的成功，我们的纯离散方法在单一架构内联合捕获空间和时间依赖性。这种统一设计通过直接的时间自回归，自然支持多种生成任务，例如文本到图像、文本到视频、图像到视频以及长交互式视频合成。大量实验表明，InfinityStar在VBenc上得分为83.74，大幅优于所有自回归模型，甚至超越了一些扩散模型竞争对手，如HunyuanVideo。在没有额外优化的情况下，我们的模型生成一个5秒、720p的视频，速度比领先的基于扩散的方法快约10倍。据我们所知，InfinityStar是第一个能够生成工业级720p视频的离散自回归视频生成器。我们发布了所有代码和模型，以促进在高效、高质量视频生成领域的进一步研究。|
|**2025-11-06**|[Forgetting is Everywhere](http://arxiv.org/abs/2511.04666)|**[link](https://github.com/rprokap/pset-9)**|通用学习算法开发中的一个根本挑战是它们在适应新数据时容易遗忘旧知识。解决这个问题需要对遗忘有一个系统性理解；然而，尽管进行了数十年的研究，尚未出现能够深入了解学习底层动态的统一定义。我们提出了一种与算法和任务无关的理论，将遗忘表征为学习器对未来经验的预测分布中缺乏自洽性，表现为预测信息的丢失。我们的理论自然地提供了一种衡量算法遗忘倾向的通用度量。为了验证该理论，我们设计了一系列全面的实验，涵盖分类、回归、生成模型和强化学习。我们通过实证证明了遗忘存在于所有学习设置中，并在决定学习效率方面发挥重要作用。综合来看，这些结果建立了对遗忘的系统性理解，并为分析和改进通用学习算法的信息保留能力奠定了基础。|
|**2025-11-06**|[Optimal Inference Schedules for Masked Diffusion Models](http://arxiv.org/abs/2511.04647)|null|标准自回归大型语言模型的一个主要瓶颈是其推理过程本质上是顺序的，导致推理时间非常长且成本高昂。为了规避这一点，研究人员提出了一类被称为扩散语言模型的模型，其中掩码扩散模型（MDM）是最成功的。MDM能够无序采样token，并且表面上可以同时并行采样多个token。然而，对于这些模型在不显著降低采样性能的情况下能进行多少并行采样，目前缺乏严格的理解。Li和Cai的先前工作获得了一些初步界限，但这些界限对于许多自然分布类别来说并不紧密。在这项工作中，我们对真实分布和采样分布之间的期望散度给出了一个新的、精确的刻画，适用于任何分布和采样器的任何去掩码策略，并展示了其与单变量函数逼近理论的优美联系。通过利用这种联系，我们为该问题获得了一系列新颖的下界和上界。虽然函数逼近的联系原则上为任何分布提供了最优的去掩码策略，但我们表明，在缺乏关于分布的强先验知识的情况下，即使在看似良性的设置中，也普遍不可能与之竞争。然而，我们还基于基础分布的充分研究的信息论性质（即其总相关性和对偶总相关性）展示了新的上界和新的采样策略，这些结果表明在某些自然设置下，可以在 $O(\log n)$步内完成采样，而性能没有任何可见损失，其中$n$ 是总序列长度。|
|**2025-11-06**|[Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems](http://arxiv.org/abs/2511.04641)|null|本文关注用于预测由偏微分方程（例如纳维-斯托克斯方程）描述的动力系统的概率技术。具体来说，本文研究并比较了流匹配范式的各种扩展，这些扩展旨在减少采样步数。在这方面，它比较了直接蒸馏、渐进蒸馏、对抗扩散蒸馏、Wasserstein GANs和整流流。此外，实验在一系列具有挑战性的系统上进行。特别地，我们还解决了直接预测大规模三维模拟的二维切片的挑战，这为求解器的高效流入生成铺平了道路。|
|**2025-11-06**|[PromptSep: Generative Audio Separation via Multimodal Prompting](http://arxiv.org/abs/2511.04623)|null|语言查询音频源分离（LASS）的近期突破表明，生成模型可以实现比传统基于掩码的方法更高的分离音频质量。然而，两个关键限制阻碍了它们的实际应用：(1) 用户通常需要分离之外的操作，例如声音移除；(2) 仅依赖文本提示来指定声源可能不直观。在本文中，我们提出了 PromptSep，旨在将 LASS 扩展为一个更广泛的通用声音分离框架。PromptSep 利用一个通过精心设计的数据模拟增强的条件扩散模型，以实现音频提取和声音移除。为了超越纯文本查询，我们通过将 Sketch2Sound 作为一种数据增强策略，引入了声音模仿作为模型的一种额外且更直观的条件模态。在多个基准上的客观和主观评估均表明，PromptSep 在声音移除和声音模仿引导的源分离方面取得了最先进的性能，同时在语言查询源分离方面保持了有竞争力的结果。|
|**2025-11-06**|[Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality](http://arxiv.org/abs/2511.04615)|null|深度学习模型可以从苏木精-伊红（H&E）图像生成虚拟免疫组织化学（IHC）染色，为实验室IHC提供了一种可扩展且低成本的替代方案。然而，图像质量的可靠评估仍然是一个挑战，因为当前基于纹理和分布的指标量化的是图像保真度，而非IHC染色的准确性。在此，我们引入了一个自动化且基于准确性的框架，用于评估十六种配对或非配对图像转换模型的图像质量。我们利用颜色去卷积技术，生成由每个虚拟IHC模型预测的染成棕色（即IHC阳性）像素的掩膜。我们使用真实和虚拟IHC的分割掩膜来计算染色准确性指标（Dice系数、IoU、Hausdorff距离），这些指标无需专家手动标注即可直接量化正确的像素级标记。我们的结果表明，传统的图像保真度指标，包括Frechet Inception距离（FID）、峰值信噪比（PSNR）和结构相似性（SSIM），与染色准确性和病理学家评估的相关性较差。PyramidPix2Pix和AdaptiveNCE等配对模型实现了最高的染色准确性，而非配对的扩散模型和基于GAN的模型在提供准确的IHC阳性像素标签方面可靠性较低。此外，全玻片图像（WSI）揭示了在基于图像块的评估中不可见的性能下降，强调了对WSI级别基准的需求。总之，该框架定义了一种可重复的方法来评估虚拟IHC模型的质量，这是加速其转化为病理学家常规应用的关键一步。|
|**2025-11-06**|[Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm](http://arxiv.org/abs/2511.04570)|null|“文本思考”和“图像思考”范式显著提高了大型语言模型（LLM）和视觉语言模型（VLM）的推理能力。然而，这些范式存在固有限制：(1) 图像仅能捕捉单一时刻，无法表示动态过程或连续变化，(2) 文本和视觉作为独立的模态而分离，阻碍了统一的多模态理解和生成。为克服这些限制，我们引入了“视频思考”这一新范式，它利用视频生成模型（如Sora-2）在统一的时间框架内弥合视觉和文本推理。为支持这项探索，我们开发了视频思考基准（VideoThinkBench）。VideoThinkBench包含两类任务：(1) 以视觉为中心的任务（例如，目测谜题），以及(2) 以文本为中心的任务（例如，GSM8K和MMMU的子集）。我们的评估证实了Sora-2是一个有能力的推理器。在以视觉为中心的任务上，Sora-2通常与最先进（SOTA）的VLM相当，甚至在目测游戏等几项任务上超越了VLM。在以文本为中心的任务上，Sora-2在MATH上达到了92%的准确率，在MMMU上达到了75.53%的准确率。此外，我们系统地分析了这些能力的来源。我们还发现自洽性和上下文学习可以提高Sora-2的性能。总之，我们的研究结果表明视频生成模型是潜在的统一多模态理解和生成模型，并将“视频思考”定位为统一的多模态推理范式。|
|**2025-11-06**|[Unified Generative Latent Representation for Functional Brain Graphs](http://arxiv.org/abs/2511.04539)|null|功能性脑图通常用独立的图论或谱描述符来表征，却忽视了这些属性在不同大脑和条件下如何共同变化并部分重叠。我们预计，密集、加权的功能连接图占据一个低维潜在几何空间，拓扑结构和谱结构都在其中呈现出渐变式变化。在本文中，我们估计了这种统一的图表示，并利用带有潜在扩散的图Transformer自编码器生成了密集的功能性脑图，其中谱几何为引导学习提供了归纳偏置。这种几何感知的潜在表示，尽管是无监督的，却能有意义地区分工作记忆状态并解码视觉刺激，通过整合神经动力学，其性能得到了进一步提升。从扩散建模的分布中，我们能够采样到具有生物学合理性和结构基础的合成密集图。|
|**2025-11-06**|[THEval. Evaluation Framework for Talking Head Video Generation](http://arxiv.org/abs/2511.04520)|null|视频生成取得了显著进展，生成的视频越来越像真实视频。然而，生成技术的快速发展超出了相应评估指标的发展速度。目前，说话人脸生成主要依赖有限的指标，评估整体视频质量、唇部同步以及进行用户研究。受此启发，我们提出了一个包含8个指标的新评估框架，这些指标涉及三个维度：(i) 质量，(ii) 自然度，和 (iii) 同步性。在选择这些指标时，我们强调效率以及与人类偏好的一致性。基于这些考量，我们精简分析了头部、嘴巴和眉毛的细粒度动态以及面部质量。我们对17个最先进模型生成的85,000个视频进行的广泛实验表明，尽管许多算法在唇部同步方面表现出色，但它们在生成表现力和无伪影细节方面仍面临挑战。这些视频是基于我们策划的一个新颖的真实数据集生成的，旨在减轻训练数据中的偏差。我们提出的基准框架旨在评估生成方法的改进。原始代码、数据集和排行榜将公开发布，并定期用新方法进行更新，以反映该领域的进展。|
|**2025-11-06**|[Towards Causal Market Simulators](http://arxiv.org/abs/2511.04469)|null|使用深度生成模型的市场生成器在合成金融数据生成方面展现出潜力，但现有方法缺乏因果推理能力，这对于反事实分析和风险评估至关重要。我们提出了一种时序神经因果模型变分自编码器（TNCM-VAE），该模型结合了变分自编码器和结构化因果模型，以生成反事实金融时间序列，同时保留了时间依赖性和因果关系。我们的方法通过在解码器架构中利用有向无环图来强制施加因果约束，并采用因果Wasserstein距离进行训练。我们在受Ornstein-Uhlenbeck过程启发的合成自回归模型上验证了我们的方法，结果表明在反事实概率估计方面表现优越，相较于真实值，L1距离低至0.03-0.10。该模型通过生成尊重底层因果机制的合理反事实市场轨迹，实现了金融压力测试、情景分析和增强型回溯测试。|
|**2025-11-04**|[Diffusion Models are Robust Pretrainers](http://arxiv.org/abs/2511.02793)|null|扩散模型因其高保真图像生成能力而获得了广泛关注。我们的工作研究了利用扩散模型在图像分类和目标检测中实现对抗鲁棒性的潜力。对抗性攻击通过扰动输入迫使标准模型做出错误预测，从而对其在这些任务中的性能构成挑战。为了解决这个问题，许多方法采用训练方案来增强模型的鲁棒性，但这增加了训练成本。在这项工作中，我们研究了基于现成扩散模型构建的模型，并展示了它们的实际意义：它们提供了一种低成本的途径来获得鲁棒表示，允许在冻结特征上训练轻量级头部，而无需进行完整的对抗训练。我们在ImageNet、CIFAR-10和PASCAL VOC数据集上的实证评估表明，基于扩散的分类器和检测器以最小的计算量实现了有意义的对抗鲁棒性。尽管在干净数据和对抗数据上的准确性仍然低于最先进的对抗训练CNN或ViT，但扩散预训练在效率和鲁棒性之间提供了一个有利的权衡。这项工作为将扩散模型集成到资源受限的鲁棒部署中开辟了一条有前景的途径。|
|**2025-11-04**|[AI-Generated Image Detection: An Empirical Study and Future Research Directions](http://arxiv.org/abs/2511.02791)|null|AI生成媒体，特别是深度伪造，所带来的威胁，正对多媒体取证、虚假信息检测和生物识别系统构成严峻挑战，导致公众对法律体系的信任受损、欺诈行为显著增加以及社会工程攻击。尽管已提出多种取证方法，但它们存在三个关键缺陷：(i) 使用非标准化的GAN或扩散模型生成图像的基准；(ii) 不一致的训练协议（例如，从头训练、冻结、微调）；以及(iii) 无法捕捉泛化能力和可解释性的有限评估指标。这些局限性阻碍了公平比较，掩盖了真实的鲁棒性，并限制了其在安全关键型应用中的部署。本文引入了一个统一的基准测试框架，用于在受控和可复现条件下系统评估取证方法。我们对十种最先进的取证方法（从头训练、冻结和微调）和七个公开数据集（GAN和扩散模型）进行了基准测试，以执行广泛而系统的评估。我们使用多种指标评估性能，包括准确率、平均精度、ROC曲线下面积、错误率和各类别敏感度。我们还使用置信度曲线和Grad-CAM热图进一步分析了模型可解释性。我们的评估表明泛化能力存在显著差异，某些方法表现出强大的域内性能，但跨模型可迁移性下降。本研究旨在引导研究界更深入地理解当前取证方法的优点和局限性，并启发开发更鲁棒、更具泛化能力和可解释性的解决方案。|
|**2025-11-04**|[XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations](http://arxiv.org/abs/2511.02776)|null|大规模机器人数据集和视觉-语言模型（VLM）的近期进展推动了视觉-语言-动作（VLA）模型的研究。然而，现有VLA模型仍面临两个基本挑战：(i) 从高维观测中生成精确的低级动作，以及 (ii) 弥合异构数据源（包括不同机器人实体和人类演示）之间的领域鸿沟。现有方法通常从视觉动态或机器人动作中编码潜在变量以指导策略学习，但它们未能充分利用大规模异构数据集中存在的互补多模态知识。在这项工作中，我们提出了X机器人模型1 (XR-1)，这是一个新颖的框架，用于跨越不同机器人、任务和环境的通用且可扩展的VLA学习。XR-1引入了统一视觉-运动代码 (UVMC)，这是一种通过双分支VQ-VAE学习的离散潜在表示，它共同编码视觉动态和机器人运动。UVMC通过 (i) 作为观测和动作之间的中间表示，以及 (ii) 对齐来自异构数据源的多模态动态信息以捕获互补知识，从而解决了这些挑战。为了有效利用UVMC，我们提出了一种三阶段训练范式：(i) 自监督UVMC学习，(ii) 在大规模跨实体机器人数据集上进行UVMC引导的预训练，以及 (iii) 任务特定的后训练。我们通过广泛的真实世界实验验证了XR-1，在六种不同的机器人实体上进行了超过14,000次推演，涵盖了超过120种不同的操作任务。XR-1持续优于最先进的基线，例如 $\pi_{0.5}$、$\pi_0$ 、RDT、UniVLA和GR00T-N1.5，同时表现出对新物体、背景变化、干扰物和照明变化的强大泛化能力。我们的项目网址是https://xr-1-vla.github.io/。|
|**2025-11-04**|[STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation](http://arxiv.org/abs/2511.02769)|null|药物分子的化学空间广阔，促使生成模型的发展，这些模型必须学习广泛的化学分布，通过捕获结构-属性表示实现条件生成，并提供快速分子生成。实现这些目标取决于建模选择，包括概率建模方法、条件生成公式、架构以及分子输入表示。为应对这些挑战，我们提出了STAR-VAE（Selfies编码、基于Transformer的自回归变分自编码器），这是一个可扩展的潜在变量框架，具有Transformer编码器和自回归Transformer解码器。它在来自PubChem的7900万个药物分子上进行训练，使用SELFIES来保证语法有效性。潜在变量公式实现了条件生成：一个属性预测器提供一个条件信号，该信号被一致地应用于潜在先验、推断网络和解码器。我们的贡献包括：(i) 一个基于Transformer的潜在变量编码器-解码器模型，该模型在SELFIES表示上进行训练；(ii) 一个用于属性引导生成的原则性条件潜在变量公式；以及(iii) 在编码器和解码器中均采用低秩适配器（LoRA）进行高效微调，从而在有限的属性和活性数据下实现快速适应。在GuacaMol和MOSES基准测试中，我们的方法达到或超过了基线，且潜在空间分析揭示了平滑、语义结构化的表示，这些表示支持无条件探索和属性感知生成。在Tartarus基准测试中，条件模型将对接分数分布转向更强的预测结合。这些结果表明，当与原则性条件作用和参数高效微调相结合时，一种现代化、规模适宜的VAE在分子生成方面仍具竞争力。|
|**2025-11-04**|[Identification and Estimation of Continuous-Time Dynamic Discrete Choice Games](http://arxiv.org/abs/2511.02701)|null|本文探讨了由Arcidiacono, Bayer, Blevins和Ellickson (2016)引入的、具有随机序贯行动的连续时间动态离散选择博弈的理论、计算和计量经济学性质。我们考察了行动到达率的识别，这在以往工作中被假定为已知，并考虑了一个具有异质行动到达率的推广版本。我们重新建立了推广模型中马尔可夫完美均衡的存在条件，并考虑了仅使用以固定间隔采样的离散时间数据来识别模型基本参数。本文考虑了三个基础示例模型：单智能体更新模型、动态进入和退出模型以及质量阶梯模型。通过这些示例，我们通过蒙特卡洛实验和使用Rust (1987)数据的实证示例，检验了估计量的计算和统计性质。实验展示了当从连续时间数据转向频率降低的离散时间数据时参数估计的行为，以及随着公司数量增长时的计算可行性。实证示例强调了允许决策率变化所带来的影响。|
|**2025-11-04**|[Using Deep Learning for Robust Classification of Fast Radio Bursts](http://arxiv.org/abs/2511.02634)|**[link](https://github.com/rtenacity/frb-analysis)**|尽管快速射电暴（FRB）的本质仍然未知，但群体层面分析可以阐明这些信号的潜在结构。在这项研究中，我们采用深度学习方法对FRB进行分类，并分析从第一个CHIME星表中学到的潜在空间中的结构模式。我们采用监督变分自编码器（sVAE）架构，该架构将变分自编码器（VAE）的表征学习能力与监督分类任务相结合，从而提高了分类性能和潜在空间的可解释性。我们构建了一个学习到的潜在空间，并在其中执行进一步的降维以发现数据中的潜在结构。我们的结果表明，sVAE模型对FRB重复爆发源实现了高分类精度，并揭示了重复爆发源和非重复爆发源群体之间的分离。在对潜在空间进行进一步分析后，我们观察到过剩色散量、谱指数和谱斜率变化是区分重复爆发源和非重复爆发源的主要特征。我们还识别出四个非重复爆发的FRB作为重复爆发源候选体，其中两个已在先前的研究中被独立标记。|
|**2025-11-04**|[A Non-Adversarial Approach to Idempotent Generative Modelling](http://arxiv.org/abs/2511.02614)|null|幂等生成网络（IGN）是一种深度生成模型，同时也是局部数据流形投影器，能将任意输入映射回流形。它们经过训练，可以作为数据上的恒等算子，并在数据流形之外作为幂等算子。然而，IGN面临模式坍塌、模式丢失和训练不稳定等问题，这源于其目标函数包含对抗性成分，可能导致模型仅部分覆盖数据流形——这是生成对抗网络共同面临的问题。我们引入非对抗性幂等生成网络（NAIGN）来解决这些问题。我们的损失函数将重建与隐式最大似然估计（IMLE）的非对抗性生成目标相结合。这改进了IGN恢复损坏数据和生成紧密匹配数据分布的新样本的能力。我们进一步证明，NAIGN隐式学习到数据流形的距离场，以及一个基于能量的模型。|
|**2025-11-04**|[Generalizable super-resolution turbulence reconstruction from minimal training data](http://arxiv.org/abs/2511.02604)|null|由于湍流系统的多尺度复杂性，完全解析湍流仍然具有挑战性。现有数据驱动方法通常需要为每个流动场景进行昂贵的再训练，并且难以泛化到其训练条件之外。利用小尺度湍流运动的普适性（柯尔莫哥洛夫K41理论），我们提出了一个面向尺度的分区生成对抗网络（SoZoGAN）框架，用于在不同领域实现高精度、零样本的湍流生成。与传统方法不同，SoZoGAN仅在一个中等雷诺数均匀各向同性湍流（HIT）的单一数据集上进行训练。该框架采用分区分解策略，根据尺度敏感的物理量将湍流快照划分为子域。在每个子域内，湍流使用仅在HIT数据库上预训练的尺度索引模型进行合成。SoZoGAN在非定常流的零样本超分辨率中展示了高精度、跨域泛化能力和鲁棒性，这一点在未经训练的HIT、湍流边界层和槽道流上得到了验证。其在均匀和非均匀湍流案例中展示出的强大泛化能力，表明其可能适用于更广泛的工业和自然湍流。这种面向尺度的分区框架与架构无关，易于从生成对抗网络（GAN）扩展到其他深度学习模型。|
|**2025-11-04**|[TAUE: Training-free Noise Transplant and Cultivation Diffusion Model](http://arxiv.org/abs/2511.02580)|null|尽管文生图扩散模型取得了显著成功，但其输出单一扁平图像的特性仍然是需要分层控制的专业应用中的一个关键瓶颈。现有解决方案要么依赖于使用大规模、难以获取的数据集进行微调，要么是免训练但仅限于生成孤立的前景元素，无法生成完整且连贯的场景。为解决此问题，我们引入了免训练噪声移植与培育扩散模型（TAUE），这是一个用于零样本、分层图像生成的新颖框架。我们的核心技术，噪声移植与培育（NTC），从前景和合成生成过程中提取中间潜在表示，并将其移植到后续层的初始噪声中。这确保了前景、背景和合成层之间的语义和结构连贯性，从而无需微调或辅助数据集即可实现一致的多层输出。大量实验表明，我们的免训练方法实现了与微调方法相当的性能，在保持高图像质量和保真度的同时增强了分层一致性。TAUE不仅消除了昂贵的训练和数据集需求，还开启了新的下游应用，例如复杂的组合编辑，为更易访问和可控的生成工作流程铺平了道路。|
|**2025-11-04**|[First-principles Prediction of Carrier Mobility in Semiconductor Nanowires Based on the Spatially Dependent Boltzmann Transport Equation](http://arxiv.org/abs/2511.02561)|null|块体半导体中的载流子迁移率通常由电子-声子 (e-ph) 散射决定。在纳米结构中，空间限制会导致显著的表面散射，从而降低迁移率并打破传统模型的空间均匀性假设。在这项工作中，我们开发了一个基于空间相关的玻尔兹曼输运方程的完全从头算框架，用于一维纳米线。我们将其应用于硅 (Si) 和氮化镓 (GaN)，假设漫散射表面散射，并揭示了迁移率-直径关系： $\mu_\mathrm{1D} = \mu_\mathrm{bulk} \left[1-\left(d/d_0\right)^{-\beta}\right]$。参数 $d_0$ 与载流子平均自由程相当，定义了一个表现出显著迁移率梯度的边界层，并与 $\beta$ 一起量化了电子-声子散射和表面散射之间的竞争。我们进一步讨论了取向、截面形状和温度的影响。此外，实验数据通常低于我们的预测，这可能归因于结构缺陷、测量中的系统误差等。因此，我们的理论方法可以为优化实验实现提供一个内在的基准。|
|**2025-10-31**|[Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals](http://arxiv.org/abs/2510.27684)|null|分布匹配蒸馏 (DMD) 将基于分数的生成模型蒸馏为高效的一步生成器，无需与其教师模型的采样轨迹进行一对一对应。然而，有限的模型容量导致一步蒸馏模型在复杂生成任务上表现不佳，例如在文本到视频生成中合成复杂的物体运动。直接将DMD扩展到多步蒸馏会增加内存使用和计算深度，导致不稳定性和效率降低。尽管现有工作提出随机梯度截断作为一种潜在解决方案，我们发现它显著降低了多步蒸馏模型的生成多样性，使其降至与一步蒸馏模型相当的水平。为解决这些局限性，我们提出了Phased DMD，一个多步蒸馏框架，该框架将分阶段蒸馏的思想与专家混合模型 (MoE) 相结合，降低了学习难度，同时增强了模型容量。Phased DMD基于两个关键思想：渐进式分布匹配和子区间内的分数匹配。首先，我们的模型将信噪比 (SNR) 范围划分为子区间，逐步将模型优化到更高的SNR水平，以更好地捕获复杂分布。其次，为确保每个子区间内的训练目标准确无误，我们进行了严谨的数学推导。我们通过蒸馏最先进的图像和视频生成模型来验证Phased DMD，包括Qwen-Image (200亿参数) 和Wan2.2 (280亿参数)。实验结果表明，Phased DMD比DMD更好地保持了输出多样性，同时保留了关键的生成能力。我们将发布我们的代码和模型。|
|**2025-10-31**|[MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design](http://arxiv.org/abs/2510.27671)|null|基于结构药物设计（SBDD）是将靶蛋白映射到候选分子配体的一项药物发现基础任务。有效地将蛋白质结构表示与分子表示对齐，并确保生成的药物与其药理学特性之间的一致性，仍然是一个关键挑战。为应对这些挑战，我们提出了MolChord，它整合了两项关键技术：(1) 为了将蛋白质和分子结构与其文本描述和序列表示（例如，蛋白质的FASTA和分子的SMILES）对齐，我们利用统一文本、小分子和蛋白质的自回归模型NatureLM作为分子生成器，并辅以一个基于扩散的结构编码器；(2) 为了引导分子产生期望的特性，我们通过整合偏好数据构建了一个属性感知数据集，并使用直接偏好优化（DPO）改进对齐过程。在CrossDocked2020上的实验结果表明，我们的方法在关键评估指标上达到了最先进的性能，突显了其作为SBDD实用工具的潜力。|
|**2025-10-31**|[Who Made This? Fake Detection and Source Attribution with Diffusion Features](http://arxiv.org/abs/2510.27602)|null|生成式扩散模型的快速发展使得合成图像的创建越来越难以与真实图像区分，引发了对真实性、版权和虚假信息的担忧。现有的监督式检测器往往难以泛化到未见过的生成器，需要大量的标注数据和频繁的再训练。我们引入了FRIDA（通过扩散特征分析进行假图像识别与来源识别），这是一个轻量级框架，它利用预训练扩散模型的内部激活进行深度伪造检测和源生成器归因。将k近邻分类器应用于扩散特征，无需微调即可实现最先进的跨生成器性能，而一个紧凑型神经网络模型则能实现准确的来源归因。这些结果表明，扩散表示内在地编码了生成器特定的模式，为合成图像取证提供了一个简单且可解释的基础。|
|**2025-10-31**|[Kinematical and dynamical contrast of dislocations in thick GaN substrates observed by synchrotron-radiation X-ray topography under six-beam diffraction conditions](http://arxiv.org/abs/2510.27597)|null|在六束衍射条件下，使用同步辐射X射线形貌术（SR-XRT）对厚氨热法氮化镓（GaN）衬底中的位错进行了研究。同步辐射源的高亮度使得超玻尔曼效应得以观测，该效应显著增强了X射线穿过350微米厚晶体的异常透射。偏离角 $\Delta\omega$的系统改变揭示了从运动学衍射到动力学衍射的清晰转变，这与基于动力学衍射理论的理论预测一致。通过选择性地激发接近六束配置的五个等效两束衍射条件，根据$g\cdot b$不可见性判据确定了单个穿透刃型位错（TEDs）的伯格斯矢量。测量的位错图像宽度与根据消光距离和$\|g\cdot b\|$依赖性得出的计算值非常吻合，证实了大多数位错具有包含$\frac{1}{3}\langle 11\bar{2}0\rangle$或$\frac{2}{3}\langle 11\bar{2}0\rangle$的$a$ 型分量的伯格斯矢量。这些结果表明，多束衍射条件下的SR-XRT为厚GaN晶体中的定量位错分析提供了一种强大、无损的方法，为对高性能GaN基电子器件至关重要的缺陷结构提供了有价值的见解。|
|**2025-10-31**|[CodeAlignBench: Assessing Code Generation Models on Developer-Preferred Code Adjustments](http://arxiv.org/abs/2510.27565)|null|随着大型语言模型生成代码的能力日益增强，评估其性能仍然是一个复杂且不断演进的挑战。现有基准主要侧重于功能正确性，却忽视了现实世界编码任务的多样性以及开发者的期望。为此，我们引入了一个多语言基准，用于评估大型语言模型的指令遵循能力，并且可以扩展以应用于任何一组独立的编码问题。我们的基准在两个关键场景中评估指令遵循情况：一是遵守初始问题中指定的预定义约束，二是根据后续指令执行改进的能力。在本文的分析中，我们通过实验评估了我们的基准测试流程，使用了来自LiveBench的编程任务，这些任务也被自动从Python翻译成Java和JavaScript。我们的自动化基准揭示，模型在指令遵循的多个维度上表现出不同水平的性能。我们的基准测试流程为代码生成模型提供了更全面的评估，突出了它们在不同语言和生成目标方面的优点和局限性。|
|**2025-10-31**|[Optimal Convergence Analysis of DDPM for General Distributions](http://arxiv.org/abs/2510.27562)|null|基于分数的扩散模型在从目标数据分布生成高质量样本方面取得了显著的经验成功。其中，去噪扩散概率模型（DDPM）是最广泛使用的采样器之一，通过估计的分数函数生成样本。尽管其在经验上取得了成功，但对DDPM的严格理论理解——特别是其收敛性质——仍然有限。在本文中，我们对DDPM采样器进行了精细的收敛分析，并在一般分布假设下建立了接近最优的收敛速度。具体来说，我们引入了一个由常数 $L$参数化的放松平滑条件，对于许多实际分布（例如，高斯混合模型）而言，该条件较小。我们证明，具有精确分数估计的DDPM采样器在Kullback-Leibler散度下达到了$\widetilde{O}\left(\frac{d\min\{d,L^2\}}{T^2}\right)$的收敛速度，其中$d$是数据维度，$T$是迭代次数，$\widetilde{O}$隐藏了$T$的多对数因子。当$L < \sqrt{d}$时，这一结果大幅改进了已知的最佳$d^2/T^2$速度。通过建立匹配的下界，我们表明我们的收敛分析对于广泛的目标分布是紧密的。此外，它揭示了DDPM和DDIM对$d$ 的依赖性相同，这提出了一个有趣的问题，即为什么DDIM在经验上通常表现得更快。|
|**2025-10-31**|[EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities](http://arxiv.org/abs/2510.27545)|null|由生成模型（例如扩散策略）参数化的隐式策略已成为机器人领域中策略学习和视觉-语言-动作（VLA）模型的标准。然而，这些方法常面临高计算成本、暴露偏差和不稳定的推理动态，这导致在分布偏移下出现发散。基于能量的模型（EBM）通过端到端地学习能量景观并建模平衡动态来解决这些问题，从而提供更高的鲁棒性和更低的暴露偏差。然而，由EBM参数化的策略历来难以有效扩展。最近关于基于能量的Transformer（EBT）的研究证明了EBMs在处理高维空间时的可扩展性，但其在解决具身模型核心挑战方面的潜力仍未得到充分探索。我们引入了一种新的基于能量的架构——EBT-策略，它解决了机器人和真实世界环境中的核心问题。在模拟和真实世界任务中，EBT-策略持续优于基于扩散的策略，同时所需的训练和推理计算量更少。值得注意的是，在某些任务上，它仅用两个推理步骤即可收敛，比扩散策略的100个步骤减少了50倍。此外，EBT-策略展现出以往模型中未见的涌现能力，例如仅使用行为克隆，无需显式重试训练即可从失败的动作序列中进行零样本恢复。通过利用其标量能量进行不确定性感知推理和动态计算分配，EBT-策略为在分布偏移下实现鲁棒、可泛化的机器人行为提供了一条有前景的路径。|
|**2025-10-31**|[InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames](http://arxiv.org/abs/2510.27497)|null|基于Transformer的自回归模型已成为跨文本和图像等模态的统一范式，但其在3D分子生成方面的扩展仍未得到充分探索。这一空白源于两个基本挑战：(1) 将分子token化为对SE(3)变换和原子索引置换均保持不变的规范1D token序列，以及(2) 设计一种能够建模混合原子级token的架构，该token将离散原子类型与连续3D坐标耦合。为应对这些挑战，我们引入了InertialAR。InertialAR设计了一种规范的token化方法，将分子对齐到其惯性坐标系并重新排序原子，以确保SE(3)和置换不变性。此外，InertialAR通过几何旋转位置编码（GeoRoPE）为注意力机制赋予了几何感知能力。另外，它采用了一种分层自回归范式来预测下一个原子级token，即首先预测原子类型，然后通过扩散损失预测其3D坐标。实验结果表明，InertialAR在QM9、GEOM-Drugs和B3LYP数据集上的无条件分子生成任务中，在10项评估指标中的7项上取得了最先进的性能。此外，它在针对目标化学功能的可控生成方面显著优于强基线模型，并在所有5项指标上均取得了最先进的结果。|
|**2025-10-31**|[Referee: Reference-aware Audiovisual Deepfake Detection](http://arxiv.org/abs/2510.27475)|null|由于先进生成模型生成的深度伪造内容迅速构成严重威胁，现有的音视频深度伪造检测方法难以泛化到未见过的伪造内容。我们提出了一种新颖的参考感知音视频深度伪造检测方法，命名为 Referee。该方法利用仅从一次性示例中提取的说话人特有线索来检测超越时空伪影的操纵。通过将来自参考内容和目标内容的身份相关查询匹配并对齐到跨模态特征中，Referee 共同推理音视频同步性和身份一致性。在 FakeAVCeleb、FaceForensics++ 和 KoDF 上的大量实验表明，Referee 在跨数据集和跨语言评估协议上取得了最先进的性能。实验结果强调了跨模态身份验证对于未来深度伪造检测的重要性。代码可在 https://github.com/ewha-mmai/referee 获取。|
|**2025-10-31**|[From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration](http://arxiv.org/abs/2510.27452)|null|科学插图要求兼具高信息密度和后期可编辑性。然而，当前的生成模型存在两个主要局限：首先，图像生成模型输出的是缺乏语义结构的栅格化图像，导致无法访问、编辑或重新排列图像中的独立视觉组件。其次，基于代码的生成方法（如TikZ或SVG）虽然提供了元素级控制，却迫使用户陷入繁琐的“编写-编译-审查”循环，并且缺乏操作的直观性。这两种方法都无法很好地满足科学创作中对效率、直观性和迭代修改的需求。为了弥合这一鸿沟，我们引入了VisPainter，一个基于模型上下文协议构建的科学插图多智能体框架。VisPainter协调管理器（Manager）、设计器（Designer）和工具箱（Toolbox）这三个专用模块，协同生成与标准矢量图形软件兼容的图表。这种模块化、基于角色的设计允许每个元素被明确地表示和操作，实现了真正的元素级控制，并且任何元素都可以在后期添加和修改。为了系统地评估科学插图的质量，我们引入了VisBench，一个具有七维评估指标的基准。它从内容、布局、视觉感知和交互成本这四个方面评估高信息密度科学插图。为此，我们进行了广泛的消融实验，以验证我们架构的合理性以及我们评估方法的可靠性。最后，我们评估了各种视觉语言模型，提出了公平且可信的模型排名，并详细比较了它们各自的能力。此外，我们分离并量化了角色划分、步骤控制和描述对插图质量的影响。|
|**2025-10-30**|[Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark](http://arxiv.org/abs/2510.26802)|null|近期视频生成模型能够生成高保真、时间连贯的视频，表明它们可能编码了大量的世界知识。除了逼真的合成之外，它们还展现出表明具备视觉感知、建模和操作能力的新兴行为。然而，一个重要问题仍然存在：视频模型是否已准备好在具有挑战性的视觉推理场景中充当零样本推理器？在这项工作中，我们进行了一项实证研究以全面调查这个问题，重点关注领先且流行的Veo-3模型。我们评估了它在12个维度上的推理行为，包括空间、几何、物理、时间以及具身逻辑，系统地描述了它的优点和失败模式。为了使这项研究标准化，我们将评估数据整理成MME-CoF，这是一个紧凑的基准，能够对帧链（CoF）推理进行深入而彻底的评估。我们的发现表明，尽管当前视频模型在短期空间连贯性、细粒度基础以及局部一致的动态方面展现出有前景的推理模式，但它们在长期因果推理、严格几何约束以及抽象逻辑方面仍然有限。总的来说，它们尚未能作为独立的零样本推理器可靠地工作，但作为互补的视觉引擎，与专用推理模型结合使用时展现出令人鼓舞的迹象。项目页面：https://video-cof.github.io|
|**2025-10-30**|[OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes](http://arxiv.org/abs/2510.26800)|**[link](https://github.com/HKU-MMLab/OmniX)**|构建3D场景有两种主流方式：程序生成和2D提升。其中，基于全景图的2D提升作为一种有前景的技术脱颖而出，它利用强大的2D生成先验来生成沉浸式、真实且多样化的3D环境。在这项工作中，我们进一步发展了这项技术，以生成可用于基于物理渲染（PBR）、重照明和模拟的图形就绪3D场景。我们的关键见解是改造2D生成模型，使其能够全景感知几何、纹理和PBR材质。与现有强调外观生成而忽略内在属性感知的2D提升方法不同，我们提出了OmniX，一个多功能且统一的框架。OmniX基于轻量级高效的跨模态适配器结构，重用2D生成先验来处理广泛的全景视觉任务，包括全景感知、生成和补全。此外，我们构建了一个大规模合成全景图数据集，其中包含来自多样化室内外场景的高质量多模态全景图。大量实验证明了我们模型在全景视觉感知和图形就绪3D场景生成方面的有效性，为沉浸式和物理真实的虚拟世界生成开辟了新的可能性。|
|**2025-10-30**|[SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting](http://arxiv.org/abs/2510.26796)|null|沉浸式应用需要从普通视频中合成时空4D内容，而无需昂贵的3D监督。现有的视频到4D方法通常依赖于手动标注的相机姿态，这对于真实场景的素材来说既费力又脆弱。最近的“先扭曲后修复”方法通过沿着新的相机轨迹扭曲输入帧并使用修复模型填充缺失区域，从而减轻了对姿态标签的需求，并从不同视角描绘了4D场景。然而，这种“轨迹到轨迹”的公式通常将相机运动与场景动态纠缠在一起，使建模和推理复杂化。我们引入了SEE4D，一个无姿态的“轨迹到相机”框架，它用渲染到一组固定虚拟相机取代了显式轨迹预测，从而将相机控制与场景建模分离。一个视图条件视频修复模型被训练来学习一个鲁棒的几何先验，方法是去噪真实合成的扭曲图像，并修复虚拟视角中被遮挡或缺失的区域，从而消除了对显式3D标注的需求。在此修复核心的基础上，我们设计了一个时空自回归推理管道，该管道遍历虚拟相机样条曲线并使用重叠窗口扩展视频，从而以有界的分步复杂性实现连贯的生成。我们在跨视图视频生成和稀疏重建基准上验证了See4D。在定量指标和定性评估方面，我们的方法相对于姿态或轨迹条件基线实现了卓越的泛化性和改进的性能，推动了从普通视频中进行实用的4D世界建模。|
|**2025-10-30**|[The Quest for Generalizable Motion Generation: Data, Model, and Evaluation](http://arxiv.org/abs/2510.26794)|**[link](https://github.com/oneScotch/ViMoGen)**|尽管3D人体运动生成（MoGen）在标准基准上取得了最新进展，但现有模型在泛化能力方面仍面临根本性瓶颈。相比之下，相邻的生成领域，尤其是视频生成（ViGen），在建模人类行为方面展现出卓越的泛化能力，这凸显了MoGen可以借鉴的可迁移见解。受此观察的启发，我们提出了一个综合框架，系统地将ViGen的知识从数据、建模和评估三个关键支柱转移到MoGen。首先，我们推出了ViMoGen-228K，一个包含228,000个高质量运动样本的大规模数据集，它将高保真光学运动捕捉数据与来自网络视频的语义标注运动以及最先进的ViGen模型生成的合成样本相结合。该数据集包括文本-运动对和文本-视频-运动三元组，极大地扩展了语义多样性。其次，我们提出了ViMoGen，一个基于流匹配的扩散Transformer，通过门控多模态条件化统一了来自运动捕捉数据和ViGen模型的先验知识。为了提高效率，我们进一步开发了ViMoGen-light，一个精炼变体，它消除了视频生成依赖性，同时保持了强大的泛化能力。最后，我们提出了MBench，一个旨在对运动质量、提示忠实度和泛化能力进行细粒度评估的层次化基准。大量实验表明，我们的框架在自动评估和人工评估中都显著优于现有方法。代码、数据和基准将公开发布。|
|**2025-10-30**|[FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design](http://arxiv.org/abs/2510.26688)|null|设计高效量子电路是探索量子计算潜力的核心瓶颈，特别是对于噪声中等规模量子（NISQ）设备，其中电路效率和抗错误能力至关重要。门序列的搜索空间呈组合式增长，而手工设计的模板常常浪费稀缺的量子比特和深度预算。我们引入了FlowQ-Net（基于流的量子设计网络），这是一种基于生成流网络（GFlowNets）的自动化量子电路合成生成式框架。该框架学习一种随机策略来顺序构建电路，根据一个灵活的、用户定义的奖励函数按比例对电路进行采样，该奖励函数可以编码性能、深度和门计数等多个设计目标。这种方法独特地实现了生成多样化的高质量电路集合，超越了单解决方案优化。我们通过大量的仿真证明了FlowQ-Net的有效性。我们将我们的方法应用于变分量子算法（VQA）拟设设计，用于分子基态估计、最大割和图像分类，这些都是近期量子计算中的关键挑战。FlowQ-Net设计的电路取得了显著改进，与常用的酉基线相比，在参数、门和深度方面，所产生的电路紧凑性提高了10-30倍，同时不影响精度。即使在受到真实世界量子设备的误差分布影响时，这一趋势依然成立。我们的结果强调了生成模型作为自动化量子电路设计的通用方法的潜力，为开发更高效的量子算法和加速量子领域的科学发现提供了一条有前景的道路。|
|**2025-10-30**|[Generative sampling with physics-informed kernels](http://arxiv.org/abs/2510.26678)|null|我们构建了一个用于格点场论及其他领域中蒙特卡洛采样的生成网络，其中逐层传播的学习在每一层上独立完成并优化。该架构利用物理信息重整化群流，通过一个给定层的相应重整化群核的简单一阶偏微分方程，提供了从一层到下一层的逐层传播步骤的访问能力。因此，它将生成任务转化为一次性求解变换核的一组独立的线性微分方程。由于这些方程是解析已知的，因此核可以迭代细化。这使得我们能够结构性地解决生成模型中普遍遇到的域外问题，并为进一步优化开辟了道路。我们在标量场论的模拟中阐明了该架构的实际可行性。|
|**2025-10-30**|[ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching](http://arxiv.org/abs/2510.26601)|null|荧光显微镜中的计算超分辨率（CSR）尽管是一个不适定问题，但其历史悠久。其核心在于寻找一种先验，用于外推成像显微镜从未成像过的显微图像中的频率。理所当然地，随着更好的数据驱动机器学习技术的出现，可以学习到更强的先验，从而使CSR带来更好的结果。本文中，我们提出了ResMatching，这是一种新颖的CSR方法，它使用引导条件流匹配来学习这种改进的数据先验。我们在BioSR数据集中对4种不同的生物结构评估了ResMatching，并将其结果与7个基线方法进行比较。ResMatching始终取得具有竞争力的结果，在所有情况下都展示了数据保真度和感知真实感之间的最佳权衡。我们观察到，当难以学习到强先验时，例如当给定的低分辨率图像包含大量噪声时，使用ResMatching的CSR特别有效。此外，我们表明ResMatching可以用于从隐式学习的后验分布中采样，并且该分布对所有测试用例都经过校准，从而使我们的方法能够提供像素级数据不确定性项，可以指导未来的用户拒绝不确定的预测。|
|**2025-10-30**|[Emu3.5: Native Multimodal Models are World Learners](http://arxiv.org/abs/2510.26583)|null|我们引入了Emu3.5，这是一种大规模多模态世界模型，能够原生预测跨视觉和语言的下一状态。Emu3.5在包含超过10万亿词元的视觉-语言交错数据集上，采用统一的下一词元预测目标进行端到端预训练，这些数据主要来源于互联网视频的连续帧和转录文本。该模型自然接受交错的视觉-语言输入并生成交错的视觉-语言输出。Emu3.5通过大规模强化学习进一步后训练，以增强多模态推理和生成能力。为提高推理效率，我们提出了离散扩散适应（DiDA），它将逐词元解码转换为双向并行预测，在不牺牲性能的情况下，将单图像推理速度提高了约20倍。Emu3.5展现出强大的原生多模态能力，包括长周期视觉-语言生成、任意到图像（X2I）生成以及复杂文本丰富图像生成。它还展现出通用的世界建模能力，实现了时空一致的世界探索以及跨越不同场景和任务的开放世界具身操作。相比之下，Emu3.5在图像生成和编辑任务上取得了与Gemini 2.5 Flash Image (Nano Banana)相当的性能，并在一系列交错生成任务上展现出卓越的结果。我们已在https://github.com/baaivision/Emu3.5开源Emu3.5以支持社区研究。|
|**2025-10-30**|[Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters](http://arxiv.org/abs/2510.26501)|null|通过可穿戴设备进行的连续心电图 (ECG) 监测为早期心血管疾病 (CVD) 检测提供了巨大潜力。然而，在资源受限环境中部署深度学习模型进行自动化分析时，由于不可避免的分布外 (OOD) 数据，面临可靠性挑战。OOD 输入，例如未曾见过的病理或受噪声干扰的信号，通常会导致标准分类器产生错误的高置信度预测，从而损害患者安全。现有的 OOD 检测方法要么忽视计算限制，要么分别处理噪声和未见过类别。本文探索了无监督异常检测 (UAD) 作为一种独立的上游过滤机制来提高鲁棒性。我们基准测试了六种 UAD 方法，包括 Deep SVDD、基于重建的模型、掩码异常检测、归一化流和扩散模型，这些方法在严格的资源限制（最多 512k 参数）下通过神经架构搜索 (NAS) 进行了优化。在 PTB-XL 和 BUT QDB 数据集上的评估旨在检测 OOD CVD 类别以及因噪声而不适合分析的信号。结果表明，Deep SVDD 在检测和效率之间始终取得了最佳权衡。在一次真实的部署模拟中，将优化后的 Deep SVDD 滤波器与诊断分类器集成，相比于仅使用分类器的基线，准确率提高了多达 21 个百分点。本研究表明，优化后的 UAD 滤波器能够保障自动化心电图分析，从而实现可穿戴设备上更安全、更可靠的连续心血管监测。|
|**2025-10-30**|[Quantum Gated Recurrent GAN with Gaussian Uncertainty for Network Anomaly Detection](http://arxiv.org/abs/2510.26487)|null|时间序列数据中的异常检测是一个关键挑战，对网络安全具有重要影响。近期的量子机器学习方法，例如量子核方法和变分量子电路，在捕获复杂数据分布以进行异常检测方面已展现出潜力，但仍受限于有限的量子比特数量。本文介绍了一种新颖的基于量子门控循环单元（QGRU）的生成对抗网络（GAN），该网络采用连续数据注入（SuDaI）和多指标门控策略，以实现鲁棒的网络异常检测。我们的模型独特地利用了一个量子增强型生成器，该生成器通过重参数化输出高斯分布的参数（均值和对数方差），并结合Wasserstein判别器来稳定对抗训练。异常通过一种新颖的门控机制识别：该机制首先基于高斯不确定性估计标记潜在异常，然后使用判别器分数和重构误差的组合对其进行验证。在基准数据集上评估，我们的方法达到了89.43%的高时间序列感知F1分数（TaF1），与现有经典和量子模型相比，展现出准确及时检测异常的卓越能力。此外，经过训练的QGRU-WGAN被部署在真实的IBM量子硬件上，并保持了高异常检测性能，证实了其在当前噪声中等规模量子（NISQ）设备上的鲁棒性和实际可行性。|
|**2025-10-28**|[Generative View Stitching](http://arxiv.org/abs/2510.24718)|**[link](https://github.com/andrewsonga/generative_view_stitching)**|自回归视频扩散模型能够生成稳定且与历史一致的长序列，但它们无法通过未来条件来指导当前生成。在具有预定义相机轨迹的相机引导视频生成中，这种局限性会导致与生成场景发生碰撞，之后自回归模型迅速崩溃。为了解决这个问题，我们提出了生成式视图拼接（GVS），它并行采样整个序列，从而使生成的场景与预定义相机轨迹的每个部分都保持一致。我们的主要贡献是一种采样算法，该算法将机器人规划中扩散拼接的现有工作扩展到视频生成。虽然这种拼接方法通常需要专门训练的模型，但GVS与任何通过扩散强制（Diffusion Forcing）训练的现成视频模型兼容，我们证明扩散强制这一流行的序列扩散框架已经提供了拼接所需的先决条件。我们随后引入了全方位引导（Omni Guidance），这是一种通过同时以过去和未来为条件来增强拼接中时间一致性的技术，并使我们提出的闭环机制能够实现长程连贯性。总之，GVS实现了稳定、无碰撞、帧间一致的相机引导视频生成，并能为各种预定义的相机路径实现闭环，包括奥斯卡·路透斯沃德的“不可能的楼梯”。结果最好以视频形式查看，网址为https://andrewsonga.github.io/gvs。|
|**2025-10-28**|[Uniform Discrete Diffusion with Metric Path for Video Generation](http://arxiv.org/abs/2510.24717)|**[link](https://github.com/baaivision/URSA)**|连续空间视频生成取得了快速进展，而离散方法由于误差累积和长上下文不一致性而落后。在这项工作中，我们重新审视离散生成建模，并提出了Uniform discRete diffuSion with metric pAth (URSA)，这是一个简单而强大的框架，它弥补了与连续方法在可扩展视频生成方面的差距。URSA 的核心在于，它将视频生成任务表述为离散时空令牌的迭代全局细化。它整合了两个关键设计：线性化度量路径和分辨率依赖的时间步长偏移机制。这些设计使URSA能够高效地扩展到高分辨率图像合成和长持续时间视频生成，同时需要显著更少的推理步数。此外，我们引入了一种异步时间微调策略，该策略在单个模型中统一了多功能任务，包括插值和图像到视频生成。在具有挑战性的视频和图像生成基准上的大量实验表明URSA始终优于现有离散方法，并达到了与最先进的连续扩散方法相媲美的性能。代码和模型可在https://github.com/baaivision/URSA获取。|
|**2025-10-28**|[Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder](http://arxiv.org/abs/2510.24671)|null|随着智能驾驶功能日益集成到量产车辆中，确保其功能性和鲁棒性带来了更大的挑战。与传统道路测试相比，基于场景的虚拟测试在时间成本效率、可复现性和边缘案例探索方面具有显著优势。我们提出了一种Transformer增强条件变分自编码器（CVAE-T）模型，用于生成环岛中的多智能体交通场景，这类场景的特点是车辆动态性高、布局复杂，但在当前研究中相对探索不足。结果表明，所提出的模型能够准确重构原始场景，并生成真实、多样化的合成场景。此外，采用了两个关键性能指标（KPIs）来评估生成场景中的交互行为。对潜在空间的分析揭示了部分解耦，其中几个潜在维度对诸如车辆进入时间、驶离时间以及速度曲线等场景属性表现出独特且可解释的影响。结果证明了该模型能够生成涉及多智能体交互的智能驾驶功能验证场景，并为其开发和迭代改进提供数据增强。|
|**2025-10-28**|[A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries](http://arxiv.org/abs/2510.24640)|null|生成式人工智能的快速发展使得高度逼真的伪造面部图像得以创建，对人工智能安全、数字媒体完整性和公众信任构成了重大威胁。面部伪造技术，从换脸和属性编辑到强大的基于扩散模型的图像合成，正越来越多地被用于错误信息、身份欺诈和诽谤等恶意目的。这一日益严峻的挑战强调了对鲁棒且通用的面部伪造检测方法的迫切需求，将其作为人工智能安全基础设施的关键组成部分。在这项工作中，我们提出了一种新颖的双分支卷积神经网络用于面部伪造检测，该网络利用来自空间域和频率域的互补线索。RGB分支捕获语义信息，而频率分支则侧重于生成模型难以抑制的高频伪影。引入了一个通道注意力模块以自适应地融合这些异构特征，突出最有信息量的通道用于伪造判别。为了指导网络的学习过程，我们设计了一个统一的损失函数FSC损失，它结合了焦点损失、有监督对比损失和频率中心边际损失，以增强类别可分离性和鲁棒性。我们在DiFF基准数据集上评估了我们的模型，该数据集包含由四种代表性方法生成的伪造图像：文本到图像、图像到图像、换脸和面部编辑。我们的方法在所有类别中都取得了优异的性能，并且超越了人类平均准确率。这些结果表明了模型的有效性及其在保护人工智能生态系统免受视觉伪造攻击方面的潜在贡献。|
|**2025-10-28**|[Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures](http://arxiv.org/abs/2510.24614)|null|健康指标（HIs）对于诊断和预测航空航天复合结构的状况至关重要，从而实现高效维护和运行安全。然而，由于材料特性变异性、随机损伤演化和多样化的损伤模式，提取可靠的HIs仍然具有挑战性。制造缺陷（例如脱粘）和在役事故（例如鸟击）进一步使这一过程复杂化。本研究提出了一个全面的数据驱动框架，该框架通过两种结合多域信号处理的学习方法来学习HIs。由于真实HIs不可用，因此提出了两种方法：(i) 一种多样性深度半监督异常检测（Diversity-DeepSAD）方法，该方法通过用作假设损伤代理的连续辅助标签进行增强，克服了先前二元标签仅区分健康和故障状态而忽略中间退化的局限性；以及 (ii) 一种退化趋势约束变分自编码器（DTC-VAE），其中通过显式趋势约束嵌入了单调性准则。具有多个激励频率的导波用于监测疲劳载荷下的单加筋复合结构。对时域、频域和时频域表示进行了探索，并通过无监督集成学习融合了每频率HIs，以减轻频率依赖性并降低方差。使用快速傅里叶变换特征，增强型Diversity-DeepSAD模型达到了81.6%的性能，而DTC-VAE提供了最一致的HIs，性能达到92.3%，优于现有基线。|
|**2025-10-28**|[Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way](http://arxiv.org/abs/2510.24605)|null|基于扩散的大语言模型（dLLM）在并行文本生成方面展现出巨大潜力，与自回归模型相比，这可能实现更高效的生成。然而，当前的dLLM存在固定生成长度的问题，这意味着dLLM的生成长度必须在解码前作为超参数确定，从而导致效率和灵活性方面的挑战。为了解决这些问题，在这项工作中，我们提出训练一种具有原生可变生成长度的扩散大语言模型，简称dLLM-Var。具体而言，我们旨在训练一个模型来准确预测生成文本中的[EOS]标记，这使得dLLM能够以块扩散方式原生推理，同时仍能保持全局双向（完全）注意力和高并行性的能力。在标准基准上的实验表明，我们的方法比传统的dLLM推理范式实现了30.1倍的加速，并且相对于Qwen和Llama等自回归模型实现了2.4倍的加速。我们的方法实现了更高的准确性和更快的推理速度，将dLLM从单纯的学术新颖性提升，并支持其在实际应用中的实用性。代码和模型已发布。|
|**2025-10-28**|[A Novel XAI-Enhanced Quantum Adversarial Networks for Velocity Dispersion Modeling in MaNGA Galaxies](http://arxiv.org/abs/2510.24598)|null|当前的量子机器学习方法在平衡预测准确性、鲁棒性和可解释性方面常面临挑战。为解决此问题，我们提出一种新颖的量子对抗框架，该框架将混合量子神经网络（QNN）与经典深度学习层相结合，由一个具有基于LIME可解释性的评估器模型引导，并通过量子GAN和自监督变体进行扩展。在所提出的模型中，一个对抗性评估器通过计算反馈损失同时引导QNN，从而优化预测准确性和模型可解释性。经验评估表明，Vanilla模型实现了RMSE = 0.27，MSE = 0.071，MAE = 0.21和R^2 = 0.59，与对抗性对应模型相比，在回归指标上提供了最一致的性能。这些结果证明了结合量子启发方法与经典架构开发轻量级、高性能和可解释的预测模型的潜力，从而将QML的适用性推向超越当前限制。|
|**2025-10-28**|[Leveraging Scale Separation and Stochastic Closure for Data-Driven Prediction of Chaotic Dynamics](http://arxiv.org/abs/2510.24583)|null|模拟湍流的计算量非常大，因为它需要解析精细尺度结构并捕获跨多个尺度的复杂非线性相互作用。对于应用于真实世界湍流问题的直接数值模拟尤其如此。因此，许多研究都集中于从数据驱动的角度分析湍流。然而，由于这些系统复杂且混沌，传统模型往往会随着时间积累误差而变得不稳定，即使在短期预测中也会导致显著退化。为了解决这些局限性，我们提出了一种纯随机方法，该方法分别对大尺度相干结构的演化和高保真统计数据的闭合进行建模。具体而言，代表相干运动的滤波数据的动力学是使用结合了变分自编码器和Transformer架构的自回归模型学习的。VAE投影是概率性的，确保了模型随机性与流体统计特性之间的一致性。与测试集相比，我们模型中随机采样轨迹的平均实现分别显示出6%和10%的相对误差。此外，我们的框架允许构建有意义的置信区间，以最小的区间宽度实现了80%的预测区间覆盖概率。为了从滤波隐空间中恢复高保真速度场，我们采用了高斯过程回归。该策略已在柯尔莫哥洛夫流上进行了测试，该流展现出与真实世界湍流相似的混沌行为。|
|**2025-10-28**|[Toward a Physical Interpretation of Phase Field Models with Dynamic Boundary Conditions](http://arxiv.org/abs/2510.24566)|null|在最近几十年中，大量研究致力于具有动态边界条件的偏微分方程（PDEs）。然而，所涉及参数的物理释义往往不明确，这反过来限制了理论分析和数值计算。例如，在具有动态边界条件的热力学一致模型中使用的Robin边界条件，曾被误解为代表化学反应，或在许多工作中被不合理地推广。在本文中，我们将体相和表面视为一个封闭系统，并开发热力学一致的相场模型，以阐明控制方程和边界条件中参数的物理含义，特别关注通过将其与纳米热力学联系起来，揭示体相和表面之间的物质和能量交换。首先，我们从封闭系统中的质量和体积守恒定律开始，阐明了Robin边界条件的物理释义，证明了相关参数与系统的特征长度尺度相关，并在物质和能量交换中起着关键作用。此外，我们的分析证明了体相中的相变量与表面上的相变量不同的物理必要性。其次，我们使用广义Onsager原理构建了四个更通用的模型，能够描述不可逆过程和不可逆-可逆耦合过程。第三，我们揭示了守恒定律和耗散定律同时决定了迁移率算子和自由能，它们是两个对偶变量。最后，我们进行结构保持的数值模拟，系统地研究了可逆过程和特征长度如何影响图案形成。|
|**2025-10-28**|[Unbiased likelihood estimation of the Langevin diffusion for animal movement modelling](http://arxiv.org/abs/2510.24539)|null|资源选择函数提供了一种描述栖息地适宜性的模型，可用于预测物种的空间利用分布。追踪数据可以建模为点过程，但时间不规则自相关的存在使其复杂化。解决此问题的一种提议模型是连续时间朗之万扩散。然而，随着观测间隔的增加，当前的估计技术会得到越来越有偏的参数估计。在本文中，我们通过在重要性采样方案中使用布朗桥来改进朗之万扩散模型的似然近似，从而解决了这个问题。我们通过一系列仿真研究表明，这种方法在许多场景中能有效消除偏差。此外，我们发现该模型在较低采样率、较长持续时间下的表现，实际上优于较高采样频率、较短持续时间下的表现。这项研究拓宽了朗之万扩散模型在较粗分辨率遥测数据上的适用性。|
|**2025-10-23**|[LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas](http://arxiv.org/abs/2510.20820)|null|尽管现有个性化生成模型具有令人印象深刻的视觉保真度，但它们缺乏对空间构图的交互式控制，并且在处理多个主体时扩展性差。为了解决这些局限性，我们提出了LayerComposer，一个用于个性化、多主体文本到图像生成的交互式框架。我们的方法引入了两项主要贡献：(1) 分层画布，这是一种新颖的表示方法，其中每个主体都被放置在独立的层上，从而实现无遮挡构图；(2) 锁定机制，它能够高保真地保留选定层，同时允许其余层灵活适应周围环境。类似于专业的图像编辑软件，所提出的分层画布允许用户通过直观的图层操作来放置、调整大小或锁定输入主体。我们通用的锁定机制不需要架构上的改变，而是依赖于固有的位置编码，并结合了一种新的互补数据采样策略。大量实验表明，与多主体个性化图像生成领域中最先进的方法相比，LayerComposer实现了卓越的空间控制和身份保持。|
|**2025-10-23**|[Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge](http://arxiv.org/abs/2510.20819)|null|生成式建模的最新进展已将扩散模型定位为从复杂数据分布中采样的最先进工具。尽管这些模型在图像和音频等单模态领域取得了显著成功，但将其能力扩展到模态转换（MT）——即在不同感官模态之间转换信息——仍然是一个开放性挑战。现有方法通常依赖于限制性假设，包括共享维度、高斯源先验和模态特定架构，这限制了它们的通用性和理论基础。在这项工作中，我们提出了潜在去噪扩散桥模型（LDDBM），这是一个基于去噪扩散桥模型的潜在变量扩展的通用模态转换框架。通过在共享潜在空间中操作，我们的方法学习了任意模态之间的桥梁，而无需对齐维度。我们引入了一种对比对齐损失来强制配对样本之间的语义一致性，并设计了一种领域无关的编码器-解码器架构，专为潜在空间中的噪声预测而设计。此外，我们提出了一种预测损失来指导训练实现准确的跨领域转换，并探索了多种训练策略以提高稳定性。我们的方法支持任意模态对，并在各种MT任务上表现出色，包括多视图到3D形状生成、图像超分辨率和多视图场景合成。全面的实验和消融研究验证了我们框架的有效性，为通用模态转换建立了新的强大基线。更多信息请参阅我们的项目页面：https://sites.google.com/view/lddbm/home。|
|**2025-10-23**|[Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers](http://arxiv.org/abs/2510.20807)|null|受自回归大型语言模型 (LLM) 的性能和可扩展性启发，基于 Transformer 的模型近期在视觉领域取得了成功。本研究探讨了 Transformer 模型在视频预测中的适配，采用简单的端到端方法，并比较了各种时空自注意力布局。鉴于因果建模在随时间变化的物理模拟中是现有视频生成方法的常见不足，我们侧重于此，并尝试通过物理对象跟踪指标和在物理模拟数据集上的无监督训练来分离时空推理。我们引入了一种简单而有效的纯 Transformer 模型用于自回归视频预测，该模型利用连续像素空间表示进行视频预测。我们的方法无需复杂的训练策略或潜在特征学习组件，与现有潜在空间方法相比，将物理精确预测的时间跨度显著延长了高达 50%，同时在常见视频质量指标上保持了可比的性能。此外，我们通过探测模型进行了可解释性实验，以识别编码了有助于准确估计偏微分方程 (PDE) 模拟参数的网络区域，并发现这可以推广到分布外模拟参数的估计。这项工作为通过一种简单、参数高效且可解释的方法，进一步基于注意力的视频时空建模提供了一个平台。|
|**2025-10-23**|[ARGenSeg: Image Segmentation with Autoregressive Image Generation Model](http://arxiv.org/abs/2510.20803)|null|我们提出了一种新颖的基于自回归生成范式的图像分割方法（ARGenSeg），在统一框架内实现了多模态理解和像素级感知。先前将图像分割集成到多模态大语言模型（MLLM）中的工作通常采用边界点表示或专用分割头。这些方法依赖于离散表示或输入到任务特定解码器的语义提示，这限制了MLLM捕获细粒度视觉细节的能力。为了解决这些挑战，我们引入了一种基于图像生成的面向MLLM的分割框架，该框架能自然地为目标对象生成密集掩码。我们利用MLLM输出视觉token，并使用通用VQ-VAE将它们反token化为图像，使分割完全依赖于MLLM的像素级理解。为了降低推理延迟，我们采用了一种下一尺度预测策略来并行生成所需的视觉token。大量实验表明，我们的方法在多个分割数据集上超越了先前的最先进方法，显著提升了推理速度，同时保持了强大的理解能力。|
|**2025-10-23**|[BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation](http://arxiv.org/abs/2510.20792)|null|图生成的快速进展引发了新的安全担忧，尤其是在后门漏洞方面。尽管先前的工作已经探索了图像扩散和无条件图生成中的后门攻击，但条件式，特别是文本引导的图生成仍然很大程度上未经研究。本文提出了BadGraph，一种针对文本引导图生成的潜在扩散模型的后门攻击方法。BadGraph利用文本触发器来污染训练数据，隐蔽地植入后门，这些后门在推理时当触发器出现时会诱导攻击者指定的子图，同时在干净输入上保持正常性能。在四个基准数据集（PubChem、ChEBI-20、PCDes、MoMu）上进行的大量实验证明了该攻击的有效性和隐蔽性：不到10%的投毒率即可达到50%的攻击成功率，而24%的投毒率足以实现超过80%的成功率，且对良性样本的性能退化可忽略不计。消融研究进一步揭示，后门是在VAE和扩散训练期间植入的，而非预训练期间。这些发现揭示了文本引导图生成的潜在扩散模型中的安全漏洞，强调了在药物发现等模型应用中存在的严重风险，并强调了在此类扩散模型中需要针对后门攻击的鲁棒防御措施。|
|**2025-10-23**|[CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image](http://arxiv.org/abs/2510.20776)|null|本文提出一种名为Cupid的基于生成的新型三维重建方法，能够从单一二维图像中准确推断物体的相机姿态、三维形状和纹理。Cupid将三维重建视为从学习到的三维物体分布中进行条件采样，并联合生成体素和像素-体素对应关系，从而在统一的生成框架下实现鲁棒的姿态和形状估计。通过将输入相机姿态和三维形状都表示为共享三维潜在空间中的分布，Cupid采用两阶段流匹配流程：(1) 粗略阶段，生成初始三维几何形状及相关的二维投影以用于姿态恢复；(2) 精细化阶段，整合姿态对齐的图像特征以增强结构保真度和外观细节。大量实验表明，Cupid超越了领先的三维重建方法，实现了超过3 dB的PSNR增益和超过10%的倒角距离（Chamfer Distance）降低，同时在姿态精度上与单目估计器相匹配，并且相对于基线三维生成模型提供了卓越的视觉保真度。如需沉浸式查看Cupid生成的三维结果，请访问cupid3d.github.io。|
|**2025-10-23**|[AlphaFlow: Understanding and Improving MeanFlow Models](http://arxiv.org/abs/2510.20771)|**[link](https://github.com/snap-research/alphaflow)**|MeanFlow最近作为一个强大的少步生成建模框架从头开始训练而出现，但其成功尚未完全理解。在这项工作中，我们表明MeanFlow目标函数自然地分解为两部分：轨迹流匹配和轨迹一致性。通过梯度分析，我们发现这些项之间存在强负相关，导致优化冲突和收敛缓慢。受这些发现的启发，我们引入了 $\alpha$-Flow，这是一系列广泛的目标函数，它将轨迹流匹配、Shortcut Model和MeanFlow统一在一个公式下。通过采用一种从轨迹流匹配平滑退火到MeanFlow的课程学习策略，$\alpha$-Flow解耦了冲突的目标函数，并实现了更好的收敛性。当使用经典DiT骨干网络在类别条件ImageNet-1K 256x256数据集上从头开始训练时，$\alpha$-Flow在不同尺度和设置下持续优于MeanFlow。我们最大的$\alpha$ -Flow-XL/2+模型使用经典DiT骨干网络取得了新的最先进结果，FID分数分别为2.58 (1-NFE)和2.15 (2-NFE)。|
|**2025-10-23**|[DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion](http://arxiv.org/abs/2510.20766)|**[link](https://github.com/guyyariv/DyPE)**|扩散Transformer模型能够生成具有卓越保真度和细节的图像，然而，由于自注意力机制的计算成本随图像tokens数量呈二次方增长，在超高分辨率下训练它们仍然极其昂贵。在本文中，我们引入了动态位置外推（DyPE），这是一种新颖的免训练方法，能够使预训练的扩散Transformer在远超其训练数据的分辨率下合成图像，且无需额外的采样成本。DyPE利用了扩散过程中固有的频谱演进，其中低频结构早期收敛，而高频信息需要更多步才能解析。具体来说，DyPE在每个扩散步骤动态调整模型的位置编码，使其频率频谱与生成过程的当前阶段相匹配。这种方法使我们能够生成分辨率远超训练分辨率的图像，例如，使用FLUX生成1600万像素的图像。在多个基准测试中，DyPE持续提升了性能，并在超高分辨率图像生成中实现了最先进的保真度，且在更高分辨率下增益更加显著。项目页面可在https://noamissachar.github.io/DyPE/获取。|
|**2025-10-23**|[AutoScape: Geometry-Consistent Long-Horizon Scene Generation](http://arxiv.org/abs/2510.20726)|null|本文提出AutoScape，一个长时序驾驶场景生成框架。其核心是一个新颖的RGB-D扩散模型，它迭代生成稀疏的、几何一致的关键帧，作为场景外观和几何的可靠锚点。为了保持长距离几何一致性，模型1) 在共享的潜在空间中联合处理图像和深度，2) 明确地以先前生成的关键帧的现有场景几何（即渲染点云）为条件，3) 并通过一个形变一致性引导来引导采样过程。鉴于高质量的RGB-D关键帧，一个视频扩散模型随后在它们之间进行插值，以生成密集且连贯的视频帧。AutoScape生成了超过20秒的真实且几何一致的驾驶视频，使长时序FID和FVD分数分别比现有最先进技术提高了48.6%和43.0%。|
|**2025-10-23**|[Separating the what and how of compositional computation to enable reuse and continual learning](http://arxiv.org/abs/2510.20709)|null|持续学习、保留并运用技能以实现目标的能力是智能和高效行为的关键特征。然而，促进技能持续学习和灵活（重）组合的神经机制仍然难以捉摸。在本文中，我们采用一种新颖的双系统方法研究循环神经网络（RNN）模型中的持续学习和已学习计算的组合式重用：一个系统推断要执行的计算（“是什么”），另一个系统实现如何执行计算（“怎么做”）。我们专注于神经科学中常被研究的一组组合式认知任务。为了构建“是什么”系统，我们首先展示了大量任务可以通过概率生成模型系统地描述，其中组合性源于离散任务阶段的共享底层词汇表。共享的阶段结构使得这些任务本质上是组合式的。我们首先展示了这种组合性可以通过概率生成模型系统地描述。此外，我们开发了一种无监督在线学习方法，该方法可以在单次试验的基础上学习此模型，在接触新任务时逐步构建其词汇表，并在一次试验中将潜在阶段结构推断为时变计算上下文。我们将“怎么做”系统实现为一个RNN，其低秩分量根据“是什么”系统推断出的上下文进行组合。上下文推断促进了低秩RNN分量的创建、学习和重用，因为新任务是按顺序引入的，从而实现了持续学习而不会发生灾难性遗忘。使用一个示例任务集，我们展示了这种双系统学习框架的有效性和竞争性性能，其正向和反向迁移的潜力，以及对未见任务的快速组合泛化能力。|
|**2025-10-21**|[DP $^2$O-SR: Direct Perceptual Preference Optimization for Real-World Image Super-Resolution](http://arxiv.org/abs/2510.18851)|null|得益于预训练文本到图像 (T2I) 扩散模型，真实世界图像超分辨率 (Real-ISR) 方法能够合成丰富逼真的细节。然而，由于T2I模型固有的随机性，不同的噪声输入经常导致输出的感知质量各不相同。尽管这种随机性有时被视为一种局限，但它也引入了更宽泛的感知质量范围，可以被利用来提升Real-ISR性能。为此，我们引入了用于真实世界图像超分辨率的直接感知偏好优化 (DP$^2$O-SR)，这是一个无需昂贵的人工标注即可将生成模型与感知偏好对齐的框架。我们通过结合在大型人类偏好数据集上训练的全参考和无参考图像质量评估 (IQA) 模型，构建了一个混合奖励信号。这种奖励鼓励结构保真度和自然外观。为了更好地利用感知多样性，我们超越了标准的“最佳对最差”选择，并从同一模型的输出中构建了多个偏好对。我们的分析表明，最佳选择比例取决于模型容量：较小模型受益于更广泛的覆盖，而较大模型对监督中更强的对比度反应更佳。此外，我们提出了分层偏好优化，它根据组内奖励差距和组间多样性自适应地加权训练对，从而实现更高效和稳定的学习。在基于扩散和基于流的T2I骨干网络上的广泛实验证明，DP$^2$ O-SR显著提升了感知质量，并能很好地泛化到真实世界基准测试中。|
|**2025-10-21**|[Protein generation with embedding learning for motif diversification](http://arxiv.org/abs/2510.18790)|null|蛋白质设计的一个根本挑战在于在生成结构多样性与保留基序生物学功能之间取得平衡。当前最先进的方法，例如RFdiffusion中的部分扩散，往往无法解决这种权衡：小扰动产生的基序与天然结构几乎相同，而大扰动则会违反生物学功能所需的几何约束。我们引入了基于嵌入学习的蛋白质生成（PGEL），这是一个通用框架，它在扩散模型冻结去噪器的表示空间中学习编码目标基序序列和结构特征的高维嵌入，然后通过在嵌入空间中引入受控扰动来增强基序多样性。因此，PGEL能够在满足典型设计指标的同时放松几何约束，从而产生更多样化但可行的结构。我们在三个代表性案例中展示了PGEL：一个单体、一个蛋白质-蛋白质界面和一个癌症相关的转录因子复合物。与部分扩散相比，在所有案例中，PGEL都实现了更大的结构多样性、更好的可设计性和改进的自洽性。我们的结果确立了PGEL作为一种通用的嵌入驱动蛋白质生成策略，能够实现功能基序的系统性、可行多样化。|
|**2025-10-21**|[A Frequentist Statistical Introduction to Variational Inference, Autoencoders, and Diffusion Models](http://arxiv.org/abs/2510.18777)|null|尽管变分推断（VI）是变分自编码器（VAEs）和去噪扩散模型（DDMs）等现代生成模型的核心，但其教学方法在不同学科中存在分歧。在统计学中，VI通常被视为一种用于后验近似的贝叶斯方法。然而，在机器学习中，VAEs和DDMs是从频率学派观点发展而来的，其中VI用于近似最大似然估计器。这为统计学家造成了障碍，因为如果没有相应的频率学派对VI的介绍，VAEs和DDMs背后的原理就难以理解其背景。本文提供了这种介绍：我们从经典的期望最大化（EM）算法开始，纯粹从频率学派观点解释了VI、VAEs和DDMs的理论。我们展示了VI如何作为不可行E步的可扩展解决方案而出现，以及VAEs和DDMs如何成为该框架的自然、基于深度学习的扩展，从而弥合了经典统计推断与现代生成式人工智能之间的鸿沟。|
|**2025-10-21**|[UltraGen: High-Resolution Video Generation with Hierarchical Attention](http://arxiv.org/abs/2510.18775)|null|视频生成领域的最新进展使得生成具有视觉吸引力的视频成为可能，在内容创作、娱乐和虚拟现实等领域具有广泛应用。然而，大多数现有的基于扩散Transformer的视频生成模型由于注意力机制随着输出宽度和高度呈二次方的计算复杂度，仅限于低分辨率输出（<=720P）。这种计算瓶颈使得原生高分辨率视频生成（1080P/2K/4K）在训练和推理时均不切实际。为了解决这一挑战，我们提出了UltraGen，一个新颖的视频生成框架，实现了i)高效和ii)端到端的原生高分辨率视频合成。具体而言，UltraGen采用一种基于全局-局部注意力分解的分层双分支注意力架构，将完整注意力解耦为用于高保真区域内容的局部注意力分支和用于整体语义一致性的全局注意力分支。我们进一步提出一种空间压缩的全局建模策略以高效学习全局依赖，以及一种分层跨窗口局部注意力机制以降低计算成本同时增强不同局部窗口之间的信息流。大量实验表明，UltraGen能够首次有效地将预训练的低分辨率视频模型扩展到1080P甚至4K分辨率，在定性和定量评估中均优于现有的最先进方法以及基于超分辨率的两阶段流水线。|
|**2025-10-21**|[Improving the Generation and Evaluation of Synthetic Data for Downstream Medical Causal Inference](http://arxiv.org/abs/2510.18768)|null|因果推断对于开发和评估医疗干预措施至关重要，然而真实世界的医疗数据集由于监管障碍通常难以访问。这使得合成数据成为一个潜在的有价值的资产，能够支持这些医学分析以及新推断方法本身的开发。生成模型可以生成与真实数据分布高度近似的合成数据，然而现有方法没有考虑到下游因果推断任务，特别是那些关注治疗的任务所带来的独特挑战。我们建立了一组理想特性，包含治疗的合成数据应满足这些特性以最大化下游效用：保留 (i) 协变量分布，(ii) 治疗分配机制，和 (iii) 结果生成机制。基于这些理想特性，我们提出了一组评估指标用于评估此类合成数据。最后，我们提出了STEAM：一种新颖的医学治疗效果分析合成数据生成方法，该方法模仿了包含治疗数据的数据生成过程并针对我们的理想特性进行优化。我们通过实验证明，与现有生成模型相比，STEAM在我们的各项指标上实现了最先进的性能，特别是在真实数据生成过程的复杂性增加时。|
|**2025-10-21**|[Diffusion Buffer for Online Generative Speech Enhancement](http://arxiv.org/abs/2510.18744)|null|在线语音增强主要用于预测模型。这些模型的一个关键优势是，对于来自数据流的输入信号帧，模型只需调用一次即可进行增强。相比之下，生成式语音增强模型通常需要多次调用，导致计算复杂度过高，不适用于许多在线语音增强应用。本文提出了扩散缓冲区（Diffusion Buffer），这是一种基于生成扩散的语音增强模型，它对来自数据流的每个输入信号帧只需一次神经网络调用，并在消费级GPU上以在线方式执行增强。扩散缓冲区的核心思想是将物理时间与扩散时间步对齐。该方法通过物理时间逐步去噪帧，其中过去的帧被去除的噪声更多。因此，增强帧以由扩散缓冲区定义的延迟输出给听者，并且输出帧具有相应的超前量。在这项工作中，我们在之前工作的基础上，精心设计了一种2D卷积UNet架构，该架构特别与扩散缓冲区的超前量对齐。我们观察到，所提出的UNet提高了性能，尤其是在算法延迟较低时。此外，我们表明使用数据预测损失而不是去噪得分匹配损失，能够在推理期间灵活控制算法延迟和质量之间的权衡。配备了新颖神经网络和损失函数的扩展扩散缓冲区，将算法延迟从320 - 960毫秒大幅降低到32 - 176毫秒，同时性能甚至有所提升。尽管此前已经表明离线生成扩散模型在未见过的噪声语音数据上优于预测方法，但我们证实在线扩散缓冲区在未见过的噪声语音数据上也优于其预测对应模型。|
|**2025-10-21**|[SSD: Spatial-Semantic Head Decoupling for Efficient Autoregressive Image Generation](http://arxiv.org/abs/2510.18716)|null|例如Janus-Pro等自回归图像生成模型能生成高质量图像，但由于视觉token数量庞大，其代价是高内存占用和不断增长的计算需求。尽管KV缓存压缩在语言建模中已被广泛研究，但对于图像生成领域，它在很大程度上仍未被探索。在这项工作中，我们首先识别出一种独特而显著的注意力现象，我们将其命名为空间局部性和涌现语义汇聚。为了利用这一关键发现，我们提出了一种新颖的KV缓存压缩框架。具体来说，我们通过自适应地将注意力头解耦成两种类型来压缩所有视觉token的KV缓存：对于空间局部性头，我们的方法维护一个短期的最近token窗口；对于语义汇聚头，它策略性地保留一组紧凑的高关注度token。我们的大量实验表明，所提出的方法在仅带来极小视觉质量损失的情况下，实现了内存使用量减少5倍和整体吞吐量显著提升6.6倍，从而在资源受限的硬件上实现了高效的原生自回归图像生成。|
|**2025-10-21**|[MoGA: Mixture-of-Groups Attention for End-to-End Long Video Generation](http://arxiv.org/abs/2510.18692)|null|使用扩散Transformer (DiT) 进行长视频生成，其瓶颈在于全注意力机制随序列长度呈二次方扩展。由于注意力高度冗余，输出主要由一小部分查询-键对决定。现有稀疏方法依赖于块级粗略估计，其准确性-效率权衡受限于块大小。本文引入了组混合注意力 (MoGA)，这是一种高效的稀疏注意力机制，它使用轻量级、可学习的token路由器来精确匹配token，而无需进行块级估计。通过语义感知路由，MoGA实现了有效的长程交互。作为一种无核方法，MoGA与包括FlashAttention和序列并行在内的现代注意力堆栈无缝集成。基于MoGA，我们开发了一个高效的长视频生成模型，能够端到端地生成分钟级、多镜头、480p分辨率、24帧/秒的视频，其上下文长度约为58万。在各种视频生成任务上的全面实验验证了我们方法的有效性。|
|**2025-10-21**|[Hydrogen redistribution in Zr-base cladding under gradients in temperature and stress](http://arxiv.org/abs/2510.18685)|null|这里使用计算模型来模拟轻水反应堆运行期间锆基核燃料包壳吸收的氢的扩散控制再分布。氢的轴向局部化导致氢化锆在靠近芯块间隙的低温区域局部析出，这一现象通过定制模型进行研究；而径向扩散导致在水侧氧化层下方形成富氢环，这一现象通过更通用模型进行研究。将计算结果与实验观测结果以及文献中报道的类似计算研究进行了比较。结果强调了氢再分布对于包壳管局部脆化的重要性。|
|**2025-10-21**|[ε-Seg: Sparsely Supervised Semantic Segmentation of Microscopy Data](http://arxiv.org/abs/2510.18637)|null|生物样本电子显微镜（EM）图像的语义分割在生命科学领域仍然是一个挑战。EM数据捕捉生物结构的细节，有时其复杂性甚至令人类观察者也感到难以应对。我们介绍了一种名为{\epsilon}-Seg的方法，它基于分层变分自编码器（HVAE），并采用了中心区域掩蔽、稀疏标签对比学习（CL）、高斯混合模型（GMM）先验以及免聚类标签预测。中心区域掩蔽和图像修复损失促使模型学习鲁棒且具有代表性的嵌入，以便区分所需类别，即使训练标签稀疏（占总图像数据的0.05%或更少）。为了获得最佳性能，我们采用CL和GMM先验来塑造HVAE的潜在空间，使得编码的输入图像块倾向于根据我们希望区分的语义类别进行聚类。最后，我们没有对潜在嵌入进行聚类以进行语义分割，而是提出了一个多层感知器（MLP）语义分割头，直接从潜在嵌入中预测类别标签。我们展示了{\epsilon}-Seg和基线方法在两个密集的生物组织EM数据集上的实证结果，并证明了我们的方法也适用于荧光显微镜数据。我们的结果表明，即使只有有限的训练标签可用，{\epsilon}-Seg也能够在复杂的生物图像数据上实现具有竞争力的稀疏监督分割结果。|
|**2025-10-16**|[Learning an Image Editing Model without Image Editing Pairs](http://arxiv.org/abs/2510.14978)|**[link](https://github.com/Sfedfcv/redesigned-pancake)**|近期图像编辑模型在遵循自然语言编辑指令方面取得了令人印象深刻的成果，但它们依赖于使用大量输入-目标对数据集进行有监督微调。这是一个关键瓶颈，因为此类自然生成的对难以大规模收集。当前的权宜之计是使用利用现有模型零样本能力的合成训练对。然而，这可能会将预训练模型的伪影传播并放大到最终训练模型中。在这项工作中，我们提出了一种新的训练范式，完全消除了对成对数据的需求。我们的方法通过在训练过程中展开一个少步扩散模型并利用视觉-语言模型（VLMs）的反馈来直接优化它。对于每个输入和编辑指令，VLM评估编辑是否遵循指令并保留了未更改的内容，从而为端到端优化提供了直接梯度。为确保视觉保真度，我们引入了分布匹配损失（DMD），它限制了生成的图像保持在预训练模型学习到的图像流形内。我们在标准基准上评估了我们的方法，并进行了一项广泛的消融研究。在没有任何成对数据的情况下，我们的方法在少步设置下，表现与在大量有监督成对数据上训练的各种图像编辑扩散模型相当。在使用相同的VLM作为奖励模型的情况下，我们也优于基于强化学习（RL）的技术，例如Flow-GRPO。|
|**2025-10-16**|[Terra: Explorable Native 3D World Model with Point Latents](http://arxiv.org/abs/2510.14977)|null|世界模型因其对真实世界的全面建模能力而受到越来越多的关注。然而，大多数现有方法仍然依赖像素对齐表示作为世界演化的基础，忽略了物理世界固有的三维特性。这可能会损害世界模型的三维一致性并降低其建模效率。在本文中，我们提出了Terra，一个原生的三维世界模型，它在一个内在的三维潜在空间中表示和生成可探索的环境。具体来说，我们提出了一种新颖的点到高斯变分自编码器（P2G-VAE），它将三维输入编码为潜在点表示，然后将其解码为三维高斯基元，以联合建模几何和外观。随后我们引入了一个稀疏点流匹配网络（SPFlow），用于生成潜在点表示，该网络同时对点潜在空间的位置和特征进行去噪。我们的Terra凭借原生的三维表示和架构实现了精确的多视角一致性，并仅通过一次生成过程即可支持从任意视点进行灵活渲染。此外，Terra通过在点潜在空间中的渐进式生成实现了可探索的世界建模。我们在来自ScanNet v2的具有挑战性的室内场景上进行了广泛的实验。Terra在重建和生成方面均取得了最先进的性能，并具有高三维一致性。|
|**2025-10-16**|[Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation](http://arxiv.org/abs/2510.14976)|**[link](https://github.com/stevenlsw/ponimator)**|近距离人与人交互姿态传达关于交互动态的丰富上下文信息。基于这些姿态，人类可以直观地推断上下文并预测可能的过去和未来动态，这借鉴了人类行为的强大先验知识。受此观察启发，我们提出了Ponimator，一个锚定于近距离交互姿态的简单框架，用于多功能交互动画。我们的训练数据由来自运动捕捉交互数据集的紧密接触两人姿态及其周围时间上下文组成。利用交互姿态先验，Ponimator采用了两个条件扩散模型：(1) 一个利用时间先验从交互姿态生成动态运动序列的姿态动画生成器，以及 (2) 一个在交互姿态不可用时应用空间先验从单一姿态、文本或两者兼有合成交互姿态的姿态生成器。总之，Ponimator支持多种任务，包括基于图像的交互动画、反应动画和文本到交互合成，促进了交互知识从高质量运动捕捉数据到开放世界场景的转移。在不同数据集和应用上的实证实验证明了姿态先验的普适性以及我们框架的有效性和鲁棒性。|
|**2025-10-16**|[pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation](http://arxiv.org/abs/2510.14974)|**[link](https://github.com/Lakonik/piFlow)**|少步扩散或流基生成模型通常将预测速度的教师模型蒸馏成预测通向去噪数据捷径的学生模型。这种格式不匹配导致了复杂的蒸馏过程，常常面临质量-多样性权衡。为解决此问题，我们提出了基于策略的流模型（ $\pi$-Flow）。$\pi$-Flow修改学生流模型的输出层，使其在一个时间步预测一个无网络的策略。该策略随后在未来的子步中以几乎可忽略的开销产生动态流速度，从而实现这些子步上快速准确的ODE积分，无需额外的网络评估。为了使策略的ODE轨迹与教师模型的轨迹匹配，我们引入了一种新颖的模仿蒸馏方法，该方法通过使用标准的$\ell_2$流匹配损失，沿策略轨迹将策略的速度与教师模型的速度进行匹配。通过简单模仿教师模型的行为，$\pi$-Flow实现了稳定和可扩展的训练，并避免了质量-多样性权衡。在ImageNet 256$^2$上，它在1个NFE下取得了2.85的FID，优于采用相同DiT架构的MeanFlow。在4个NFE下，对FLUX.1-12B和Qwen-Image-20B，$\pi$ -Flow实现了显著更好的多样性，优于最先进的少步方法，同时保持了教师模型级别的质量。|
|**2025-10-16**|[RainDiff: End-to-end Precipitation Nowcasting Via Token-wise Attention Diffusion](http://arxiv.org/abs/2510.14962)|null|降水临近预报（即根据当前观测预测未来雷达回波序列）是一项关键但极具挑战性的任务，原因在于大气本身固有的混沌性以及时空动态的紧密耦合。尽管基于扩散模型的最新进展试图捕获大尺度运动和细粒度随机变异性，但它们常常面临可扩展性问题：潜在空间方法需要单独训练的自编码器，这增加了复杂性并限制了泛化能力；而像素空间方法计算密集，且通常忽略注意力机制，降低了其建模长程时空依赖的能力。为了解决这些局限性，我们提出了一种逐令牌注意力机制，并将其不仅集成到U-Net扩散模型中，还集成到时空编码器中，以动态捕获多尺度空间交互和时间演变。与现有方法不同，我们的方法将注意力原生集成到架构中，而无需承担像素空间扩散模型常见的高昂资源成本，从而消除了对单独潜在模块的需求。我们在各种数据集上进行的广泛实验和视觉评估表明，所提出的方法显著优于最先进的方法，在复杂降水预报场景中展现出卓越的局部保真度、泛化能力和鲁棒性。|
|**2025-10-16**|[RealDPO: Real or Not Real, that is the Preference](http://arxiv.org/abs/2510.14955)|null|视频生成模型近期在合成质量方面取得了显著进展。然而，生成复杂动作仍然是一个关键挑战，因为现有模型常常难以生成自然、平滑且上下文一致的运动。生成运动与真实世界运动之间的这种差距限制了它们的实际应用性。为了解决这个问题，我们引入了RealDPO，这是一种新颖的对齐范式，它利用真实世界数据作为偏好学习的正样本，从而实现更准确的运动合成。与提供有限纠正反馈的传统监督微调（SFT）不同，RealDPO采用直接偏好优化（DPO）结合定制的损失函数来增强运动的真实感。通过将真实世界视频与错误的模型输出进行对比，RealDPO实现了迭代自我校正，逐步提升运动质量。为了支持复杂运动合成的后训练，我们提出了RealAction-5K，这是一个精选的高质量视频数据集，捕捉了具有丰富而精确运动细节的人类日常活动。大量实验表明，与现有最先进模型和现有偏好优化技术相比，RealDPO显著提高了视频质量、文本对齐和运动真实感。|
|**2025-10-16**|[OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression](http://arxiv.org/abs/2510.14954)|null|全身多模态人体运动生成面临两个主要挑战：创建有效的运动生成机制以及将文本、语音和音乐等各种模态整合到一个统一的框架中。与以往通常采用离散掩码建模或自回归建模的方法不同，我们开发了一种连续掩码自回归运动Transformer，其中考虑到人体运动的序列特性，执行因果注意力。在这个Transformer中，我们引入了门控线性注意力和RMSNorm模块，它们促使Transformer关注关键动作，并抑制由异常运动或多模态中异构分布引起的不稳定性。为了进一步增强运动生成和多模态泛化能力，我们采用DiT结构来扩散从Transformer到目标的条件。为了融合不同模态，AdaLN和交叉注意力被利用来注入文本、语音和音乐信号。实验结果表明，我们的框架在所有模态上都优于以往方法，包括文本到运动、语音到手势和音乐到舞蹈。我们的方法代码将公开。|
|**2025-10-16**|[DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation](http://arxiv.org/abs/2510.14949)|null|像英语这样的接触语言表现出丰富的地域差异，以方言的形式存在，这些方言经常被方言使用者在与生成模型交互时使用。然而，多模态生成模型在给定方言文本输入的情况下能否有效地生成内容？在这项工作中，我们通过构建一个涵盖六种常见英语方言的新大规模基准来研究这个问题。我们与方言使用者合作，收集并验证了超过4200个独特的提示，并在17个图像和视频生成模型上进行了评估。我们的自动化和人工评估结果表明，当前最先进的多模态生成模型在提示中仅使用一个方言词时，会表现出32.26%至48.17%的性能下降。常见的缓解方法，如微调和提示重写，只能将方言性能提高很小的幅度（< 7%），同时可能导致标准美式英语（SAE）性能的显著下降。为此，我们设计了一种用于多模态生成模型的通用基于编码器的缓解策略。我们的方法旨在教会模型识别新的方言特征，同时保持SAE性能。在Stable Diffusion 1.5等模型上的实验表明，我们的方法能够同时将五种方言的性能提升至与SAE相当的水平（+34.4%），同时对SAE性能的损失几乎为零。|
|**2025-10-16**|[Decoding in the presence of ISI without interleaving ORBGRAND AI](http://arxiv.org/abs/2510.14939)|null|码间串扰 (ISI) 发生在各种信道中，是时间色散的结果。它可以通过均衡来减轻，但这会导致噪声着色。对于这种着色噪声，我们提出了一种名为有序可靠性比特猜测随机加性噪声解码 (ORBGRAND-AI) 的解码器，其灵感来源于统计物理学中近似独立性的发展。通过放弃交织，ORBGRAND-AI在ISI信道中，对于相同每信息比特能量，可以实现与使用交织器的最先进软输入解码器（例如循环冗余校验辅助逐次抵消列表 (CA-SCL) 解码）相同或更低的码块错误率 (BLER)。为了评估ORBGRAND-AI的解码性能，我们考虑了延迟抽头模型及其相关的着色噪声。具体而言，我们研究了一个两抽头双码ISI信道，以及一个源自物理信息建模与仿真工具RFView数据的ISI信道。我们在各种不完善信道状态信息假设下研究了双码和RFView信道，并表明二阶自回归模型足以描述RFView信道效应。|
|**2025-10-16**|[Sound Masking Strategies for Interference with Mosquito Hearing](http://arxiv.org/abs/2510.14921)|null|听觉掩蔽的使用在心理声学和工程应用中一直备受关注，旨在掩盖对人类或与我们栖息地重叠的物种造成干扰的声音。在大多数情况下，我们力求最大程度地减少对野生动物交流的干扰。然而，对于携带病原体的昆虫，我们可能希望最大化这些干扰，以此作为控制其种群的一种方式。在当前工作中，我们探索了主动听觉系统通用模型和蚊子听觉系统模型中的候选掩蔽策略。对于这两种模型，我们发现将所有声功率集中在一个或几个频率上的掩蔽表现最佳。我们提出，基于快速频率调制的掩蔽对于最大程度地破坏信息传输和最小化可懂度最为有效。我们希望这些结果将有助于指导声学信号的避免或选择，分别用于最大化或最小化交流。|
|**2025-10-14**|[UniFusion: Vision-Language Model as Unified Encoder in Image Generation](http://arxiv.org/abs/2510.12789)|null|尽管视觉生成领域的最新进展显著，但大多数现有架构仍依赖于图像和文本的独立编码器。这种分离限制了扩散模型执行跨模态推理和知识迁移的能力。之前弥合这一差距的尝试通常使用VLM的最后一层信息、采用多个视觉编码器，或者联合训练大型统一模型用于文本和图像生成，这需要大量的计算资源和大规模数据，从而限制了其可及性。我们提出了UniFusion，一个基于扩散的生成模型，它以一个冻结的大型视觉-语言模型（VLM）为条件，该VLM作为一个统一的多模态编码器。UniFusion的核心是层级注意力池化（LAP）机制，该机制从冻结VLM的文本和视觉token中提取高级语义和低级细节，以此来条件化扩散生成模型。我们证明了LAP在生成任务的文本-图像对齐方面以及将VLM的视觉信息忠实地迁移到扩散模型方面优于其他浅层融合架构，这对于编辑至关重要。我们提出了VLM使能的灵活推理重写注入（VERIFI），它仅以VLM在模型内提示重写过程中生成的文本token为条件来条件化扩散Transformer（DiT）。VERIFI结合了条件分布的对齐性与VLM的推理能力，以提高推理时的能力和灵活性。此外，在编辑任务上进行微调不仅改善了生成任务的文本-图像对齐，表明了跨模态知识迁移，而且展现出巨大的泛化能力。我们的模型在单图像编辑上训练后，能够零样本泛化到多个图像参考，进一步证明了UniFusion统一编码器设计的合理性。|
|**2025-10-14**|[MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars](http://arxiv.org/abs/2510.12785)|**[link](https://github.com/felixtaubner/mvp4d)**|数字人形象旨在模拟人类在虚拟环境中的动态外观，从而在游戏、电影、虚拟现实等领域实现沉浸式体验。然而，创建和动画化照片级真实感数字人形象的传统流程昂贵且耗时，需要大型摄像机捕捉设备和专业3D艺术家的 G大量手动工作。随着强大的图像和视频生成模型的出现，近期方法能够从目标对象的单张随意拍摄的参考图像自动渲染出真实感的动画形象。尽管这些技术显著降低了形象创建的门槛并提供了引人注目的真实感，但它们缺乏多视角信息或显式3D表示所提供的约束。因此，当从严重偏离参考图像的视角渲染时，图像质量和真实感会下降。在本文中，我们构建了一个视频模型，该模型基于单张参考图像和目标表情，生成数字人可动画化的多视角视频。我们的模型MVP4D基于最先进的预训练视频扩散模型，能同时从围绕目标对象360度变化的视角生成数百帧。我们展示了如何将该模型的输出提炼成一个可实时渲染的4D形象。与以往方法相比，我们的方法显著提高了生成形象的真实感、时间一致性和3D一致性。|
|**2025-10-14**|[FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution](http://arxiv.org/abs/2510.12747)|**[link](https://github.com/smthemex/ComfyUI_FlashVSR)**|扩散模型最近在视频修复方面取得了进展，但由于高延迟、巨大的计算开销以及对超高分辨率的泛化能力差，将其应用于实际视频超分辨率 (VSR) 仍然充满挑战。本工作的目标是通过实现效率、可扩展性和实时性能，使基于扩散模型的 VSR 变得实用。为此，我们提出了 FlashVSR，首个基于扩散模型的一步式流媒体框架，旨在实现实时 VSR。FlashVSR 在单张 A100 GPU 上对 768x1408 视频的运行速度约为 17 FPS，这得益于它结合了三项互补的创新：(i) 一个易于训练的三阶段蒸馏管道，实现了流式超分辨率；(ii) 局部受限的稀疏注意力，减少了冗余计算，同时弥合了训练-测试分辨率鸿沟；(iii) 一个微小的条件解码器，加速了重建而不牺牲质量。为支持大规模训练，我们还构建了 VSR-120K，一个包含 120k 视频和 180k 图像的新数据集。大量实验表明，FlashVSR 可可靠地扩展到超高分辨率，并取得了最先进的性能，相比于之前的一步式扩散 VSR 模型，速度提升高达 12 倍。我们将发布代码、预训练模型和数据集，以促进未来在高效基于扩散模型的 VSR 方面的研究。|
|**2025-10-14**|[T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping](http://arxiv.org/abs/2510.12724)|**[link](https://github.com/Barrybarry-Smith/TRO-Grasp)**|灵巧抓取因其高维状态与动作空间的复杂性，在机器人学中仍然是一个核心挑战。我们提出了T(R,O) Grasp，一个基于扩散的框架，它能够高效地在多种机器人手上生成精确且多样的抓取。其核心是T(R,O) 图，这是一种统一表示，它对机器人手和物体之间的空间变换进行建模，同时编码它们的几何属性。一个图扩散模型，结合高效的逆运动学求解器，支持无条件和有条件的抓取合成。对多种灵巧手进行的大量实验表明，T(R,O) Grasp在NVIDIA A100 40GB GPU上实现了94.83%的平均成功率、0.21秒的推理速度和每秒41次抓取的吞吐量，显著优于现有基线。此外，我们的方法具有鲁棒性，并可在不同实现之间泛化，同时显著降低了内存消耗。更重要的是，高推理速度实现了闭环灵巧操作，凸显了T(R,O) Grasp发展成为灵巧抓取基础模型的潜力。|
|**2025-10-14**|[DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization](http://arxiv.org/abs/2510.12691)|null|扩散模型已成为解决高维逆问题的强大生成先验，然而，当仅有受损或带噪声的观测可用时，学习这些模型仍然具有挑战性。在这项工作中，我们提出了一种使用期望最大化（EM）从受损数据中训练扩散模型的新方法。我们提出的方法DiffEM在E步中利用条件扩散模型从观测中重建干净数据，然后在M步中使用重建的数据来改进条件扩散模型。理论上，我们假设有适当的统计条件，为DiffEM迭代提供了单调收敛保证。我们通过在各种图像重建任务上的实验证明了我们方法的有效性。|
|**2025-10-14**|[Moment-based Posterior Sampling for Multi-reference Alignment](http://arxiv.org/abs/2510.12651)|null|我们提出了一种贝叶斯方法来解决多参考对齐问题，即从噪声干扰的随机偏移观测中恢复信号。尽管现有频率学方法能够在任意低信噪比下准确恢复信号，但它们需要大量样本。相比之下，我们提出的方法利用扩散模型作为数据驱动的即插即用先验，将这些先验条件化于样本功率谱（一种移不变统计量），从而实现准确的后验采样和不确定性量化。适当先验的使用显著减少了所需的样本数量，这在模拟实验中得到了证明，并与期望最大化和双谱反演等最先进方法进行了比较。这些发现确立了我们的方法作为解决其他轨道恢复问题（例如冷冻电子显微镜 (cryo-EM)）的一个有前景的框架。|
|**2025-10-14**|[Contraction and entropy production in continuous-time Sinkhorn dynamics](http://arxiv.org/abs/2510.12639)|null|最近，在有限正则化参数 $\varepsilon$下，Sinkhorn算法的步长趋零极限被证明是概率测度空间中的一种镜像下降。我们给出了在由镜像Hessian诱导的两个时变度量下的$L^2$收缩准则，这等价于某些条件期望算子的强制性。接着我们给出了Sinkhorn流的熵产生率的一个精确恒等式，该熵产生率此前仅已知为非正。检查该速率表明，扩散过程的标准半群分析系统地扩展到Sinkhorn流。我们表明该流在目标边缘分布上诱导了可逆马尔可夫动力学，作为Onsager梯度流。我们定义了与其（非局部）无穷小生成元相关的Dirichlet形式，为其证明了一个Poincaré不等式，并表明在Sinkhorn流中，只要$\varepsilon > 0$ ，谱隙就严格为正。最后，我们表明熵衰减呈指数级当且仅当对数Sobolev不等式（LSI）成立。我们举例说明了Sinkhorn LSI的两个直接实际用例：作为生成模型训练的潜在空间的设计原则，以及作为离散时间算法的停止启发式。|
|**2025-10-14**|[Adapting Noise to Data: Generative Flows from 1D Processes](http://arxiv.org/abs/2510.12636)|**[link](https://github.com/TUB-Angewandte-Mathematik/Adapting-Noise)**|我们引入了一个利用一维噪声过程构建生成模型的通用框架。除了扩散过程之外，我们还概述了证明我们方法灵活性的示例。受此启发，我们提出了一个新颖的框架，其中一维过程本身是可学习的，这通过使用适应数据的分位数函数来参数化噪声分布实现。我们的构建与包括流匹配和一致性模型在内的标准目标函数无缝集成。学习基于分位数的噪声在存在时能够自然地捕获厚尾和紧支撑。数值实验凸显了我们方法的灵活性和有效性。|
|**2025-10-14**|[Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training](http://arxiv.org/abs/2510.12586)|null|像素空间生成模型通常更难训练，并且与它们的潜在空间对应模型相比，性能普遍较差，留下了一个持续存在的性能和效率差距。在本文中，我们引入了一种新颖的两阶段训练框架，弥补了像素空间扩散模型和一致性模型的这一差距。在第一阶段，我们预训练编码器以从干净图像中捕获有意义的语义，同时将它们与沿着相同确定性采样轨迹的点对齐，该轨迹将点从先验分布演化到数据分布。在第二阶段，我们将编码器与随机初始化的解码器集成，并对扩散模型和一致性模型进行端到端的完整模型微调。我们的训练框架在ImageNet数据集上表现出强大的实验性能。具体而言，我们的扩散模型在ImageNet-256上实现了2.04的FID，在ImageNet-512上实现了2.35，仅需75次函数评估（NFE），在生成质量和效率上都大幅超越了之前的像素空间方法，同时在可比的训练成本下可与领先的基于VAE的模型相媲美。此外，在ImageNet-256上，我们的一致性模型在单次采样步骤中实现了8.82的惊人FID，显著超越了其潜在空间对应模型。据我们所知，这标志着首次成功地直接在高分辨率图像上训练一致性模型，而无需依赖预训练的VAE或扩散模型。|
|**2025-10-14**|[LayerSync: Self-aligning Intermediate Layers](http://arxiv.org/abs/2510.12581)|null|我们提出LayerSync，这是一种领域无关的方法，用于提升扩散模型的生成质量和训练效率。先前研究强调了生成质量与扩散模型学习到的表示之间的联系，表明对模型中间表示施加外部引导可以加速训练。我们通过使用扩散模型自身的中间表示进行正则化来重新构思这种范式。基于观察到表示质量在扩散模型层之间存在差异，我们表明语义最丰富的表示可以作为对较弱表示的内在引导，从而减少了对外部监督的需求。我们的方法LayerSync是一种自给自足的即插即用正则化项，对扩散模型训练没有额外开销，并且可以从视觉领域推广到其他模态。LayerSync不需要预训练模型，也不需要额外数据。我们广泛评估了该方法在图像生成任务上的表现，并展示了其对音频、视频和运动生成等其他领域的适用性。我们表明它持续提升了生成质量和训练效率。例如，在ImageNet数据集上，我们将基于流的Transformer的训练速度提高了8.75倍以上，并将生成质量提升了23.6%。代码可在https://github.com/vita-epfl/LayerSync获取。|
|**2025-10-10**|[BaNEL: Exploration Posteriors for Generative Modeling Using Only Negative Rewards](http://arxiv.org/abs/2510.09596)|null|当今的生成模型在大量有监督数据和表征生成质量的信息丰富奖励函数下表现出色。它们运作的假设是，有监督数据为模型预训练提供知识，而奖励函数提供关于如何进一步提高生成质量和正确性的密集信息。然而，在一些重要问题的最困难实例中，会遇到两个问题：(1) 基础生成模型获得的奖励信号接近于零，以及 (2) 调用奖励预言机的成本很高。这种设置带来了与标准基于奖励的后训练截然不同的根本性学习挑战。为了解决这一问题，我们提出了BaNEL（贝叶斯负面证据学习）算法，该算法仅利用失败尝试对模型进行后训练，同时最大限度地减少奖励评估次数（NREs）。我们的方法基于这样的理念：学习失败背后规律的问题可以被视为另一个循环内的生成建模问题。随后，我们利用该模型评估新数据是否与先前观察到的失败相似，并引导生成远离这些失败。实验表明，BaNEL 可以在不观察任何成功样本的情况下，在多个稀疏奖励任务上提高模型性能，其成功率比现有新颖性奖励方法高出数个数量级，同时使用的奖励评估次数更少。|
|**2025-10-10**|[STaTS: Structure-Aware Temporal Sequence Summarization via Statistical Window Merging](http://arxiv.org/abs/2510.09593)|null|时间序列数据通常包含潜在的时间结构、局部平稳状态之间的转换、重复模式以及变异性爆发，这些在标准表示学习流程中很少被利用。现有模型通常在原始序列或固定窗口序列上操作，将所有时间步视为信息量相等，这导致在长序列或噪声序列中出现低效率、鲁棒性差和可扩展性有限的问题。我们提出了STaTS，一个轻量级、无监督的结构感知时间序列摘要框架，它能自适应地将单变量和多变量时间序列压缩成紧凑的、信息保留的令牌序列。STaTS使用基于BIC的统计散度准则，跨多个时间分辨率检测变化点，然后使用均值等简单函数或GMMs等生成模型对每个片段进行总结。这个过程实现了高达30倍的序列压缩，同时保留了核心时间动态。STaTS作为一个模型无关的预处理器运行，可以与现有无监督时间序列编码器集成，无需重新训练。在150多个数据集上进行了广泛实验，包括UCR-85、UCR-128和UEA-30档案上的分类任务，以及ETTh1、ETTh2、ETTm1和Electricity上的预测任务，结果表明STaTS能够实现全模型性能的85-90%，同时显著降低计算成本。此外，STaTS提高了噪声下的鲁棒性，并保留了判别性结构，优于基于均匀和聚类的压缩基线。这些结果将STaTS定位为一种高效、结构感知时间序列建模的原则性通用解决方案。|
|**2025-10-10**|[Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference](http://arxiv.org/abs/2510.09574)|null|在未知环境中进行自主导航，要求机器人在不依赖预定义地图或大量训练的情况下，在不确定性下同时进行探索、定位和规划。我们提出了一种受生物学启发、基于主动推断的框架，名为主动推断映射与规划 (AIMAPP)。该模型在一个单一的生成模型中统一了映射、定位和决策。受海马体导航的启发，它利用拓扑推理、位置细胞编码和情景记忆来指导行为。智能体在线构建和更新稀疏拓扑地图，动态学习状态转换，并通过最小化预期自由能来规划行动。这使其能够平衡目标导向行为和探索行为。我们实现了一个ROS兼容的导航系统，该系统与传感器和机器人无关，能够与各种硬件配置集成。它以完全自监督的方式运行，对漂移具有弹性，并且无需任何预训练即可支持探索和目标导向导航。我们在大规模真实和模拟环境中展示了对比最先进规划模型的强大性能，突出了系统对模糊观测、环境变化和传感器噪声的适应性。该模型为非结构化环境中的可扩展、自监督导航提供了一种受生物学启发、模块化的解决方案。AIMAPP可在https://github.com/decide-ugent/AIMAPP获取。|
|**2025-10-10**|[TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control](http://arxiv.org/abs/2510.09561)|null|当前的可控扩散模型通常依赖于固定架构，通过修改中间激活来注入基于新模态的引导。这种方法针对动态、多阶段的去噪过程采用静态条件策略，限制了模型随着生成过程从粗略结构演变到精细细节时调整其响应的能力。我们引入了TC-LoRA（时间调制条件LoRA），这是一种新范式，通过直接调节模型权重实现了动态、上下文感知的控制。我们的框架使用超网络实时生成LoRA适配器，在每个扩散步骤中基于时间和用户条件为冻结骨干网络定制权重修改。这种机制使模型能够学习并执行一种明确的、自适应的策略，以在整个生成过程中应用条件引导。通过在各种数据域上的实验，我们证明了这种动态、参数化的控制相比于静态的、基于激活的方法，显著提高了生成保真度以及对空间条件的依从性。TC-LoRA建立了一种替代方法，其中模型的条件策略通过对其权重的更深层次的功能性适应进行修改，使控制与任务和生成阶段的动态需求保持一致。|
|**2025-10-10**|[SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models](http://arxiv.org/abs/2510.09541)|**[link](https://github.com/facebookresearch/SPG)**|扩散大语言模型（dLLMs）因其能够并行解码多个tokens的能力，正作为自回归模型的一种高效替代方案而兴起。然而，通过强化学习（RL）使dLLMs与人类偏好或任务特定奖励对齐具有挑战性，因为它们难以处理的对数似然阻碍了标准策略梯度方法的直接应用。尽管先前的研究使用证据下界（ELBO）等替代量，但这些单边近似会引入显著的策略梯度偏差。为了解决这个问题，我们提出了夹心策略梯度（SPG），它同时利用了真实对数似然的上限和下限。实验表明，SPG显著优于基于ELBO或一步估计的基线方法。具体而言，SPG在dLLMs的最新强化学习方法上，于GSM8K任务中将准确率提高了3.6%，在MATH500中提高了2.6%，在Countdown中提高了18.4%，在Sudoku中提高了27.0%。|
|**2025-10-10**|[Conditional Flow Matching for Bayesian Posterior Inference](http://arxiv.org/abs/2510.09534)|null|我们提出了一种基于流匹配的生成式多元后验采样器。它提供了一个简单的训练目标，并且无需进行似然评估。该方法学习数据和参数联合空间中的动态分块三角速度场，从而得到从源分布到目标后验的确定性传输映射。其逆映射（称为向量秩）可以通过对速度进行可逆时间积分来获得。利用动态设计具有优势：对速度施加适当约束可以产生单调映射，进而得到条件Brenier映射，从而能够快速同时生成贝叶斯可信集，其等高线对应于Monge-Kantorovich数据深度的水平集。相比于基于GAN和基于扩散的对应方法，我们的方法计算成本更低，并且能够捕获复杂的后验结构。最后，我们提供了关于恢复的后验分布及其相应贝叶斯可信集的一致性的频率学理论保证。|
|**2025-10-10**|[Precoder Design in Multi-User FDD Systems with VQ-VAE and GNN](http://arxiv.org/abs/2510.09495)|null|通过生成模型结合传播环境的学习统计数据，鲁棒预编码在频分双工（FDD）系统中可高效实现。我们基于先前成功设计站点特定预编码器的工作，该工作结合了高斯混合模型（GMM）和图神经网络（GNN）。在本文中，通过利用矢量量化变分自编码器（VQ-VAE），我们规避了GMM的一个主要缺点，即GMM组件的数量随反馈比特呈指数级增长的问题。此外，VQ-VAE的深度学习架构使我们能够将GNN与VQ-VAE以及导频优化联合训练，形成一个端到端（E2E）模型，从而为多用户无线系统带来和速率的显著性能提升。仿真结果表明，所提出的框架优于涉及子离散傅里叶变换（DFT）导频矩阵和迭代预编码算法的传统方法，从而能够部署具有更少导频或反馈比特的系统。|
|**2025-10-10**|[CRPS-LAM: Regional ensemble weather forecasting from matching marginals](http://arxiv.org/abs/2510.09484)|null|天气预报中的机器学习越来越依赖集成方法来提供概率预报。基于扩散的模型在局地模式建模 (LAM) 中表现出强大的性能，但在采样时计算成本仍然很高。借鉴基于连续等级概率评分 (CRPS) 训练的全球天气预报模型的成功经验，我们引入了CRPS-LAM，这是一种使用基于CRPS的目标函数训练的概率性LAM预报模型。通过采样并将单个潜在噪声向量注入模型，CRPS-LAM在单个前向传播中生成集成成员，实现了比基于扩散的模型快高达39倍的采样速度。我们在MEPS区域数据集上评估了该模型，结果显示CRPS-LAM的误差与扩散模型相当。通过同时保留精细尺度的预报细节，该方法作为一种有效的概率性区域天气预报方法而脱颖而出。|
|**2025-10-10**|[Efficient Autoregressive Inference for Transformer Probabilistic Models](http://arxiv.org/abs/2510.09477)|**[link](https://github.com/acerbilab/transformer-ar-buffer)**|用于摊销概率推断的基于Transformer的模型，如神经过程、先验拟合网络和表格基础模型，擅长单次通过的边际预测。然而，许多现实世界应用，从信号插值到多列表格预测，都需要捕获预测之间依赖关系的连贯联合分布。虽然纯自回归架构能高效生成此类分布，但它们牺牲了使这些模型在元学习中强大的灵活集合条件化能力。相反，从基于集合的模型获取联合分布的标准方法需要在每个自回归步骤中对整个增强条件集进行昂贵的重新编码。我们引入了一种因果自回归缓冲区，它保留了这两种范式的优点。我们的方法将上下文编码与条件集更新解耦。模型一次性处理上下文并将其缓存。然后，一个动态缓冲区捕获目标依赖关系：当目标被纳入时，它们进入缓冲区并关注缓存的上下文和先前缓冲的目标。这使得高效的批量自回归生成和单次通过的联合对数似然评估成为可能。一个统一的训练策略允许以最小的额外成本无缝集成基于集合和自回归模式。在合成函数、脑电图信号、认知模型和表格数据上，我们的方法匹配了强大基线的预测精度，同时提供了高达20倍的联合采样速度。我们的方法结合了自回归生成模型的效率和基于集合条件化的表示能力，使联合预测对于基于Transformer的概率模型变得实用。|
|**2025-10-10**|[Few-shot multi-token DreamBooth with LoRa for style-consistent character generation](http://arxiv.org/abs/2510.09475)|null|视听行业正在经历深刻变革，它不仅整合人工智能发展以自动化日常任务，还以此启发新的艺术形式。本文旨在解决生成几乎无限数量的新颖角色的问题，这些角色能保留一小部分人类设计的参考角色的艺术风格和共享视觉特征，从而拓宽动画、游戏及相关领域的创作可能性。我们的解决方案基于DreamBooth（一种成熟的文本到图像扩散模型微调技术），并对其进行调整以解决两个核心挑战：捕捉超出文本提示的复杂角色细节以及训练数据的少样本特性。为此，我们提出了一种多token策略，该策略使用聚类将独立的token分配给单个角色及其集体风格，并结合了基于LoRA的参数高效微调。通过移除类别特定的正则化集并在生成过程中引入随机token和嵌入，我们的方法允许无限的角色创建，同时保留学习到的风格。我们在五个小型专用数据集上评估了我们的方法，并使用定量指标和人类评估研究将其与相关基线进行了比较。我们的结果表明，我们的方法生成了高质量、多样化的角色，同时保留了参考角色独特的审美特征，人类评估进一步证实了其有效性并凸显了我们方法的潜力。|
|**2025-10-09**|[Who Said Neural Networks Aren't Linear?](http://arxiv.org/abs/2510.08570)|**[link](https://github.com/gnocchiarsugo/NN-Linearity)**|神经网络以其非线性而闻名。然而，线性是相对于一对向量空间 $f$$:$$X$$\to$$Y$定义的。是否有可能识别一对非标准向量空间，使得一个通常非线性的函数实际上是线性的？本文介绍了一种通过构造使这些向量空间显式化的方法。我们发现，如果我们将一个线性算子$A$夹在两个可逆神经网络之间，即$f(x)=g_y^{-1}(A g_x(x))$，那么相应的向量空间$X$和$Y$将由源自$g_x$和$g_y$的新定义的加法和标量乘法运算诱导。我们将这种架构称为线性化器（Linearizer）。该框架使得线性代数的全部工具，包括奇异值分解（SVD）、伪逆、正交投影等，都可应用于非线性映射。此外，我们证明了共享一个神经网络的两个线性化器（Linearizer）的组合也是一个线性化器。我们利用这一特性，证明了使用我们的架构训练扩散模型可以将数百个采样步骤合并为一个步骤。我们进一步利用该框架在网络上强制执行幂等性（即$f(f(x))=f(x)$ ），从而得到一个全局投影生成模型，并展示了模块化风格迁移。|
|**2025-10-09**|[NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos](http://arxiv.org/abs/2510.08568)|null|使机器人能够零样本执行新颖的抓取操作任务是机器人学的一个核心目标。大多数现有方法假设任务在已知分布内，或依赖于特定形态数据的微调，从而限制了跨平台的迁移。我们提出了NovaFlow，一个自主操作框架，它无需任何演示即可将任务描述转换为目标机器人的可执行计划。给定任务描述，NovaFlow使用视频生成模型合成视频，并利用现成的感知模块将其提炼为3D可操作物体流。从物体流中，它计算刚性物体的相对位姿，并通过抓取方案和轨迹优化将其实现为机器人动作。对于可变形物体，此流作为基于粒子动力学模型的模型化规划的跟踪目标。通过将任务理解与低层控制解耦，NovaFlow能够自然地跨形态迁移。我们在一个桌面Franka机械臂和一台Spot四足移动机器人上，对刚性、铰接式和可变形物体操作任务进行了验证，并实现了无需演示或特定形态训练的有效零样本执行。项目网站：https://novaflow.lhy.xyz/。|
|**2025-10-09**|[MultiCOIN: Multi-Modal COntrollable Video INbetweening](http://arxiv.org/abs/2510.08561)|null|视频中间帧生成在两个图像帧之间创建平滑自然的过渡，使其成为视频编辑和长视频合成不可或缺的工具。该领域现有工作无法生成大型、复杂或精细的运动。特别是，它们无法适应用户意图的多样性，并且普遍缺乏对中间帧细节的精细控制，导致与创作理念不符。为了弥补这些空白，我们引入了\modelname{}，一个视频中间帧生成框架，它允许多模态控制，包括深度过渡和分层、运动轨迹、文本提示以及用于运动定位的目标区域，同时在灵活性、易用性和精细视频插值的精度之间取得平衡。为实现这一点，我们采用扩散Transformer（DiT）架构作为我们的视频生成模型，因为它已被证明能够生成高质量长视频。为确保DiT与我们的多模态控制兼容，我们将所有运动控制映射到一个通用的稀疏且用户友好的基于点的表示作为视频/噪声输入。此外，为了尊重在不同粒度和影响力层面操作的各种控制，我们将内容控制和运动控制分离为两个分支，以编码所需的特征，然后引导去噪过程，从而产生两个生成器，一个用于运动，另一个用于用于内容。最后，我们提出了一种分阶段训练策略，以确保我们的模型平稳学习多模态控制。大量的定性定量实验表明，多模态控制能够实现更具动态性、可定制性和上下文准确性的视觉叙事。|
|**2025-10-09**|[VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning](http://arxiv.org/abs/2510.08555)|null|我们引入了任意时空视频补全任务，其中视频是从放置在任意空间位置和时间戳上的任意用户指定块生成的，类似于在视频画布上作画。这种灵活的表述自然地将许多现有的可控视频生成任务——包括首帧图像到视频、修复、扩展和插值——统一到一个单一、连贯的范式下。然而，实现这一愿景在现代潜在视频扩散模型中面临一个根本障碍：因果VAE引入的时间模糊性，其中多个像素帧被压缩成单个潜在表示，使得精确的帧级条件控制在结构上变得困难。我们通过VideoCanvas解决了这一挑战，这是一个新颖的框架，它将上下文条件控制（ICC）范式应用于这种细粒度控制任务，且零新增参数。我们提出了一种混合条件控制策略，解耦了空间和时间控制：空间放置通过零填充处理，而时间对齐则通过时序RoPE插值实现，该插值为每个条件在潜在序列中分配一个连续的分数位置。这解决了VAE的时间模糊性，并实现了在冻结骨干网络上像素帧感知的控制。为了评估这项新能力，我们开发了VideoCanvasBench，这是第一个用于任意时空视频补全的基准，涵盖了场景内保真度和场景间创造力。实验证明，VideoCanvas显著优于现有条件控制范式，在灵活统一的视频生成领域建立了新的最先进水平。|
|**2025-10-09**|[Permutation-Invariant Spectral Learning via Dyson Diffusion](http://arxiv.org/abs/2510.08535)|null|扩散模型是生成建模的核心，并通过扩散邻接矩阵表示已应用于图。对于具有 $n$个节点的图，多达$n!$ 种这样的表示所带来的挑战，仅通过使用置换等变学习架构得到了部分缓解。尽管它们计算效率高，但现有的图扩散模型难以区分某些图族，除非图数据通过特别设计的特征进行增强。这一缺点源于在学习架构内部强制施加归纳偏置。在这项工作中，我们利用随机矩阵理论解析地提取扩散过程的谱性质，使我们能够将归纳偏置从架构中推入动力学中。基于此，我们引入了戴森扩散模型，该模型采用戴森布朗运动来捕获邻接矩阵上厄恩斯坦-乌伦贝克过程的谱动力学，同时保留所有非谱信息。我们证明戴森扩散模型能准确学习图谱，并优于现有的图扩散模型。|
|**2025-10-09**|[Kontinuous Kontext: Continuous Strength Control for Instruction-based Image Editing](http://arxiv.org/abs/2510.08532)|null|基于指令的图像编辑提供了一种通过自然语言操纵图像的强大而直观的方式。然而，仅仅依赖文本指令限制了对编辑程度的细粒度控制。我们引入了Kontinuous Kontext，这是一种指令驱动的编辑模型，它提供了对编辑强度的新维度控制，使用户能够以平滑连续的方式，逐步将编辑从无变化调整到完全实现的结果。Kontinuous Kontext扩展了一个最先进的图像编辑模型，使其能够接受一个额外的输入，即一个标量编辑强度，该强度随后与编辑指令配对，从而实现对编辑程度的显式控制。为了注入这种标量信息，我们训练了一个轻量级投影网络，将输入标量和编辑指令映射到模型调制空间中的系数。为了训练我们的模型，我们利用现有生成模型合成了一个多样化的图像-编辑-指令-强度四元组数据集，随后进行过滤阶段以确保质量和一致性。Kontinuous Kontext为指令驱动的编辑提供了一种统一方法，可实现从微妙到强烈的编辑强度的细粒度控制，涵盖风格化、属性、材质、背景和形状变化等多种操作，且无需进行属性特定训练。|
|**2025-10-09**|[X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering](http://arxiv.org/abs/2510.08530)|null|我们提出了X2Video，这是首个扩散模型，能够渲染由反照率、法线、粗糙度、金属性和辐照度等内在通道引导的逼真视频，同时支持通过参考图像以及针对全局和局部区域的文本提示进行直观的多模态控制。内在引导允许对颜色、材质、几何形状和光照进行精确操纵，而参考图像和文本提示在缺乏内在信息时提供直观调整。为实现这些功能，我们将内在引导的图像生成模型XRGB扩展到视频生成，采用了新颖高效的混合自注意力机制（Hybrid Self-Attention），该机制确保了视频帧之间的时间一致性并增强了对参考图像的保真度。我们进一步开发了一种掩码交叉注意力机制（Masked Cross-Attention），以解耦全局和局部文本提示，并将其有效地应用于各自的局部和全局区域。对于长视频生成，我们新颖的递归采样方法（Recursive Sampling）结合了渐进式帧采样、关键帧预测和帧插值，以保持长程时间一致性并防止误差累积。为支持X2Video的训练，我们构建了一个名为InteriorVideo的视频数据集，包含来自295个室内场景的1,154个房间，并配有可靠的真实内在通道序列和平滑的摄像机轨迹。定性和定量评估均表明，X2Video能够生成由内在条件引导的长时间、时间一致且逼真的视频。此外，X2Video有效地适应了通过参考图像、全局和局部文本提示进行的多模态控制，并通过参数调整同时支持对颜色、材质、几何形状和光照的编辑。项目页面：https://luckyhzt.github.io/x2video|
|**2025-10-09**|[FlexTraj: Image-to-Video Generation with Flexible Point Trajectory Control](http://arxiv.org/abs/2510.08527)|null|我们提出了FlexTraj，一个具有灵活点轨迹控制的图像到视频生成框架。FlexTraj引入了一种统一的基于点的运动表示，该表示为每个点编码了一个分割ID、一个时间一致的轨迹ID以及一个用于外观线索的可选颜色通道，从而实现了密集和稀疏的轨迹控制。相较于通过token拼接或ControlNet将轨迹条件注入视频生成器，FlexTraj采用了一种高效的序列拼接方案，该方案实现了更快的收敛、更强的可控性和更高效的推理，同时在未对齐条件下保持了鲁棒性。为了训练这样一个统一的点轨迹控制视频生成器，FlexTraj采用了一种退火训练策略，该策略逐步减少了对完整监督和对齐条件的依赖。实验结果表明，FlexTraj实现了多粒度、与对齐无关的视频生成轨迹控制，支持运动克隆、拖拽式图像到视频、运动插值、摄像机重定向、灵活动作控制和网格动画等多种应用。|
|**2025-10-09**|[InstructX: Towards Unified Visual Editing with MLLM Guidance](http://arxiv.org/abs/2510.08485)|null|随着多模态大语言模型（MLLMs）在视觉理解和推理方面展现出强大能力，利用它们提升扩散模型编辑性能的兴趣日益增长。尽管进展迅速，但大多数研究缺乏对MLLM设计选择的深入分析。此外，在视频编辑等一些困难任务中，MLLM与扩散模型的集成仍然是一个开放性挑战。在本文中，我们提出了InstructX，一个用于图像和视频编辑的统一框架。具体而言，我们对集成MLLM和扩散模型以进行指令驱动的跨任务编辑进行了全面研究。基于这项研究，我们分析了图像和视频在统一建模中的协作与区别。(1)我们表明，在图像数据上进行训练可以在没有明确监督的情况下产生涌现的视频编辑能力，从而缓解了稀缺视频训练数据所带来的限制。(2)通过整合模态特定的MLLM特征，我们的方法有效地在单个模型中统一了图像和视频编辑任务。大量实验表明，我们的方法可以处理广泛的图像和视频编辑任务，并取得了最先进的性能。|
|**2025-10-09**|[Universality and kernel-adaptive training for classically trained, quantum-deployed generative models](http://arxiv.org/abs/2510.08476)|null|瞬时量子多项式（IQP）量子电路玻恩机器（QCBM）已被提出作为一种有前景的针对比特串的量子生成模型。最近的工作表明，IQP-QCBM 的训练在所谓的基于高斯核的最大均值差异（MMD）损失函数方面是经典可处理的，同时仍保持其在采样本身方面具备量子优势的潜力。然而，该模型在多个方面需要改进以提升其更广泛的实用性：(1) 已知基本模型不具备普适性，即它无法表示任意分布，并且此前尚不清楚是否可以通过添加隐藏（辅助）量子比特来实现普适性；(2) MMD 损失中使用的固定高斯核可能导致训练问题，例如梯度消失。在本文中，我们解决了第一个问题，并在第二个问题上取得了决定性进展。我们证明，对于一个 $n$ 量子比特的 IQP 生成器，添加 $n + 1$ 个隐藏量子比特可以使模型具有普适性。对于后者，我们提出了一种核自适应训练方法，其中核通过对抗性方式进行训练。我们表明，在核自适应方法中，MMD 值的收敛性意味着生成器在分布上的弱收敛。我们还解析地分析了基于 MMD 的训练方法的局限性。最后，我们通过专门设计用于突显所提出方法改进的数据集，验证了其性能优势。结果表明，核自适应训练在总变差距离方面优于固定高斯核，并且该差距随数据集维度的增加而增大。这些修改和分析阐明了这些新型量子生成方法的局限性和潜力，即使在无法访问可扩展量子计算机的情况下，它们也能首次提供关于经典模型与量子模型比较能力方面真正可扩展的见解。|
|**2025-10-07**|[Fine-grained Defocus Blur Control for Generative Image Models](http://arxiv.org/abs/2510.06215)|null|当前的文本到图像扩散模型在生成多样化、高质量图像方面表现出色，然而它们难以整合细粒度相机元数据，例如精确的光圈设置。在这项工作中，我们引入了一种新颖的文本到图像扩散框架，该框架利用相机元数据（即通常嵌入在图像文件中的EXIF数据），并侧重于生成可控的镜头模糊。我们的方法模仿物理图像形成过程，首先生成一个全聚焦图像，估计其单目深度，利用一种新颖的焦点距离变换器预测一个合理的焦点距离，然后利用现有的可微分镜头模糊模型形成一个散焦图像。梯度通过整个过程反向传播，使我们能够无需显式监督进行学习，以根据内容元素和提供的EXIF数据生成散焦效果。在推理时，这使得用户能够对散焦效果进行精确的交互式控制，同时保留场景内容，这是现有扩散模型无法实现的。实验结果表明，我们的模型实现了卓越的细粒度控制，而不会改变所描绘的场景。|
|**2025-10-07**|[Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models](http://arxiv.org/abs/2510.06209)|null|生成模型近期进展为自动驾驶汽车领域带来了令人振奋的新机遇。具体而言，视频生成模型正在被探索用作可控的虚拟测试环境。与此同时，端到端（E2E）驾驶模型已成为传统模块化自动驾驶系统的精简替代方案，因其简洁性和可扩展性而广受欢迎。然而，这些技术在仿真和规划中的应用提出了重要问题。首先，尽管视频生成模型可以生成越来越逼真的视频，但这些视频能否忠实地遵循指定条件并足够真实以用于E2E自动驾驶规划器评估？其次，鉴于数据对于理解和控制E2E规划器至关重要，我们如何才能更深入地了解它们的偏差并提高它们泛化到分布外场景的能力？在本文中，我们通过弥合驾驶模型与生成式世界模型（Drive&Gen）之间的鸿沟来解决这些问题。我们提出了新颖的统计度量，利用E2E驾驶员来评估生成视频的真实性。通过利用视频生成模型的可控性，我们进行了有针对性的实验，以研究影响E2E规划器性能的分布差距。最后，我们表明视频生成模型产生的合成数据为真实世界数据收集提供了一种经济高效的替代方案。这种合成数据有效地提高了E2E模型在现有运行设计域之外的泛化能力，促进了自动驾驶汽车服务向新运行场景的扩展。|
|**2025-10-07**|[StarEmbed: Benchmarking Time Series Foundation Models on Astronomical Observations of Variable Stars](http://arxiv.org/abs/2510.06200)|null|时间序列基础模型 (TSFMs) 正越来越多地被采纳为高性能通用时间序列表示学习器。尽管它们的训练语料库庞大，但它们排除了天文时间序列数据。对恒星的观测产生了具有独特挑战的拍字节级时间序列数据，这些挑战包括不规则采样和异方差性。我们引入了 StarEmbed，这是第一个用于在恒星时间序列观测（“光变曲线”）上严谨和标准化评估最先进TSFMs的公开基准。我们在三个科学驱动的下游任务上进行基准测试：无监督聚类、有监督分类和分布外源检测。StarEmbed 整合了来自兹威基瞬变设施的多变量光变曲线和一份专家审核的标签目录，产生了分布在七个天体物理类别中的约4万条手动标注光变曲线。我们评估了三个TSFMs（MOIRAI、Chronos、Chronos-Bolt）和一个领域专用transformer（Astromer）的零样本表示能力，并将其与手工特征提取（天体物理学文献中长期存在的基线方法）进行了对比。我们的结果表明，这些TSFMs，尤其是Chronos模型（它们是在与天文观测数据完全不同的数据上训练的），可以在某些任务中超越已有的天体物理学专用基线，并有效地泛化到全新的数据上。特别是，TSFMs在我们的分布外源检测基准上提供了最先进的性能。通过对天文时间序列数据上TSFMs的首次基准测试，我们测试了它们泛化的极限，并推动了时域天文学的范式转变，即从使用特定任务的、完全有监督的流程转向采用通用基础模型表示来分析来自即将到来的观测站的拍字节级数据集。|
|**2025-10-07**|[Thermodynamic Performance Limits for Score-Based Diffusion Models](http://arxiv.org/abs/2510.06174)|null|我们通过推导基于熵率的性能极限，建立了基于分数的扩散模型与非平衡热力学之间的根本联系。我们的主要理论贡献是数据负对数似然的一个下界，它将模型性能与扩散过程的熵率联系起来。我们在一个合成数据集上数值验证了这个界限并考察了它的紧致性。通过建立与熵率——系统熵、内在熵和交换熵——的桥梁，我们为这些模型的热力学操作提供了新的见解，并将其与麦克斯韦妖进行类比，以及对热力学计算硬件的启示。我们的框架通过随机热力学将生成建模性能与基本物理原理联系起来。|
|**2025-10-07**|[Bimanual 3D Hand Motion and Articulation Forecasting in Everyday Images](http://arxiv.org/abs/2510.06145)|**[link](https://github.com/ap229997/forehand4d)**|我们旨在解决从单张图像预测日常场景中双手三维手部运动与姿态的问题。为了弥补多样化场景中三维手部标注的不足，我们设计了一个标注流程，其中包含一个扩散模型，用于将二维手部关键点序列提升为四维手部运动。对于预测模型，我们采用扩散损失以考虑到手部运动分布中的多模态性。在6个数据集上进行的大量实验表明，在具有插补标签的多样化数据上进行训练带来了显著益处（14%的改进），并且我们的提升（42%的提升）和预测（16.4%的增益）模型相较于最佳基线具有显著有效性，尤其在对日常图像的零样本泛化能力方面表现突出。|
|**2025-10-07**|[Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation](http://arxiv.org/abs/2510.06131)|null|生成式医疗模型的最新进展受限于模态特异性场景，这阻碍了图像、病理和临床笔记中互补证据的整合。这种碎片化限制了它们发展成为能够学习并推理整个生物医学数据范围的基础模型。我们提出了MeDiM，首个医学离散扩散模型，它在没有模态特异性组件的情况下，学习跨模态的共享分布。MeDiM统一了多种生成任务：在图像和文本之间进行翻译，并根据提示在不同领域联合生成图像-报告对。基于离散扩散框架，MeDiM通过共享的概率空间连接了视觉和语言表示。为了实现统一和灵活的医学生成，我们采用多模态大语言模型（MLLM）作为扩散骨干，利用其先验知识和跨模态推理能力。引入了两项关键设计：(1) 移除因果注意力掩码以实现双向上下文，以及 (2) 注入连续时间步嵌入以增强扩散感知。实验表明高保真医学生成（MIMIC-CXR上的FID为16.60，PathGen上的FID为24.19）和准确的报告生成（METEOR分别为0.2650和0.2580）。联合生成的图像-报告对进一步提升了下游性能（BLEU-1提高6.43%，BLEU-2提高18.57%，BLEU-3提高31.58%，METEOR提高4.80%），表明MeDiM支持连贯且具有临床依据的多模态输出。|
|**2025-10-07**|[Towards Data-Efficient Medical Imaging: A Generative and Semi-Supervised Framework](http://arxiv.org/abs/2510.06123)|null|医学影像中的深度学习常受限于稀缺且不平衡的标注数据。我们提出了SSGNet，一个统一的框架，它结合了类别特定的生成建模与迭代半监督伪标签，以提升分类和分割性能。SSGNet并非作为独立模型运行，而是通过使用StyleGAN3生成的图像扩展训练数据，并通过迭代伪标签细化标签来增强现有基线模型。在多个医学影像基准测试上的实验证明了分类和分割性能的持续提升，同时Frechet Inception Distance分析证实了生成样本的高质量。这些结果突出了SSGNet作为一种实用的策略，能够缓解标注瓶颈并提高医学图像分析的鲁棒性。|
|**2025-10-07**|[PolyGraph Discrepancy: a classifier-based metric for graph generation](http://arxiv.org/abs/2510.06122)|null|现有用于评估图生成模型的方法主要依赖于基于图描述符的最大均值差异（MMD）指标。尽管这些指标可以对生成模型进行排序，但它们不提供绝对的性能度量。它们的值也高度依赖于外部参数，即核函数和描述符的参数化，这使得它们在不同的图描述符之间不可比较。我们引入了PolyGraph差异（PGD），这是一个旨在解决这些局限性的新评估框架。它通过拟合二元分类器来区分由这些描述符特征化的真实图和生成图，从而近似图分布的Jensen-Shannon距离。这些分类器的数据对数似然近似了这两个分布之间JS距离的变分下界。所得指标被限制在单位区间[0,1]内，并且在不同的图描述符之间是可比较的。我们进一步推导了一个有理论依据的汇总指标，该指标结合了这些单独的指标，为给定描述符提供了距离的最大紧密下界。彻底的实验表明，与MMD指标相比，PGD提供了更鲁棒和更富有洞察力的评估。用于基准测试图生成模型的PolyGraph框架已在https://github.com/BorgwardtLab/polygraph-benchmark公开提供。|
|**2025-10-07**|[Mechanistic-statistical inference of mosquito dynamics from mark-release-recapture data](http://arxiv.org/abs/2510.06080)|null|针对蚊媒疾病的生物防治策略，例如不育昆虫技术 (SIT)、RIDL 和基于沃尔巴克氏菌的释放，需要可靠地估计所释放雄性的扩散和存活情况。我们提出了一个用于标记-释放-再捕获 (MRR) 数据的机制-统计框架，将基于个体的二维扩散模型与其反应-扩散极限相结合。推断基于求解宏观系统并将其嵌入每日诱捕计数的泊松观测模型中，不确定性通过参数自举法量化。我们使用模拟数据验证了可识别性，并将该模型应用于古巴哈瓦那埃尔卡诺的一次城市MRR活动，该活动涉及四次每周释放不育埃及伊蚊雄性。最受支持的模型表明平均预期寿命约为五天，典型位移约为180米。与存活或扩散的经验拟合不同，我们的机制方法联合估计了移动、死亡率和捕获，产生了生物学上可解释的参数，并为设计和评估基于SIT的干预措施提供了一个有原则的框架。|
|**2025-10-07**|[Controllable Audio-Visual Viewpoint Generation from 360° Spatial Information](http://arxiv.org/abs/2510.06060)|null|随着扩散模型的出现，有声视频的生成取得了显著进展。然而，现有方法通常缺乏从大型沉浸式360度环境中生成视点特定内容所需的细粒度控制。这一局限性限制了创建能够感知画外事件的视听体验。据我们所知，这是首次提出一个用于可控视听生成的框架，解决了这一未被探索的空白。具体而言，我们通过引入一组源自完整360度空间的强大条件信号，提出了一个扩散模型：即用于识别感兴趣区域的全景显著图、用于定义目标视点的边界框感知的有符号距离图以及整个场景的描述性文本。通过整合这些控制，我们的模型生成了受更广泛、不可见环境背景连贯影响的空间感知视点视频和音频，引入了对真实和沉浸式视听生成至关重要的强大可控性。我们展示了视听示例，证明了我们框架的有效性。|
|**2025-10-03**|[Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image Segmentation](http://arxiv.org/abs/2510.03216)|**[link](https://github.com/ATPLab-LUMS/Wave-GMS)**|为了在医院和医疗机构中公平部署AI工具，我们需要高性能且可在内存有限、批次大小大的经济高效GPU上训练的深度分割网络。在这项工作中，我们提出了Wave-GMS，一个用于医学图像分割的轻量级高效多尺度生成模型。Wave-GMS的可训练参数数量大幅减少，无需加载内存密集型预训练视觉基础模型，并支持在内存有限的GPU上使用大批次大小进行训练。我们在四个公开可用数据集（BUS、BUSI、Kvasir-Instrument和HAM10000）上进行了广泛实验，结果表明Wave-GMS实现了最先进的分割性能和卓越的跨域泛化能力，同时仅需约2.6M的可训练参数。代码可在https://github.com/ATPLab-LUMS/Wave-GMS获取。|
|**2025-10-03**|[Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner](http://arxiv.org/abs/2510.03206)|null|扩散语言模型，特别是掩码离散扩散模型，最近取得了巨大成功。尽管一些理论和初步的实证结果表明，循环Transformer或连续思维链的潜在推理具有优势，但连续扩散模型通常不如其离散对应物。在本文中，我们认为扩散语言模型不一定需要在离散空间中。具体而言，我们证明了连续扩散模型比离散扩散和循环Transformer具有更强的表达能力。我们将理论表达能力与经验性能之间的矛盾归因于它们的实际可训练性：虽然连续扩散提供了循环Transformer所缺乏的中间监督，但它们在将token从连续表示空间解码到离散token空间时引入了额外的困难。因此，我们提出了协同演化连续离散扩散（Coevolutionary Continuous Discrete Diffusion, CCDD），它在连续表示空间和离散token空间的并集上定义了一个联合多模态扩散过程，利用一个单一模型在联合空间中同时去噪。通过结合两种模态，CCDD在潜在空间中具有丰富的语义表达能力，并通过显式离散token的帮助，实现了良好的可训练性和样本质量。我们还为CCDD提出了有效的架构和先进的训练/采样技术，这在对真实世界任务进行的大量语言建模实验中展现出强大的经验性能。|
|**2025-10-03**|[Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft](http://arxiv.org/abs/2510.03198)|null|自回归视频扩散模型已被证明对世界建模和交互式场景生成有效，Minecraft游戏玩法是其代表性应用。为了忠实地模拟游戏过程，模型必须在探索新场景时生成自然内容，并在重新访问已探索区域时保持空间一致性。在有限的计算预算下，它必须在有限的上下文窗口内压缩和利用历史线索，这暴露了一个权衡：仅限时间记忆缺乏长期空间一致性，而添加空间记忆则能增强一致性，但当模型过度依赖不足的空间上下文时，可能会降低新场景生成质量。我们提出了记忆强制（Memory Forcing），这是一种将训练协议与几何索引空间记忆相结合的学习框架。混合训练揭示了不同的游戏玩法机制，指导模型在探索期间依赖时间记忆，并在重新访问时结合空间记忆。链式前向训练通过模型推演扩展了自回归训练，其中链式预测创建了更大的姿态变化，并鼓励依赖空间记忆来保持一致性。点到帧检索通过将当前可见点映射到其源帧来有效地检索历史记录，而增量三维重建则维护并更新一个显式三维缓存。大量实验表明，记忆强制在不同环境中实现了卓越的长期空间一致性和生成质量，同时为扩展序列保持了计算效率。|
|**2025-10-03**|[Product-Quantised Image Representation for High-Quality Image Synthesis](http://arxiv.org/abs/2510.03191)|null|乘积量化（PQ）是一种用于可伸缩向量编码的经典方法，但在高保真图像生成中的潜在表示方面应用有限。在这项工作中，我们提出了PQGAN，这是一种量化图像自编码器，它将PQ集成到知名的VQGAN的向量量化（VQ）框架中。PQGAN在重建性能方面比最先进的方法实现了显著改进，包括量化方法及其连续对应物。我们实现了37dB的PSNR分数，而先前工作为27dB，并且能够将FID、LPIPS和CMMD分数降低高达96%。我们成功的关键是对码本大小、嵌入维度和子空间分解之间相互作用的深入分析，其中向量量化和标量量化是特殊情况。我们获得了新颖的发现，例如在缩放嵌入维度时，VQ和PQ的性能表现出相反的方式。此外，我们的分析展示了PQ的性能趋势，有助于指导最佳超参数选择。最后，我们证明了PQGAN可以无缝集成到预训练扩散模型中。这使得生成显著更快、更计算高效，或者在无额外成本的情况下使输出分辨率翻倍，将PQ定位为图像合成中离散潜在表示的强大扩展。|
|**2025-10-03**|[UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization](http://arxiv.org/abs/2510.03161)|null|随着图像生成技术的飞速发展，合成图像变得越来越逼真，带来了严重的社会风险，例如虚假信息和欺诈。因此，伪造图像检测与定位 (FIDL) 对于维护信息完整性和社会安全变得至关重要。尽管现有的领域专用检测方法表现出色，但它们的实际应用性仍然有限，主要归因于它们的狭窄专业化、糟糕的跨领域泛化能力以及缺乏一个集成的自适应框架。为解决这些问题，我们提出了UniShield，一个新颖的基于多智能体的统一系统，能够跨越图像篡改、文档篡改、深度伪造和AI生成图像等不同领域检测和定位图像伪造。UniShield创新性地集成了感知智能体与检测智能体。感知智能体智能地分析图像特征以动态选择合适的检测模型，而检测智能体则将各种专家检测器整合到一个统一框架中并生成可解释的报告。大量实验表明，UniShield取得了最先进的结果，超越了现有的统一方法和领域专用检测器，凸显了其卓越的实用性、适应性和可扩展性。|
|**2025-10-03**|[Mask2IV: Interaction-Centric Video Generation via Mask Trajectories](http://arxiv.org/abs/2510.03135)|null|生成以交互为中心的视频，例如描绘人类或机器人与物体交互的视频，对于具身智能至关重要，因为它们为机器人学习、操作策略训练和可供性推理提供了丰富多样的视觉先验。然而，现有方法通常难以建模此类复杂动态的交互。尽管最近的研究表明掩码可以作为有效的控制信号并提升生成质量，但获取密集精确的掩码标注仍然是实际应用中的主要挑战。为了克服这一局限，我们引入了Mask2IV，这是一个专门为以交互为中心的视频生成设计的新颖框架。它采用解耦的两阶段流程，首先预测执行者和物体的合理运动轨迹，然后基于这些轨迹生成视频。这种设计消除了用户提供密集掩码输入的需要，同时保留了操纵交互过程的灵活性。此外，Mask2IV支持多功能且直观的控制，允许用户指定交互的目标物体，并通过动作描述或空间位置线索引导运动轨迹。为了支持系统的训练和评估，我们创建了两个基准，涵盖了人-物交互和机器人操作场景中多样化的动作和物体类别。大量实验表明，与现有基线相比，我们的方法实现了卓越的视觉真实感和可控性。|
|**2025-10-03**|[HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion](http://arxiv.org/abs/2510.03122)|null|从大脑活动中重建视觉信息促进了神经科学与计算机视觉之间的跨学科融合。然而，现有方法在准确恢复高度复杂的视觉刺激方面仍面临挑战。这一困难源于自然场景的特点：低级特征表现出异质性，而高级特征由于上下文重叠显示出语义纠缠。受视觉皮层分层表征理论的启发，我们提出了HAVIR模型，该模型将视觉皮层分为两个分层区域，并从每个区域提取不同的特征。具体而言，结构生成器从空间处理体素中提取结构信息并将其转换为潜在扩散先验，而语义提取器将语义处理体素转换为CLIP嵌入。这些组件通过多功能扩散模型集成以合成最终图像。实验结果表明，HAVIR即使在复杂场景中也能提高重建的结构和语义质量，并且优于现有模型。|
|**2025-10-03**|[Distilled Protein Backbone Generation](http://arxiv.org/abs/2510.03095)|null|扩散和流基生成模型最近在蛋白质骨架生成任务中表现出强大性能，为从头蛋白质设计提供了前所未有的能力。然而，尽管在生成质量方面取得了显著性能，这些模型受限于其生成速度，通常在逆扩散过程中需要数百个迭代步骤。这一计算瓶颈限制了它们在大规模蛋白质发现中的实际效用，因为大规模发现需要数千到数百万个候选结构。为解决这一挑战，我们探索了分数蒸馏技术，该技术在视觉领域已成功减少采样步骤数并保持高生成质量。然而，直接改编这些方法会导致不可接受的低可设计性。通过广泛研究，我们确定了如何适当调整最先进的分数蒸馏策略——分数恒等蒸馏（SiD），以训练少步蛋白质骨架生成器，从而显著减少采样时间，同时保持与预训练教师模型相当的性能。特别是，多步生成与推理时噪声调制相结合是成功的关键。我们证明，我们蒸馏出的少步生成器在采样速度上实现了超过20倍的提升，同时在可设计性、多样性和新颖性方面达到了与Proteina教师模型相似的水平。推理成本的降低使得大规模计算机辅助蛋白质设计成为可能，从而使扩散模型更接近实际蛋白质工程应用。|
|**2025-10-03**|[Latent Diffusion Unlearning: Protecting Against Unauthorized Personalization Through Trajectory Shifted Perturbations](http://arxiv.org/abs/2510.03089)|null|文生图扩散模型在快速且高保真个性化方面表现出显著成效，即使只提供少量用户图像。然而，个性化技术的有效性引发了关于数据隐私、知识产权保护和未经授权使用的担忧。为了缓解这种未经授权的使用和模型复制，利用图像投毒技术生成“不可学习”训练样本的想法已经出现。现有的相关方法隐蔽性有限，因为它们在像素空间中操作，导致图像中出现噪声和伪影。在这项工作中，我们提出了一种新颖的基于模型的扰动策略，该策略在扩散模型的潜在空间中操作。我们的方法在去噪和反演之间交替，同时修改去噪轨迹的起始点。这种轨迹偏移采样确保扰动后的图像保持与原始输入的高视觉保真度，同时能够抵抗下游生成模型的反演和个性化。这种方法将不可学习性集成到潜在扩散模型（LDMs）的框架中，从而实现了一种实用且不易察觉的防御，以对抗未经授权的模型适应。我们在四个基准数据集上验证了我们的方法，以证明其对最先进反演攻击的鲁棒性。结果表明，我们的方法在隐蔽性（在PSNR、SSIM和FID等感知指标上约为8%至10%）和鲁棒性（在五种对抗性设置下平均约为10%）方面取得了显著改进，突显了其在保护敏感数据方面的有效性。|
|**2025-10-03**|[What Drives Compositional Generalization in Visual Generative Models?](http://arxiv.org/abs/2510.03075)|null|组合泛化，即生成已知概念新颖组合的能力，是视觉生成模型的关键要素。然而，并非所有促成或抑制它的机制都已完全理解。在这项工作中，我们系统性地研究了各种设计选择如何以积极或消极的方式影响图像和视频生成中的组合泛化。通过受控实验，我们确定了两个关键因素：(i) 训练目标是作用于离散分布还是连续分布，以及 (ii) 训练期间条件作用在多大程度上提供了关于构成概念的信息。基于这些见解，我们展示了通过辅助的基于JEPA的连续目标来放松MaskGIT的离散损失，可以提高像MaskGIT这样的离散模型中的组合性能。|
|**2025-10-02**|[Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity](http://arxiv.org/abs/2510.02315)|null|文生图（T2I）模型在单实体提示下表现出色，但难以处理多主体描述，经常出现属性泄露、身份纠缠和主体遗漏。我们提出了首个理论框架，其具有原则性、可优化的目标，用于引导采样动态以实现多主体保真度。通过随机最优控制（SOC）视角审视流匹配（FM），我们将主体解耦问题公式化为对已训练FM采样器的控制。这产生了两种与架构无关的算法：(i) 一种无需训练的测试时控制器，通过单次更新扰动基础速度；以及 (ii) 伴随匹配 (Adjoint Matching)，一种轻量级微调规则，将控制网络回归到反向伴随信号，同时保留基础模型能力。相同的公式统一了先前的注意力启发式方法，通过流-扩散对应关系扩展到扩散模型，并提供了首个明确为多主体保真度设计的微调路径。经验上，在Stable Diffusion 3.5、FLUX和Stable Diffusion XL上，两种算法都持续改进了多主体对齐，同时保持了基础模型的风格。测试时控制在商用GPU上高效运行，并且在有限提示下训练的微调控制器能够泛化到未见过的提示。我们进一步强调了FOCUS（解耦主体的流最优控制），它在各种模型上实现了最先进的多主体保真度。|
|**2025-10-02**|[Inferring Dynamic Physical Properties from Video Foundation Models](http://arxiv.org/abs/2510.02311)|null|我们研究从视频中预测动态物理属性的任务。更具体地说，我们考虑需要时间信息才能推断的物理属性：弹跳物体的弹性、流动液体的粘度以及物体在表面上滑动时的动摩擦。为此，我们做出了以下贡献：(i) 我们为每种物理属性收集了一个新的视频数据集，包含合成训练和测试划分，以及用于真实世界评估的真实划分。(ii) 我们探索了三种从视频中推断物理属性的方法：(a) 一种预言机方法，我们使用经典计算机视觉技术提供本质上反映该属性的视觉线索；(b) 一种简单的读出机制，使用视觉提示和可训练提示向量在预训练视频生成模型和自监督模型上进行交叉注意力；(c) 针对多模态大型语言模型（MLLMs）的提示策略。(iii) 我们表明，以生成式或自监督方式训练的视频基础模型取得了相似的性能，尽管落后于预言机方法，并且MLLMs目前逊于其他模型，尽管它们的性能可以通过合适的提示得到改善。|
|**2025-10-02**|[NoiseShift: Resolution-Aware Noise Recalibration for Better Low-Resolution Image Generation](http://arxiv.org/abs/2510.02307)|null|在固定分辨率集上训练的文生图扩散模型，即使被要求生成低于训练时所见分辨率的图像时，其泛化能力也往往不足。目前，高分辨率文生图生成器难以轻松地为那些可能不需要高分辨率图像的用户提供一种开箱即用且经济高效的替代方案。我们发现了扩散模型中的一个关键技术洞察，解决它有助于克服这一局限性：噪声调度器在不同分辨率下具有不等的感知效果。相同水平的噪声从低分辨率图像中移除的信号比从高分辨率图像中移除的更多，这导致了训练与测试的不匹配。我们提出了NoiseShift，这是一种无需训练的方法，它可以根据分辨率大小重新校准去噪器的噪声水平。NoiseShift无需更改模型架构或采样调度，且与现有模型兼容。当应用于Stable Diffusion 3、Stable Diffusion 3.5和Flux-Dev时，低分辨率下的图像质量得到显著提升。在LAION-COCO数据集上，NoiseShift平均将SD3.5的FID提高了15.89%，SD3提高了8.56%，Flux-Dev提高了2.44%。在CelebA数据集上，NoiseShift平均将SD3.5的FID提高了10.36%，SD3提高了5.19%，Flux-Dev提高了3.02%。这些结果证明了NoiseShift在缓解分辨率相关伪影和提高低分辨率图像生成质量方面的有效性。|
|**2025-10-02**|[Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is Geometry Adaptive](http://arxiv.org/abs/2510.02305)|null|扩散模型已取得最先进的性能，在各种领域展现出卓越的泛化能力。然而，支撑这些强大能力的机制仍仅部分被理解。一个主要猜想，基于流形假设，将此成功归因于它们适应数据中低维几何结构的能力。本工作为此猜想提供了证据，侧重于这种现象如何通过分数匹配的学习问题表述而产生。我们通过研究平滑经验分数匹配目标极小值点的效果来考察隐式正则化的作用。我们的理论和经验结果证实，平滑分数函数——或等价地，在对数密度域中进行平滑——会产生与数据流形相切的平滑。此外，我们表明，扩散模型泛化所沿的流形可以通过选择适当的平滑来控制。|
|**2025-10-02**|[Knowledge Distillation Detection for Open-weights Models](http://arxiv.org/abs/2510.02302)|**[link](https://github.com/shqii1j/distillation_detection)**|我们提出了知识蒸馏检测任务，旨在确定一个学生模型是否由给定的教师模型蒸馏而来，且仅在可获取学生模型权重和教师模型API的实际设置下进行。这个问题源于对模型来源和通过蒸馏进行未经授权复制的日益增长的担忧。为了解决这项任务，我们引入了一个与模型无关的框架，该框架结合了无数据输入合成和统计分数计算来检测蒸馏。我们的方法适用于分类模型和生成模型。在用于图像分类和文本到图像生成的多种架构上的实验表明，我们的方法在检测准确性方面比最强的基线提高了，具体为在CIFAR-10上提高了59.6%，在ImageNet上提高了71.2%，以及在文本到图像生成任务上提高了20.0%。代码可在https://github.com/shqii1j/distillation_detection获取。|
|**2025-10-02**|[Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models](http://arxiv.org/abs/2510.02300)|null|我们引入了平衡匹配（EqM），一个从平衡动力学视角构建的生成建模框架。EqM 摒弃了传统扩散模型和基于流的生成模型中的非平衡、时间条件动力学，转而学习隐式能量景观的平衡梯度。通过这种方法，我们可以在推理时采用基于优化的采样过程，其中样本通过在所学景观上进行梯度下降获得，并可使用可调节步长、自适应优化器和自适应计算。经验上，EqM 在生成性能上超越了扩散/流模型，在ImageNet 256 $\times$ 256数据集上实现了1.90的FID。EqM 在理论上也证明能够从数据流形中学习和采样。除了生成之外，EqM 是一个灵活的框架，可以自然地处理包括部分加噪图像去噪、OOD检测和图像合成在内的任务。通过用统一的平衡景观替代时间条件速度，EqM 在基于流的模型和基于能量的模型之间提供了更紧密的桥梁，并为优化驱动的推理提供了一个简单途径。|
|**2025-10-02**|[Continual Personalization for Diffusion Models](http://arxiv.org/abs/2510.02296)|null|在增量设置下更新扩散模型在实际应用中具有实用性，但在计算上具有挑战性。我们提出了一种新颖的学习策略——概念神经元选择（CNS），这是一种在持续学习方案中执行个性化的简单而有效的方法。CNS独特地识别扩散模型中与目标概念密切相关的神经元。为了缓解灾难性遗忘问题，同时保留零样本文本到图像生成能力，CNS以增量方式微调概念神经元，并共同保留了先前概念学到的知识。真实世界数据集的评估表明，CNS以最少的参数调整实现了最先进的性能，在单概念和多概念个性化工作中均优于以前的方法。CNS还实现了无融合操作，减少了持续个性化的内存存储和处理时间。|
|**2025-10-02**|[Test-Time Anchoring for Discrete Diffusion Posterior Sampling](http://arxiv.org/abs/2510.02291)|**[link](https://github.com/LituRout/APS)**|我们研究了使用预训练离散扩散基础模型进行后验采样的问题，旨在无需重新训练特定任务模型即可从带噪声测量中恢复图像。尽管扩散模型在生成建模方面取得了显著成功，但大多数进展依赖于连续高斯扩散。相比之下，离散扩散提供了一个统一框架，用于联合建模文本和图像等类别数据。除了统一性之外，离散扩散还提供更快的推理、更精细的控制以及原则上无需训练的贝叶斯推理，使其特别适合后验采样。然而，现有离散扩散后验采样方法面临严峻挑战：无导数引导产生稀疏信号，连续松弛限制了适用性，分裂吉布斯采样器遭受维度灾难。为克服这些局限性，我们为掩码扩散基础模型引入了锚定后验采样（APS），该方法基于两项关键创新——在离散嵌入空间中用于类梯度引导的量化期望，以及用于自适应解码的锚定重掩码。我们的方法在标准基准测试的线性和非线性逆问题上，在离散扩散采样器中实现了最先进的性能。我们进一步展示了我们方法在免训练风格化和文本引导编辑中的优势。|
|**2025-10-02**|[MultiModal Action Conditioned Video Generation](http://arxiv.org/abs/2510.02287)|**[link](https://github.com/Aryia-Behroziuan/References)**|当前视频模型作为世界模型表现不佳，因为它们缺乏细粒度控制。通用家用机器人需要实时精细运动控制，以处理精细任务和紧急情况。在这项工作中，我们引入了细粒度多模态动作来捕捉这种精确控制。我们考虑了本体感觉、动觉、力触觉和肌肉激活等感知能力。这种多模态感知自然地实现了细粒度交互，而这些交互是文本条件生成模型难以模拟的。为了有效模拟细粒度多感官动作，我们开发了一种特征学习范式，该范式对这些模态进行对齐，同时保留每种模态提供的独特信息。我们进一步提出了一种正则化方案，以增强动作轨迹特征在表示复杂交互动力学时的因果关系。实验表明，结合多模态感知可以提高模拟精度并减少时间漂移。广泛的消融研究和下游应用证明了我们工作的有效性和实用性。|
|**2025-10-02**|[Learning to Generate Object Interactions with Physics-Guided Video Diffusion](http://arxiv.org/abs/2510.02284)|null|近期视频生成模型已取得显著进展，现已应用于电影、社交媒体制作和广告。除了其创造性潜力，此类模型还有望成为用于机器人技术和具身决策的世界模拟器。然而，尽管取得了巨大进步，当前方法在生成物理上可信的物体交互方面仍面临挑战，并且缺乏基于物理的控制机制。为了解决这一局限性，我们引入了KineMask，一种物理引导的视频生成方法，能够实现逼真的刚体控制、交互和效果。给定单张图像和指定的物体速度，我们的方法生成具有推断运动和未来物体交互的视频。我们提出了一种两阶段训练策略，通过物体掩码逐步移除未来运动监督。利用这一策略，我们在简单交互的合成场景中训练视频扩散模型（VDM），并展示了真实场景中物体交互的显著改进。此外，KineMask通过预测性场景描述将低级运动控制与高级文本条件结合，有效支持了复杂动态现象的合成。大量实验表明，KineMask相比于规模相似的近期模型取得了显著改进。消融研究进一步强调了VDM中低级和高级条件的互补作用。我们的代码、模型和数据将公开可用。|
|**2025-09-30**|[Stitch: Training-Free Position Control in Multimodal Diffusion Transformers](http://arxiv.org/abs/2509.26644)|null|近年来，文生图（T2I）生成模型发展迅速，但准确捕捉“在……上方”或“在……右侧”等空间关系仍是一个持续存在的挑战。早期方法通过外部位置控制改善了空间关系遵循能力。然而，随着架构演进以提升图像质量，这些技术与现代模型变得不兼容。我们提出了Stitch，一种免训练方法，通过自动生成的边界框将外部位置控制整合到多模态扩散Transformer（MMDiT）中。Stitch通过在指定边界框内生成单个对象并将其无缝拼接，生成的图像既空间准确又视觉美观。我们发现，定向注意力头能够捕获必要信息，在生成过程中隔离并剪切单个对象，而无需完全完成图像。我们在PosEval上评估了Stitch，这是我们针对基于位置的T2I生成的基准。PosEval包含五个新任务，将位置概念扩展到超越基本GenEval任务的范围，表明即使是顶级模型，在基于位置的生成方面仍有显著提升空间。在Qwen-Image、FLUX和SD3.5上进行测试，Stitch持续增强了基础模型，甚至将FLUX在GenEval的位置任务上提升了218%，在PosEval上提升了206%。Stitch在PosEval上与Qwen-Image结合取得了最先进的结果，相较于现有模型提升了54%，所有这些都是在免训练的情况下将位置控制整合到领先模型中实现的。代码可在https://github.com/ExplainableML/Stitch获取。|
|**2025-09-30**|[Query-Kontext: An Unified Multimodal Model for Image Generation and Editing](http://arxiv.org/abs/2509.26641)|null|统一多模态模型（UMMs）在文本到图像生成（T2I）和编辑（TI2I）方面表现出卓越的性能，无论是作为将强大的视觉-语言模型（VLM）与基于扩散的生成器耦合的组装式统一框架，还是作为理解与生成模态早期融合的朴素统一多模态模型。我们认为，在当前的统一框架中，多模态生成推理的关键能力，即涵盖指令理解、接地以及用于身份保持和忠实重建的图像指代，与高保真合成内在纠缠。在这项工作中，我们引入了Query-Kontext，这是一种新颖的方法，通过由从多模态输入中编码的语义线索和粗粒度图像条件组成的多模态“kontext”来连接VLM和扩散模型。这种设计将多模态生成推理的复杂能力委托给强大的VLM，同时保留扩散模型用于高质量视觉合成的作用。为此，我们提出了一种三阶段渐进式训练策略。首先，我们通过多模态kontext令牌将VLM连接到轻量级扩散头部，以释放VLM的生成推理能力。其次，我们将此头部扩展到大型预训练扩散模型，以增强视觉细节和真实感。最后，我们引入一个低级图像编码器来提高图像保真度，并在下游任务上执行指令微调。此外，我们构建了一个综合数据管道，集成了真实、合成和开源数据集，涵盖了多样化的多模态图像参考场景，包括图像生成、指令驱动编辑、定制生成和多主体组合。实验表明，我们的方法与强大的统一基线相匹配，在某些情况下甚至超越了特定任务的最先进方法。|
|**2025-09-30**|[Video Object Segmentation-Aware Audio Generation](http://arxiv.org/abs/2509.26604)|**[link](https://github.com/ilpoviertola/SAGANet)**|现有的多模态音频生成模型通常缺乏精确的用户控制，这限制了它们在专业拟音工作流程中的应用性。特别是，这些模型侧重于整个视频，并且未能提供精确的方法来优先处理场景中的特定对象，导致生成不必要的背景声音或将注意力集中在错误的对象上。为弥补这一不足，我们提出了一项新颖的视频对象分割感知音频生成任务，该任务明确地将声音合成与对象级分割图进行条件关联。我们提出了SAGANet，这是一种新的多模态生成模型，它通过利用视觉分割掩码以及视频和文本提示来实现可控音频生成。我们的模型为用户提供了对音频生成的细粒度和视觉局部化控制。为了支持这项任务并进一步研究分割感知拟音，我们提出了Segmented Music Solos，这是一个包含分割信息的乐器演奏视频基准数据集。我们的方法在现有最先进方法的基础上取得了显著改进，并为可控、高保真拟音合成树立了新标准。代码、样本和Segmented Music Solos可在https://saganet.notion.site获取。|
|**2025-09-30**|[Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation](http://arxiv.org/abs/2509.26555)|null|视频生成领域的最新进展已能实现从用户提供的提示词生成高保真视频。然而，现有模型和基准未能捕捉专业视频生成的复杂性和要求。为此，我们引入了稳定电影计量学 (Stable Cinemetrics)，这是一个结构化评估框架，将电影制作控制规范为四个相互独立、层级化的分类体系：设置、事件、光照和摄像机。这些分类体系共同定义了76个根植于行业实践的细粒度控制节点。利用这些分类体系，我们构建了一个与专业用例相符的提示词基准，并开发了一个用于提示词分类和问题生成的自动化流程，从而能够独立评估每个控制维度。我们进行了一项大规模人工研究，涵盖10多个模型和2万个视频，由80多名电影专业人士组成的团队进行标注。我们的分析，无论是粗粒度还是细粒度，都揭示出即使是目前最强大的模型也存在显著差距，尤其是在事件和摄像机相关控制方面。为了实现可扩展的评估，我们训练了一个自动评估器，这是一个与专家标注对齐的视觉-语言模型，其性能优于现有的零样本基线。SCINE是将专业视频生成置于视频生成模型领域中的首个方法，它引入了以电影控制为核心的分类体系，并通过结构化评估流程和详细分析来支持这些体系，以指导未来的研究。|
|**2025-09-30**|[The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models](http://arxiv.org/abs/2509.26543)|null|对比解释，即说明AI系统为何产生某个输出（目标）而非另一个输出（对照），在可解释AI领域被广泛认为比标准解释更具信息量和可解释性。然而，为语音转文本（S2T）生成模型获取此类解释仍然是一个开放的挑战。借鉴特征归因技术，我们提出了第一个在S2T中获取对比解释的方法，通过分析输入语谱图的哪些部分影响了在不同输出之间的选择。通过一项关于语音翻译中性别分配的案例研究，我们表明我们的方法能够准确识别驱动选择一种性别而非另一种性别的音频特征。通过将对比解释的范围扩展到S2T，我们的工作为更好地理解S2T模型提供了基础。|
|**2025-09-30**|[HilbertA: Hilbert Attention for Image Generation with Diffusion Models](http://arxiv.org/abs/2509.26538)|null|为扩散Transformer设计稀疏注意力需要协调二维空间局部性与GPU效率，这是当前方法难以实现的权衡。现有方法强制保证二维空间局部性，但通常会导致非合并内存访问。我们提出了HilbertA，一种二维感知且GPU高效的稀疏注意力机制。HilbertA沿着希尔伯特曲线重新排序图像token，以实现连续内存布局同时保留空间邻域，并跨层采用滑动调度，从而在没有重复或非合并内存访问的情况下实现长距离信息传播。为进一步增强跨瓦片通信和位置感知，HilbertA引入了一个小型中央共享区域。在Triton中实现后，HilbertA在Flux.1-dev上与先前方法相比，在提供可比图像质量的同时实现了显著加速，证明了硬件对齐的二维稀疏注意力在高分辨率图像生成中的可行性。HilbertA在生成 $1024\times 1024$图像时提供了$2.3\times$的注意力加速，在$2048\times 2048$时高达$4.17\times$ ，同时实现了与基线相当或超越基线的图像质量。|
|**2025-09-30**|[Interdisciplinary Digital Twin Engine InterTwin for calorimeter simulation](http://arxiv.org/abs/2509.26527)|null|量能器簇射模拟计算成本高昂，而生成模型提供了一种高效的替代方案。然而，在准确性和速度之间取得平衡仍然是一个挑战，其中分布尾部建模是主要的限制。可逆生成网络CaloINN在模拟质量和效率之间提供了一种权衡。正在进行的研究旨在引入一系列针对分析级可观测值的后处理修改，以提高分布尾部的准确性。作为开发开源数字孪生引擎的interTwin项目倡议的一部分，我们在interTwin AI框架内实现了CaloINN。|
|**2025-09-30**|[STaR-Attack: A Spatio-Temporal and Narrative Reasoning Attack Framework for Unified Multimodal Understanding and Generation Models](http://arxiv.org/abs/2509.26473)|null|统一多模态理解与生成模型（UMM）在理解和生成任务中都展现了卓越的能力。然而，我们发现UMM中存在一个源于生成-理解耦合的漏洞。攻击者可以利用生成功能制作一个信息丰富的对抗性图像，然后利用理解功能在单次处理中吸收该图像，我们称之为跨模态生成注入（CMGI）。当前针对恶意指令的攻击方法通常局限于单一模态，并且依赖于带有语义漂移的提示重写，这使得UMM的独特漏洞未被探索。我们提出了STaR-Attack，这是首个利用UMM独特安全弱点且不带语义漂移的多轮越狱攻击框架。具体而言，我们的方法在时空上下文中定义了一个与目标查询强相关的恶意事件。STaR-Attack利用三幕叙事理论，生成事件前和事件后的场景，同时将恶意事件隐藏为高潮。在执行攻击策略时，最初两轮利用UMM的生成能力为这些场景生成图像。随后，通过利用其理解能力，引入了一种基于图像的问题猜测和回答游戏。STaR-Attack将原始恶意问题嵌入良性候选问题中，迫使模型在给定叙事上下文的情况下选择并回答最相关的问题。大量实验表明，STaR-Attack持续超越现有方法，在Gemini-2.0-Flash上实现高达93.06%的ASR，并超越了最强的现有基线FlipAttack。我们的工作揭示了一个关键但未充分开发的漏洞，并强调了UMM中安全对齐的必要性。|
|**2025-09-30**|[DiVeQ: Differentiable Vector Quantization Using the Reparameterization Trick](http://arxiv.org/abs/2509.26469)|null|向量量化在深度模型中很常见，但其硬分配会阻断梯度并阻碍端到端训练。我们提出DiVeQ，它将量化视为添加一个模仿量化失真的误差向量，从而保持前向传播的硬性，同时允许梯度流动。我们还提出了一种空间填充变体（SF-DiVeQ），它分配到一个由连接码字的线构建的曲线，从而实现更小的量化误差和码本的充分利用。这两种方法都无需辅助损失或温度调度即可进行端到端训练。在各种数据集上的VQ-VAE压缩和VQGAN生成任务中，它们相较于其他量化方法改进了重建和样本质量。|
|**2025-09-30**|[Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models](http://arxiv.org/abs/2509.26436)|null|扩散模型能够生成高质量图像，但由于其高计算需求而面临部署挑战。尽管8比特离群值感知训练后量化 (PTQ) 能够达到与全精度相当的性能，但将PTQ扩展到4比特仍然充满挑战。4比特量化中更大的步长会放大密集、低幅度激活中的舍入误差，导致精细纹理的丢失。我们假设不仅离群值，小幅度激活也对纹理保真度至关重要。为此，我们提出了一种用于扩散模型的4比特PTQ方案，即通过残差截断和零抑制的量化 (QuaRTZ)。QuaRTZ采用8比特min-max量化处理离群值，并通过前导零抑制压缩到4比特以保留最低有效位 (LSB)，从而保留纹理细节。我们的方法通过平衡离群值保留和最低有效位 (LSB) 精度，减少了舍入误差并提高了量化效率。理论推导和经验评估均表明QuaRTZ在不同激活分布下具有良好的泛化能力。值得注意的是，4比特QuaRTZ在FLUX.1-schnell上实现了6.98的FID，优于需要辅助FP16分支的SVDQuant。|
|**2025-09-26**|[Pixel Motion Diffusion is What We Need for Robot Control](http://arxiv.org/abs/2509.22652)|null|我们提出了DAWN (Diffusion is All We Need for robot control)，这是一个统一的基于扩散的框架，用于语言条件下的机器人操作，它通过结构化的像素运动表示桥接了高级运动意图和低级机器人动作。在DAWN中，高级和低级控制器都被建模为扩散过程，从而产生了一个完全可训练的端到端系统，具有可解释的中间运动抽象。DAWN在具有挑战性的CALVIN基准测试中取得了最先进的结果，展示了强大的多任务性能，并进一步在MetaWorld上验证了其有效性。尽管模拟与现实之间存在显著的领域差距且现实世界数据有限，我们仍展示了仅需少量微调即可实现可靠的真实世界迁移，阐明了基于扩散的运动抽象在机器人控制中的实际可行性。我们的结果表明，将扩散建模与以运动为中心的表示相结合，可作为可扩展和鲁棒机器人学习的强大基线。项目页面：https://nero1342.github.io/DAWN/|
|**2025-09-26**|[RefAM: Attention Magnets for Zero-Shot Referral Segmentation](http://arxiv.org/abs/2509.22650)|null|目前大多数指代分割方法仅通过微调或组合多个预训练模型来实现强大性能，这通常以额外训练和架构修改为代价。同时，大规模生成扩散模型编码了丰富的语义信息，使其作为通用特征提取器具有吸引力。在这项工作中，我们引入了一种新方法，直接利用来自扩散Transformer的特征（即注意力分数）进行下游任务，既不需要架构修改也不需要额外训练。为了系统地评估这些特征，我们通过涵盖图像和视频的视觉-语言基础任务扩展了基准。我们的关键见解是停用词充当注意力磁铁：它们累积过剩注意力，并且可以通过过滤来减少噪声。此外，我们识别出在更深层出现的全局注意力汇聚点（GAS），并表明它们可以安全地被抑制或重定向到辅助词元，从而得到更清晰、更准确的基础图。我们进一步提出了一种注意力再分配策略，其中添加的停用词将背景激活划分成更小的簇，产生更清晰、更局部的热图。基于这些发现，我们开发了RefAM，一个简单的免训练基础框架，它结合了交叉注意力图、GAS处理和再分配。在零样本指代图像和视频分割基准上，我们的方法始终优于现有方法，在无需微调或额外组件的情况下建立了新的领先水平。|
|**2025-09-26**|[Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs](http://arxiv.org/abs/2509.22646)|null|人类能否识别AI生成（伪造）视频并提供有根据的理由？尽管视频生成模型发展迅速，但一个关键维度——即人类能否在生成的视频中检测到深度伪造痕迹（也就是揭示视频为机器生成的时空有依据的视觉伪影）——却在很大程度上被忽视了。我们引入了DeeptraceReward，这是首个细粒度、空间感知和时间感知的基准，用于标注人类感知到的伪造痕迹，以作为视频生成奖励。该数据集包含4.3K条详细标注，涵盖3.3K个高质量生成视频。每条标注都提供自然语言解释，精确指出包含感知痕迹的边界框区域，并标记精确的起始和结束时间戳。我们将这些标注整合为9个主要类别的深度伪造痕迹，这些痕迹使人类能够识别视频为AI生成，并训练多模态语言模型（LMs）作为奖励模型，以模仿人类的判断和定位。在DeeptraceReward上，我们的7B奖励模型在伪造线索识别、定位和解释方面平均比GPT-5高出34.7%。有趣的是，我们观察到一个一致的难度梯度：二元真假分类明显比细粒度深度伪造痕迹检测更容易；在后者中，性能从自然语言解释（最容易）到空间定位，再到时间标注（最难）逐渐下降。通过突出人类感知的深度伪造痕迹，DeeptraceReward为实现具有社会意识和值得信赖的视频生成提供了一个严谨的测试平台和训练信号。|
|**2025-09-26**|[Language Models Can Learn from Verbal Feedback Without Scalar Rewards](http://arxiv.org/abs/2509.22638)|**[link](https://github.com/sail-sg/feedback-conditional-policy)**|大型语言模型（LLMs）通常通过人类或AI反馈进行强化学习（RL）训练，然而此类方法通常将细致的反馈压缩成标量奖励，丢弃了其大部分丰富性并导致尺度不平衡。我们提出将语言反馈视为条件信号。受文本到图像生成中语言先验的启发（这使得从未见过的提示也能生成新颖的输出），我们引入了反馈条件策略（FCP）。FCP直接从响应-反馈对中学习，通过离线数据的最大似然训练来近似反馈条件后验。我们进一步开发了一个在线自举阶段，在该阶段中，策略在积极条件下生成并接收新的反馈以完善自身。这重新定义了反馈驱动学习为条件生成而非奖励优化，为LLMs直接从语言反馈中学习提供了一种更具表达力的方式。我们的代码可在https://github.com/sail-sg/feedback-conditional-policy获取。|
|**2025-09-26**|[Scale-Wise VAR is Secretly Discrete Diffusion](http://arxiv.org/abs/2509.22636)|null|自回归（AR）Transformer已成为视觉生成领域的一种强大范式，这主要归因于它们的可扩展性、计算效率以及与语言和视觉统一的架构。其中，下一尺度预测视觉自回归生成（VAR）最近展现出卓越性能，甚至超越了基于扩散的模型。在这项工作中，我们重新审视了VAR，并揭示了一个理论见解：当配备马尔可夫注意力掩码时，VAR在数学上等同于离散扩散。我们将这种重新解释命名为基于离散扩散的可扩展视觉细化（SRDD），从而在AR Transformer与扩散模型之间建立了一个原则性桥梁。利用这一新视角，我们展示了如何直接引入扩散模型的优势，例如迭代细化，并减少VAR中的架构低效性，从而带来更快的收敛、更低的推理成本以及改进的零样本重建。在多个数据集上，我们表明VAR的基于扩散的视角在效率和生成方面带来了持续的提升。|
|**2025-09-26**|[Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance](http://arxiv.org/abs/2509.22635)|null|小样本图像分类由于标注样本数量有限而仍具挑战。近期方法探索了使用文本到图像扩散模型生成合成训练数据，但通常需要大量的模型微调或外部信息源。我们提出了一种新颖的免训练方法DIPSY，它利用IP-Adapter进行图像到图像翻译，仅使用现有的小样本生成高度判别性的合成图像。DIPSY引入了三项关键创新：(1)一种扩展的无分类器引导方案，能够独立控制正向和负向图像条件；(2)一种基于类别相似度的采样策略，用于识别有效的对比样本；以及(3)一个简单而有效的流程，无需模型微调或外部字幕生成和过滤。在十个基准数据集上的实验表明，我们的方法达到了最先进或可比的性能，同时消除了对生成模型适应或对用于字幕生成和图像过滤的外部工具的依赖。我们的结果突出了利用双图像提示结合正负向引导在生成类别判别性特征方面的有效性，特别是对于细粒度分类任务。|
|**2025-09-26**|[A Theoretical Analysis of Discrete Flow Matching Generative Models](http://arxiv.org/abs/2509.22623)|null|我们对端到端训练的离散流匹配（DFM）生成模型提供了理论分析。DFM是一种有前景的离散生成建模框架，它通过训练神经网络来近似变换速度场，从而学习底层的生成动力学。我们的分析通过分解最终的分布估计误差，建立了一系列明确的保证。我们首先证明，生成分布与目标分布之间的全变差距离受所学速度场的风险控制。接着，我们通过分析该风险的两个主要来源来对其进行约束：(i) 近似误差，我们量化了Transformer架构表示真实速度的能力；以及 (ii) 估计误差，我们推导了统计收敛速度，以限制在有限数据集上训练所产生的误差。通过综合这些结果，我们首次提供了正式证明，表明随着训练集规模的增加，经过训练的DFM模型生成的分布可证明地收敛到真实数据分布。|
|**2025-09-26**|[LongLive: Real-time Interactive Long Video Generation](http://arxiv.org/abs/2509.22622)|null|我们提出了LongLive，一个帧级自回归（AR）框架，用于实时交互式长视频生成。长视频生成在效率和质量方面都面临挑战。扩散模型和强制扩散模型可以生成高质量视频，但由于双向注意力机制而效率低下。因果注意力AR模型支持KV缓存以加速推理，但由于长视频训练期间的内存挑战，在长视频上质量往往下降。此外，除了静态提示生成之外，交互能力（例如流式提示输入）对于动态内容创建至关重要，使用户能够实时引导叙事。这种交互式需求显著增加了复杂性，尤其是在确保提示转换期间的视觉一致性和语义连贯性方面。为了解决这些挑战，LongLive采用了因果的帧级AR设计，该设计集成了KV重缓存机制（该机制用新提示刷新缓存状态，以实现平滑、一致的切换）、流式长时微调（以支持长视频训练并对齐训练与推理，即“训练长，测试长”）以及短窗口注意力机制与帧级注意力槽（简称“帧槽”）相结合（在实现更快生成的同时保持长程一致性）。凭借这些关键设计，LongLive仅需32个GPU日就将一个13亿参数的短片段模型微调至分钟级视频生成。在推理时，LongLive在单个NVIDIA H100上保持20.7 FPS，并在短视频和长视频的VBench测试中都取得了优异性能。LongLive在单个H100 GPU上支持长达240秒的视频。LongLive进一步支持INT8量化推理，且仅有微小的质量损失。|
|**2025-09-26**|[Transport Based Mean Flows for Generative Modeling](http://arxiv.org/abs/2509.22592)|null|流匹配生成模型已成为连续数据生成的一种强大范式，在图像、3D形状和点云等领域取得了最先进的结果。尽管它们取得了成功，但这些模型由于需要大量顺序采样步骤而面临推理速度慢的问题。近期工作旨在通过减少采样步骤数量来加速推理。特别是，均值流提供了一种一步生成方法，在保持强大生成性能的同时显著提高了速度。然而，在许多连续域中，均值流未能忠实地近似原始多步流匹配过程的行为。在这项工作中，我们通过将基于最优传输的采样策略整合到均值流框架中来解决这一局限性，从而使一步生成器能够更好地保留原始多步流过程的真实性和多样性。在受控低维设置以及图像生成、图像到图像翻译和点云生成等高维任务上的实验表明，我们的方法在一步生成建模中实现了卓越的推理准确性。|
|**2025-09-26**|[EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation](http://arxiv.org/abs/2509.22578)|null|基于模仿学习的策略在机器人操作中表现良好，但当它们从单一自我中心视角训练时，在自我中心视角偏移下性能通常会下降。为解决此问题，我们提出了EgoDemoGen，这是一个通过在新自我中心帧中重定向动作并使用我们提出的生成式视频修复模型EgoViewTransfer合成相应自我中心观察视频来生成成对新自我中心视演示的框架，该模型以新视角重投影的场景视频和从重定向关节动作渲染的仅包含机器人的视频为条件。EgoViewTransfer使用自监督双重重投影策略从预训练的视频生成模型进行微调。我们在仿真（RoboTwin2.0）和真实世界机器人上评估了EgoDemoGen。在使用EgoDemoGen生成的新自我中心视演示和原始标准自我中心视演示的混合数据进行训练后，策略成功率在标准自我中心视角下绝对提高了+17.0%，并在仿真中，在新自我中心视角下绝对提高了+17.7%。在真实世界机器人上，绝对改进分别为+18.3%和+25.8%。此外，随着EgoDemoGen生成演示比例的增加，性能持续提升，但回报递减。这些结果表明EgoDemoGen为实现对自我中心视角鲁棒的机器人操作提供了一条实用的途径。|
|**2025-09-25**|[SD3.5-Flash: Distribution-Guided Distillation of Generative Flows](http://arxiv.org/abs/2509.21318)|null|我们提出了SD3.5-Flash，这是一个高效的少步蒸馏框架，将高质量图像生成普及到消费级设备。我们的方法通过专门针对少步生成重新设计的分布匹配目标，蒸馏了计算成本高昂的修正流模型。我们引入了两项关键创新：“时间步共享”以减少梯度噪声，以及“分步时间步微调”以提高提示对齐。结合文本编码器重构和专用量化等全面的流水线优化，我们的系统实现了跨不同硬件配置的快速生成和内存高效部署。这使得从手机到台式电脑等全系列设备都能普及访问。通过包括大规模用户研究在内的广泛评估，我们证明SD3.5-Flash始终优于现有少步方法，使先进的生成式AI真正可用于实际部署。|
|**2025-09-25**|[NewtonGen: Physics-Consistent and Controllable Text-to-Video Generation via Neural Newtonian Dynamics](http://arxiv.org/abs/2509.21309)|null|当今大规模文本到视频生成的主要瓶颈是物理一致性和可控性。尽管近期取得了进展，但最先进的模型通常会产生不真实的运动，例如物体向上坠落，或速度和方向的突然变化。此外，这些模型缺乏精确的参数控制，难以在不同的初始条件下生成物理一致的动力学。我们认为，这一根本性局限源于当前模型仅从外观学习运动分布，而缺乏对底层动力学的理解。在这项工作中，我们提出了NewtonGen，一个将数据驱动合成与可学习物理原理相结合的框架。其核心是可训练的神经牛顿动力学（NND），它能够建模和预测多种牛顿运动，从而将潜在的动力学约束注入视频生成过程。通过联合利用数据先验和动力学指导，NewtonGen能够实现具有精确参数控制的物理一致视频合成。|
|**2025-09-25**|[Taxonomy-aware Dynamic Motion Generation on Hyperbolic Manifolds](http://arxiv.org/abs/2509.21281)|null|机器人的人形动作生成通常借鉴生物力学研究，这些研究常将复杂的人体动作归类到层级分类体系中。尽管这些分类法提供了关于动作之间如何相互关联的丰富结构信息，但这种信息在动作生成模型中经常被忽视，导致生成的动作与其底层层级结构之间存在脱节。本文介绍了GPHDM，这是一种新颖的方法，它学习潜在表示，同时保留动作的层级结构和时间动态性，以确保物理一致性。我们的模型通过将高斯过程动力学模型（GPDM）的动力学先验扩展到双曲流形，并将其与分类法感知的归纳偏置相结合来实现这一点。基于这种几何和分类法感知框架，我们提出了三种新颖的机制，用于生成既具有分类结构又物理一致的动作：两种概率递归方法和一种基于回拉度量测地线的方法。在手抓取分类法上生成逼真动作序列的实验表明，所提出的GPHDM忠实地编码了底层分类法和时间动态性，并生成了新颖的物理一致轨迹。|
|**2025-09-25**|[Does FLUX Already Know How to Perform Physically Plausible Image Composition?](http://arxiv.org/abs/2509.21278)|null|图像合成旨在将用户指定对象无缝插入新场景，但现有模型难以处理复杂光照（例如，精确阴影、水面反射）以及多样化、高分辨率的输入。现代文本到图像扩散模型（例如，SD3.5、FLUX）已编码基本的物理和分辨率先验知识，但缺乏一个框架来释放它们，而无需诉诸于潜在空间反演（这常将物体姿态锁定在上下文不合适的方向上）或脆弱的注意力操作。我们提出了SHINE，一个用于消除误差的无缝高保真插入的免训练框架。SHINE引入了流形引导锚点损失，利用预训练定制适配器（例如，IP-Adapter）来引导潜在表示，以实现忠实的主体表示，同时保持背景完整性。我们还提出了降级抑制引导和自适应背景融合，以进一步消除低质量输出和可见接缝。为解决缺乏严格基准的问题，我们引入了ComplexCompo，它具有多样化的分辨率和挑战性条件，例如低光照、强光照、复杂阴影和反射表面。在ComplexCompo和DreamEditBench上的实验表明，SHINE在标准度量（例如，DINOv2）和与人类感知一致的分数（例如，DreamSim、ImageReward、VisionReward）上均表现出最先进的性能。代码和基准将在发布时公开可用。|
|**2025-09-25**|[Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](http://arxiv.org/abs/2509.21262)|**[link](https://github.com/nagadit/Un-Doubling-Diffusion)**|同形异义词是指拼写相同但意义不同的词语，它们对许多生成模型构成了挑战。当提示中出现同形异义词时，扩散模型可能会同时生成该词的多种含义，这被称为同形异义词重复问题。这个问题因盎格鲁中心偏见而进一步复杂化，这种偏见在文本到图像模型流程之前包含一个额外的翻译步骤。结果是，即使在原始语言中并非同形异义词的词语，在翻译成英语后也可能变成同形异义词并失去其原义。在本文中，我们介绍了一种衡量重复率的方法，并使用基于视觉-语言模型（VLM）的自动评估和人工评估两种方式，对不同的扩散模型进行了评估。此外，我们研究了通过提示扩展来缓解同形异义词重复问题的方法，证明了这种方法也能有效减少与盎格鲁中心偏见相关的重复。自动评估流程的代码已公开可用。|
|**2025-09-25**|[Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation](http://arxiv.org/abs/2509.21257)|null|在语言模型和视觉-语言模型中，幻觉被广义地理解为模型基于其先验知识或偏见而非给定输入生成的内容。尽管这种现象已在这些领域得到研究，但尚未为文本到图像（T2I）生成模型明确界定。现有评估主要关注对齐性，检查提示中指定的元素是否出现，但忽视了模型在提示之外生成的内容。我们主张将T2I中的幻觉定义为偏见驱动的偏差，并提出了一个包含三类别的分类法：属性幻觉、关系幻觉和对象幻觉。这种界定方式为评估引入了上限并揭示了隐藏的偏见，为T2I模型更丰富的评估提供了基础。|
|**2025-09-25**|[Federated Flow Matching](http://arxiv.org/abs/2509.21250)|**[link](https://github.com/scnu-kevinkong/FedFlow)**|当今数据是去中心化的，在各种设备和机构中生成和存储，而隐私、所有权和法规阻碍了数据的集中化。这促使了对无需中央聚合，直接从本地分布式数据中训练生成模型的需求。在本文中，我们介绍了联邦流匹配 (FFM)，一个在隐私约束下训练流匹配模型的框架。具体来说，我们首先研究了FFM-vanilla，其中每个客户端使用独立的源和目标耦合在本地训练，保持了隐私但产生了弯曲的流，这减慢了推理速度。接着我们开发了FFM-LOT，它采用局部最优传输耦合以改善每个客户端内的流的直度，但在异构数据下缺乏全局一致性。最后，我们提出了FFM-GOT，一种基于最优传输半对偶公式的联邦策略，其中一个共享的全局势函数协调了跨客户端的耦合。在合成数据集和图像数据集上的实验表明，FFM 实现了隐私保护的训练，同时在联邦设置中提高了流的直度和样本质量，性能可与集中式基线相媲美。|
|**2025-09-25**|[Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets](http://arxiv.org/abs/2509.21245)|**[link](https://github.com/Tencent-Hunyuan/Hunyuan3D-Omni)**|原生3D生成模型的最新进展加速了游戏、电影和设计领域的资产创建。然而，大多数方法仍然主要依赖于图像或文本条件，并且缺乏细粒度的跨模态控制，这限制了其可控性和实际应用。为了弥补这一空白，我们提出了Hunyuan3D-Omni，一个基于Hunyuan3D 2.1构建的、用于细粒度可控3D资产生成的统一框架。除了图像，Hunyuan3D-Omni还接受点云、体素、边界框和骨骼姿态先验作为条件信号，从而实现了对几何、拓扑和姿态的精确控制。与为每个模态设置独立头部不同，我们的模型在一个单一的跨模态架构中统一了所有信号。我们采用一种渐进式、难度感知采样策略进行训练，该策略在每个样本中选择一种控制模态，并偏向于更难的信号（例如骨骼姿态）采样，同时降低较容易信号（例如点云）的权重，这促进了鲁棒的多模态融合以及对缺失输入的优雅处理。实验表明，这些额外的控制提高了生成精度，实现了几何感知变换，并增强了生产工作流程的鲁棒性。|
|**2025-09-25**|[Evaluating the Evaluators: Metrics for Compositional Text-to-Image Generation](http://arxiv.org/abs/2509.21227)|null|文本到图像生成已取得快速进展，但评估输出是否真正捕捉到提示中描述的对象、属性和关系仍然是一个核心挑战。这一领域的评估严重依赖自动化指标，然而这些指标通常是出于惯例或流行度而被采用，而非经过人类判断的验证。由于该领域的评估和报告的进展直接依赖于这些指标，了解它们在多大程度上反映了人类偏好至关重要。为了解决这个问题，我们对广泛用于组合式文本-图像评估的指标进行了一项广泛研究。我们的分析超越了简单的相关性，考察了它们在各种组合挑战中的表现，并比较了不同指标家族与人类判断的一致性。结果表明，没有单一指标在所有任务中表现一致：性能随组合问题的类型而变化。值得注意的是，基于VQA的指标尽管流行，但并非普遍优越，而某些基于嵌入的指标在特定情况下表现更强。正如预期，仅基于图像的指标对组合式评估贡献甚微，因为它们是为感知质量而非对齐而设计的。这些发现强调了仔细和透明地选择指标的重要性，既为了可信赖的评估，也为了将它们用作生成中的奖励模型。项目页面可在该网址获取：\href{https://amirkasaei.com/eval-the-evals/}{this URL}。|
|**2025-09-25**|[MeanSE: Efficient Generative Speech Enhancement with Mean Flows](http://arxiv.org/abs/2509.21214)|null|语音增强（SE）改善了降质语音的质量，其中流匹配等生成模型因其卓越的感知质量而受到关注。然而，基于流的模型需要多次函数评估（NFEs）才能实现稳定和令人满意的性能，导致计算负载高且单次函数评估（1-NFE）性能较差。在本文中，我们提出了 MeanSE，一种使用均值流的高效生成式语音增强模型，它对平均速度场进行建模，以实现高质量的单次函数评估（1-NFE）增强。实验结果表明，我们提出的 MeanSE 在单次函数评估（NFE）下显著优于流匹配基线，展现出极佳的域外泛化能力。|
|**2025-09-23**|[CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching](http://arxiv.org/abs/2509.19300)|null|条件生成建模旨在从包含数据-条件对的样本中学习条件数据分布。为此，扩散和基于流的方法已取得引人注目的结果。这些方法使用学习到的（流）模型将忽略条件的初始标准高斯噪声传输到条件数据分布。因此，模型需要学习质量传输和条件注入。为了减轻模型的需求，我们提出了流匹配的条件感知重参数化（CAR-Flow）——一种轻量级的、学习到的偏移，其对源分布、目标分布或两者进行条件化。通过重新定位这些分布，CAR-Flow缩短了模型必须学习的概率路径，从而在实践中实现更快的训练。在低维合成数据上，我们可视化并量化了CAR的效果。在更高维度的自然图像数据（ImageNet-256）上，为SiT-XL/2配备CAR-Flow将FID从2.07降低到1.68，同时引入不到0.6%的额外参数。|
|**2025-09-23**|[Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation](http://arxiv.org/abs/2509.19296)|**[link](https://github.com/nv-tlabs/lyra)**|生成虚拟环境的能力对于从游戏到机器人学、自动驾驶和工业AI等物理AI领域的应用至关重要。当前基于学习的3D重建方法依赖于捕获的真实世界多视角数据，而这些数据并非总是容易获得。视频扩散模型在最近的进展展示了卓越的想象能力，然而它们的2D本质限制了应用，仅限于机器人需要在环境中导航和交互的仿真场景。在本文中，我们提出了一种自蒸馏框架，旨在将视频扩散模型中的隐式3D知识蒸馏到显式3D高斯溅射（3DGS）表示中，从而消除了对多视角训练数据的需求。具体来说，我们用一个3DGS解码器增强了典型的RGB解码器，该解码器由RGB解码器的输出进行监督。在这种方法中，3DGS解码器可以纯粹地用视频扩散模型生成的合成数据进行训练。在推理时，我们的模型可以从文本提示或单张图像合成3D场景，用于实时渲染。我们的框架进一步扩展到从单目输入视频生成动态3D场景。实验结果表明，我们的框架在静态和动态3D场景生成中取得了最先进的性能。|
|**2025-09-23**|[OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps](http://arxiv.org/abs/2509.19282)|null|尽管布局到图像生成取得了稳步进展，但当前方法在处理包含显著边界框重叠的布局时仍然面临挑战。我们确定了两个主要挑战：(1) 大面积重叠区域和 (2) 语义区分度极小的重叠实例。通过定性示例和定量分析，我们证明了这些因素如何降低生成质量。为了系统地评估这个问题，我们引入了 OverLayScore，一个量化重叠边界框复杂性的新颖度量指标。我们的分析表明，现有基准偏向于 OverLayScore 值较低的简单案例，从而限制了它们在更具挑战性条件下评估模型性能的有效性。为了弥补这一差距，我们提出了 OverLayBench，一个具有高质量标注并在不同 OverLayScore 水平上呈现平衡分布的新基准。作为改进复杂重叠性能的初步步骤，我们还提出了 CreatiLayout-AM，一个在精选的非模态掩码数据集上微调的模型。综合来看，我们的贡献为在真实和具有挑战性的场景下实现更鲁棒的布局到图像生成奠定了基础。项目链接：https://mlpc-ucsd.github.io/OverLayBench。|
|**2025-09-23**|[A Gradient Flow Approach to Solving Inverse Problems with Latent Diffusion Models](http://arxiv.org/abs/2509.19276)|null|求解病态逆问题需要强大而灵活的先验。我们提出通过一种名为扩散正则化 Wasserstein 梯度流 (DWGF) 的新型免训练方法，利用预训练的潜在扩散模型来完成此任务。具体而言，我们将后验采样问题表述为潜在空间中 Kullback-Leibler 散度的正则化 Wasserstein 梯度流。我们使用 StableDiffusion (Rombach et al., 2022) 作为先验，在标准基准测试上展示了我们方法的性能。|
|**2025-09-23**|[Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps](http://arxiv.org/abs/2509.19252)|null|连续人体运动理解因其高维度和固有的冗余性，在计算机视觉领域仍然是一个核心挑战。高效的压缩和表示对于分析复杂运动动态至关重要。在这项工作中，我们引入了一个对抗性精炼的VQ-GAN框架，该框架采用密集运动标记化技术来压缩时空热图，同时保留人体运动的细粒度轨迹。我们的方法结合了密集运动标记化与对抗性精炼，消除了非对抗性基线中观察到的重建伪影，例如运动拖影和时间错位。我们在CMU Panoptic数据集上的实验提供了我们方法优越性的确凿证据，其SSIM指标优于dVAE基线9.31%，并降低了37.1%的时间不稳定性。此外，我们的密集标记化策略实现了一种新颖的运动复杂性分析，揭示了2D运动可以用紧凑的128个标记词汇表进行最佳表示，而3D运动的复杂性则需要一个大得多的1024个标记码本才能实现忠实重建。这些结果确立了该方法在各种运动分析应用中的实际部署可行性。本工作的代码库可在https://github.com/TeCSAR-UNCC/Pose-Quantization获取。|
|**2025-09-23**|[Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation](http://arxiv.org/abs/2509.19244)|null|我们提出了Lavida-O，一个统一的多模态掩码扩散模型（MDM），能够执行图像理解和生成任务。与现有仅支持简单图像级理解任务和低分辨率图像生成的多模态扩散语言模型（如MMaDa和Muddit）不同，Lavida-O展现了许多新能力，例如目标定位、图像编辑和高分辨率（1024像素）图像合成。它也是第一个利用其理解能力，通过规划和迭代自反思来改进图像生成和编辑结果的统一MDM。为了实现有效和高效的训练和采样，Lavida-O引入了许多新颖技术，例如弹性混合Transformer架构、通用文本条件化和分层采样。我们在RefCOCO目标定位、GenEval文本到图像生成和ImgEdit图像编辑等广泛基准测试中取得了最先进的性能，优于现有的自回归和连续扩散模型（如Qwen2.5-VL和FluxKontext-dev），同时在推理时提供了显著的加速。|
|**2025-09-23**|[Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data](http://arxiv.org/abs/2509.19208)|null|在热成像中进行精确的植物分割仍然是高通量田间表型分析面临的重大挑战，尤其是在室外环境中，植物与杂草之间对比度低以及频繁的遮挡阻碍了性能。为此，我们提出了一个框架，该框架利用合成RGB图像、有限的真实标注集以及基于GAN的跨模态对齐来增强热图像中的语义分割。我们使用1,128张包含作物和杂草植物复杂混合的合成图像训练了模型，以生成作物和杂草植物的图像分割掩膜。我们还评估了在训练过程中使用不同采样策略整合少至五张真实、手动分割的田间图像所带来的益处。当将所有合成图像与少量标注的真实图像结合时，与完整的真实数据基线相比，我们观察到杂草类别最大相对改进为22%，植物类别为17%。通过使用CycleGAN-turbo将RGB图像转换为热图像实现了跨模态对齐，从而实现了无需校准的鲁棒模板匹配。结果表明，将合成数据与有限的手动标注以及通过生成模型进行的跨域转换相结合，可以显著提升复杂田间环境中多模态图像的分割性能。|
|**2025-09-23**|[GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding](http://arxiv.org/abs/2509.19135)|null|人类出行轨迹，通常记录为签到序列，为短期访问模式和持久生活规律提供了独特的视角。在这项工作中，我们引入了GSTM-HMU，一个生成式时空框架，旨在通过明确建模人类运动的语义和时间复杂性来推进出行分析。该框架包含四项关键创新。首先，时空概念编码器（STCE）将地理位置、POI类别语义和周期性时间节奏整合到统一的向量表示中。其次，认知轨迹记忆（CTM）自适应地过滤历史访问，强调近期和行为显著的事件，以更有效地捕捉用户意图。第三，生活方式概念库（LCB）贡献了结构化的人类偏好线索，例如活动类型和生活模式，以增强可解释性和个性化。最后，面向任务的生成头将学习到的表示转化为多个下游任务的预测。我们在Gowalla、WeePlace、Brightkite和FourSquare等四个广泛使用的真实世界数据集上进行了广泛实验，并在三个基准任务上评估了性能：下一位置预测、轨迹-用户识别和时间估计。结果表明，与强大的基线相比，性能有持续且显著的提升，证实了GSTM-HMU在从复杂出行数据中提取语义规律的有效性。除了原始性能提升外，我们的发现还表明生成式建模为构建更鲁棒、可解释和可推广的人类出行智能系统提供了有前景的基础。|
|**2025-09-23**|[World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation](http://arxiv.org/abs/2509.19080)|null|机器人操作策略通常通过模仿学习进行初始化，但其性能受限于专家数据的稀缺性和覆盖范围狭窄。强化学习能够改进策略以缓解这一局限，然而真实机器人训练成本高昂且不安全，而在模拟器中训练则存在从模拟到真实世界的鸿沟。生成模型在近期取得的进展在真实世界模拟中展现出卓越的能力，扩散模型尤其擅长生成。这引出了一个问题：如何结合基于扩散模型的世界模型来增强机器人操作中的预训练策略。在这项工作中，我们提出了World4RL，一个利用基于扩散的世界模型作为高保真模拟器，完全在想象环境中改进机器人操作预训练策略的框架。与以往主要利用世界模型进行规划的工作不同，我们的框架实现了直接的端到端策略优化。World4RL围绕两个原则设计：预训练一个能够在多任务数据集中捕获多样化动力学的扩散世界模型，以及完全在一个冻结的世界模型中改进策略以避免在线的真实世界交互。我们进一步设计了一种针对机器人操作的two-hot动作编码方案，并采用扩散骨干网络以提高建模保真度。大量的模拟和真实世界实验表明，World4RL提供了高保真环境建模并实现了持续的策略改进，取得了比模仿学习和其他基线方法显著更高的成功率。更多可视化结果可在https://world4rl.github.io/获取。|
|**2025-09-23**|[WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction](http://arxiv.org/abs/2509.19073)|null|3D高斯泼溅 (3DGS) 已成为一种强大的基于图像的对象重建表示方法，但在稀疏视角设置下其性能急剧下降。先前工作通过采用扩散模型修复受损渲染来解决这一局限性，随后将其用作后续优化的伪真值。尽管有效，此类方法在扩散模型微调和修复步骤中带来了巨大的计算开销。我们提出了WaveletGaussian，一个用于更高效稀疏视角3D高斯对象重建的框架。我们的核心思想是将扩散转移到小波域：扩散仅应用于低分辨率LL子带，而高频子带通过轻量级网络进行精炼。我们进一步提出了一种高效的在线随机掩码策略来构建扩散模型微调的训练对，取代了常用的但效率低下的留一法策略。在Mip-NeRF 360和OmniObject3D这两个基准数据集上的实验表明，WaveletGaussian在实现具有竞争力的渲染质量的同时，大幅缩短了训练时间。|
|**2025-09-19**|[MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](http://arxiv.org/abs/2509.16197)|null|能够理解和生成视觉内容的统一多模态大语言模型（LLM）具有巨大的潜力。然而，现有的开源模型往往在这些能力之间面临性能权衡。我们提出了Manzano，一个简单且可扩展的统一框架，通过结合混合图像分词器和精心设计的训练方案，显著缓解了这种矛盾。一个单一的共享视觉编码器驱动两个轻量级适配器，在共同的语义空间内生成用于图像到文本理解的连续嵌入和用于文本到图像生成的离散token。一个统一的自回归LLM以文本和图像token的形式预测高层次语义，随后一个辅助扩散解码器将图像token转换为像素。该架构，结合涵盖理解和生成数据的统一训练方案，实现了这两种能力的可扩展联合学习。Manzano在统一模型中取得了最先进的结果，并与专业模型具有竞争力，尤其是在富文本评估方面。我们的研究表明，任务冲突极小，并且随着模型规模的扩大能持续获得性能提升，从而验证了我们选择混合分词器的设计决策。|
|**2025-09-19**|[Quantum Generative Adversarial Autoencoders: Learning latent representations for quantum data generation](http://arxiv.org/abs/2509.16186)|null|本工作中，我们引入了量子生成对抗自编码器 (QGAA)，这是一种用于生成量子数据的量子模型。QGAA 由两个组成部分构成：(a) 用于压缩量子态的量子自编码器 (QAE)，以及 (b) 用于学习已训练 QAE 潜在空间的量子生成对抗网络 (QGAN)。这种方法赋予 QAE 生成能力。QGAA 的效用在两个代表性场景中得到证明：(a) 纯纠缠态的生成，以及 (b) H $_2$ 和 LiH 的参数化分子基态的生成。在多达 6 量子比特的模拟中，经训练的 QGAA 估计的能量平均误差对于 H$_2$ 为 0.02 Ha，对于 LiH 为 0.06 Ha。这些结果表明了 QGAA 在量子态生成、量子化学和近期量子机器学习应用方面的潜力。|
|**2025-09-19**|[AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models](http://arxiv.org/abs/2509.16141)|null|文生图（T2I）模型近期在根据文本描述生成图像方面取得了显著成功。然而，在准确渲染以动作和交互为主要语义焦点的复杂场景时，挑战依然存在。本文的关键观察是，T2I模型经常难以捕捉动作描绘中固有的微妙且通常隐含的属性，导致生成的图像缺乏关键的上下文细节。为了实现系统性评估，我们引入了AcT2I，这是一个旨在评估T2I模型在根据以动作为中心的提示生成图像方面的性能的基准。我们通过实验验证，主流T2I模型在AcT2I上表现不佳。我们进一步假设这一缺点源于现有T2I模型训练语料库中固有属性和上下文依赖的表示不完整。我们在此基础上开发了一种无需训练的知识蒸馏技术，利用大型语言模型来解决这一局限性。具体而言，我们通过整合三个维度上的密集信息来增强提示，观察到向提示注入时间细节显著提高了图像生成准确性，我们的最佳模型实现了72%的增长。我们的发现突出了当前T2I方法在生成需要复杂推理的图像方面的局限性，并证明以系统方式整合语言知识可以显著促进细致入微且上下文准确的图像生成。|
|**2025-09-19**|[Dynamic Classifier-Free Diffusion Guidance via Online Feedback](http://arxiv.org/abs/2509.16131)|null|无分类器引导 (CFG) 是文生图扩散模型的基石，然而其有效性受限于静态引导尺度的使用。这种“一刀切”的方法未能适应不同提示词的多样化需求；此外，先前诸如基于梯度的校正或固定启发式调度等解决方案引入了额外复杂性且难以泛化。在这项工作中，我们通过引入一个用于动态CFG调度的框架来挑战这种静态范式。我们的方法利用来自一系列通用和专用的小规模潜在空间评估（例如，用于对齐的CLIP、用于保真度的判别器以及人类偏好奖励模型）的在线反馈，以在逆向扩散过程的每一步评估生成质量。基于此反馈，我们执行贪婪搜索以选择每个时间步的最佳CFG尺度，从而为每个提示词和样本创建独特的量身定制的引导调度。我们在小规模模型和最先进的Imagen 3上证明了我们方法的有效性，显示出在文本对齐、视觉质量、文本渲染和数值推理方面取得了显著改进。值得注意的是，与默认的Imagen 3基线相比，我们的方法在整体偏好方面实现了高达53.8%的人类偏好胜率，在针对文本渲染等特定能力的提示词上，这一数字增加到55.5%。我们的工作确立了最佳引导调度本质上是动态且依赖于提示词的，并提供了一个高效且可泛化的框架来实现它。|
|**2025-09-19**|[DiffusionNFT: Online Diffusion Reinforcement with Forward Process](http://arxiv.org/abs/2509.16117)|null|在线强化学习 (RL) 对语言模型的后训练至关重要，但由于难以处理的似然，其在扩散模型上的扩展仍然充满挑战。最近的工作离散化了逆向采样过程以实现GRPO风格的训练，然而它们却继承了根本性的缺点，包括求解器限制、前向-逆向不一致性以及与无分类器指导 (CFG) 的复杂集成。我们引入了扩散负样本感知微调 (DiffusionNFT)，这是一种新的在线强化学习范式，它通过流匹配直接在前向过程中优化扩散模型。DiffusionNFT对比正负生成来定义一个隐式的策略改进方向，自然地将强化信号融入监督学习目标中。这种公式化方法使得能够使用任意黑盒求解器进行训练，消除了似然估计的需要，并且只需要干净图像而非采样轨迹来进行策略优化。在直接对比中，DiffusionNFT比FlowGRPO效率提升高达25倍，同时无需CFG。例如，DiffusionNFT在1k步内将GenEval分数从0.24提高到0.98，而FlowGRPO在超过5k步和额外CFG使用下达到0.95。通过利用多个奖励模型，DiffusionNFT显著提升了SD3.5-Medium在所有测试的基准中的性能。|
|**2025-09-19**|[PRISM: Probabilistic and Robust Inverse Solver with Measurement-Conditioned Diffusion Prior for Blind Inverse Problems](http://arxiv.org/abs/2509.16106)|null|扩散模型现已普遍用于解决计算成像中的逆问题。然而，大多数基于扩散的逆求解器需要完全了解前向算子才能使用。在这项工作中，我们引入了一种新颖的、带有测量条件扩散先验（PRISM）的概率且鲁棒的逆求解器，以有效解决盲逆问题。相较于现有方法，PRISM通过将强大的测量条件扩散模型整合到理论上严谨的后验采样方案中，提供了一项技术进步。在盲图像去模糊上的实验验证了所提出方法的有效性，证明了PRISM在图像和模糊核恢复方面均优于最先进的基线方法。|
|**2025-09-19**|[Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising](http://arxiv.org/abs/2509.16091)|null|本文提出盲点引导扩散（Blind-Spot Guided Diffusion），一种用于真实世界图像去噪的新颖自监督框架。我们的方法解决了两个主要挑战：一是盲点网络（BSN）的局限性，这类网络由于空间独立性假设，常牺牲局部细节并引入像素不连续性；二是将扩散模型应用于自监督去噪的困难。我们提出了一种双分支扩散框架，它结合了一个基于BSN的扩散分支（用于生成半干净图像）和一个捕获底层噪声分布的传统扩散分支。为了在没有配对数据的情况下实现有效训练，我们利用基于BSN的分支来引导采样过程，在捕获噪声结构的同时保留局部细节。在SIDD和DND数据集上进行的广泛实验证明了最先进的性能，确立了我们的方法作为一种高效的真实世界去噪自监督解决方案。代码和预训练模型已发布于：https://github.com/Sumching/BSGD。|
|**2025-09-19**|[Randomized Smoothing Meets Vision-Language Models](http://arxiv.org/abs/2509.16088)|null|随机平滑（RS）是确保机器学习模型正确性的突出技术之一，通过它可以解析推导出逐点鲁棒性认证。尽管RS在分类领域已得到充分理解，但其在生成模型中的应用尚不明确，因为生成模型的输出是序列而非标签。我们通过将生成输出与一个预言机分类任务联系起来解决了这个问题，并表明RS仍然可以启用：最终响应可以被分类为离散动作（例如，视觉语言行动模型VLAs中的服务机器人指令），或分类为有害与无害（视觉语言模型VLMs中的内容审核或有害信息检测），甚至可以应用预言机将答案聚类为语义等价的类别。假设预言机分类器比较的错误率有界，我们发展了将样本数量与相应鲁棒性半径关联起来的理论。我们进一步解析推导了改进的缩放定律，将认证半径和准确性与样本数量关联起来，表明早期结果，即减少2到3个数量级的样本量即可满足要求且损失最小，在更弱的假设下仍然有效。总之，这些进展使鲁棒性认证对于最先进的视觉语言模型VLMs既有明确定义又在计算上可行，这一点已通过针对最近的越狱式对抗性攻击的验证得到证实。|
|**2025-09-19**|[Rethinking Molecule Synthesizability with Chain-of-Reaction](http://arxiv.org/abs/2509.16084)|null|分子生成模型的一个众所周知的缺陷是它们不能保证生成可合成的分子。为解决此问题已进行了大量尝试，但考虑到可合成分子指数级大的组合空间，现有方法在空间覆盖方面表现出局限性，并且分子优化性能不佳。为解决这些问题，我们引入了ReaSyn，这是一个用于可合成投影的生成框架，模型通过生成合成路径来探索给定分子在可合成空间中的邻域，从而得到可合成类似物。为了充分利用合成路径中包含的化学知识，我们提出了一种新颖的视角，将合成路径视为大型语言模型 (LLM) 中的推理路径。具体而言，受LLM中思维链 (CoT) 推理的启发，我们引入了反应链 (CoR) 表示法，该表示法明确说明了路径中每一步的反应物、反应类型和中间产物。借助CoR表示法，ReaSyn可以在每个反应步骤中获得密集监督，从而在监督训练期间明确学习化学反应规则并执行逐步推理。此外，为了进一步增强ReaSyn的推理能力，我们提出了基于强化学习 (RL) 的微调以及专为可合成投影定制的目标导向的测试时计算扩展。ReaSyn在可合成分子重建中实现了最高的重建率和路径多样性，在可合成目标导向分子优化中实现了最高的优化性能，并在可合成命中扩展方面显著优于先前的可合成投影方法。这些结果突显了ReaSyn在组合规模庞大的可合成化学空间中导航的卓越能力。|
|**2025-09-19**|[Generating Detailed Character Motion from Blocking Poses](http://arxiv.org/abs/2509.16064)|null|我们专注于使用生成扩散模型解决运动细节化任务：将以稀疏的、姿态粗糙且时间不精确的阻挡姿态表示的角色动画粗略版本，转换为细节丰富、自然逼真的角色动画。当前的扩散模型可以解决校正时间不精确姿态的时间问题，但我们发现，目前尚无好的解决方案可以利用扩散先验来为稀疏的阻挡姿态集增加额外的姿态细节。我们通过一个简单的推理时技巧克服了这一挑战。在特定的扩散步骤中，我们使用每个阻挡姿态的容差权重，将无条件扩散模型的输出与输入的阻挡姿态约束进行融合，并将此结果作为输入条件传递给一个预先存在的运动重定时模型。我们发现，这种方法显著优于现有尝试通过融合模型输出或将阻挡姿态约束表示为引导来添加细节的方法。结果是首个能够鲁棒地将阻挡级别姿态转换为合理细节化角色动画的扩散模型。|
|**2025-09-18**|[Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model](http://arxiv.org/abs/2509.15220)|null|为了从标定图像重建三维几何，基于学习的多视图立体（MVS）方法通常执行多视图深度估计，然后将深度图融合为网格或点云。为了提高计算效率，许多方法会初始化一个粗糙深度图，然后逐步以更高分辨率对其进行细化。最近，扩散模型在生成任务中取得了巨大成功。扩散模型从随机噪声开始，通过迭代去噪过程逐步恢复样本。在本文中，我们提出了一种新颖的MVS框架，将扩散模型引入MVS。具体来说，我们将深度细化公式化为一个条件扩散过程。考虑到深度估计的判别性特征，我们设计了一个条件编码器来指导扩散过程。为了提高效率，我们提出了一种结合轻量级2D U-Net和卷积GRU的新颖扩散网络。此外，我们提出了一种新颖的基于置信度的采样策略，以根据扩散模型估计的置信度自适应地采样深度假设。基于我们新颖的MVS框架，我们提出了两种新颖的MVS方法：DiffMVS和CasDiffMVS。DiffMVS在运行时间和GPU内存方面达到了最先进的效率，并取得了有竞争力的性能。CasDiffMVS在DTU、Tanks & Temples和ETH3D数据集上实现了最先进的性能。代码可在以下网址获取：https://github.com/cvg/diffmvs。|
|**2025-09-18**|[RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|本文提出了RynnVLA-001，一个基于人类演示的大规模视频生成式预训练构建的视觉-语言-动作（VLA）模型。我们提出了一种新颖的两阶段预训练方法。第一阶段，即以自我为中心的视频生成式预训练，利用1200万个以自我为中心的操作视频训练一个图像到视频模型，以初始帧和语言指令为条件预测未来帧。第二阶段，即以人为中心的轨迹感知建模，通过联合预测未来的关键点轨迹来扩展此方法，从而有效地弥合了视觉帧预测与动作预测之间的鸿沟。此外，为了增强动作表示，我们提出了ActionVAE，这是一个变分自编码器，它将动作序列压缩成紧凑的潜在嵌入，从而降低了VLA输出空间的复杂性。在相同的下游机器人数据集上进行微调时，RynnVLA-001取得了优于最先进基线方法的卓越性能，证明了所提出的预训练策略为VLA模型提供了更有效的初始化。|
|**2025-09-18**|[Fair-GPTQ: Bias-Aware Quantization for Large Language Models](http://arxiv.org/abs/2509.15206)|null|大型生成语言模型的高内存需求使得量化技术备受关注，该技术通过将模型权重映射到低精度整数来降低计算成本、内存使用和延迟。GPTQ等方法能有效最小化量化过程中的输入-权重乘积误差；然而，最近的实证研究表明，它们可能增加有偏输出并降低公平性基准测试上的性能，目前尚不清楚是哪些特定权重导致了这个问题。在这项工作中，我们通过在量化目标中添加明确的群体公平性约束，在量化与模型公平性之间建立了新的联系，并引入了Fair-GPTQ，这是第一个明确设计用于减少大型语言模型中不公平性的量化方法。所添加的约束指导舍入操作的学习，以实现对受保护群体偏见更少的文本生成。具体来说，我们关注涉及职业偏见的刻板印象生成以及跨越性别、种族和宗教的歧视性语言。Fair-GPTQ对性能影响极小，在零样本基准测试上至少能保持90%的基线准确率，相对于半精度模型减少了不公平性，并保留了4比特量化的内存和速度优势。我们还将Fair-GPTQ的性能与现有去偏方法进行了比较，发现在种族刻板印象基准测试上，其性能与迭代零空间投影去偏方法相当。总的来说，这些结果验证了我们针对带有群体偏置项的量化问题的理论解决方案，突出了其在生成模型量化时减少群体偏置的适用性，并表明我们的方法还可以进一步用于分析量化过程中通道和权重层面对公平性的贡献。|
|**2025-09-18**|[Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning](http://arxiv.org/abs/2509.15188)|null|自回归（AR）语言模型逐个token生成文本，这限制了它们的推理速度。基于扩散的语言模型提供了一种有前景的替代方案，因为它们可以并行解码多个token。然而，我们发现了当前扩散语言模型中的一个关键瓶颈：长解码窗口问题，即远离输入上下文生成的token经常变得不相关或重复。像半自回归这样的先前解决方案通过将窗口分成块来解决这个问题，但这牺牲了速度和双向性，从而消除了扩散模型的主要优势。为了克服这个问题，我们提出了卷积解码（Conv），这是一种基于归一化的方法，它在不进行硬性分段的情况下缩小了解码窗口，从而带来了更好的流畅性和灵活性。此外，我们引入了基于拒绝规则的微调（R2FT），这是一种事后训练方案，可以更好地对齐远离上下文位置的token。我们的方法在开放式生成基准测试（例如，AlpacaEval）中，在扩散语言模型基线中取得了最先进的结果，且步长显著低于先前工作，证明了速度和质量的双重提升。|
|**2025-09-18**|[Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation](http://arxiv.org/abs/2509.15185)|null|近期研究证明了高质量视觉表征在图像生成中的重要性，并突出了生成模型在图像理解方面的局限性。作为一种最初为自然语言设计的生成范式，自回归模型也面临着类似的挑战。在这项工作中，我们首次系统地研究了将下一个token预测范式应用于视觉领域的机制。我们确定了三个阻碍高层视觉语义学习的关键特性：局部和条件依赖性、步间语义不一致性以及空间不变性不足。我们表明，通过在训练过程中引入自监督目标，这些问题可以得到有效解决，从而形成了一种新颖的训练框架：自回归模型自引导训练（ST-AR）。ST-AR无需依赖预训练表征模型，显著增强了自回归模型的图像理解能力，并提升了生成质量。具体而言，ST-AR在LlamaGen-L上实现了约42%的FID提升，在LlamaGen-XL上实现了49%的FID提升，同时保持了相同的采样策略。|
|**2025-09-18**|[A Race Bias Free Face Aging Model for Reliable Kinship Verification](http://arxiv.org/abs/2509.15177)|**[link](https://github.com/bardiya2254kariminia/Age-Transformation-Without-Racial-Bias-Kinship-Verification)**|亲属关系验证中的年龄差距问题是指父母和子女照片之间的时间差。此外，他们的同龄照片通常难以获得，且人脸老化模型存在种族偏见，这会影响照片的逼真度。因此，我们提出了一种人脸老化GAN模型RA-GAN，它由两个新模块RACEpSp和特征混合器组成，旨在生成无种族偏见的图像。这些无偏见的合成照片被用于亲属关系验证，以研究验证同龄父母-子女图像的效果。实验表明，在种族准确性方面，我们的RA-GAN在所有年龄组中平均优于SAM-GAN 13.14%，并在60岁以上年龄组中优于CUSP-GAN 9.1%。此外，RA-GAN在所有年龄组中保留主体身份的能力优于SAM-GAN和CUSP-GAN。此外，我们证明将KinFaceW-I和KinFaceW-II数据集中的父母和子女图像转换为同龄可以提高所有年龄组的验证准确性。在KinFaceW-I数据集上，使用我们的RA-GAN，父子、父女、母子和母女等亲属关系的准确性分别提高了5.22%、5.12%、1.63%和0.41%。此外，在KinFaceW-II数据集上，父女、父子和母子关系的准确性分别提高了2.9%、0.39%和1.6%。代码可在Github上获取。|
|**2025-09-18**|[Watermarking and Anomaly Detection in Machine Learning Models for LORA RF Fingerprinting](http://arxiv.org/abs/2509.15170)|null|射频指纹识别（RFFI）通过无线设备模拟电路的微小差异来区分它们，从而避免繁重的密码认证。尽管基于频谱图的深度学习提高了准确性，但模型仍然容易受到复制、篡改和规避的攻击。我们提出了一个更强大的RFFI系统，它结合了用于所有权证明的水印技术和用于发现可疑输入的异常检测。使用基于对数梅尔频谱图的ResNet-34，我们嵌入了三种水印：一个简单触发器、一个对噪声和滤波具有鲁棒性的对抗性训练触发器，以及一个隐藏的梯度/权重签名。一个带有Kullback-Leibler（KL）热启动和free-bits的卷积变分自编码器（VAE）用于标记离分布查询。在LoRa数据集上，我们的系统实现了94.6%的准确率、98%的水印成功率和0.94的AUROC，提供了可验证、防篡改的认证。|
|**2025-09-18**|[AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use](http://arxiv.org/abs/2509.15153)|null|多元时间序列异常检测对于识别意外事件至关重要，在机器学习领域已被探索了几十年。然而，将这些方法直接应用于强力工具使用任务的数据具有挑战性，因为现实世界中的流式传感器数据本质上是嘈杂的，表现出非平稳行为，并且在不同任务和工具之间存在差异。为了解决这些挑战，我们提出了一种名为AnoF-Diff的方法，该方法基于扩散模型从时间序列数据中提取力矩特征，并利用力矩特征来检测异常。我们将我们的方法与四项强力工具使用任务上的其他最先进方法在F1分数和受试者工作特征曲线下面积（AUROC）方面进行了比较，结果表明我们的方法具有更好的性能，并且对噪声数据集更鲁棒。我们还提出了一种基于一步扩散的并行异常分数评估方法，并展示了我们的方法如何在多项强力工具使用实验中用于在线异常检测。|
|**2025-09-18**|[WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance](http://arxiv.org/abs/2509.15130)|null|近期视频扩散模型因其丰富的潜在世界先验知识，在空间智能任务中展现出强大潜力。然而，这种潜力受到其有限的可控性和几何不一致性的阻碍，在它们的强大先验知识与3D/4D任务中的实际应用之间造成了差距。因此，现有方法通常依赖于重新训练或微调，这可能导致预训练知识退化并产生高昂的计算成本。为此，我们提出了WorldForge，一个免训练、推理时框架，由三个紧密耦合的模块组成。步内递归细化在推理过程中引入了一种递归细化机制，该机制在每个去噪步骤中反复优化网络预测，以实现精确的轨迹注入。流门控潜在融合利用光流相似性，在潜在空间中将运动与外观解耦，并选择性地将轨迹引导注入到运动相关通道中。双路径自校正引导比较有引导和无引导的去噪路径，以自适应地纠正由噪声或未对齐的结构信号引起的轨迹漂移。这些组件共同作用，在无需训练的情况下注入细粒度、轨迹对齐的引导，实现了精确的运动控制和逼真的内容生成。在各种基准上进行的大量实验验证了我们方法在真实感、轨迹一致性和视觉保真度方面的优越性。这项工作引入了一种新颖的即插即用范式用于可控视频合成，为利用生成先验知识进行空间智能提供了一个新视角。|
|**2025-09-18**|[Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model](http://arxiv.org/abs/2509.15124)|**[link](https://github.com/sanpinnawala/BrainPhys)**|建模神经退行性疾病的潜在机制需要能够从稀疏、高维神经影像数据中捕捉异质且空间变化的动态的方法。将基于偏微分方程（PDE）的物理知识与机器学习相结合，相较于经典数值方法，提供了增强的可解释性和实用性。然而，当前物理集成机器学习方法仅限于考虑单个PDE，这严重限制了它们在多种机制导致不同组（即亚型）疾病中的应用，并加剧了模型误设定和退化的问题。在本文中，我们提出了一种深度生成模型，用于学习由基于物理的PDEs控制的潜在动态模型混合，超越了假设单一PDE结构的传统方法。我们的方法将反应扩散PDEs集成到变分自编码器（VAE）混合模型框架中，支持从神经影像数据中推断可解释潜在变量（例如扩散系数和反应速率）的亚型。我们在合成基准上评估了我们的方法，并展示了其在从正电子发射断层扫描（PET）数据中揭示阿尔茨海默病进展的机制亚型方面的潜力。|
|**2025-09-22**|[Show-o2: Improved Native Unified Multimodal Models](http://arxiv.org/abs/2506.15564)|null|本文提出改进的本地统一多模态模型Show-o2，该模型利用自回归建模和流匹配技术。该模型构建于3D因果变分自编码器空间之上，通过空间（-时间）融合的双路径构建统一的视觉表示，实现了在图像和视频模态间的可扩展性，同时确保了有效多模态理解和生成。基于语言模型，自回归建模和流匹配分别本地应用于语言头和流头，以促进文本token预测和图像/视频生成。本文设计了一种两阶段训练方案，以有效学习并扩展到更大模型。所得的Show-o2模型在处理广泛的多模态理解和生成任务方面展现出多功能性，涵盖文本、图像和视频等多种模态。代码和模型已在https://github.com/showlab/Show-o发布。|
|**2025-02-24**|[Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions](http://arxiv.org/abs/2502.17119)|null|近年来，生成模型在图像生成、文本合成、音频创建、视频生成和数据增强等多种应用中取得了卓越的性能。扩散模型通过解决生成对抗网络（GANs）和变分自编码器（VAEs）的局限性，例如训练不稳定、模式崩溃和多模态分布表示不佳等问题，已成为更优越的替代方案。这一成功激发了广泛的研究兴趣。在表格数据领域，扩散模型也开始展现出对GANs和VAEs的类似优势，取得了显著的性能突破，并展示了其在解决表格数据建模中独特挑战方面的潜力。然而，尽管图像和时间序列等领域已有大量综述总结了扩散模型的发展，但在表格数据方面，文献中仍存在显著空白。尽管对表格数据扩散模型的兴趣日益增长，但系统回顾和总结这些进展的工作却很少。这种缺乏专门综述的情况限制了对这一关键领域中挑战、进展和未来方向的清晰理解。本综述通过对表格数据扩散模型进行全面回顾来弥补这一空白。本综述涵盖了从2015年6月扩散模型出现到2024年12月期间的工作，分析了几乎所有相关研究，并在一个GitHub仓库中维护更新。假设读者具备统计学和扩散模型的基础知识，我们采用数学公式进行严谨细致的回顾，旨在推动这一新兴且令人兴奋领域的发展。|
|**2024-12-11**|[Multimodal Latent Language Modeling with Next-Token Diffusion](http://arxiv.org/abs/2412.08635)|null|多模态生成模型需要一种统一的方法来处理离散数据（例如文本和代码）和连续数据（例如图像、音频、视频）。在这项工作中，我们提出了潜在语言建模（LatentLM），它使用因果Transformer无缝整合了连续和离散数据。具体来说，我们采用变分自编码器（VAE）将连续数据表示为潜在向量，并引入下一个token扩散来对这些向量进行自回归生成。此外，我们开发了 $σ$ -VAE来解决方差崩溃的挑战，这对于自回归建模至关重要。大量实验证明了LatentLM在各种模态中的有效性。在图像生成方面，LatentLM在性能和可扩展性上均超越了扩散Transformer。当集成到多模态大型语言模型中时，LatentLM提供了一个通用接口，统一了多模态生成和理解。实验结果表明，在扩大训练token规模的设置下，LatentLM与Transfusion和向量量化模型相比，取得了良好的性能。在文本到语音合成方面，LatentLM在说话人相似度和鲁棒性方面优于最先进的VALL-E 2模型，同时所需的解码步骤减少了10倍。这些结果确立了LatentLM是推进大型多模态模型的一种高效且可扩展的方法。|
|**2024-01-03**|[Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models](http://arxiv.org/abs/2312.13763)|null|文本引导扩散模型彻底改变了图像和视频生成，并已成功用于基于优化的3D对象合成。在本文中，我们转而关注尚未充分探索的文本到4D设置，并使用分数蒸馏方法，额外增加时间维度来合成动态的、可动画的3D对象。与先前工作相比，我们采用了一种新颖的基于组合生成的方法，并结合文本到图像、文本到视频和3D感知多视图扩散模型，在4D对象优化过程中提供反馈，从而同时确保时间一致性、高质量视觉外观和真实几何形状。我们的方法名为Align Your Gaussians (AYG)，利用带有形变场的动态3D高斯泼溅作为4D表示。对AYG至关重要的是一种新颖的方法，用于规范移动3D高斯的分布，从而稳定优化过程并诱导运动。我们还提出了一种运动放大机制以及一种新的自回归合成方案，用于生成和组合多个4D序列以实现更长时间的生成。这些技术使我们能够合成生动的动态场景，在定性和定量方面超越了现有工作，并实现了最先进的文本到4D性能。由于高斯4D表示，不同的4D动画可以无缝组合，正如我们所展示的。AYG为动画、模拟和数字内容创作以及合成数据生成开辟了有前景的途径。|
|**2024-04-09**|[BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models](http://arxiv.org/abs/2312.02813)|null|扩散模型在文本驱动的图像和视频生成方面取得了巨大进展。目前，文本到图像基础模型已广泛应用于各种下游图像合成任务，例如可控图像生成和图像编辑，而下游视频合成任务由于多种原因探索较少。首先，训练一个视频生成基础模型需要巨大的内存和计算开销。即使有了视频基础模型，下游视频合成任务仍然需要额外的昂贵训练。其次，尽管一些工作以免训练的方式将图像扩散模型扩展到视频，但时间一致性无法很好地保持。最后，这些适应方法是专门为一项任务设计的，无法泛化到不同任务。为了缓解这些问题，我们提出了一种免训练的通用视频合成框架，命名为 BIVDiff，通过桥接特定的图像扩散模型和通用的文本到视频基础扩散模型。具体来说，我们首先使用特定的图像扩散模型（例如 ControlNet 和 Instruct Pix2Pix）进行逐帧视频生成，然后对生成的视频执行混合反演，最后将反演得到的潜在变量输入视频扩散模型（例如 VidRD 和 ZeroScope）进行时间平滑。这种解耦框架实现了针对不同目的的灵活图像模型选择，具有强大的任务泛化能力和高效率。为了验证 BIVDiff 的有效性和通用性，我们进行了一系列广泛的视频合成任务，包括可控视频生成、视频编辑、视频修复和视频外绘。|
|**2024-05-26**|[4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling](http://arxiv.org/abs/2311.17984)|null|近期文本到4D生成领域的突破依赖于预训练的文本到图像和文本到视频模型来生成动态3D场景。然而，当前的文本到4D方法在场景外观质量、3D结构和运动之间面临一个三方权衡。例如，文本到图像模型及其3D感知变体在互联网规模的图像数据集上进行训练，可以用于生成具有真实外观和3D结构的场景——但没有运动。文本到视频模型在相对较小的视频数据集上进行训练，可以生成具有运动的场景，但外观和3D结构较差。尽管这些模型具有互补的优势，但它们也存在对立的弱点，使得难以以一种缓解这种三方权衡的方式来结合它们。在此，我们引入了混合分数蒸馏采样（hybrid score distillation sampling），这是一种交替优化过程，它融合了来自多个预训练扩散模型的监督信号，并结合了各自的优点，以实现高保真文本到4D生成。通过使用混合SDS，我们展示了合成具有引人注目的外观、3D结构和运动的4D场景。|
|**2023-09-02**|[RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model](http://arxiv.org/abs/2309.00810)|null|文本到图像生成 (TTI) 指的是使用能够处理文本输入并根据文本描述生成高保真图像的模型。使用神经网络的文本到图像生成可以追溯到生成对抗网络 (GAN) 的出现，随后是自回归Transformer。扩散模型是一种突出的生成模型，通过重复步骤系统性地引入噪声来生成图像。由于扩散模型在图像合成方面取得了令人印象深刻的成果，它已被确立为文本到图像模型使用的主要图像解码器，并将文本到图像生成带到了机器学习 (ML) 研究的最前沿。在大模型时代，模型规模的扩大以及与大语言模型的结合进一步提升了TTI模型的性能，使得生成结果几乎与真实世界图像难以区分，彻底改变了我们检索图像的方式。我们的探索性研究促使我们思考，通过结合创新模型架构和预测增强技术，文本到图像模型还有进一步的扩展方式。我们将本次综述工作分为五个主要部分，详细阐述了主要文献的框架，以便深入探讨不同类型的文本到图像生成方法。在此之后，我们对这些方法进行了详细的比较和批判，并为未来的工作提供了可能的改进途径。在未来的工作中，我们认为TTI的发展可以为创作带来显著的生产力提升，尤其是在AIGC时代背景下，并且可以扩展到更复杂的任务，如视频生成和3D生成。|
|**2023-10-26**|[Control3Diff: Learning Controllable 3D Diffusion Models from Single-view Images](http://arxiv.org/abs/2304.06700)|null|扩散模型最近已成为2D领域生成建模的事实上的方法。然而，将扩散模型扩展到3D领域极具挑战性，因为难以获取用于训练的3D真实数据。另一方面，将隐式3D表示集成到GANs中的3D GANs在仅使用单视角图像数据集进行训练时，展现出卓越的3D感知生成能力。然而，3D GANs未能提供直接的方法来精确控制图像合成。为了解决这些挑战，我们提出了Control3Diff，这是一种结合了扩散模型和3D GANs优势的3D扩散模型，旨在实现针对单视角数据集的多功能、可控的3D感知图像合成。Control3Diff明确地建模了底层的潜在分布（可选择地以外部输入为条件），从而在扩散过程中实现了直接控制。此外，我们的方法是通用的，适用于任何类型的控制输入，这使我们能够使用相同的扩散目标进行训练，而无需任何辅助监督。我们在FFHQ、AFHQ和ShapeNet等标准图像生成基准上验证了Control3Diff的有效性，使用了图像、草图和文本提示等多种条件输入。请查阅项目网站（\url{https://jiataogu.me/control3diff}）以获取视频比较。|
|**2019-10-29**|[A Prior of a Googol Gaussians: a Tensor Ring Induced Prior for Generative Models](http://arxiv.org/abs/1910.13148)|null|生成模型在文本、图像、视频和音频合成等许多领域生成逼真的对象。大多数流行的模型——生成对抗网络 (GANs) 和变分自编码器 (VAEs)——通常采用标准高斯分布作为先验。先前的工作表明，更丰富的先验分布族可能有助于避免GANs中的模式崩溃问题，并改进VAEs中的证据下界。我们提出了一种新的先验分布族——张量环诱导先验 (TRIP)——它将指数级数量的高斯分布打包到一个参数数量相对较少的高维格点中。我们表明这些先验改进了GANs的Fréchet Inception距离和VAEs的证据下界。我们还在存在缺失条件的条件生成设置中研究了带有TRIP的生成模型。总之，我们为生成模型提出了一种新颖的即插即用框架，该框架可用于任何GAN和VAEs类架构。|

